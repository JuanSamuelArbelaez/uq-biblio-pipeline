@article{dup_1,
    author = "Zhao, Haoyu and Han, Zhengbiao and Yin, Shuqi and yang, Nan and Hansen, Preben",
    title = "From interface to inference: mapping the impact of generative artificial intelligence affordances on user risk perception",
    journal = "Telematics and Informatics",
    volume = "101",
    pages = "102299",
    year = "2025",
    issn = "0736-5853",
    doi = "https://doi.org/10.1016/j.tele.2025.102299",
    url = "https://www.sciencedirect.com/science/article/pii/S0736585325000619",
    keywords = "Perceived affordances, User risk perception, Generative artificial intelligence, Human-computer interaction",
    abstract = "A deep understanding of Generative Artificial Intelligence (GAI) is crucial not only for technological development but also for formulating effective risk response strategies. However, previous studies have mainly focused on how individual factors affect GAI risk perception while the technical functions and features that are the root causes of user concerns regarding GAI remain unclear. To address this gap, the current study, grounded in affordance theory, explored how perceived affordances of GAI influenced user risk perceptions across six dimensions: information, security, technical, social, ethical, and legal. A hierarchical regression analysis was conducted on a survey of 1,031 GAI users to examine the impact of interactivity, agency, and security affordances on these risk dimensions. The results indicate that higher perceptions of affordances such as bandwidth, synchrony, and transparency are significantly associated with lower risk perceptions across all dimensions. Notably, women reported higher perceived risks than men in most categories, whereas age and GAI usage experience did not significantly affect these perceptions. These findings highlight the importance of enhancing user control, transparency, and privacy protections in GAI system design to effectively mitigate perceived risks. This study contributes to the literature by providing a multidimensional analysis of risk perception in the context of GAI, offering practical insights for the development of inclusive, transparent, and user-centered artificial intelligence systems."
}

@article{dup_2,
    author = "Liu, Shengyu and Hoekstra, Sipke and Thiede, Sebastian",
    title = "Environmental Assessment and Improvement of Factory Building Designs based on Generative Artificial Intelligence",
    journal = "Procedia CIRP",
    volume = "135",
    pages = "1202-1207",
    year = "2025",
    note = "32nd CIRP Conference on Life Cycle Engineering (LCE2025)",
    issn = "2212-8271",
    doi = "https://doi.org/10.1016/j.procir.2024.12.119",
    url = "https://www.sciencedirect.com/science/article/pii/S2212827125004184",
    keywords = "Generative Artificial Intelligence, Life Cycle Assessment, Factory",
    abstract = "The paper explores an innovative approach to evaluate the environmental impact of factory buildings at early design stages. Generative design, a cutting-edge computational technique, is employed to generate multiple factory building design alternatives based on user and case specific boundary conditions, e.g. related to material flow and space restrictions. This paper aims to integrate generative design principles with environmental assessment metrics to improve factory buildings for minimal environmental footprint, e.g. driven through energy demand. Thus, a framework that combines the generative factory design approach with key environmental assessment parameters is introduced. The effectiveness of generative design in enhancing the environmental performance of factory buildings is demonstrated with a case study. A comparative analysis of different designs highlights main influencing factors, as well as trade-offs and synergies between different manufacturing system performances and environmental oriented objectives. With that, the paper underlines the value of generative design as a transformative tool in sustainable factory design and provides actionable insights for architects, engineers, and policymakers aiming to develop greener industrial facilities."
}

@article{dup_3,
    author = "Ghanbari, Fahime and Schulz, Alexander and Morales, Manuel A. and Rodriguez, Jennifer and Street, Jordan A. and Arcand, Kathryn and Johnson, Scott and Pierce, Patrick and Hoeger, Christopher W. and Tsao, Connie W. and Manning, Warren J. and Nezafat, Reza",
    title = "Free-breathing single-beat exercise cardiovascular magnetic resonance with generative artificial intelligence for evaluation of volumetric and functional cardiac indices: A reproducibility study",
    journal = "Journal of Cardiovascular Magnetic Resonance",
    volume = "27",
    number = "1",
    pages = "101901",
    year = "2025",
    issn = "1097-6647",
    doi = "https://doi.org/10.1016/j.jocmr.2025.101901",
    url = "https://www.sciencedirect.com/science/article/pii/S1097664725000638",
    keywords = "Exercise-CMR, Free-breathing single-beat cine, Biventricular volumetric and functional indices",
    abstract = "Background Exercise cardiovascular magnetic resonance (Ex-CMR) can reveal pathophysiologies not evident at rest by quantifying biventricular volume and function during or immediately after exercise. However, achieving reproducible Ex-CMR measurements is challenging due to limited spatial and temporal resolution. This study aimed to develop and evaluate a free-breathing, high-spatiotemporal-resolution single-beat Ex-CMR cine enhanced by generative artificial intelligence. We assessed image analysis reproducibility, scan-rescan reproducibility, and impact of the reader's experience on the analysis. Methods Imaging was performed on a 3T CMR system using a free-breathing, highly accelerated, multi-slice, single-beat cine sequence (in-plane spatiotemporal resolution of 1.9 × 1.9 mm² and 37 ms, respectively). High acceleration was achieved by combining compressed sensing reconstruction with a resolution-enhancement generative adversarial inline neural network. Ex-CMR was performed using a supine ergometer positioned immediately outside the magnet bore. Single-beat cine images were acquired at rest and immediately post-exercise. In a prospective study, the protocol was evaluated in 141 subjects. A structured image analysis workflow was implemented. Four expert readers, with or without prior training in single-beat Ex-CMR, independently rated all images for diagnostic and image quality. The subjective assessment used two 3-point Likert scales. Biventricular parameters were calculated. Inter- and intra-observer reproducibility were assessed. Fifteen healthy subjects were re-imaged 1 year later for scan-rescan reproducibility. Reproducibility was assessed using intraclass correlation coefficient (ICC), with agreement evaluated via Bland-Altman analysis, linear regression, and Pearson correlation. Results Free-breathing, single-beat Ex-CMR cine enabled imaging of the beating heart within 30 ± 6 s, with technically successful scans in 96\% (136/141) of subjects. Post-exercise single-beat cine images were assessed as diagnostic in 98\% (133/136), 96\% (131/136), 82\% (112/136), and 65\% (89/136) of cases by four readers (ordered by descending years of Ex-CMR experience). Good image quality was reported in 74\% (100/136) to 80\% (109/136) of subjects. Biventricular parameters were successfully measured in all subjects, demonstrating good to excellent inter-observer reproducibility. Scan/rescan reproducibility over 1 year, assessed by two independent readers, showed excellent inter-visit ICCs (0.96–1.0) and strong correlations (R² ≥ 0.92, p < 0.001 for left ventricle; R² ≥ 0.95, p < 0.001 for right ventricle). Conclusion Single-beat Ex-CMR enabled evaluation of biventricular volumetric and functional indices with excellent reproducibility."
}

@article{dup_4,
    author = "Owens, Otis L and Leonard, Michael S",
    title = "Evaluating an AI Chatbot “Prostate Cancer Info” for Providing Quality Prostate Cancer Screening Information: Cross-Sectional Study",
    journal = "JMIR Cancer",
    volume = "11",
    year = "2025",
    issn = "2369-1999",
    doi = "https://doi.org/10.2196/72522",
    url = "https://www.sciencedirect.com/science/article/pii/S2369199925000606",
    keywords = "generative artificial intelligence, chatbot, chatGPT, prostate cancer, cancer screening, shared decision making, artificial intelligence",
    abstract = "Background Generative artificial intelligence (AI) chatbots may be useful tools for supporting shared prostate cancer (PrCA) screening decisions, but the information produced by these tools sometimes lack quality or credibility. “Prostate Cancer Info” is a custom GPT chatbot developed to provide plain-language PrCA information only from websites of key authorities on cancer and peer-reviewed literature. Objective The objective of this paper was to evaluate the accuracy, completeness, and readability of Prostate Cancer Info’s responses to frequently asked PrCA screening questions. Methods A total of 23 frequently asked PrCA questions were individually input into Prostate Cancer Info. Responses were recorded in Microsoft Word and reviewed by 2 raters for their accuracy and completeness. Readability of content was determined by pasting responses into a web-based Flesch Kincaid Reading Ease Scores calculator. Results Responses to all questions were accurate and culturally appropriate. In total, 17 of the 23 questions (74\%) had complete responses. The average readability of responses was 64.5 (SD 8.7; written at an 8th-grade level). Conclusions Generative AI chatbots, such as Prostate Cancer Info, are great starting places for learning about PrCA screening and preparing men to engage in shared decision-making but should not be used as independent sources of PrCA information because key information may be omitted. Men are encouraged to use these tools to complement information received from a health care provider."
}

@article{dup_5,
    author = "Baucon, Andrea and Morelli, Corrado and {Neto de Carvalho}, Carlos and Kustascher, Evelyn",
    title = "Life in an Artinskian (Cisuralian) Permian megacaldera: Benthic palaeoecology in the shadow of the Bolzano Supervolcano (Athesian Volcanic District, Italy)",
    journal = "Palaeogeography, Palaeoclimatology, Palaeoecology",
    volume = "638",
    pages = "112027",
    year = "2024",
    issn = "0031-0182",
    doi = "https://doi.org/10.1016/j.palaeo.2024.112027",
    url = "https://www.sciencedirect.com/science/article/pii/S0031018224000166",
    keywords = "Supervolcano, Freshwater, Trace fossils, Caldera, Planolites, Artificial intelligence",
    abstract = "Volcanic processes create peculiar types of terrestrial and freshwater ecosystems but, surprisingly, very little is known about the infaunal palaeoecology of continental volcanic ecosystems such as caldera lakes and streams. Here, we report an invertebrate trace fossil association from the largest and best-exposed Permian (Cisuralian) supervolcano in Europe, the Bolzano Supervolcano. The fossil association is dominated by abundant trace fossils that are unusually straight, i.e., their curvature is zero along the entire preserved length. The trace fossils are attributed to Planolites and Palaeophycus and they form a bioturbated texture (ichnofabric) with a characteristically high bioturbation intensity (percent bioturbated>90\%). U-shaped (Arenicolites) and concentrically-lined (Cylindrichnus) burrows are minor components of the ichnofabric. The characteristics of the trace fossil association suggest substrate colonization by r-strategic organisms during periods of minor volcanic activity. In these periods of stasis, the volcanic rocks were eroded by seasonal streams, which provided suitable softground substrates for the infauna. Insects are regarded as the most plausible tracemakers of the straight burrows. Similar ichnofabrics are found in other continental volcanoclastic sites, suggesting that ichnofabrics dominated by straight burrows may represent an ichnological proxy of brief windows for colonization in volcanically influenced freshwater environments. Generative artificial intelligence has been used to graphically reconstitute the tiering pattern and the palaeoenvironment. As such, this study provides the first application of AI to the graphic representation of a bioturbated palaeoenvironment."
}

@article{dup_6,
    author = "Hamed, Ahmed Abdeen and Zachara-Szymanska, Malgorzata and Wu, Xindong",
    title = "Safeguarding authenticity for mitigating the harms of generative AI: Issues, research agenda, and policies for detection, fact-checking, and ethical AI",
    journal = "iScience",
    volume = "27",
    number = "2",
    pages = "108782",
    year = "2024",
    issn = "2589-0042",
    doi = "https://doi.org/10.1016/j.isci.2024.108782",
    url = "https://www.sciencedirect.com/science/article/pii/S2589004224000038",
    keywords = "Biocomputational method, Bioinformatics, Biological sciences, Computational bioinformatics, Natural sciences, Neural networks, Artificial intelligence, Artificial intelligence applications",
    abstract = "Summary As the influence of transformer-based approaches in general and generative artificial intelligence (AI) in particular continues to expand across various domains, concerns regarding authenticity and explainability are on the rise. Here, we share our perspective on the necessity of implementing effective detection, verification, and explainability mechanisms to counteract the potential harms arising from the proliferation of AI-generated inauthentic content and science. We recognize the transformative potential of generative AI, exemplified by ChatGPT, in the scientific landscape. However, we also emphasize the urgency of addressing associated challenges, particularly in light of the risks posed by disinformation, misinformation, and unreproducible science. This perspective serves as a response to the call for concerted efforts to safeguard the authenticity of information in the age of AI. By prioritizing detection, fact-checking, and explainability policies, we aim to foster a climate of trust, uphold ethical standards, and harness the full potential of AI for the betterment of science and society."
}

@article{dup_7,
    author = "Seyfi, Siamak and Kim, Myung Ja and Nazifi, Amin and Murdy, Samantha and Vo-Thanh, Tan",
    title = "Understanding tourist barriers and personality influences in embracing generative AI for travel planning and decision-making",
    journal = "International Journal of Hospitality Management",
    volume = "126",
    pages = "104105",
    year = "2025",
    issn = "0278-4319",
    doi = "https://doi.org/10.1016/j.ijhm.2025.104105",
    url = "https://www.sciencedirect.com/science/article/pii/S0278431925000283",
    keywords = "Generative AI, ChatGPT, Innovation resistance, Personality traits, Tourist decision-making",
    abstract = "As generative artificial intelligence (GAI) technologies become increasingly integrated into the travel industry, understanding the barriers tourists face in adopting these innovative technologies for their travel planning and decision-making has growingly become a critical area of focus. Drawing on the theoretical frameworks of innovation resistance and Big Five personality traits, this study surveyed potential travelers in Korea and the US to assess their personality characteristics, innovation resistance, and perceptions of AI-generated travel recommendations. The findings, derived from structural equation modeling, multi-group analysis, and fuzzy-set qualitative comparative analysis, reveal that variations in personality traits significantly affect tourists’ reluctance to adopting these technologies. Overall, the results of this study contribute to the theoretical understanding of acceptance of GAI and offer practical insights for tourism industry stakeholders, enabling them to tailor their offerings to different personality types and enhance the travel experience for a wide range of travelers."
}

@article{dup_8,
    author = "Suffoletto, Brian",
    title = "Deceptively Simple yet Profoundly Impactful: Text Messaging Interventions to Support Health",
    journal = "Journal of Medical Internet Research",
    volume = "26",
    year = "2024",
    issn = "1438-8871",
    doi = "https://doi.org/10.2196/58726",
    url = "https://www.sciencedirect.com/science/article/pii/S1438887124005235",
    keywords = "SMS intervention, behavior, intervention, review, text messaging, SMS, interventions, behaviors, behaviour, behaviours, effectiveness, development, impact, narrative review, physical activity, diet, weight loss, mental health, substance use, meta-analysis, chatbot, chatbots, large language model, LLM, large language models, mobile phone",
    abstract = "This paper examines the use of text message (SMS) interventions for health-related behavioral support. It first outlines the historical progress in SMS intervention research publications and the variety of funds from US government agencies. A narrative review follows, highlighting the effectiveness of SMS interventions in key health areas, such as physical activity, diet and weight loss, mental health, and substance use, based on published meta-analyses. It then outlines advantages of text messaging compared to other digital modalities, including the real-time capability to collect information and deliver microdoses of intervention support. Crucial design elements are proposed to optimize effectiveness and longitudinal engagement across communication strategies, psychological foundations, and behavior change tactics. We then discuss advanced functionalities, such as the potential for generative artificial intelligence to improve user interaction. Finally, major challenges to implementation are highlighted, including the absence of a dedicated commercial platform, privacy and security concerns with SMS technology, difficulties integrating SMS interventions with medical informatics systems, and concerns about user engagement. Proposed solutions aim to facilitate the broader application and effectiveness of SMS interventions. Our hope is that these insights can assist researchers and practitioners in using SMS interventions to improve health outcomes and reducing disparities."
}

@article{dup_9,
    author = "Son, Wooyoung and Kwon, Soonhong and Lee, Jong-Hyouk",
    title = "A DID-based one-time session key authentication mechanism for secure human-AI chatbot communication",
    journal = "Computers and Electrical Engineering",
    volume = "127",
    pages = "110622",
    year = "2025",
    issn = "0045-7906",
    doi = "https://doi.org/10.1016/j.compeleceng.2025.110622",
    url = "https://www.sciencedirect.com/science/article/pii/S0045790625005658",
    keywords = "AI chatbot, RPA system, DID, Session key",
    abstract = "As generative Artificial Intelligence (AI) technology has recently gained popularity, society is undergoing a full-scale transformation centered around AI. This technology is attracting attention across various fields, particularly as it meets the growing demand for ‘24/7 availability’. Among these applications, AI chatbot-based Robotic Process Automation (RPA) systems have demonstrated the ability to automate tasks, and with the integration of generative AI, they can now handle more advanced operations such as sending emails and managing complex workflows. However, because AI chatbot-based RPA systems are required to perform sensitive and high-level tasks, secure identity authentication is essential. Traditional Public Key Infrastructure (PKI)-based authentication mechanisms pose risks, as they often require storing personal information within the AI chatbot system—potentially increasing the damage in the event of a security breach. To address this issue, this paper proposes an authentication mechanism that uses a Decentralized Identity (DID)-based one-time session key. By leveraging DID technology, the proposed mechanism ensures self-sovereignty and privacy. Furthermore, the use of a one-time session key guarantees session independence, non-reusability, and untraceability. A performance comparison with PKI-based mechanisms shows that when more than five authentications are performed, the proposed mechanism achieves higher time efficiency, highlighting its advantages in both security and effectiveness. Additionally, potential security threats in each step of the proposed system are analyzed probabilistically. A mathematical formula is presented to demonstrate that the likelihood of such threats occurring is very low. By performing partial differentiation on the attack success probability with respect to representative variables at each step, the analysis identifies which authentication process most significantly influences overall system security. This provides clear insights for designing secure authentication systems based on the proposed approach."
}

@article{dup_10,
    author = "Masrouri, Milad and Paul, Kamalendu and Qin, Zhao",
    title = "Generative AI model trained by molecular dynamics for rapid mechanical design of architected graphene",
    journal = "Extreme Mechanics Letters",
    volume = "72",
    pages = "102230",
    year = "2024",
    issn = "2352-4316",
    doi = "https://doi.org/10.1016/j.eml.2024.102230",
    url = "https://www.sciencedirect.com/science/article/pii/S235243162400110X",
    keywords = "Architected graphene, Molecular dynamics, Stable Diffusion, Low Rank Adaptation, Von Mises stress field",
    abstract = "Generative artificial intelligence (AI) is shown to be a useful tool to automatically learn from existing information and generate new information based on their connections, but its usage for quantitative mechanical research is less understood. Here, we focus on the structure-mechanics relationship of architected graphene as graphene with void defects of specific patterns. We use Molecular Dynamics (MD) to simulate uniaxial tension on architected graphene, extract the von Mises stress field in mechanical loading, and use the results to train a fine-tuned generative AI model through a Low-Rank Adaptation method. This model enables the freely designed architected graphene structures and predicts its associated stress field in uniaxial tension loading through simple descriptive language. We demonstrate that the fine-tuned model can be established with a few training images and can quantitatively predict the stress field for graphene with various defect geometries and distributions not included in the training set. We validate the accuracy of the stress field with MD simulations. Moreover, we illustrate that our generative AI model can predict the stress field from a schematic drawing of the architected graphene through image-to-image generation. These features underscore the promising future for employing advanced generative AI models in end-to-end advanced nanomaterial design and characterization, enabling the creation of functional, structural materials without using complex numerical modeling and data processing."
}

@article{dup_11,
    author = "Ferrer, Javianna Castellanos and {Horta Caicedo}, Alvaro J. and {Alejandro Peña-Ruiz}, Omar Alejandro and Bermudez, Francisco",
    title = "ChatGPT(4.0) Has the Capacity to Diagnose Orbital Floor Fractures: Fiction or Reality?",
    journal = "Journal of Oral and Maxillofacial Surgery",
    volume = "83",
    number = "9, Supplement",
    pages = "S131-S132",
    year = "2025",
    issn = "0278-2391",
    doi = "https://doi.org/10.1016/j.joms.2025.06.196",
    url = "https://www.sciencedirect.com/science/article/pii/S0278239125005634"
}

@article{dup_12,
    author = "Shenoy, Devika A. and Lindsay, Christina and Martin, Allison N. and Snyderman, Ralph",
    title = "Perspectives on navigating the use of artificial intelligence by patients for their surgical care management",
    journal = "The American Journal of Surgery",
    pages = "116540",
    year = "2025",
    issn = "0002-9610",
    doi = "https://doi.org/10.1016/j.amjsurg.2025.116540",
    url = "https://www.sciencedirect.com/science/article/pii/S0002961025003630"
}

@article{dup_13,
    author = "Chatterjee, Pranam",
    title = "Beyond small molecule-based protein targeting in the era of deep learning",
    journal = "Current Opinion in Biomedical Engineering",
    volume = "28",
    pages = "100501",
    year = "2023",
    issn = "2468-4511",
    doi = "https://doi.org/10.1016/j.cobme.2023.100501",
    url = "https://www.sciencedirect.com/science/article/pii/S2468451123000570"
}

@article{dup_14,
    author = "Lazzaro, Carlo",
    title = "When cost-effectiveness analysis bites: Avoiding the pitfalls of extended dominance",
    journal = "Oral Oncology",
    volume = "150",
    pages = "106724",
    year = "2024",
    issn = "1368-8375",
    doi = "https://doi.org/10.1016/j.oraloncology.2024.106724",
    url = "https://www.sciencedirect.com/science/article/pii/S1368837524000423"
}

@article{dup_15,
    author = "Yilmaz, Esra Karabag and Hakalmaz, Ali Ekber and Saygılı, Seha and Agbas, Ayse and Karatas, Kubra and Cebi, Memnune Nur and Ozcan, Rahsan and Kurugoglu, Sebuh and Elicevik, Mehmet and Emir, Haluk and Canpolat, Nur",
    title = "Increased risk of chronic kidney disease in children with anorectal malformations",
    journal = "Journal of Pediatric Urology",
    volume = "21",
    number = "4",
    pages = "908-914",
    year = "2025",
    issn = "1477-5131",
    doi = "https://doi.org/10.1016/j.jpurol.2025.03.015",
    url = "https://www.sciencedirect.com/science/article/pii/S1477513125001536",
    keywords = "Anorectal malformation, Bladder dysfunction, Children, Chronic kidney disease, Kidney and urinary tract anomalies",
    abstract = "Summary Background Anorectal malformations (ARM) are often accompanied by urological anomalies, which can contribute to the development of chronic kidney disease (CKD). Objective This study aimed to investigate the prevalence of kidney and urinary tract anomalies, as well as bladder dysfunction, and their potential impact on the development of CKD in children with ARM. Study design This single-center, retrospective study included 175 children with ARM, after excluding 75 children with missing data. Clinical and radiological findings and serum creatinine levels were obtained from medical records. Anorectal malformations were classified as “high” and “low” type based on the Wingspread classification, and also further classified by fistula type and sex distribution according to the Krickenbeck International Classification. CKD was defined and staged according to the KDIGO (Kidney Disease Improving Global Outcomes) guidelines. Results The median age of the patients was 9.7 years, with a male-to-female ratio of 1.13:1. Among the 175 patients, 97 (55 \%) had intermediate or low-type ARM, and 78 (45 \%) had high-type ARM. Kidney and/or urinary tract anomalies were identified in 85 patients (48.5 \%), with 63 having kidney anomalies and 71 having urinary tract anomalies. The most common urinary tract anomaly was vesicoureteral reflux (n = 58). Bladder dysfunction was observed in 56 patients (32 \%). CKD was diagnosed in 30 patients (17 \%); six of them were in CKD stage 5, and the remaining 24 were in stages 2–4. The development of CKD was more common in both females and males with kidney anomalies (p < 0.001), urinary tract anomalies (p < 0.001 and p = 0.002, respectively), bladder dysfunction (p < 0.001), urinary tract infection (p < 0.001), in addition females with persistent cloaca (p = 0.023) and spinal anomalies (p = 0.013). Kidney anomalies and bladder dysfunction were independently associated with the development of CKD (p < 0.001 and p = 0.046, respectively). Discussion This study highlights that approximately half of the children with ARM had kidney and urinary tract anomalies, and one-third had bladder dysfunction. Additionally, almost one-fifth of the patients developed CKD, mostly in the early stages. Our findings also suggest that both kidney anomalies and bladder dysfunction are significant risk factors for CKD development in children with ARM. Conclusion This study emphasizes the presence of kidney anomalies, along with bladder dysfunction as risk factors for CKD. Physicians should take care to monitor and manage these risks to minimize the long-term impacts on kidney health in children with ARM."
}

@article{dup_16,
    author = "Chan, Anthony K.C. and Siriwardena, Ajith K.",
    title = "Management of Colorectal Cancer with Synchronous Liver Metastases: A systematic review of national and International Clinical Guidelines (CoSMIC-G)",
    journal = "Surgery Open Science",
    volume = "22",
    pages = "61-66",
    year = "2024",
    issn = "2589-8450",
    doi = "https://doi.org/10.1016/j.sopen.2024.10.009",
    url = "https://www.sciencedirect.com/science/article/pii/S2589845024001313",
    keywords = "Colorectal cancer, Synchronous liver metastases, Guidelines",
    abstract = "Introduction The contemporary management of patients with colorectal cancer and synchronous liver metastases is complex. This study appraises the recommendations made by national/international guidelines for the diagnosis and management of patients with synchronous liver metastases from colorectal cancer. Methods A systematic review of national and international guidelines published between 2011 and 2024 was carried out using PubMed, OvidSP and Guidelines International Network databases. The quality of guidelines was evaluated using the Appraisal of Guidelines for Research \& Evaluation II (AGREE II) instrument. Guidelines were assessed for the quality of advice for specific scenarios. The protocol was registered with PROSPERO (CRD42021243744). Results The search strategy returned ninety unique articles with 11 guidelines eligible for inclusion. Of these, one (9 \%) guideline defined ‘synchronous disease’ at outset, eight (73 \%) recommended neoadjuvant chemotherapy as first intervention. Seven (64 \%) guidelines supported synchronous hepatic resection with colectomy. One (9 \%) recommended against synchronous surgery. Conclusions This study demonstrates important variations between international clinical guidelines on diagnostic workup and management of synchronous liver metastases in colorectal cancer. [167 words]."
}

@article{dup_17,
    author = "Gasque, Rodrigo Antonio and Zaietta, Noelia and Mollard, Lourdes and Beltrame, Magali Chahdi and Virreira, Marcelo Enrique Lenz and Quiñonez, Emilio Gastón and Mattera, Francisco Juan",
    title = "HPB SmartNotes: The impact of artificial intelligence on surgeon workload in the outpatient office",
    journal = "EngMedicine",
    volume = "2",
    number = "4",
    pages = "100101",
    year = "2025",
    issn = "2950-4899",
    doi = "https://doi.org/10.1016/j.engmed.2025.100101",
    url = "https://www.sciencedirect.com/science/article/pii/S2950489925000478",
    keywords = "Artificial intelligence, Office visits, Natural language processing, HPB surgery",
    abstract = "In this study, we aimed to evaluate the feasibility, linguistic accuracy, and coherence of medical notes generated by the integration of an automatic speech recognition system (ASR) and a generative pre-trained transformer (GPT) in an outpatient surgical setting and to assess their impact on documentation time. This prospective exploratory study included 20 adults who visited their first outpatient clinic due to hepatobiliary or pancreatic conditions. Consultations were audio-recorded, transcribed using Whisper-1 (OpenAI), and converted into structured Subjective, Objective, Assessment and Plan (SOAP) clinical notes using ChatGPT 3.5 (OpenAI), implemented through Python 3.11.6. The transcriptions were manually reviewed against gold-standard references, and the ASR performance was quantified using standard metrics from the Jiwer library. Descriptive statistics were computed, and the ChatGPT note quality was evaluated using a standardized checklist, before assessing for statistical significance. The median patient age was 47 years (65 \% female). The average interview duration was 15.98 min. Whisper transcribed audio in a median of 59.3 s, and ChatGPT generated SOAP notes in 5.7 s. ChatGPT produced satisfactory results in 85 \% of cases, with a significant performance. The ASR system demonstrated acceptable transcription quality. The integration of Whisper and ChatGPT drastically reduced the documentation time compared with manual electronic health record (EHR) entry. Despite some limitations, these results highlight the promise of artificial intelligence (AI)-powered documentation tools in outpatient practice. Further research with larger samples and direct comparisons with traditional methods is warranted to confirm these findings and address the ethical, legal, and implementation challenges associated with AI in clinical environments."
}

@article{dup_18,
    author = "Reid, Jared and McCrosson, Matthew and Tobin, Jacqueline and Rivas, Gabriella and Rothwell, Stacey and Hartsock, Langdon and Reid, Kristoff",
    title = "Opportunistic CT screening demonstrates increased risk for peri-articular fractures in osteoporotic patients",
    journal = "Orthopaedics \& Traumatology: Surgery \& Research",
    volume = "110",
    number = "8",
    pages = "103935",
    year = "2024",
    issn = "1877-0568",
    doi = "https://doi.org/10.1016/j.otsr.2024.103935",
    url = "https://www.sciencedirect.com/science/article/pii/S1877056824001919",
    keywords = "Osteoporosis, Opportunistic CT scan, Peri-articular fracture, Fragility fracture",
    abstract = "Background Underdiagnosis or undertreatment of osteoporosis consequently impacts individual morbidity and mortality, as well as on healthcare systems and communities as a whole. Dual-energy x-ray absorptiometry (DXA) is the gold standard method for identifying osteoporosis, however, opportunistic CT screening is capable of precisely estimating bone mineral density (BMD) in abdominopelvic imaging with no additional cost, radiation exposure or inconvenience to patients. This study uses opportunistic CT screening to determine the prevalence of osteoporosis and anatomic distribution patterns in patients presenting with lower extremity fractures at our institution. Hypothesis Trauma patients with low bone mineral density (BMD) are more likely to present with peri-articular versus shaft fractures. Patients and methods We conducted a retrospective review of 721 patients presenting as trauma activations to the emergency department (ED) of a Level 1 Trauma Center with lower extremity fractures. Patients were excluded if under the age of 18 or lacking a CT scan upon arrival in the ED. Hounsfield Units (HU) were measured at the L1 vertebral level on CT scans to determine bone mineral density. Values of ≤100 HU were consistent with osteoporosis, whereas 101–150 HU were consistent with osteopenia. Results The final cohort included 416 patients, with mean age of 49 ± 21 years. Average bone density was 203.9 ± 73.4 HU. 15.9\% of patients were diagnosed as osteopenic and 9.9\% as osteoporotic. 64.2\% of fractures were peri-articular, 25.7\% were shaft, and 10.1\% were a combination. Peri-articular fractures were significantly more likely to have lower average BMD than shaft fractures (189 ± 74.7 HU vs. 230.6 ± 66.1 HU, p < 0.001). Discussion Our study demonstrates a significant relationship between low bone mineral density and lower extremity fracture pattern, however, likely influenced by other factors such as sex. Opportunistic CT screening for osteoporosis in trauma settings provides ample opportunity for early detection of low BMD and implementation of highly effective lifestyle modification and pharmacotherapy intervention. Reduction in the overall incidence of peri-articular fracture with widespread adoption of opportunistic CT screening may lessen the morbidity, mortality, and total cost currently afflicting patients, healthcare systems, and communities. Level of evidence III, therapeutic"
}

@article{dup_19,
    author = "Levin, Gabriel and Piedimonte, Sabrina and Zand, Behrouz",
    title = "Navigating the complexities of artificial intelligence in scientific writing: a dual perspective",
    journal = "International Journal of Gynecological Cancer",
    volume = "34",
    number = "10",
    pages = "1495-1498",
    year = "2024",
    issn = "1048-891X",
    doi = "https://doi.org/10.1136/ijgc-2024-005691",
    url = "https://www.sciencedirect.com/science/article/pii/S1048891X24035850",
    keywords = "Carcinoma, Ovarian Epithelial, Cervical Cancer, Vulvar and Vaginal Cancer, Uterine Cancer"
}

@article{dup_20,
    author = "Ito, Daisuke and Inoue, Keizo and Fujioka, Yuichi and Miki, Teruhiko and Ishikawa, Shinsuke and Happoya, Akihiko and Watanabe, Seigo and Miura, Tomohiro and Oyaizu, Kenichi",
    title = "Novel polyphenylene sulfide resin for high-frequency copper-clad laminates with low dielectric tangent and flame retardancy",
    journal = "Polymer",
    volume = "338",
    pages = "129095",
    year = "2025",
    issn = "0032-3861",
    doi = "https://doi.org/10.1016/j.polymer.2025.129095",
    url = "https://www.sciencedirect.com/science/article/pii/S003238612501081X",
    abstract = "We report a novel poly(2,6-dimethyl-1,4-phenylene sulfide) resin bearing vinyl groups (PMPS-V) designed for next-generation copper-clad laminates used in high-frequency applications. Oligo(2,6-dimethyl-1,4-phenylene ether) resins are commonly used owing to their low dielectric constant and high thermal resistance; however, further reduction in dielectric loss tangents is needed for future communication networks. Materials with excellent dielectric properties typically exhibit low polarity and high flammability, presenting a trade-off between dielectric performance and flame retardancy. PMPS-V exhibits thermosetting behavior and an extremely low dielectric-loss tangent (<0.001 at 10 GHz). Owing to its polyphenylene sulfide backbone, PMPS-V meets the UL-94 V-0 flame retardancy standard. Long-term heat resistance testing at 150 °C confirmed minimal degradation in dielectric properties, demonstrating excellent thermal stability. In addition, PMPS-V has a high glass transition temperature and favorable solubility in common solvents such as toluene, making it suitable for printed wiring board applications. These results indicate that PMPS-V is a promising candidate for next-generation low dielectric materials."
}

@article{dup_21,
    author = "Shu-yu, Dong and Jin-qu, Zhang",
    title = "Analysis of the Recognition Effect on the Number of Spiral Arms in Spiral Galaxy Images Using ResNet",
    journal = "Chinese Astronomy and Astrophysics",
    volume = "49",
    number = "3",
    pages = "537-550",
    year = "2025",
    issn = "0275-1062",
    doi = "https://doi.org/10.1016/j.chinastron.2025.09.002",
    url = "https://www.sciencedirect.com/science/article/pii/S0275106225000748",
    keywords = "galaxies, spiral galaxy—techniques, image processing—methods, data analysis—methods, classification",
    abstract = "The spiral arm information contained in spiral galaxy images, especially the number of spiral arms, is of great value for studying the structural evolution and dynamics of galaxies. Against the backdrop of explosive growth in galaxy observation data, how to quickly identify the number of spiral arms has become an important issue in the study of spiral galaxies. The research is based on the Galaxy Zoo DECaLS (Dark Energy Camera Legacy Survey) dataset and studies the ResNet (Residual Networks) model's method of identifying the number of spiral arms from spiral galaxy images. The experimental results show that the accuracy of the ResNet32 model is 83\%, which is the best compared to network models such as ViT (Vision Transformer), EfficientNet, and DenseNet. In terms of recognition of different numbers of spiral arms, there is a strong relationship between recognition accuracy and the number of training samples. There are 6800 images with 2 spiral arms, with an F1-Score value of 0.9, while there are only 237 images with 4 spiral arms, with the lowest F1-Score value. The experiment further analyzed the recognition effect of fused traditional galaxy image features and found that the role of fused traditional galaxy image features in improving the recognition of spiral arms is limited."
}

@article{dup_22,
    author = "Magnani, Jared W. and Plevniak, Keri and Ferry, Danielle and Martin, Deborah and Brooks, Maria M. and Kimani, Everlyne and Ólafsson, Stefán and Rollman, Bruce L. and Paasche-Orlow, Michael K. and {El Khoudary}, Samar R. and Bickmore, Timothy",
    title = "The mobile health intervention for rural patients with atrial fibrillation a randomized controlled trial",
    journal = "International Journal of Cardiology",
    volume = "438",
    pages = "133575",
    year = "2025",
    issn = "0167-5273",
    doi = "https://doi.org/10.1016/j.ijcard.2025.133575",
    url = "https://www.sciencedirect.com/science/article/pii/S0167527325006187",
    keywords = "Atrial fibrillation, Digital health, Rurality, Self-management, Health literacy",
    abstract = "Background Rural individuals with atrial fibrillation (AF) experience challenges to anticoagulation adherence and self-management of the condition. We tested an intervention to improve anticoagulation adherence, quality of life, and health care utilization in rural individuals with AF. Methods We randomized rural patients with AF receiving anticoagulation to receive a smartphone-based relational agent (for disease education and adherence guidance) and a heart rate and rhythm monitor for 4 months or a smartphone-based health education app. Adherence was determined with 12-month proportion of days covered (PDC), and secondary outcomes of quality of life and health care utilization from interviews and health records. Results The trial randomized 270 individuals 1:1 (median [IQR] age 73.1 [67.5–78.6]; 163 [60.4 \%] female sex). Over the 4-month intervention, intervention participants used the relational agent a median of 101 (IQR: 72, 110) days. In an intention-to-treat analysis there was no significant difference in 12-month PDC between the intervention and control groups (median [IQR]: intervention 0.97 [0.89–1.00] versus control 0.97 [0.92–1.00]) or in PDC ≥0.80. Intervention participants were more likely to self-report anticoagulation adherence than control at 4 and 8 months (95.7 \% vs 88.4 \% and 93.0 \% vs 78.8 \%, respectively) but not at 12 months. There were no significant differences by assigned intervention for the other secondary outcomes. Conclusions Randomization to the relational agent intervention was not associated with improved PDC at 12-months but with greater interim self-reported adherence compared to a control. This study demonstrates the successful use of a smartphone-based agent to address adherence among rural individuals with AF."
}

@article{dup_23,
    author = "Miralles-Muñoz, Francisco Antonio and {de La Pinta-Zazo}, Carlos and Albero-Catalá, Luis and Vizcaya-Moreno, María Flores",
    title = "The method of femoral tunnel drilling in anterior cruciate ligament reconstruction does not influence the return to sport rate",
    journal = "Journal of Orthopaedics",
    volume = "56",
    pages = "87-91",
    year = "2024",
    issn = "0972-978X",
    doi = "https://doi.org/10.1016/j.jor.2024.05.017",
    url = "https://www.sciencedirect.com/science/article/pii/S0972978X24001776",
    keywords = "ACL, Knee, Arthroscopy, Ligament reconstruction, Sport, Satisfaction",
    abstract = "Background Limited evidence is available comparing the modified transtibial (MTT) and transportal (TP) techniques in anterior cruciate ligament (ACL) reconstruction and their impact on returning to sports participation. The objective was to analyze the outcomes after arthroscopic reconstruction of the ACL in recreational athletes with a 2-year postoperative follow-up, comparing the MTT and TP techniques, based on the method used to drill the femoral tunnel. Hypotesis The rate of return to sport would be comparable regardless of the surgical technique used. Material and methods A retrospective study was conducted with 66 patients who underwent arthroscopic monofascicular ACL reconstruction between September 2016 and March 2020. Patients aged between 16 and 50 years old, recreational athletes at Tegner levels 6 and 7, with a 2-year follow-up were included. Groups were established for comparative analysis (MTT vs TP) based on the method for drilling the femoral tunnel. The main outcome variable was the return to sport at the same level. Secondary variables included patient satisfaction evaluated with a visual analogue scale (VAS) and knee function according to the Lysholm scale. Results At 2 years of postoperative follow-up, the return to sport rate was 30.3 \% in the MTT group and 33.3 \% in the TP group (p = 0.791). There were no significant differences between both groups in patient satisfaction (p = 0.664) and knee function (p = 0.113). Conclusion Drilling the femoral tunnel with the MTT and TP techniques did not influence the rate of return to sport, patient satisfaction, and knee function in recreational athletes with 2 years of postoperative follow-up. Level of evidence III."
}

@article{dup_24,
    author = "Ho, Brittany and Mayberry, Ta’Rhonda and Nguyen, Khanh Linh and Dhulipala, Manohar and Pallipuram, Vivek Krishnamani",
    title = "ChatReview: A ChatGPT-enabled natural language processing framework to study domain-specific user reviews",
    journal = "Machine Learning with Applications",
    volume = "15",
    pages = "100522",
    year = "2024",
    issn = "2666-8270",
    doi = "https://doi.org/10.1016/j.mlwa.2023.100522",
    url = "https://www.sciencedirect.com/science/article/pii/S2666827023000750",
    keywords = "Natural Language Processing, ChatGPT, Sentiment analysis, Prompt engineering, Intelligent search engines, Recommender system",
    abstract = "Intelligent search engines including pre-trained generative transformers (GPT) have revolutionized the user search experience. Several fields including e-commerce, education, and hospitality are increasingly exploring GPT tools to study user reviews and gain critical insights to improve their service quality. However, massive user-review data and imprecise prompt engineering lead to biased, irrelevant, and impersonal search results. In addition, exposing user data to these search engines may pose privacy issues. Motivated by these factors, we present ChatReview, a ChatGPT-enabled natural language processing (NLP) framework that effectively studies domain-specific user reviews to offer relevant and personalized search results at multiple levels of granularity. The framework accomplishes this task using four phases including data collection, tokenization, query construction, and response generation. The data collection phase involves gathering domain-specific user reviews from public and private repositories. In the tokenization phase, ChatReview applies sentiment analysis to extract keywords and categorize them into various sentiment classes. This process creates a token repository that best describes the user sentiments for a given user-review data. In the query construction phase, the framework uses the token repository and domain knowledge to construct three types of ChatGPT prompts including explicit, implicit, and creative. In the response generation phase, ChatReview pipelines these prompts into ChatGPT to generate search results at varying levels of granularity. We analyze our framework using three real-world domains including education, local restaurants, and hospitality. We assert that our framework simplifies prompt engineering for general users to produce effective results while minimizing the exposure of sensitive user data to search engines. We also present a one-of-a-kind Large Language Model (LLM) peer assessment of the ChatReview framework. Specifically, we employ Google’s Bard to objectively and qualitatively analyze the various ChatReview outputs. Our Bard-based analyses yield over 90\% satisfaction, establishing ChatReview as a viable survey analysis tool."
}

@article{dup_25,
    author = "Shah, Jagrut and Al-Hashimi, Amel and Benedetto, Magela and Ruchaya, Prashant Jay",
    title = "From bench to bedside: The critical need for standardized senescence detection",
    journal = "Archives of Cardiovascular Diseases",
    volume = "118",
    number = "3",
    pages = "205-211",
    year = "2025",
    issn = "1875-2136",
    doi = "https://doi.org/10.1016/j.acvd.2024.12.008",
    url = "https://www.sciencedirect.com/science/article/pii/S1875213625000324",
    keywords = "Senescence, Ageing, Cardiovascular disease, Cancer, Neurodegenerative disease",
    abstract = "Cellular senescence, identified as a state of permanent cell cycle arrest, has become central to understanding aging and disease. Initially seen as a cellular aging mechanism, it is now recognized for its roles in development, tissu repair and tumour suppression. However, the accumulation of senescent cells with age contributes to chronic diseases such as diabetes, atherosclerosis and neurodegeneration. Recent efforts have focused on “senotherapeutics”, including senolytics, which aim to eliminate senescent cells to mitigate age-related decline. Despite significant advances, senescence research faces critical challenges because of inconsistent detection methods. Common markers, such as p16INK4a and senescence-associated β-galactosidase, vary across tissues and contexts, complicating cross-study comparisons and clinical applications. A standardized multifaceted approach to senescence detection is essential, and should incorporate complementary methods, clear thresholds for senescence classification and considerations for cell type-specific variations. Such standardization would enhance reproducibility, streamline research and facilitate clinical translation, advancing therapeutic applications in aging and disease management."
}

@article{dup_26,
    author = "Breitling, Lutz P. and Dragomir, Anca D. and Duan, Chongyang and Luta, George",
    title = "On the current and future potential of simulations based on directed acyclic graphs",
    journal = "Global Epidemiology",
    volume = "9",
    pages = "100186",
    year = "2025",
    issn = "2590-1133",
    doi = "https://doi.org/10.1016/j.gloepi.2025.100186",
    url = "https://www.sciencedirect.com/science/article/pii/S2590113325000045",
    keywords = "Simulation studies, Directed acyclic graphs, Selection bias, Confounding, Real world evidence, Regression modelling, Emulated target trial",
    abstract = "Real-world data are playing an increasingly important role in regulatory decision making. Adequately addressing bias is of paramount importance in this context. Structural representations of bias using directed acyclic graphs (DAGs) provide a unified approach to conceptualize bias, distinguish between different types of bias, and identify ways to address bias. DAG-based data simulation further enhances the scope of this approach. Recently, DAGs have been used to demonstrate how missing eligibility information can compromise emulated target trial analysis, a cutting edge approach to estimate treatment effects using real-world data. The importance of simulation for methodological research has received substantial recognition in the past few years, and others have argued that simulating data based on DAGs can be especially helpful for understanding various epidemiological concepts. In the present work, we present two concrete examples of how simulations based on DAGs can be used to gain insights into issues commonly encountered in real-world analytics, i.e., regression modelling to address confounding bias, and the potential extent of selection bias. Increasing accessibility and extending the simulation algorithms of existing software to include longitudinal and time-to-event data are identified as priorities for further development. With such extensions, simulations based on DAGs would be an even more powerful tool to advance our understanding of the rapidly growing toolbox of real-world analytics."
}

@article{dup_27,
    author = "Acar, Oguz A.",
    title = "Commentary: Reimagining marketing education in the age of generative AI",
    journal = "International Journal of Research in Marketing",
    volume = "41",
    number = "3",
    pages = "489-495",
    year = "2024",
    issn = "0167-8116",
    doi = "https://doi.org/10.1016/j.ijresmar.2024.06.004",
    url = "https://www.sciencedirect.com/science/article/pii/S0167811624000521",
    keywords = "Generative AI, GenAI, Large language models, AI in education, Marketing education",
    abstract = "Generative AI (GenAI) holds the potential to revolutionise marketing education by enhancing the learning experience and addressing long-standing pedagogical challenges. This paper explores the transformative impact of GenAI, focusing on three primary dimensions: cost efficiency \& scalability, personalisation \& accessibility, and creativity \& innovation. However, despite these substantial benefits, GenAI also presents important risks and challenges. I therefore underscore the need for strategic and responsible implementation, recommending several approaches such as foundational AI literacy, human oversight, alignment with learning objectives and bespoke pedagogical frameworks to harness GenAI's full potential while mitigating associated risks. Finally, I emphasise that the discussion should evolve from whether we should use GenAI to when and how we should use it."
}

@incollection{dup_28,
    editor = "Kumar, Ashish and Singh, Divya",
    author = "Chaturvedi, Vijit",
    title = "13 - A futuristic aspect towards modern healthcare system facilitated through artificial intelligence: A comprehensive perspective",
    booktitle = "Revolutionizing Medical Systems using Artificial Intelligence",
    publisher = "Academic Press",
    pages = "245-264",
    year = "2025",
    isbn = "978-0-443-32862-6",
    doi = "https://doi.org/10.1016/B978-0-443-32862-6.00013-4",
    url = "https://www.sciencedirect.com/science/article/pii/B9780443328626000134",
    keywords = "Artificial intelligence, machine learning-based healthcare, techno-social aspect in healthcare, digital health, AI health tools, health sustainability",
    abstract = "The enhanced transformation in healthcare with developing and changed consumerism attributes in the most critical and crucial segment of the country’s development, healthcare, is seamless. From 2020 to projected 2030 the healthcare market is expected to reach US$194.4 billion. Artificial intelligence (AI) is understood as an intelligent system that implements various human intelligence-like functions whether it is data-based insights or combined applications of science, mathematics, language, human psychology, and engineering with the help of algorithms and software, thus helping analyze data and applications in healthcare. The present chapter highlights the historical developments in the healthcare industry from a traditional approach to an AI-based healthcare system and discusses the application of techno-based health tools and various available platforms and strategies that are reinventing the definition of health across the globe. The chapter also discusses challenges, future scope and developments, and the role of generative AI in healthcare that will make healthcare a highly affordable, seamless, errorless, authentic, equitable, and inclusive system. The findings will help delve into developments and advancements that technology has brought in the healthcare industry, it will also help in understanding the challenges and priorities of investment done in healthcare and important issues like safety, privacy, and trust while balancing the technology-enabled and tech-driven approaches. Thus it will help provide new insights for futuristic development and give new vistas for others to ensure healthcare progression."
}

@article{dup_29,
    author = "Culler, Steven D. and Peacock, W. Frank and Simon, April W.",
    title = "Cost of treatment failure: Medicare spending on stroke for atrial fibrillation patients not receiving anticoagulation",
    journal = "Journal of the Neurological Sciences",
    volume = "453",
    pages = "120814",
    year = "2023",
    issn = "0022-510X",
    doi = "https://doi.org/10.1016/j.jns.2023.120814",
    url = "https://www.sciencedirect.com/science/article/pii/S0022510X23002757",
    keywords = "Atrial fibrillation, Ischemic stroke, Medicare program spending",
    abstract = "Background It is well known that atrial fibrillation (AF) patients not receiving anticoagulants are at higher risk of Ischemic Stroke (IS). Objective Our objective is to estimate how much the Medicare program spends during one-year treating a Medicare beneficiary (MB) with AF who were not being anticoagulated prior to or during their IS hospitalization. Methods This cross-sectional study population consisted of all MBs in the fee-for-service program who were discharged from a hospitalization for IS having AF during 2018. Patients were excluded for a prior history of stroke or already receiving long-term anticoagulants. Medicare spending was defined as paid claims during the index hospitalization and all facility claims that began within 12-months of the index hospital discharge date even if admission occurred in 2019. Results The final sample was 50,509 MBs. Average Medicare Part A spending per beneficiary was $46,867 ± $49,212, for a total of nearly $2.5 billion. Highest average spending per MB was for hospital services $25,848, of which $15,790 ± $20,984 occurred during the index hospitalization, and $10,058 ± $21,956 for rehospitalization. The Medicare program average MB spending included $8131 ± $14,979 at skilled nursing facilities, $5538 ± $12,739 at rehabilitation facilities, and $3056 ± $7495 for outpatient facilities or emergency departments. Conclusion MBs with AF who are not treated with anticoagulants and then suffer an ischemic stroke result in one-year Medicare Part A program spending of approximately $47,000 per person compared to an average spending of approximately $12,800 per beneficiary in the Medicare program in 2018 [1]. Identification and anticoagulation treatment in AF could result in significant healthcare savings."
}

@article{dup_30,
    author = "Potgieter, Ingrid L. and Sooknannan, Renitha and Coetzee, Melinde",
    title = "Emotional intelligence in young emerging adults: A focus on Wong and Law's scale in the digital work sphere",
    journal = "Heliyon",
    volume = "10",
    number = "7",
    pages = "e29133",
    year = "2024",
    issn = "2405-8440",
    doi = "https://doi.org/10.1016/j.heliyon.2024.e29133",
    url = "https://www.sciencedirect.com/science/article/pii/S2405844024051648",
    keywords = "Emotional intelligence, Emerging adults, Measurement scale, Digital competence",
    abstract = "Despite the growing research on the usefulness and validity of the four-factor Wong and Law Emotional Intelligence Scale (WLEIS), empirical evidence for its relevance to Black African young emerging adults seems non-existent. The study's objective was to assess the relevance of the original WLEIS factor structure for a sample (N = 365) of South African Technical and Vocational Education and Training (TVET) final year students (mean age = 24.3 years; SD = 2.38). Exploratory and confirmatory factor analyses, and convergent and discriminant validity tests revealed a three-factor first-order structure with uniquely descriptive items characteristic of the sample's emotional intelligence. The findings contribute to the WLEIS measurement of emotional intelligence in young emerging adults who are preparing to enter the digital-age work world."
}

@article{dup_31,
    author = "Pino, Giovanni and Pichierri, Marco and Sit, Kokho Jason",
    title = "Will consumers pay for e-fashion? A multi-study investigation",
    journal = "International Journal of Retail \& Distribution Management",
    volume = "53",
    number = "7",
    pages = "685-698",
    year = "2025",
    issn = "0959-0552",
    doi = "https://doi.org/10.1108/IJRDM-10-2023-0583",
    url = "https://www.sciencedirect.com/science/article/pii/S095905522500004X",
    keywords = "Digital clothes, Product uniqueness, Sensation-seeking, Need for touch, Willingness to pay",
    abstract = "Purpose Digital clothes (DCs) are an emerging product category whose commercial success will heavily depend on consumers’ perception of their economic and symbolic value. However, existing studies have overlooked the empirical assessment of consumers’ willingness to pay (WTP) for such products. As a result, the factors underlying consumers’ motivation to pay for them are still a matter of debate. Design/methodology/approach We ran three quantitative studies, including one involving participants in a real consumption context that assessed: (1) whether the perceived uniqueness of DCs increases consumers’ WTP for these products and (2) whether this effect depends on consumers’ sensation-seeking tendency (SST) and the instrumental need for touch (NFT). Findings We found that the higher the perceived uniqueness of DCs, the higher the consumers’ WTP for them. This effect was stronger for consumers who exhibited high SST and NFT. Practical implications DC developers and retailers should consider uniqueness as a key driver of DC consumption. They should target sensation seekers with high instrumental NFT who perceive DCs as unique products. Originality/value This research extends the understanding of the determinants of DC consumption by developing a framework that simultaneously accounts for the effects determined by a distinctive feature of these products (i.e. their uniqueness) as well as consumers’ personal characteristics."
}

@article{dup_32,
    author = "{Al Moosa}, Hayem A. and Sobaih, Abu Elnasr E. and Zaiem, Imed and Alzahrani, Thamer and Zouari, Eya A. and Alshebami, Ali Saleh and Edrees, Hussein N.E. and Al-Qutaish, Amer A.",
    title = "The AI paradox in marketing: Fascination, resistance, and reinvention",
    journal = "Journal of Open Innovation: Technology, Market, and Complexity",
    volume = "11",
    number = "4",
    pages = "100629",
    year = "2025",
    issn = "2199-8531",
    doi = "https://doi.org/10.1016/j.joitmc.2025.100629",
    url = "https://www.sciencedirect.com/science/article/pii/S2199853125001647",
    keywords = "Artificial intelligence, AI in marketing, AI benefits, AI paradox, AI resistance, Automation, Professional perceptions, Technology acceptance model (TAM)",
    abstract = "Grounded in the Technology Acceptance Model (TAM), this research explores how marketing professionals perceive AI adoption, examining the paradoxical tensions between technological fascination and professional resistance that challenge traditional TAM assumptions. This study draws on an exploratory qualitative approach involving 24 international marketing professionals (with 3–30 years of experience) from Africa, Europe, the United States, and the Gulf region. Data was collected through semi-structured interviews, using purposive sampling, and continued until theoretical saturation was achieved. Data analysis is based on a thematic content analysis method. Our analysis reveals three paradoxical perceptions (favorable, unfavorable, ambivalent) and identifies a novel five-category benefit taxonomy (technological, organizational, psychological, economic, communicational) alongside six barrier categories, challenging the linear adoption models prevalent in existing literature. The results show that professionals perceive AI primarily as a complementary tool that improves their individual performance while fundamentally transforming their profession. Theoretically, this study extends TAM by incorporating professional resistance and paradoxical adoption patterns, highlighting the limitations of linear acceptance models when applied to AI adoption within creative professional contexts. The study identifies the marketing experts’ perspectives on the future of their profession, the areas with high potential for AI impact, as well as the skills needed to remain relevant in the face of increasing integration of this technology. Practically, our findings provide a framework for managing AI adoption resistance in emerging markets and guidelines for organizations navigating the AI transformation paradox. Managerial implications are formulated to guide marketing professionals in the investment and use of AI, integrating it consistently into their daily practice."
}

@article{dup_33,
    author = "Javaid, Hira and Petrescu, Constantin Cezar and Schmunk, Lisa J. and Monahan, Jack M. and O'Reilly, Paul and Garg, Manik and McGirr, Leona and Khasawneh, Mahmoud T. and {Al Lail}, Mustafa and Ganta, Deepak and Stubbs, Thomas M. and Sun, Benjamin B. and Vitsios, Dimitrios and Martin-Herranz, Daniel E.",
    title = "The impact of artificial intelligence on biomarker discovery",
    journal = "Emerging Topics in Life Sciences",
    volume = "8",
    number = "2",
    pages = "89-105",
    year = "2025",
    issn = "2397-8562",
    doi = "https://doi.org/10.1042/ETLS20243003",
    url = "https://www.sciencedirect.com/science/article/pii/S2397856225000047",
    keywords = "biomarkers, diagnostics, biomarker discovery, artificial intelligence, multi-omics, electronic health records, multi-modal data",
    abstract = "Artificial intelligence (AI) is transforming many fields, including healthcare and medicine. In biomarker discovery, AI algorithms have had a profound impact, thanks to their ability to derive insights from complex high-dimensional datasets and integrate multi-modal datatypes (such as omics, electronic health records, imaging or sensor and wearable data). However, despite the proliferation of AI-powered biomarkers, significant hurdles still remain in translating them to the clinic and driving adoption, including lack of population diversity, difficulties accessing harmonised data, costly and time-consuming clinical studies, evolving AI regulatory frameworks and absence of scalable diagnostic infrastructure. Here, we provide an overview of the AI toolkit available for biomarker discovery, and we discuss exciting examples of AI-powered biomarkers across therapeutic areas. Finally, we address the challenges ahead of us to ensure that these technologies reach patients and users globally and unlock a new era of fast innovation for precision medicine."
}

@article{dup_34,
    author = "Zhang, Yidi and Lucas, Margarida and Bem-haja, Pedro and Pedro, Luís",
    title = "The effect of student acceptance on learning outcomes: AI-generated short videos versus paper materials",
    journal = "Computers and Education: Artificial Intelligence",
    volume = "7",
    pages = "100286",
    year = "2024",
    issn = "2666-920X",
    doi = "https://doi.org/10.1016/j.caeai.2024.100286",
    url = "https://www.sciencedirect.com/science/article/pii/S2666920X24000894",
    keywords = "Student acceptance, Learning outcomes, AI videos, Short videos, Foreign language learning",
    abstract = "The use of video and paper-based materials is commonly widespread in foreign language learning (FLL). It is well established that the level of acceptance of these materials influences learning outcomes, but there is lack of evidence regarding the use and related impact of videos generated by artificial intelligence (AI) on these aspects. This paper used linear mixed models and path analysis to investigate the influence of student acceptance of AI-generated short videos on learning outcomes compared to paper-based materials. Student acceptance was assessed based on perceived ease of use (PEU), perceived usefulness (PU), attitude (A), intentions (I), and concentration (C). The results indicate that both AI-generated short videos and paper-based materials can significantly enhance learning outcomes. AI-generated short videos are more likely to be accepted by students with lower pre-test scores and may lead to more significant learning outcomes when PEU, PU, A, I and C are at higher levels. On the other hand, paper-based materials are more likely to be accepted by students with higher pre-test scores and may lead to more significant learning outcomes when PEU, PU, A, I and C are at lower levels. These findings offer empirical evidence supporting the use of AI-generated short videos in FLL and provide suggestions for selecting appropriate learning materials in different FLL contexts."
}

@article{dup_35,
    author = "Bruynseels, Koen and Asveld, Lotte and {van den Hoven}, Jeroen",
    title = "“Foundation models for research: A matter of trust?”",
    journal = "Artificial Intelligence in the Life Sciences",
    volume = "7",
    pages = "100126",
    year = "2025",
    issn = "2667-3185",
    doi = "https://doi.org/10.1016/j.ailsci.2025.100126",
    url = "https://www.sciencedirect.com/science/article/pii/S2667318525000029",
    keywords = "Foundation models, Large language models, AI agents, Epistemic, Trust, Reliance",
    abstract = "Science would not be possible without trust among experts, trust of the public in experts, and reliance on scientific instruments and methods. The rapid adoption of scientific foundation models and their use in AI agents is changing scientific practices and thereby impacting this epistemic fabric which hinges on trust and reliance. Foundation models are machine learning models that are trained on large bodies of data and can be applied to a multitude of tasks. Their application in science raises the question of whether scientific foundation models can be relied upon as a research tool and to what extent, or even be trusted as if they were research partners. Conceptual clarification of the notions of trust and reliance in science is pivotal in the face of foundation models. Trust and reliance form the glue for the increasingly distributed epistemic labour within contemporary technoscientific systems. We build on two concepts of trust in science, namely trust in science as shared values, and trust in science based on commitments to processes that provide objective claims. We analyse whether scientific foundation models are research tools to which the concept of reliance applies, or research partners that can be trustworthy or not. We consider these foundation models within their socio-technical contexts. Allocation of trust should be reserved for human agents and the organizations they operate in. Reliance applies to foundation models and artificial intelligence agents. This distinction is important to unambiguously allocate responsibility, which is crucial in maintaining the fabric of trust that underpins science."
}

@article{dup_36,
    author = "Khongkomolsakul, Waritsara and Yang, Eunhye and Dadmohammadi, Younas and Dong, Hongmin and Lin, Tiantian and Huang, Yunan and Abbaspourrad, Alireza",
    title = "Enzyme immobilization with plant-based polysaccharides through complex coacervation",
    journal = "LWT",
    volume = "219",
    pages = "117537",
    year = "2025",
    issn = "0023-6438",
    doi = "https://doi.org/10.1016/j.lwt.2025.117537",
    url = "https://www.sciencedirect.com/science/article/pii/S002364382500221X",
    keywords = "Enzyme immobilization, Phytase, Polysaccharide, Molecular docking, Protein-polysaccharide intermolecular interaction",
    abstract = "Plant-based polysaccharides (PSs) were used to immobilize phytase in a coacervate system. Molecular docking predicted the intermolecular interactions and conformations between the phytase and the polysaccharide and correlated them to the activity recovery of phytase in the coacervate complex. PSs with two different functional groups, sulfate (iota (IC), lambda (LC), and kappa (KC) carrageenan) and carboxylate (low methoxyl pectin (LMP) and sodium alginate (SA)) were investigated. The optimized conditions for coacervation and activity recovery were pH 4 with a phytase-to-polysaccharide volume ratio of 12:1. Zeta potential measurements, FTIR spectroscopy, and molecular docking confirmed that electrostatic interactions and hydrogen bonding were the main driving forces for coacervate formation. Coacervate complexes of phytase formed with LMP, SA, or KC showed a high activity retention after immobilization, with approximately 30\% yield of complex and 75\% immobilization efficiency of the phytase. The lower enzyme activity retention observed for IC and LC complexes is attributed to these PSs binding to the enzyme's active site. Overall, this work contributes to the body of knowledge about intermolecular interactions between phytase and polysaccharides and can serve as a guide to formulating stable, functional ingredients for a plant-based diet."
}

@article{dup_37,
    author = "Turner, Marianne and Lin, Angel M.Y.",
    title = "Translanguaging: Process and power in education",
    journal = "Linguistics and Education",
    volume = "83",
    pages = "101340",
    year = "2024",
    issn = "0898-5898",
    doi = "https://doi.org/10.1016/j.linged.2024.101340",
    url = "https://www.sciencedirect.com/science/article/pii/S0898589824000731",
    keywords = "Translanguaging, Monolingualism, Education, Capital, Habitus, Linguistic inequity",
    abstract = "In this article we develop translanguaging as a theoretical perspective in education by drawing together ideas of process and symbolic power. We first outline critiques of translanguaging, most particularly the issue of deconstructivism and concerns about transformative limitations. We then focus on the potential of translanguaging as a conceptual frame for how language mediates learning in the context of social inequity (schools). We primarily draw on Bakhtin's (1981) theorisation of language and Bourdieu's (1991) understanding of the relationship between language and symbolic power to suggest that taking sociohistorical context as central to translanguaging can help us to move beyond ‘internal’ structuralist debates and open up productive lines of inquiry at the intersection of language and learning."
}

@article{dup_38,
    author = "Turvey, Jake and McKay, Dana and Kaur, Sarah T and Castree, Natasha and Chang, Shanton and Lim, Megan S C",
    title = "Exploring the Feasibility and Acceptability of Technological Interventions to Prevent Adolescents’ Exposure to Online Pornography: Qualitative Research",
    journal = "JMIR Pediatrics and Parenting",
    volume = "7",
    year = "2024",
    issn = "2561-6722",
    doi = "https://doi.org/10.2196/58684",
    url = "https://www.sciencedirect.com/science/article/pii/S2561672224000762",
    keywords = "pornography, sexual health, young people, co-design, online safety, age verification, adolescents, attitudes, acceptability, usability, feasibility",
    abstract = "Background Amid growing concern over children’s access to online pornography, policy makers are looking toward new and emerging technological concepts for unexplored solutions including artificial intelligence and facial recognition. Objective This study sought to explore and ideate emerging technological interventions that are feasible, acceptable, and effective in preventing and controlling the exposure of young people to online pornographic material. Methods We conducted a series of qualitative co-design workshops with both adult (n=8; aged 32-53 years) and adolescent participants (n=4; aged 15-17 years) to ideate potential technological interventions that are feasible, acceptable, and effective at preventing and controlling the exposure of young people to online pornographic material. A story stem methodology was used to explore participants’ attitudes toward two unique technological prototypes. Results Participants expressed a generally favorable view of the proposed technological concepts but remained unconvinced of their overall utility and effectiveness in preventing the intentional viewing of pornography by young people. Age-appropriate parent-child conversations remained participants’ preferred approach to mitigating potential harms from pornographic material, with parents also expressing a desire for more educational resources to help them better navigate these discussions. User privacy and data security were a primary concern for participants, particularly surrounding the use and collection of biometric data. Conclusions Internationally, policy makers are taking action to use age assurance technologies to prevent children’s access to online pornography. It is important to consider the needs and opinions of parents and young people in the use and implementation of these technologies. Participants in this study were generally supportive of new and emerging technologies as useful tools in preventing the accidental exposure of young people to online pornographic material. However, participants remained less convinced of their ability to avert intentional viewing, with substantial concerns regarding technological efficacy, adaptability, and user privacy. Further, co-design and prototype refinement are needed to better understand user acceptability and comfortability of these new technological interventions, alongside additional research exploring sociocultural differences in information needs and user experiences."
}

@article{dup_39,
    author = "Yan, Huili and Tian, Tian and Xiong, Hao",
    title = "The power of emojis: Enhancing the willingness to adopt chatbot recommendations",
    journal = "Journal of Retailing and Consumer Services",
    volume = "87",
    pages = "104388",
    year = "2025",
    issn = "0969-6989",
    doi = "https://doi.org/10.1016/j.jretconser.2025.104388",
    url = "https://www.sciencedirect.com/science/article/pii/S0969698925001675",
    keywords = "Chatbots, Willingness to adopt recommendations, Emotion as social information model, Relationship norm orientation, Identity disclosure",
    abstract = "Chatbots have become an integral component of online services in the tourism industry. Emojis, which act as crucial nonverbal cues, have gained widespread attention because of their unique role in enhancing the emotional expression of chatbots. However, the impact of emoji use by chatbots on consumers’ willingness to adopt recommendations has yet to receive sufficient scholarly attention. On the basis of the emotion as social information (EASI) model, this study conducts three online experiments to explore the mechanisms by which emoji use by chatbots influences the willingness to adopt recommendations within the context of tourism services. The findings from the three studies indicate that (1) compared with chatbots that do not use emojis, those that incorporate emojis significantly enhance consumers’ willingness to adopt recommendations; (2) empathy and trust serve as mediators in this relationship; and (3) relationship norm orientation and identity disclosure moderate both the main effect and the mediating effects. This study contributes to the literature on emoji use in chatbots and provides practical insights for tourism companies in the design and deployment of chatbots."
}

@article{dup_40,
    author = "Wu, Fan and Fan, Lin",
    title = "A study on the innovative design of the blue Jiaxie pattern integrating extension semantics and fuzzy comprehensive evaluation",
    journal = "Results in Engineering",
    volume = "27",
    pages = "105989",
    year = "2025",
    issn = "2590-1230",
    doi = "https://doi.org/10.1016/j.rineng.2025.105989",
    url = "https://www.sciencedirect.com/science/article/pii/S2590123025020614",
    keywords = "Extension semantics, Blue Jiaxie, Innovative design of patterns, Fuzzy comprehensive evaluation",
    abstract = "In order to meet the diversified aesthetic demands of the intangible cultural heritage (ICH) market and achieve the creative transformation of Jiaxie in the contemporary context, the most representative pattern primitives are selected as the design objects according to the cultural connotation of Jiaxie, the characteristic semantic vocabularies of the pattern primitive objects are summarized and the extension theory is used to calculate the value of the extension interval of the characteristic semantic vocabulary and the correlation diagram. The semantics and correlation diagrams with larger quantitative values are selected as the reference elements of pattern innovation design for the practice of pattern innovation, and the weights of the evaluation indexes are determined by using hierarchical analysis and fuzzy comprehensive evaluation method. The satisfaction of the overall objective and hierarchical indexes of the innovation design scheme are calculated through the comparative analysis with the traditional scheme and the comparative results of satisfaction evaluation show that the innovative design scheme of blue Jiaxie based on Jiaxie semantics can better reflect the connotation of its culture, which is conducive to the expression and dissemination of cultural values, and provides certain reference for the innovative development of traditional patterns in the contemporary context."
}

@article{dup_41,
    author = "Moura, Ricardo and {Pessanha Santos}, Nuno and Catarino, Maria Eduarda",
    title = "Fishing effort and enforcement in the Azores Marine Protected Areas: How prevalent is illegal fishing?",
    journal = "Aquaculture and Fisheries",
    year = "2025",
    issn = "2468-550X",
    doi = "https://doi.org/10.1016/j.aaf.2025.05.002",
    url = "https://www.sciencedirect.com/science/article/pii/S2468550X25000632",
    keywords = "Fisheries inspection, Fisheries analysis, Economic risk, Illegal fishing, Marine life, Ocean protected areas, Azores, Marine protected areas, Data analysis, Data visualization",
    abstract = "Fishing is a significant global food source, providing protein for millions of people. The Food and Agriculture Organization (FAO) is committed to ensuring access to high-quality food, reducing hunger, and promoting sustainable fisheries to address global population growth and hunger. However, illegal, unreported, and unregulated fishing poses a significant challenge, threatening marine biodiversity and food security. Portugal has the 10th largest Exclusive Economic Zone (EEZ), with waters around mainland Portugal, the Azores, and Madeira. This research focuses on the Azores region, known for its traditional multispecific fishery around the island slopes and seamounts. The region's fisheries face data scarcity issues and complicating effective management. By combining Vessel Monitoring System (VMS) records from 2016 to 2022 and Portuguese Navy (PoN) Fiscalization Reports (FISCREP) from 2015 to 2022, it was possible to use appropriate metrics to characterize the fishing effort and analyze the effectiveness of the inspections conducted in the Azores EEZ. The Total Boat-Meter (TBM) metric combines the number and length of boats to quantify the fishing effort better. The analysis shows that the fishing effort in the protected areas is very high, highlighting the pressure on the protected ecosystems. The findings aim to assist regulatory institutions and researchers in assessing fishing pressure and promoting sustainable fisheries management in the Azores to preserve marine ecosystems."
}

@article{dup_42,
    author = "Værnesbranden, Magdalena R. and Staff, Anne Cathrine and Wiik, Johanna and Sjøborg, Katrine and Rueegg, Corina S. and Sugulle, Meryam and {Lødrup Carlsen}, Karin C. and Granum, Berit and Haugen, Guttorm and Hedlin, Gunilla and Johannessen, Camilla G. and Nordlund, Björn and Nystrand, Camilla F. and Rangberg, Anbjørg and Rehbinder, Eva M. and Rudi, Knut and Sandberg, Yvonne and Skjerven, Håvard O. and Söderhäll, Cilla and Vettukattil, Riyas and Jonassen, Christine M.",
    title = "Placental human papillomavirus infections and adverse pregnancy outcomes",
    journal = "Placenta",
    volume = "152",
    pages = "23-30",
    year = "2024",
    issn = "0143-4004",
    doi = "https://doi.org/10.1016/j.placenta.2024.05.126",
    url = "https://www.sciencedirect.com/science/article/pii/S0143400424002406",
    keywords = "Placental biopsies, Genital HPV infection, Human papillomavirus, PreventADALL, Placental dysfunction syndromes",
    abstract = "Introduction Knowledge on prevalence and association of human papillomavirus (HPV) in third trimester placentae and adverse pregnancy outcomes is limited. We investigated the prevalence of placental HPV at delivery, explored urine HPV characteristics associated with placental HPV and whether placental HPV increased the risk adverse pregnancy outcomes. Methods Pregnant women were enrolled in the Scandinavian PreventADALL mother-child cohort study at midgestation. Human papillomavirus genotyping was performed on placental biopsies collected at delivery (n = 587) and first-void urine at midgestation and delivery (n = 556). Maternal characteristics were collected by questionnaires at gestational week 18 and 34. Adverse pregnancy outcomes were registered from chart data including hypertensive disorders of pregnancy, gestational diabetes mellitus and newborns small for gestational age. Uni- and multivariable regression models were used to investigate associations. Results Placental HPV was detected in 18/587 (3 \%). Twenty-eight genotypes were identified among the 214/556 (38 \%) with midgestational urine HPV. Seventeen of the 18 women with placental HPV were midgestational HPV positive with 89 \% genotype concordance. Midgestational high-risk-(HR)-HPV and high viral loads of Any- or HR-HPV were associated with placental HPV. Persisting HPV infection from midgestation to delivery was not associated with placental HPV. Adverse pregnancy outcomes were seen in 2/556 (0.4 \%) of women with placental HPV. Discussion In this general cohort of pregnant women, the prevalence of placental HPV was 3 \%, and midgestational urinary HPV 38 \%. High HPV viral load increased the risk for placental HPV infections. We observed no increased risk for adverse pregnancy outcomes in women with placental HPV."
}

@article{dup_43,
    author = "Chien, Sufan and Sarojini, Harshini and Rajaee, Arezoo and Bayat, Mohammad and Chien, Samson and Kotwal, Girish",
    title = "Creating an Extremely Long-lasting Neuroischemic Wound Model",
    journal = "JID Innovations",
    volume = "5",
    number = "2",
    pages = "100328",
    year = "2025",
    issn = "2667-0267",
    doi = "https://doi.org/10.1016/j.xjidi.2024.100328",
    url = "https://www.sciencedirect.com/science/article/pii/S2667026724000766",
    keywords = "Animal model, Neuroischemia, Rabbit, Long term, Wound",
    abstract = "In wound study and dressing development, a lack of a suitable animal model that can recapitulate the complex pathophysiology of human chronic wounds has been a major hurdle. Chronic wounds are defined as wounds that heal with a significant delay, usually over a period >2–3 months, but no current animal wound model has such a longischemia. After a longexploration, our group has developed an animal wound model with ischemia and nerve damage lasting for at least 6 months. This model can be easily combined with other conditions such as diabetes and aging for wound mechanistic study and critical testing of dressings. This report presents the method that has significant utility in evaluating therapies that could become the future standard for screening all new wound dressings."
}

@article{dup_44,
    author = "Mutavhatsindi, Hygon and Manyelo, Charles M. and Snyders, Candice I. and {Van Rensburg}, Ilana and Kidd, Martin and Stanley, Kim and Tromp, Gerard and Dietze, Reynaldo and Thiel, Bonnie and {van Helden}, Paul D. and Belisle, John T. and Johnson, John L. and Boom, W. Henry and Walzl, Gerhard and Chegou, Novel N.",
    title = "Baseline and end-of-treatment host serum biomarkers predict relapse in adults with pulmonary tuberculosis",
    journal = "Journal of Infection",
    volume = "89",
    number = "1",
    pages = "106173",
    year = "2024",
    issn = "0163-4453",
    doi = "https://doi.org/10.1016/j.jinf.2024.106173",
    url = "https://www.sciencedirect.com/science/article/pii/S0163445324001075",
    keywords = "Tuberculosis, Treatment response, Relapse, Biomarkers, Biosignatures",
    abstract = "Summary Background There is a need for new tools for monitoring of the response to TB treatment. Such tools may allow for tailored treatment regimens, and stratify patients initiating TB treatment into different risk groups. We evaluated combinations between previously published host biomarkers and new candidates, as tools for monitoring TB treatment response, and prediction of relapse. Methods Serum samples were collected at multiple time points, from patients initiating TB treatment at research sites situated in South Africa (ActionTB study), Brazil and Uganda (TBRU study). Using a multiplex immunoassay platform, we evaluated the concentrations of selected host inflammatory biomarkers in sera obtained from clinically cured patients with and without subsequent relapse within 2 years of TB treatment completion. Results A total of 130 TB patients, 30 (23\%) of whom had confirmed relapse were included in the study. The median time to relapse was 9.7 months in the ActionTB study (n = 12 patients who relapsed), and 5 months (n = 18 patients who relapsed) in the TBRU study. Serum concentrations of several host biomarkers changed during TB treatment with IL-6, IP-10, IL-22 and complement C3 showing potential individually, in predicting relapse. A six-marker signature comprising of TTP, BMI, sICAM-1, IL-22, IL-1β and complement C3, predicted relapse, prior to the onset of TB treatment with 89\% sensitivity and 94\% specificity. Furthermore, a 3-marker signature (Apo-CIII, IP-10 and sIL-6R) predicted relapse in samples collected at the end of TB treatment with sensitivity of 71\% and specificity of 74\%. A previously identified baseline relapse prediction signature (TTP, BMI, TNF-β, sIL-6R, IL-12p40 and IP-10) also showed potential in the current study. Conclusion Serum host inflammatory biomarkers may be useful in predicting relapse in TB patients prior to the initiation of treatment. Our findings have implications for tailored patient management and require prospective evaluation in larger studies."
}

@article{dup_45,
    author = "Zhang, Shuyan and Li, Jingtan and Shen, Lin and Zhao, Zhonghao and Lee, Minjun and Qian, Kun and Sun, Naidi and Hu, Bin",
    title = "Structure and oxygen saturation recovery of sparse photoacoustic microscopy images by deep learning",
    journal = "Photoacoustics",
    volume = "42",
    pages = "100687",
    year = "2025",
    issn = "2213-5979",
    doi = "https://doi.org/10.1016/j.pacs.2025.100687",
    url = "https://www.sciencedirect.com/science/article/pii/S2213597925000060",
    keywords = "Deep learning, Photoacoustic microscopy, Sparse data, High-speed imaging, Image reconstruction",
    abstract = "Photoacoustic microscopy (PAM) leverages the photoacoustic effect to provide high-resolution structural and functional imaging. However, achieving high-speed imaging with high spatial resolution remains challenging. To address this, undersampling and deep learning have emerged as common techniques to enhance imaging speed. Yet, existing methods rarely achieve effective recovery of functional images. In this study, we propose Mask-enhanced U-net (MeU-net) for recovering sparsely sampled PAM structural and functional images. The model utilizes dual-channel input, processing photoacoustic data from 532 nm and 558 nm wavelengths. Additionally, we introduce an adaptive vascular attention mask module that focuses on vascular information recovery and design a vessel-specific loss function to enhance restoration accuracy. We simulate data from mouse brain and ear imaging under various levels of sparsity (4 ×, 8 ×, 12 ×) and conduct extensive experiments. The results demonstrate that MeU-net significantly outperforms traditional interpolation methods and other representative models in structural information and oxygen saturation recovery."
}

@article{dup_46,
    author = "Juel, Rachel and Bwire, Constance and Eddine, Hajar Chams and Mariyam, Deena and Umesh, Harshita and Alobeid, Roaa and Bonnet, Gabrielle and Milner, James and Yeung, Shunmay and Hughes, Robert",
    title = "Visualising future, sustainable cities: Insights from participatory workshops at the COP28 climate conference",
    journal = "Cities",
    volume = "165",
    pages = "106137",
    year = "2025",
    issn = "0264-2751",
    doi = "https://doi.org/10.1016/j.cities.2025.106137",
    url = "https://www.sciencedirect.com/science/article/pii/S026427512500438X",
    keywords = "Youth, Climate, Sustainability, Urban, AI, Health",
    abstract = "Climate change significantly impacts urban youth, yet they are rarely invited to contribute to sustainable urban-planning. To address this, four workshops were held during the 28th session of the United Nations Framework Convention on Climate Change Conference of Parties (COP28) in Dubai. These workshops gathered insights into the experiences of urban children and youth in cities affected by climate change through discussions with youth and other stakeholders present at COP28. Opportunities for creating healthier and more sustainable youth-focused cities were identified using a participatory approach. Youth facilitators led discussions between participants and an expert panel, and participants shared their experiences and perspectives of growing up in cities and their hopes for future youth-focused cities amidst a changing climate. Narrative was collected through an online collaboration tool, which was fed into an artificial intelligence tool to generate images, which served as triggers for further discussion. The thematic analysis of the narratives was conducted by a team of early-career researchers. Three themes were identified: the effects of climate change on urban youth, visions for healthier and more sustainable cities prioritising youth, and principles guiding action. The findings emphasize the importance of involving young people and representing children's needs in research and decision-making."
}

@article{dup_47,
    author = "Parmanto, Bambang and Aryoyudanta, Bayu and Soekinto, Timothius Wilbert and Setiawan, I Made Agus and Wang, Yuhan and Hu, Haomin and Saptono, Andi and Choi, Yong Kyung",
    title = "A Reliable and Accessible Caregiving Language Model (CaLM) to Support Tools for Caregivers: Development and Evaluation Study",
    journal = "JMIR Formative Research",
    volume = "8",
    year = "2024",
    issn = "2561-326X",
    doi = "https://doi.org/10.2196/54633",
    url = "https://www.sciencedirect.com/science/article/pii/S2561326X24004189",
    keywords = "large language model, caregiving, caregiver, informal care, carer, GPT, language model, LLM, elderly, aging, ChatGPT, machine learning, natural language processing, NLP",
    abstract = "Background In the United States, 1 in 5 adults currently serves as a family caregiver for an individual with a serious illness or disability. Unlike professional caregivers, family caregivers often assume this role without formal preparation or training. Thus, there is an urgent need to enhance the capacity of family caregivers to provide quality care. Leveraging technology as an educational tool or an adjunct to care is a promising approach that has the potential to enhance the learning and caregiving capabilities of family caregivers. Large language models (LLMs) can potentially be used as a foundation technology for supporting caregivers. An LLM can be categorized as a foundation model (FM), which is a large-scale model trained on a broad data set that can be adapted to a range of different domain tasks. Despite their potential, FMs have the critical weakness of “hallucination,” where the models generate information that can be misleading or inaccurate. Information reliability is essential when language models are deployed as front-line help tools for caregivers. Objective This study aimed to (1) develop a reliable caregiving language model (CaLM) by using FMs and a caregiving knowledge base, (2) develop an accessible CaLM using a small FM that requires fewer computing resources, and (3) evaluate the model’s performance compared with a large FM. Methods We developed a CaLM using the retrieval augmented generation (RAG) framework combined with FM fine-tuning for improving the quality of FM answers by grounding the model on a caregiving knowledge base. The key components of the CaLM are the caregiving knowledge base, a fine-tuned FM, and a retriever module. We used 2 small FMs as candidates for the foundation of the CaLM (LLaMA [large language model Meta AI] 2 and Falcon with 7 billion parameters) and adopted a large FM (GPT-3.5 with an estimated 175 billion parameters) as a benchmark. We developed the caregiving knowledge base by gathering various types of documents from the internet. We focused on caregivers of individuals with Alzheimer disease and related dementias. We evaluated the models’ performances using the benchmark metrics commonly used in evaluating language models and their reliability for providing accurate references with their answers. Results The RAG framework improved the performance of all FMs used in this study across all measures. As expected, the large FM performed better than the small FMs across all metrics. Interestingly, the small fine-tuned FMs with RAG performed significantly better than GPT 3.5 across all metrics. The fine-tuned LLaMA 2 with a small FM performed better than GPT 3.5 (even with RAG) in returning references with the answers. Conclusions The study shows that a reliable and accessible CaLM can be developed using small FMs with a knowledge base specific to the caregiving domain."
}

@article{dup_48,
    author = "Yuan, Zhiqiang and Zhong, Xueting and Huang, Wenyen and Li, Zhiyi and Tang, Xin and Tan, Qi",
    title = "GenAI-enabled microteaching lesson study: developing prospective secondary mathematics teachers’ TPACK in an online summer camp",
    journal = "International Journal for Lesson and Learning Studies",
    volume = "14",
    number = "3",
    pages = "298-317",
    year = "2025",
    issn = "2046-8253",
    doi = "https://doi.org/10.1108/IJLLS-11-2024-0273",
    url = "https://www.sciencedirect.com/science/article/pii/S2046825325000083",
    keywords = "GenAI, Pedagogical AI agent, Digital technology, GeoGebra, Microteaching lesson study, TPACK",
    abstract = "Purpose This study aims to explore the impact and mechanisms of an online summer camp incorporating generative AI (GenAI)-enabled microteaching lesson study on the technological pedagogical content knowledge (TPACK) of prospective secondary mathematics teachers (PSMTs). Design/methodology/approach A mixed-methods research approach was employed, with 21 PSMTs participating in a 9-day online summer camp that included two rounds of microteaching lesson study, expert lectures, plenary discussions, and group discussions. Data were collected using pre- and post-mathematics-specific TPACK scales, teaching artifacts, and qualitative reflections to evaluate the evolution of PSMTs’ TPACK and identify key influencing factors. Findings The study reveals statistically significant improvements across all sub-domains of the TPACK framework among PSMTs. The degree of improvement in the TPACK sub-domain varied among participants, with some experiencing significant enhancement, others moderate gains, and a few showing smaller changes. The study identifies four critical factors driving TPACK development: expert guidance, practical exploration, collaborative learning, and ongoing reflection, which enhanced PSMTs’ incorporation of digital technologies (e.g. GeoGebra, GenAI) into their teaching practices. Research limitations/implications This study demonstrates that incorporating GenAI into microteaching lesson study significantly enhances TPACK, thereby highlighting its potential for structured, scaffolded teacher professional development. Additionally, the study shows that online formats can effectively support teachers’ TPACK development, offering a replicable model for future programs. Originality/value This study innovatively incorporates GenAI into microteaching lesson study, offering a novel approach to enhance PSMTs’ TPACK. It also validates a mathematics-specific TPACK scale and identifies key factors for effective teacher professional development in technology-integrated environment."
}

@article{dup_49,
    author = "Becker, Amanda and Filipp, Mallory and Lantz, Connor and Glinton, Kristofor and Thorp, Edward B.",
    title = "HIF-1α is required to differentiate the neonatal Macrophage protein secretome from adults",
    journal = "Cellular Immunology",
    volume = "403-404",
    pages = "104861",
    year = "2024",
    issn = "0008-8749",
    doi = "https://doi.org/10.1016/j.cellimm.2024.104861",
    url = "https://www.sciencedirect.com/science/article/pii/S0008874924000649",
    keywords = ", Macrophage, Regeneration, Inflammation, Immunometabolism",
    abstract = "The immune response to stress diverges with age, with neonatal macrophages implicated in tissue regeneration versus tissue scarring and maladaptive inflammation in adults. Integral to the macrophage stress response is the recognition of hypoxia and pathogen-associated molecular patterns (PAMPs), which are often coupled. The age-specific, cell-intrinsic nature of this stress response remains vague. To uncover age-defined divergences in macrophage crosstalk potential after exposure to hypoxia and PAMPs, we interrogated the secreted proteomes of neonatal versus adult macrophages via non-biased mass spectrometry. Through this approach, we newly identified age-specific signatures in the secretomes of neonatal versus adult macrophages in response to hypoxia and the prototypical PAMP, lipopolysaccharide (LPS). Neonatal macrophages secreted proteins most consistent with an anti-inflammatory, regenerative phenotype protective against apoptosis and oxidative stress, dependent on hypoxia inducible transcription factor-1α (HIF-1α). In contrast, adult macrophages secreted proteins consistent with a pro-inflammatory, glycolytic phenotypic signature consistent with pathogen killing. Taken together, these data uncover fundamental age and HIF-1α dependent macrophage responses that may be targeted to calibrate the innate immune response during stress and inflammation."
}

@article{dup_50,
    author = "Di, Sheng-Kui and Wang, Yao-Yue and Yang, Dong and Liu, Yan-Hui and Zhang, Jing and Zheng, Wen-Zhi",
    title = "SMOTE-enhanced XGBoost for rapid seismic damage assessment of bridge portfolios",
    journal = "Soil Dynamics and Earthquake Engineering",
    volume = "199",
    pages = "109712",
    year = "2025",
    issn = "0267-7261",
    doi = "https://doi.org/10.1016/j.soildyn.2025.109712",
    url = "https://www.sciencedirect.com/science/article/pii/S0267726125005056",
    keywords = "Bridge portfolios, Post-earthquake rapid assessment, Machine learning, Class imbalance, Data augmentation",
    abstract = "Post-earthquake damage assessment of bridge portfolios faces challenges in balancing efficiency and accuracy. While machine learning offers a promising solution, it often faces difficulties due to complex damage scenarios and imbalanced data, where safe samples vastly outnumber those requiring inspection or classified as dangerous. This imbalance limits the performance of machine learning models. To address these issues, this study proposes a rapid seismic damage assessment method for bridge portfolios using a SMOTE-enhanced XGBoost model. By utilizing bridge parameters and seismic data, this method eliminates the need for time-consuming on-site inspections, enabling quick and accurate predictions of bridge safety and traffic capacity. SMOTE is used to generate synthetic samples for all categories, with sampling ratios carefully adjusted to determine the optimal configuration that maximizes accuracy and improves data balance. The enhanced XGBoost model is then trained on the balanced dataset to classify bridge conditions, effectively mitigating the impact of class imbalance. The study also compares the performance of XGBoost, Random Forest, and AdaBoost on both original and SMOTE-balanced datasets. Results indicate that the SMOTE-enhanced XGBoost model achieves a best accuracy of 83.3 \%–87.5 \%. This study integrates oversampling techniques with machine learning and proposes an automated modeling framework for imbalanced data. Its key innovation lies in the automatic determination of the optimal oversampling ratio, which is incorporated into the XGBoost training process to significantly improve classification performance and generalization ability, providing reliable support for emergency response and functional recovery."
}

@article{dup_51,
    author = "Hou, Lei and Min, Yu and Pan, Xue and Gong, Zaiwu",
    title = "Distinguishing AI-generated versus real tourism photos: Visual differences, human judgment, and deep learning detection",
    journal = "Information Processing \& Management",
    volume = "62",
    number = "5",
    pages = "104218",
    year = "2025",
    issn = "0306-4573",
    doi = "https://doi.org/10.1016/j.ipm.2025.104218",
    url = "https://www.sciencedirect.com/science/article/pii/S0306457325001591",
    keywords = "AI-generated content, Tourism photos, Tourism marketing, Deep learning models, AI content detection",
    abstract = "The widespread use of AI-generated photos in marketing raises concerns about authenticity, trust, and misinformation. Addressing these challenges requires understanding the differences between AI-generated and human-captured (real) photos and developing effective detection methods. In this study, we compiled a database of AI and real coastal-related tourism photos to analyze their visual differences, and the detection accuracy of both human and deep learning models. While real photos display diverse color schemes and richer textures, AI photos exhibit enhanced brightness and simplified textures. Despite such significant differences in color and texture features, human judgment largely fails to distinguish AI from real photos, resulting in an average accuracy of only 67.7 \%. To address this limitation, a hybrid deep learning model was developed, combining a CNN module for image processing and a dense module for integrating explicit visual features. While a single CNN module achieved an accuracy of 92.9 \%, largely outperforming human judgment, the inclusion of explicit features further improves the model’s accuracy to 96.1 \%, highlighting the importance of multimodal feature integration. The study contributes to understanding the implications of generative AI in marketing, underscores the importance of transparency for online content, and advances methodological approaches for detecting AI-generated visuals."
}

@article{dup_52,
    author = "Amadeh, Tohid and rafie, Matin and Radmanesh, Shadmehr and azizi, Alireza and Ahangarian, Ahmadreza and Fathollahi, Pourya and Ahmadloo, Hadise",
    title = "Intelligent Diet Recommendation System Powered by Artificial Intelligence for Personalized Nutritional Solutions",
    journal = "Clinical Nutrition ESPEN",
    year = "2025",
    issn = "2405-4577",
    doi = "https://doi.org/10.1016/j.clnesp.2025.09.002",
    url = "https://www.sciencedirect.com/science/article/pii/S2405457725029249",
    keywords = "Artificial Intelligence, Diet Therapy, Body Composition, Food Preferences, Feeding Behavior, InBody",
    abstract = "Abstract: Background and aims The increasing number of non-communicable diseases, such diabetes and obesity, makes it even more important to have accurate and personalized dietary solutions. Based on a lot of research, standard diet advice may not be accurate enough to meet individual health demands. The Intelligent Diet Recommendation System is an artificial intelligence-powered platform that gives personalized dietary recommendations based on extensive body composition data and cultural eating habits. Methods The Intelligent Diet Recommendation System gathers key measurements, including body mass index and body fat percentage, using cutting-edge body analysis tools. Customized diets were created using 3D body modeling technologies and machine learning algorithms. The system’s performance was evaluated by assessing the inaccuracy rate of its dietary recommendations. Results The Intelligent Diet Recommendation System made personalized diet plans based on physiological and cultural factors with an error rate of less than 3\%. Conclusions The results show that the Intelligent Diet Recommendation System is a scalable, artificial intelligence-based way to solve global health problems that makes dietary advice much more accurate and easy to find. This system offers a new way of doing nutritional therapy that could improve health outcomes around the world."
}

@article{dup_53,
    author = "Soto, David and Higashida, Manabu and Shirai, Shizuka and Ueda, Mayumi and Uranishi, Yuki",
    title = "Enhancing Learning Dynamics: Integrating Interactive Learning Environments and ChatGPT for Computer Networking Lessons",
    journal = "Procedia Computer Science",
    volume = "246",
    pages = "3595-3604",
    year = "2024",
    note = "28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)",
    issn = "1877-0509",
    doi = "https://doi.org/10.1016/j.procs.2024.09.198",
    url = "https://www.sciencedirect.com/science/article/pii/S1877050924022130",
    keywords = "Higher Education, Interactive Learning Environments, Generative AI, ChatGPT",
    abstract = "The COVID-19 pandemic has catalyzed a rapid transformation in higher education, prompting institutions to embrace online learning and e-learning as essential mechanisms for academic continuity. In this context, Interactive Learning Environments (ILEs), augmented with generative AI chatbots, represent a promising approach to enhancing the effectiveness of virtual education and interactive learning. This paper investigates the efficacy of an ILE integrated with ChatGPT in the context of computer networking education. A pilot experiment was conducted with three graduate students with basic IT networking background. The study examined the impact of integrating ChatGPT within the ILE on students’ engagement, comprehension, and overall learning outcomes. Methodological details, including learning program design, learning outcomes assessment, ILE settings, and ChatGPT integration are presented. Results from pre- and post-assessment tests, quizzes, and students’ feedback on ChatGPT’s utility as a learning aid are discussed. The findings suggest a significant improvement in students’ comprehension and performance following their engagement with the ILE while using ChatGPT as a support tool. Despite a few drawbacks reported by the students in terms of the interfaces’ ease of use, and the timely response and appropriate content delivered by ChatGPT, they were overall satisfied with the experience. The students would recommend ChatGPT for learning purposes under certain controlled environments. This study contributes to the growing body of literature on interactive learning technologies and highlights the potential of generative AI chatbots such as ChatGPT to revolutionize computer networking education in the digital age."
}

@article{dup_54,
    author = "Shilo, Anna and Raidou, Renata G.",
    title = "Visual narratives to edutain against misleading visualizations in healthcare",
    journal = "Computers \& Graphics",
    volume = "123",
    pages = "104011",
    year = "2024",
    issn = "0097-8493",
    doi = "https://doi.org/10.1016/j.cag.2024.104011",
    url = "https://www.sciencedirect.com/science/article/pii/S0097849324001468",
    keywords = "Healthcare edutainment, Misleading visualizations, Uncertainty, Visual narratives, Interactive game",
    abstract = "We propose an interactive game based on visual narratives to edutain, i.e., to educate while entertaining, broad audiences against misleading visualizations in healthcare. Uncertainty at various stages of the visualization pipeline may give rise to misleading visual representations. These comprise misleading elements that may negatively impact the audiences by contributing to misinformed decisions, delayed treatments, and a lack of trust in medical information. We investigate whether visual narratives within the setting of an educational game support recognizing and addressing misleading elements in healthcare-related visualizations. Our methodological approach focuses on three key aspects: (i) identifying uncertainty types in the visualization pipeline which could serve as the origin of misleading elements, (ii) designing fictional visual narratives that comprise several misleading elements linking to these uncertainties, and (iii) proposing an interactive game that aids the communication of these misleading visualization elements to broad audiences. The game features eight fictional visual narratives built around misleading visualizations, each with specific assumptions linked to uncertainties. Players assess the correctness of these assumptions to earn points and rewards. In case of incorrect assessments, interactive explanations are provided to enhance understanding For an initial assessment of our game, we conducted a user study with 21 participants. Our study indicates that when participants incorrectly assess assumptions, they also spend more time elaborating on the reasons for their mistakes, indicating a willingness to learn more. The study also provided positive indications on game aspects such as memorability, reinforcement, and engagement, while it gave us pointers for future improvement."
}

@article{dup_55,
    author = "{Amini Farsani}, Mohammad and Stapleton, Paul and Jamali, Hamid R.",
    title = "Charting L2 argumentative writing: A systematic review",
    journal = "Journal of Second Language Writing",
    volume = "68",
    pages = "101208",
    year = "2025",
    issn = "1060-3743",
    doi = "https://doi.org/10.1016/j.jslw.2025.101208",
    url = "https://www.sciencedirect.com/science/article/pii/S1060374325000335",
    keywords = "Argumentative writing, Research synthesis, L2",
    abstract = "Instilling in students the ability to argue effectively is one of the most important responsibilities of educators at any level. This may be why so much focus is put on the quality of reasoning in schools and universities both in L1 and L2 contexts, especially when arguments appear in written form. Research conducted on L2 written argumentation has covered myriad aspects in educational contexts which calls for the need to provide a big picture view of the types of studies conducted and their associated scholars. Accordingly, in the present study, we reviewed 108 articles on L2 argumentative writing research from 2003 to 2023 adopting a synthetic approach to investigate the impact of theoretical orientations, research methodology, and the main topics of interest. The findings revealed L2 written argumentation has gathered global interest across all educational levels. Primary topic focuses were on language usage, pedagogy, and assessment, while there was less interest in the actual quality of the argumentative content. The most frequently used theoretical frameworks were theories related to modified Toulmin models, cognition, society and culture (i.e., sociocultural theory), linguistic complexity, and genre. Research methodologies were mostly quantitative. Implications and recommendations for those working on L2 argumentative writing are discussed."
}

@article{dup_56,
    author = "{Berber Sardinha}, Tony",
    title = "AI-generated vs human-authored texts: A multidimensional comparison",
    journal = "Applied Corpus Linguistics",
    volume = "4",
    number = "1",
    pages = "100083",
    year = "2024",
    issn = "2666-7991",
    doi = "https://doi.org/10.1016/j.acorp.2023.100083",
    url = "https://www.sciencedirect.com/science/article/pii/S2666799123000436",
    keywords = "Artificial intelligence, Multidimensional analysis, Register",
    abstract = "The goal of this study is to assess the degree of resemblance between texts generated by artificial intelligence (GPT) and (written and spoken) texts produced by human individuals in real-world settings. A comparative analysis was conducted along the five main dimensions of variation that Biber (1988) identified. The findings revealed significant disparities between AI-generated and human-authored texts, with the AI-generated texts generally failing to exhibit resemblance to their human counterparts. Furthermore, a linear discriminant analysis, performed to measure the predictive potential of dimension scores for identifying the authorship of texts, demonstrated that AI-generated texts could be identified with relative ease based on their multidimensional profile. Collectively, the results underscore the current limitations of AI text generation in emulating natural human communication. This finding counters popular fears that AI will replace humans in textual communication. Rather, our findings suggest that, at present, AI's ability to capture the intricate patterns of natural language remains limited."
}

@article{dup_57,
    author = "Li, Xiaoran and Li, Yanyan and Mao, Ziqi and Gong, Rushi",
    title = "The effects of group awareness support combined with collaboration scripts on adaptive social regulation in promoting students' challenge awareness and social regulation strategies",
    journal = "Computers \& Education",
    volume = "235",
    pages = "105324",
    year = "2025",
    issn = "0360-1315",
    doi = "https://doi.org/10.1016/j.compedu.2025.105324",
    url = "https://www.sciencedirect.com/science/article/pii/S0360131525000922",
    keywords = "Cooperative/collaborative learning, Teaching/learning strategies, Improving classroom teaching",
    abstract = "Adaptive social regulation refers to students' strategic adaptation of social regulatory actions in response to challenges. If group members enact social regulation strategies to cope with encountered challenges, adaptive social regulation occurs; if not, maladaptive behavior may arise. Adaptive social regulation contributes to effective collaboration, but two obstacles may hinder this process: (a) a lack of challenge awareness and (b) insufficient social regulation strategies. Research indicates that the combination of group awareness support and collaboration scripts could be a promising approach to foster adaptive social regulation. A current limitation is that previous studies have mainly focused on fostering the regulation of just a very limited set of specific challenges, neglecting the promotion of students' awareness and regulation of multiple challenges during collaborative learning. Therefore, this study proposes a combined group awareness support and collaboration scripts tool, referred to as CACS. The research was conducted in a semester-long authentic English academic writing course. Thirty-two postgraduates were randomly assigned to five groups using the CACS tool (experimental condition) and five groups without it (control condition). This study not only quantitatively validates the effectiveness of combining group awareness support with collaboration scripts in enhancing adaptive social regulation, but also qualitatively explores the underlying mechanisms through interviews. The quantitative findings demonstrate that the groups in the experimental condition showed improvements in challenge awareness, adaptive social regulation, and the overall adoption of social regulation strategies. The qualitative analysis identifies key features of group awareness support and collaboration scripts that contribute to adaptive social regulation, including increasing students’ knowledge of challenges, facilitating a shared understanding of challenging situations, and encouraging the adoption of social regulation strategies through effective reflection."
}

@article{dup_58,
    author = "McClure, Jennifer B and Heffner, Jaimee L and Krakauer, Chloe and Mun, Sophia and Catz, Sheryl L",
    title = "A Novel mHealth App for Smokers Living With HIV Who Are Ambivalent About Quitting Smoking: Formative Research and Randomized Feasibility Study",
    journal = "JMIR Formative Research",
    volume = "8",
    year = "2024",
    issn = "2561-326X",
    doi = "https://doi.org/10.2196/58063",
    url = "https://www.sciencedirect.com/science/article/pii/S2561326X24003810",
    keywords = "HIV, tobacco, nicotine, smoking cessation, mobile health, mHealth, motivation, ambivalence, app, mobile phone",
    abstract = "Background More people who smoke and are living with HIV now die from tobacco-related diseases than HIV itself. Most people are ambivalent about quitting smoking and want to quit someday but not yet. Scalable, effective interventions are needed to motivate and support smoking cessation among people ambivalent about quitting smoking (PAQS) who are living with HIV. Objective This study aims to develop an app-based intervention for PAQS who are living with HIV and assess its feasibility, acceptability, and potential impact. Results of this study will inform plans for future research and development. Methods In phase 1, PAQS living with HIV (n=8) participated in user-centered design interviews to inform the final intervention app design and recruitment plan for a subsequent randomized pilot study. In phase 2, PAQS living with HIV were randomized to either a standard care control app or a similar experimental app with additional content tailored for PAQS and those with HIV. Participants were followed for 3 months. Feasibility focused on recruitment, retention, and participants’ willingness to install the app. The study was not powered for statistical significance. Indices of acceptability (satisfaction and use) and impact (smoking behavior change and treatment uptake) were assessed via automated data and self-report among those who installed and used the app (n=19). Results Recruitment for both study phases was a challenge, particularly via web-based and social media platforms. Enrollment success was greater among people living with HIV recruited from a health care provider and research registry. Once enrolled, retention for the phase 2 randomized study was good; 74\% (14/19) of the participants completed the 3-month follow-up. Phase 1 findings suggested that PAQS living with HIV were receptive to using an app-based intervention to help them decide whether, when, and how to stop smoking, despite not being ready to quit smoking. Phase 2 findings further supported this conclusion based on feedback from people who agreed to use an app, but group differences were observed. Indices of acceptability favored the experimental arm, including a descriptively higher mean number of sessions and utilization badges. Similarly, indices of potential impact were descriptively higher in the experimental arm (proportion reducing smoking, making a quit attempt, or calling free tobacco quitline). No participants in either arm quit smoking at the 3-month follow-up. Conclusions On the basis of this formative work, PAQS living with HIV may be receptive to using a mobile health–based app intervention to help them decide whether, when, or how to stop using tobacco. Indices of acceptability and impact indicate that additional research and development are warranted. Trial Registration ClinicalTrials.gov NCT05339659; https://clinicaltrials.gov/study/NCT05339659"
}

@article{dup_59,
    author = "Piccarozzi, Michela and Silvestri, Cecilia and Fici, Luigi and Silvestri, Luca",
    title = "Metaverse: a possible sustainability enabler in the transition from Industry 4.0 to 5.0.",
    journal = "Procedia Computer Science",
    volume = "232",
    pages = "1839-1848",
    year = "2024",
    note = "5th International Conference on Industry 4.0 and Smart Manufacturing (ISM 2023)",
    issn = "1877-0509",
    doi = "https://doi.org/10.1016/j.procs.2024.02.006",
    url = "https://www.sciencedirect.com/science/article/pii/S1877050924001832",
    keywords = "Metaverse, Sustainability, Industry 4.0, Industry 5.0",
    abstract = "Industry 4.0 has supported and changed the way companies operate over the last decade. Today, the increasing focus on sustainability in all its pillars is initiating a critical process and revision about the Fourth Industrial Revolution. A new scenario characterized by human-centricity, resilience and social sustainability, named Industry 5.0, is emerging. In this transition process, new and old enabling technologies are appearing, among them the Metaverse. Although its actual functions are not yet fully investigated, from different perspective this tool could adequately support the definition of Industry 5.0 by creating a symbiotic ecosystem between companies, workers and consumers. Against this backdrop, the aim of this paper is to investigate, through a systematic literature review, the role of the Metaverse in the approach to sustainability in order to understand in which way this technology can be useful for the transition. The results may support policy makers, managers and practitioners in understanding the role of Metaverse in sustainability and in the new wave of Industrial Revolution. Limits and future research steps are also discussed."
}

@article{dup_60,
    author = "Locke, Sean and Osborne, Jenna",
    title = "Determining the Right Levels of Health Coaching and Heart Rate Variability Biofeedback in a Workplace Behavior Change Intervention: Multiphase Optimization Strategy Preparation Study",
    journal = "JMIR Formative Research",
    volume = "8",
    year = "2024",
    issn = "2561-326X",
    doi = "https://doi.org/10.2196/47181",
    url = "https://www.sciencedirect.com/science/article/pii/S2561326X24000982",
    keywords = "mobile health, mHealth, behavior change, stress management, intervention, pilot study, heart rate variability, health coaching, coach, coaching, coaches, work-related stress, stress, wellness, burnout, behavioral intervention, work, worker, workers, employee, employees, occupational health, job, satisfaction, web-based, remote, corporate, web analytics, biofeedback, survey, surveys, interview, interviews, experience, experiences, attitude, attitudes, opinion, opinion, perception, perceptions, perspective, perspectives, acceptance",
    abstract = "Background Work-related stress is associated with poor job performance and negative health outcomes. Changing health behaviors through corporate wellness programs can improve physical and mental health and help employees manage stress. This project sought to pilot the potential addition of brief coaching and biofeedback to an 8-week web-based self-help program to improve employee stress using the multiphase optimization strategy. Objective This study aims to determine which candidate components will be tested in a later optimization phase and at what dose they will be tested, examine the feasibility and acceptability of delivering the different components, investigate whether the outcomes can be feasibly measured, and review evidence to build a conceptual model before the optimization phase. Methods The study was positioned within the preparation phase of the multiphase optimization strategy. It is a 2×2×2×2 design with 4 components: 2 types of health coaching and 2 types of biofeedback. All components were tested by turning them on or off. A total of 16 adult office workers (mean age 40, SD 14.3 years; n=15 women) completed an 8-week self-paced web-based stress management and health behavior change program and were randomly assigned to 1 of the 16 conditions, created from a combination of the 4 candidate components. Assessments included web analytics, surveys, and interviews regarding program recommendations, likes, and dislikes. Results Findings from the interviews provided suggestions to improve the intervention (eg, separating wellness from stress content) and trial conduct (eg, streamlining the onboarding process). On average, participants logged into the wellness program 83 times (range 36-291), with 75\% (12/16) participant retention and 67\% (8/12) survey completion. There were no reported problems with coaching or obtaining data from interviews or apps. The interview findings suggested potential mediators to include and assess in a future conceptual model. Conclusions The results provided areas to improve the intervention content and trial methods. Instead of progressing to the next scheduled large-scale optimization phase, our plan to iterate through a second preparation phase after making changes to the protocol, apps, and corporate coaching partner."
}

@article{dup_61,
    author = "Duan, Huarui and Chi, Xiaojing and Yang, Xuehua and Pan, Shengnan and Liu, Xiuying and Gao, Peixiang and Zhang, Fangyuan and Zhang, Xinhui and Dong, Xuemeng and Liao, Yi and Yang, Wei",
    title = "Computational design and improvement of a broad influenza virus HA stem targeting antibody",
    journal = "Structure",
    volume = "33",
    number = "3",
    pages = "489-503.e5",
    year = "2025",
    issn = "0969-2126",
    doi = "https://doi.org/10.1016/j.str.2025.01.002",
    url = "https://www.sciencedirect.com/science/article/pii/S0969212625000024",
    keywords = "computational biology, RosettaAntibodyDesign, influenza A virus, hemagglutinin, neutralizing antibody",
    abstract = "Summary Broadly neutralizing antibodies (nAbs) are vital therapeutic tools to counteract both pandemic and seasonal influenza threats. Traditional strategies for optimizing nAbs generally rely on labor-intensive, high-throughput mutagenesis screens. Here, we present an innovative structure-based design framework for the optimization of nAbs, which integrates epitope-paratope analysis, computational modeling, and rational design approaches, complemented by comprehensive experimental assessment. This approach was applied to optimize MEDI8852, a nAb targeting the stalk region of influenza A virus hemagglutinin (HA). The resulting variant, M18.1.2.2, shows a marked enhancement in both affinity and neutralizing efficacy, as demonstrated both in vitro and in vivo. Computational modeling reveals that this improvement can be attributed to the fine-tuning of interactions between the antibody’s side-chains and the epitope residues that are highly conserved across the influenza A virus HA stalk. Our dry-wet iterative protocol for nAb optimization presented here yielded a promising candidate for influenza intervention."
}

@article{dup_62,
    author = "Fasano, Francesco and Bartoli, Chiara and Cappa, Francesco and Boccardelli, Paolo",
    title = "Exploring the impact of AI on Web3 decentralized platform business model innovation",
    journal = "Journal of Engineering and Technology Management",
    volume = "78",
    pages = "101911",
    year = "2025",
    issn = "0923-4748",
    doi = "https://doi.org/10.1016/j.jengtecman.2025.101911",
    url = "https://www.sciencedirect.com/science/article/pii/S0923474825000529",
    keywords = "Artificial Intelligence, Platform, Decentralized, Blockchain, Business model, Innovation, Web3",
    abstract = "Advancements in information technologies have revolutionized business models (BMs), which are now increasingly based on digital platforms. The spread of Web3 has led to further development in this direction, giving rise to platform business models enabled by blockchain technology. At the same time, the advent of artificial intelligence (AI) has further expanded opportunities to innovate BMs. In this study we examine how the integration of AI influences BMs in blockchain-based platforms. We find that the integration of AI plays a key role in the three main dimensions of platform business models: value creation, value delivery, and value capture. We demonstrate, in particular, how AI enhances operational efficiency, strategic governance, and decision-making in Web3 platforms enabled by blockchains. Moreover, AI optimizes personalization, matching processes, and interactions in decentralized platforms. AI also fosters innovation in decentralized platform BMs and requires a skilled workforce. This research underscores how AI can improve performance in blockchain-based platforms, advancing scientific knowledge of decentralized platforms and offering recommendations for managers and policymakers on how to innovate their BMs and leverage AI to maximize value across platforms."
}

@article{dup_63,
    author = "Rosenberger, Julian and Wolfrum, Lukas and Weinzierl, Sven and Kraus, Mathias and Zschech, Patrick",
    title = "CareerBERT: Matching resumes to ESCO jobs in a shared embedding space for generic job recommendations",
    journal = "Expert Systems with Applications",
    volume = "275",
    pages = "127043",
    year = "2025",
    issn = "0957-4174",
    doi = "https://doi.org/10.1016/j.eswa.2025.127043",
    url = "https://www.sciencedirect.com/science/article/pii/S0957417425006657",
    keywords = "Job consultation, Job markets, Job recommendation system, BERT, NLP",
    abstract = "The rapidly evolving labor market, driven by technological advancements and economic shifts, presents significant challenges for traditional job matching and consultation services. In response, we introduce an advanced support tool for career counselors and job seekers based on CareerBERT, a novel approach that leverages the power of unstructured textual data sources, such as resumes, to provide more accurate and comprehensive job recommendations. In contrast to previous approaches that primarily focus on job recommendations based on a fixed set of concrete job advertisements, our approach involves the creation of a corpus that combines data from the European Skills, Competences, and Occupations (ESCO) taxonomy and EURopean Employment Services (EURES) job advertisements, ensuring an up-to-date and well-defined representation of general job titles in the labor market. Our two-step evaluation approach, consisting of an application-grounded evaluation using EURES job advertisements and a human-grounded evaluation using real-world resumes and Human Resources (HR) expert feedback, provides a comprehensive assessment of CareerBERT’s performance. Our experimental results demonstrate that CareerBERT outperforms both traditional and state-of-the-art embedding approaches while showing robust effectiveness in human expert evaluations. These results confirm the effectiveness of CareerBERT in supporting career consultants by generating relevant job recommendations based on resumes, ultimately enhancing the efficiency of job consultations and expanding the perspectives of job seekers. This research contributes to the field of NLP and job recommendation systems, offering valuable insights for both researchers and practitioners in the domain of career consulting and job matching."
}

@article{dup_64,
    author = "Lin, Guanjing and House, John and Chen, Yimin and Granderson, Jessica and Zhang, Wanpeng",
    title = "Active multi-mode data analysis to improve fault diagnosis in AHUs",
    journal = "Energy and Buildings",
    volume = "337",
    pages = "115621",
    year = "2025",
    issn = "0378-7788",
    doi = "https://doi.org/10.1016/j.enbuild.2025.115621",
    url = "https://www.sciencedirect.com/science/article/pii/S0378778825003512",
    keywords = "Fault diagnosis, Air handling unit, Multi-mode data analysis, Energy management and information system, Smart building",
    abstract = "Faults in heating, ventilation and air conditioning systems can lead to increased energy consumption, occupant comfort issues, and reduced equipment lifetime. Commercial fault detection and diagnosis (FDD) tools has been increasingly deployed in U.S. commercial buildings. While they are helping to achieve energy efficiency and operational reliability, there remain gaps in their fault diagnostic capabilities. The diagnostic results often contain multiple distinct candidate root causes (CRCs) or offer no insight into CRCs. This study developed a novel active rule-based multi-mode data analysis method to enhance diagnostic resolution by applying proven rule sets and additional new rules to data from multiple known operational modes. The proposed method was demonstrated using enhanced air handling unit performance assessment rule sets and validated with the simulated data of two air handling units. New metrics, namely, reduced number of CRCs and improvement ratio, were developed to quantify the improvement of fault diagnostic resolution. The validation results showed that the proposed method effectively reduced the number of CRCs in contrast to analyzing data solely for a single mode of operation. It achieved a median improvement ratio of 80\% in 19 test cases."
}

@article{dup_65,
    author = "Mukherjee, Shreya",
    title = "Factors impeding buy now, pay later (BNPL) adoption in India: A mixed-method approach",
    journal = "Journal of Retailing and Consumer Services",
    volume = "87",
    pages = "104402",
    year = "2025",
    issn = "0969-6989",
    doi = "https://doi.org/10.1016/j.jretconser.2025.104402",
    url = "https://www.sciencedirect.com/science/article/pii/S096969892500181X",
    keywords = "Buy now pay later (BNPL), Decision making trial and evaluation laboratory (DEMATEL), Financial technology adoption, Mixed-methods, Behavioral finance, Netnography, Innovation resistance theory",
    abstract = "Buy Now, Pay Later (BNPL) services are reshaping digital credit access in India, yet their adoption remains limited due to complex and interrelated consumer barriers. While previous research has explored general fintech or digital payment adoption, there is a significant gap in understanding BNPL-specific barriers, particularly how these barriers influence one another within India’s distinct socio-economic and regulatory landscape. India’s rapid fintech growth, large unbanked population, evolving regulatory environment, and uneven levels of digital and financial literacy make it a unique and urgent case for such inquiry. Thus, this study aims to identify and rank the key barriers to BNPL adoption in the Indian context and analyze their causal interrelationships, and adopts a sequential mixed-methods design for the same. In the qualitative phase, a netnographic analysis of BNPL app reviews—supported by existing literature (specifically Innovation Resistance Theory) and expert insights—was used to identify barriers. In the quantitative phase, the ‘Decision-Making Trial and Evaluation Laboratory’ (DEMATEL) method was employed to analyze seven identified barriers, categorize them into causal and effect groups, and assess their interdependencies. The findings reveal digital illiteracy as the most influential causal barrier, affecting others such as inertia, privacy concerns, hidden fees and high penalty fees, and negative credit profiles. Impulse buying and regulatory concerns also emerged as key causal factors. The study offers practical recommendations, such as financial education, responsible lending, and regulatory reform, and contributes to BNPL literature by applying a novel methodological lens to an underexplored market. These insights can guide stakeholders seeking to responsibly scale BNPL adoption in India."
}

@article{dup_66,
    author = "España, Sergio and {van der Maaten}, Chris and Gulden, Jens and Pastor, Óscar",
    title = "Ethical reasoning methods for ICT: What they are and when to use them",
    journal = "Data \& Knowledge Engineering",
    volume = "155",
    pages = "102373",
    year = "2025",
    issn = "0169-023X",
    doi = "https://doi.org/10.1016/j.datak.2024.102373",
    url = "https://www.sciencedirect.com/science/article/pii/S0169023X24000971",
    keywords = "Conceptual modelling, Ethics, Ethical reasoning, Sustainability assessment, Method engineering, Situational factors",
    abstract = "Information and communication technology (ICT) brings about numerous advantages across various domains of our lives. However, alongside these benefits, there is a growing awareness of its potential negative ethical, social, and environmental impacts. Consequently, stakeholders ranging from conceptual modellers to policy makers often find themselves grappling with ethical considerations stemming from ICT engineering and usage. This paper presents a review of 10 ethical reasoning methods suitable for the ICT domain. We have employed a method engineering technique to author metamodels for the methods, which were subsequently subjected to validation by experts proficient in the respective methods. Following a situational method engineering approach, we have also characterised each ethical reasoning method and validated the characterisation with the experts. This has allowed us to develop a tool that helps select the method that is most suitable for a given ethical reasoning situation. Furthermore, we deliberate on the practical application of ethical reasoning methods within conceptual modelling contexts. We are confident that we have laid the groundwork for further research into ethical reasoning of ICT, with a specific emphasis on its role during conceptual modelling."
}

@article{dup_67,
    author = "Ni, Hsiao-Ping and Liu, Chi-Yun and Paul, Fermodelie and Chong, Wai Oswald and Chou, Jui-Sheng",
    title = "Enhancing supply chain resilience and efficiency of HVAC systems in semiconductor manufacturing facilities using graph-based large multimodal models",
    journal = "Applied Energy",
    volume = "398",
    pages = "126420",
    year = "2025",
    issn = "0306-2619",
    doi = "https://doi.org/10.1016/j.apenergy.2025.126420",
    url = "https://www.sciencedirect.com/science/article/pii/S030626192501150X",
    keywords = "Large multimodal model, Graph neural network, HVAC systems, Semiconductor manufacturing facilities, Supply chain management, Circular economy",
    abstract = "Semiconductor manufacturing facilities (SMFs) demand ultra-precise environmental conditions maintained by specialized HVAC systems, critical for a resilient and sustainable semiconductor supply chain. While AI-driven solutions have been applied to generic supply chain optimization, they often fail in addressing the unique challenges of SMFs, where HVAC systems must maintain sub-0.1 °C temperature stability, account for 40–60 \% of facility energy consumption, and comply with stringent cleanroom standards. This paper proposes an innovative framework that integrates graph-based large multimodal models (G-LMMs), enhanced by graph neural networks (GNNs), to optimize SMF HVAC supply chains across the Design, Construction, Installation, Maintenance, and Operation (DCIMO) phases. GNNs enable the capture and analysis of complex relationships within HVAC systems, facilitating real-time anomaly detection and optimized material flows. Unlike conventional AI models, G-LMMs combine GNNs with multimodal data processing to achieve three key advancements: (1) real-time anomaly detection, (2) automated compliance monitoring, and (3) circular economy integration through resource reuse. G-LMMs enhance supply chain visibility by harmonizing diverse data types while meeting SMFs' precision requirements. As the first framework to unify GNNs and multimodal AI for HVAC optimization, this approach represents a paradigm shift in sustainable semiconductor manufacturing, with broader implications for industries reliant on precision-controlled environments."
}

@article{dup_68,
    author = "Thakkar, Prit and Khatri, Sachi and Dobariya, Drashti and Patel, Darpan and Dey, Bishwajit and Singh, Alok Kumar",
    title = "Advances in materials and machine learning techniques for energy storage devices: A comprehensive review",
    journal = "Journal of Energy Storage",
    volume = "81",
    pages = "110452",
    year = "2024",
    issn = "2352-152X",
    doi = "https://doi.org/10.1016/j.est.2024.110452",
    url = "https://www.sciencedirect.com/science/article/pii/S2352152X24000379",
    keywords = "Material science, Machine learning, Battery, Supercapacitor, Energy technology",
    abstract = "The increasing global need for energy supply in modern society has created a pressing need to explore new materials for renewable energy technologies. However, conventional trial and error methods in materials science are often tedious as well as costly, making it challenging to meet the growing demands. In recent years, machine learning (ML) become a prominent research strategy transfigure the discovery of materials. This review offers a concise summary of the elementary ML procedures and widely used algorithms in the field of materials science. It particularly emphasizes the latest advancements in utilizing ML for predicting material properties and developing materials for energy-related fields like Li-Ion batteries, Super-Capacitors, and Hybrid Systems. Furthermore, the review discusses the contributions of ML to experimental research. This review intents to serve as a guiding resource for future developments of ML in materials science."
}

@article{dup_69,
    author = "Nawn, Debaleena and Hassan, Sk. Sarif and Sil, Moumita and Ghosh, Ankita and Goswami, Arunava and Basu, Pallab and Dayhoff, Guy W. and Lundstrom, Kenneth and Uversky, Vladimir N.",
    title = "The distal-proximal relationships among the human moonlighting proteins: Evolutionary hotspots and Darwinian checkpoints",
    journal = "International Journal of Biological Macromolecules",
    volume = "259",
    pages = "128998",
    year = "2024",
    issn = "0141-8130",
    doi = "https://doi.org/10.1016/j.ijbiomac.2023.128998",
    url = "https://www.sciencedirect.com/science/article/pii/S014181302305897X",
    keywords = "Moonlighting proteins, Phylogeny, Distal-proximal, Promiscuous proteins, Signature-features",
    abstract = "Moonlighting proteins, known for their ability to perform multiple, often unrelated functions within a single polypeptide chain, challenge the traditional “one gene, one protein, one function” paradigm. As organisms evolved, their genomes remained relatively stable in size, but the introduction of post-translational modifications and sub-strategies like protein promiscuity and intrinsic disorder enabled multifunctionality. Enzymes, in particular, exemplify this phenomenon, engaging in unrelated processes alongside their primary catalytic roles. This study employs a systematic, quantitative informatics approach to shed light on human moonlighting protein sequences. Phylogenetic analyses of human moonlighting proteins are presented, elucidating the distal-proximal relationships among these proteins based on sequence-derived quantitative features. The findings unveil the captivating world of human moonlighting proteins, urging further investigations in the emerging field of moonlighting proteomics, with the potential for significant contributions to our understanding of multifunctional proteins and their roles in diverse cellular processes and diseases."
}

@article{dup_70,
    author = "Nutarelli, Federico and Edet, Samuel and Gnecco, Giorgio and Riccaboni, Massimo",
    title = "Predicting the technological complexity of global cities based on unsupervised and supervised machine learning methods",
    journal = "Journal of Economic Behavior \& Organization",
    volume = "234",
    pages = "107011",
    year = "2025",
    issn = "0167-2681",
    doi = "https://doi.org/10.1016/j.jebo.2025.107011",
    url = "https://www.sciencedirect.com/science/article/pii/S0167268125001301",
    keywords = "Innovation, Urban studies, Technological change, Artificial intelligence, Global cities",
    abstract = "Analyzing and predicting innovation in global cities, i.e. cities with a high degree of economic integration into the world economy, can help identify emerging technologies and inform investment decisions that facilitate talent attraction and urban planning. In this context, the contribution of this paper is to analyze the technological complexity of global cities. We show how the combination of state-of-the-art network community detection and supervised machine learning can support local innovation and development policies by predicting the future competitiveness of global cities based on an up-to-date patent dataset. Network community detection with the Poisson stochastic block model is used as an unsupervised pre-processing step to find cities with similar innovation profiles and create homogeneous training sets that improve predictive power, interpretability and computational efficiency in a subsequent supervised learning task. The paper then compares the use of different supervised machine learning methods to predict the future competitiveness of global cities. Tree-based methods turn out to achieve better prediction performance than other supervised machine learning methods on various metrics based on the ground truth derived from historical patent production. The analytical method used in this paper can help policy makers identify technology sectors where global cities could focus their future investments and provide information on the temporal evolution of geographical patterns related to innovation."
}

@article{dup_71,
    author = "Vera-Amaro, Guillermo and Rojano-Cáceres, José Rafael",
    title = "Towards accessible website design through artificial intelligence: A systematic literature review",
    journal = "Information and Software Technology",
    volume = "186",
    pages = "107821",
    year = "2025",
    issn = "0950-5849",
    doi = "https://doi.org/10.1016/j.infsof.2025.107821",
    url = "https://www.sciencedirect.com/science/article/pii/S0950584925001600",
    keywords = "Web accessibility, Systematic literature review, Artificial intelligence, Wcag, Machine learning, Large language models",
    abstract = "Context: Web accessibility ensures that individuals with disabilities can access, navigate, and interact with online content effectively. Despite the availability of the Web Content Accessibility Guidelines (WCAG), significant barriers persist, largely due to the complexity of their implementation. Artificial intelligence (AI), particularly machine learning models, has emerged as a promising avenue to address these challenges, offering solutions for evaluation, correction, and content generation. Objective: This study aims to systematically review the intersection of web accessibility and AI by evaluating how AI-based methods enhance compliance with accessibility standards over the period 2019–2025, assessing their efficacy and alignment with WCAG principles. Methods: A systematic literature review (SLR) was conducted in three phases: planning, execution, and reporting. Research questions were formulated guiding the selection of search terms and strategies. A systematic search process was implemented, complemented by a snowballing technique to ensure comprehensive coverage of relevant studies. The quality of selected studies was rigorously assessed using predefined criteria, and data extraction was carried out following established best practices. The analysis combined narrative synthesis for qualitative insights and bibliometric techniques for quantitative evaluation. Results: From 277 studies, 31 were identified as relevant, highlighting AI’s primary contributions to generating alternative text for images, automating compliance assessments, providing correction suggestions, and designing alternative interfaces to enhance accessibility. Advances in large language models (LLMs) further demonstrate their potential for facilitating the creation of accessible content. Conclusions: AI presents significant potential to improve web accessibility by streamlining evaluation processes and supporting the creation of accessible content. However, further research is needed to address limitations such as inconsistent compliance and the lack of focus on non-visual disabilities. These findings underline the importance of leveraging AI to facilitate inclusive web design practices while ensuring adherence to accessibility standards."
}

@article{dup_72,
    author = "Rungruangjit, Warinrampai and Mongkol, Kulachet and Piriyakul, Intaka and Charoenpornpanichkul, Kitti",
    title = "The power of human-like virtual-influencer-generated content: Impact on consumers’ willingness to follow and purchase intentions",
    journal = "Computers in Human Behavior Reports",
    volume = "16",
    pages = "100523",
    year = "2024",
    issn = "2451-9588",
    doi = "https://doi.org/10.1016/j.chbr.2024.100523",
    url = "https://www.sciencedirect.com/science/article/pii/S2451958824001568",
    keywords = "Artificial intelligence, Emotional content, Generated content, Uses and gratifications theory, Virtual influencer, Willingness to follow",
    abstract = {The swift progress in machine learning algorithms, artificial intelligence, and interactive immersive media technologies has led to the introduction of computer-generated imagery on Instagram. This feature, so-called “human-like virtual influencers (VIs)", has revolutionized the way people interact with technology. Using a combination of cutting-edge AI technologies, in a novel application of computer vision algorithms, and large language models to extract the content posted by two popular human-like VIs on Instagram, the present study is the first to categorize and classify types of human-like virtual-influencer-generated content. Quantitative methods, such as partial least squares structural equation modeling (PLS-SEM), were used to examine the impact of human-like virtual-influencer-generated content on consumers' willingness to follow as well as purchase intentions. The information was gathered from 650 Thai customers. The findings showed that consumers' willingness to follow and purchase intentions were significantly influenced by the positive effects of emotional appeal content, which includes relational, entertaining, positive emotion, and negative emotion content. These effects outweighed those of rational appeal content, such as informative and remunerative content, as well as authenticity appeal content. Meanwhile, disclosing sponsored content had no effect on consumers' willingness to follow. The theoretical underpinnings of uses and gratifications (U\&G) theory, parasocial relationships and Richins' hierarchical model of emotions are confirmed and expanded upon in this work, and the suggested inclusive approach also significantly advances the expanding corpus of research on VIs. Our research also provides a contribution to the recent literature on human-like VI marketing.}
}

@article{dup_73,
    author = "Giamattei, Luca and Guerriero, Antonio and Pietrantuono, Roberto and Russo, Stefano",
    title = "Causal reasoning in Software Quality Assurance: A systematic review",
    journal = "Information and Software Technology",
    volume = "178",
    pages = "107599",
    year = "2025",
    issn = "0950-5849",
    doi = "https://doi.org/10.1016/j.infsof.2024.107599",
    url = "https://www.sciencedirect.com/science/article/pii/S0950584924002040",
    keywords = "Causal reasoning, Causal discovery, Causal inference, Software quality",
    abstract = "Context: Software Quality Assurance (SQA) is a fundamental part of software engineering to ensure stakeholders that software products work as expected after release in operation. Machine Learning (ML) has proven to be able to boost SQA activities and contribute to the development of quality software systems. In this context, Causal Reasoning is gaining increasing interest as a methodology to go beyond a purely data-driven approach by exploiting the use of causality for more effective SQA strategies. Objective: Provide a broad and detailed overview of the use of causal reasoning for SQA activities, in order to support researchers to access this research field, identifying room for application, main challenges and research opportunities. Methods: A systematic review of the scientific literature on causal reasoning for SQA. The study has found, classified, and analyzed 86 articles, according to established guidelines for software engineering secondary studies. Results: Results highlight the primary areas within SQA where causal reasoning has been applied, the predominant methodologies used, and the level of maturity of the proposed solutions. Fault localization is the activity where causal reasoning is more exploited, especially in the web services/microservices domain, but other tasks like testing are rapidly gaining popularity. Both causal inference and causal discovery are exploited, with the Pearl’s graphical formulation of causality being preferred, likely due to its intuitiveness. Tools to favor their application are appearing at a fast pace — most of them after 2021. Conclusions: The findings show that causal reasoning is a valuable means for SQA tasks with respect to multiple quality attributes, especially during V\&V, evolution and maintenance to ensure reliability, while it is not yet fully exploited for phases like requirements engineering and design. We give a picture of the current landscape, pointing out exciting possibilities for future research."
}

@article{dup_74,
    author = "Muhammad, Sibtain and Ahmad, Haroon and Yan, Yuqian and Chen, Xin and Muhammad, Saz and Maridevaru, Madappa C. and Roy, Shubham and Wang, Zun and Zhang, Yinghe and Guo, Bing",
    title = "Hemicyanine-based fluorescent probes: Advancements in biomedical sensing and activity-based detection",
    journal = "Coordination Chemistry Reviews",
    volume = "534",
    pages = "216602",
    year = "2025",
    issn = "0010-8545",
    doi = "https://doi.org/10.1016/j.ccr.2025.216602",
    url = "https://www.sciencedirect.com/science/article/pii/S0010854525001729",
    keywords = "Hemicyanine dyes, NIR fluorescence probes, Biomarker detection, Non-intrusive, Imaging, Polymethine dyes",
    abstract = "Near-infrared (NIR) fluorescent probes have revolutionized in vivo imaging by enabling the real-time detection of biomarkers for disease diagnosis and drug screening. Among these, donor-π-acceptor (D-π-A) architecture of hemicyanine dyes have gained attention for their high fluorescence quantum yield, ease in structural versatility, and good capability to construct activatable probes. Hemicyanine-based NIR activatable probes (HNAPs) leverage intramolecular charge transfer (ICT) mechanisms for precise, biomarker-responsive fluorescence activation, making them invaluable tools in preclinical and clinical research. This review highlights the principles of molecular design and applications of HNAPs for detecting key biomarkers associated with several diseases, including as skin conditions, digestive problems, cancer, inflammation, and acute organ failure. These probes enable real-time imaging with high specificity, addressing critical clinical challenges in early diagnosis and monitoring disease progression. Moreover, the translational potential of HNAPs lies in their capacity for non-invasive imaging and targeted biomarker detection, paving the way for innovations in imaging-guided diagnosis and treatment strategies. The versatility of hemicyanine scaffolds and their ability to be tailored for diverse applications underscore their unique value in bioimaging. This progress emphasizes the transformative potential of HNAPs in advancing precision diagnostics and improving clinical outcomes. We hope this review would stimulate interest among wide researchers and expedite the clinic translation for HNAPs."
}

@article{dup_75,
    author = "Rosseel, Hannes and {van Waterschoot}, Toon",
    title = "A state-of-the-art review on acoustic preservation of historical worship spaces through auralization",
    journal = "Signal Processing",
    volume = "234",
    pages = "109992",
    year = "2025",
    issn = "0165-1684",
    doi = "https://doi.org/10.1016/j.sigpro.2025.109992",
    url = "https://www.sciencedirect.com/science/article/pii/S0165168425001069",
    keywords = "Acoustic preservation, Historical worship spaces, Room acoustics, Auralization",
    abstract = "Historical Worship Spaces (HWS) are significant architectural landmarks which hold both cultural and spiritual value. The acoustic properties of these spaces play a crucial role in historical and contemporary religious liturgies, rituals, and ceremonies, as well as in the performance of sacred music. However, the original acoustic characteristics of these spaces are often at risk due to repurposing, renovations, natural disasters, or deterioration over time. This paper presents a comprehensive review of the current state of research on the acquisition, analysis, and synthesis of acoustics, with a focus on HWS. An example case study of the Nassau chapel in Brussels, Belgium, is presented to demonstrate the application of these techniques for the preservation and auralization of historical worship space acoustics. The paper concludes with a discussion of the challenges and opportunities in the field, and outlines future research directions."
}

@article{dup_76,
    author = "Li, Pengjun and Zhao, Qixin and Liu, Yingmin and Zhong, Chao and Wang, Jinlong and Lyu, Zhihan",
    title = "Survey and Prospect for Applying Knowledge Graph in Enterprise Risk Management",
    journal = "Computers, Materials and Continua",
    volume = "78",
    number = "3",
    pages = "3825-3865",
    year = "2024",
    issn = "1546-2218",
    doi = "https://doi.org/10.32604/cmc.2024.046851",
    url = "https://www.sciencedirect.com/science/article/pii/S1546221824003618",
    keywords = "Knowledge graph, enterprise risk, risk identification, risk management, review",
    abstract = "Enterprise risk management holds significant importance in fostering sustainable growth of businesses and in serving as a critical element for regulatory bodies to uphold market order. Amidst the challenges posed by intricate and unpredictable risk factors, knowledge graph technology is effectively driving risk management, leveraging its ability to associate and infer knowledge from diverse sources. This review aims to comprehensively summarize the construction techniques of enterprise risk knowledge graphs and their prominent applications across various business scenarios. Firstly, employing bibliometric methods, the aim is to uncover the developmental trends and current research hotspots within the domain of enterprise risk knowledge graphs. In the succeeding section, systematically delineate the technical methods for knowledge extraction and fusion in the standardized construction process of enterprise risk knowledge graphs. Objectively comparing and summarizing the strengths and weaknesses of each method, we provide recommendations for addressing the existing challenges in the construction process. Subsequently, categorizing the applied research of enterprise risk knowledge graphs based on research hotspots and risk category standards, and furnishing a detailed exposition on the applicability of technical routes and methods. Finally, the future research directions that still need to be explored in enterprise risk knowledge graphs were discussed, and relevant improvement suggestions were proposed. Practitioners and researchers can gain insights into the construction of technical theories and practical guidance of enterprise risk knowledge graphs based on this foundation."
}

@article{dup_77,
    author = "Wang, Yong and Deng, Zhi and Zhao, Jiaxi and Kopiev, Victor Feliksovich and Gao, Donglai and Chen, Wen-Li",
    title = "Progress in beamforming acoustic imaging based on phased microphone arrays: Algorithms and applications",
    journal = "Measurement",
    volume = "242",
    pages = "116100",
    year = "2025",
    issn = "0263-2241",
    doi = "https://doi.org/10.1016/j.measurement.2024.116100",
    url = "https://www.sciencedirect.com/science/article/pii/S0263224124019857",
    keywords = "Phased microphone arrays, Acoustic imaging, Beamforming, Source location, Time-delay estimation",
    abstract = "Beamforming acoustic imaging technology, utilizing phased microphone arrays, enables precise sound source localization and finds widespread application in aerodynamic wind tunnel testing, acoustic signal recognition, and mechanical fault diagnosis. This paper presents a comprehensive review of beamforming evolution, detailing its mathematical foundations and diverse applications in acoustic imaging. Various beamforming methodologies are critically analyzed using wind tunnel test data, and an overview of correction methods for external interferences and array optimization approaches is provided. Through this examination, the strengths and limitations of each method are highlighted, offering insights for future research. Additionally, potential future enhancements, including paradigm-shift approaches to advance beamforming capabilities, are explored, suggesting directions for further innovation. This review aims to establish a foundation for newcomers to the field, stimulate academic discussion, and drive ongoing research in acoustic imaging. By elucidating beamforming complexities, correction methods, and optimization techniques, this study seeks to enhance collective knowledge and support continued advancements in this technology."
}

@article{dup_78,
    author = "Han, Zhonghua and Qiao, Jianling and Zhang, Liwen and Chen, Qing and Yang, Han and Ding, Yulin and Zhang, Keshi and Song, Wenping and Song, Bifeng",
    title = "Recent progress of efficient low-boom design and optimization methods",
    journal = "Progress in Aerospace Sciences",
    volume = "146",
    pages = "101007",
    year = "2024",
    issn = "0376-0421",
    doi = "https://doi.org/10.1016/j.paerosci.2024.101007",
    url = "https://www.sciencedirect.com/science/article/pii/S0376042124000332",
    keywords = "Sonic boom, Supersonic transport, Low-boom design, Surrogate-based optimization, Adjoint method",
    abstract = "Reducing the sonic boom to a community-acceptable level is a fundamental challenge in the configuration design of the next-generation supersonic transport aircraft. This paper conducts a survey of recent progress in developing efficient low-boom design and optimization methods, and provides a perspective on the state-of-the-art and future directions. First, the low- and high-fidelity sonic boom prediction methods used in metric of low-boom design are briefly introduced. Second, efficient low-boom inverse design methods are reviewed, such as the classic Jones–Seebass–George–Darden (JSGD) method (and its variants), the high-fidelity near-field-overpressure-based method, and the mixed-fidelity method. Third, direct numerical optimization methods for low-boom designs, including the gradient-, surrogate-, and deep-learning-based optimization methods, are reviewed. Fourth, the applications of low-boom design and optimization methods to representative low-boom configurations are discussed, and the challenging demands for commercially viable supersonic transports are presented. In addition to providing a comprehensive summary of the existing research, the practicality and effectiveness of the developed methods are assessed. Finally, key challenges are identified, and further research directions such as full-carpet-low-boom-driven multidisciplinary design optimization considering mission requirements are recommended."
}

@article{dup_79,
    author = "Chakraborty, Rajat and Naskar, Ruchira",
    title = "Role of human physiology and facial biomechanics towards building robust deepfake detectors: A comprehensive survey and analysis",
    journal = "Computer Science Review",
    volume = "54",
    pages = "100677",
    year = "2024",
    issn = "1574-0137",
    doi = "https://doi.org/10.1016/j.cosrev.2024.100677",
    url = "https://www.sciencedirect.com/science/article/pii/S1574013724000613",
    keywords = "Deepfake, Facial biomechanics, Generative AI, Physiological signal, rPPG, Social engineering",
    abstract = "AI based multimedia content generation, already having achieved hyper-realism, deeply influences human perception and trust. Since emerging around late 2017, deepfake technology has rapidly gained popularity due to its diverse applications, raising significant concerns regarding its malicious and unethical use. Although many deepfake detectors have been developed by forensic researchers in recent years, there is an urgent need for robust detectors that can overcome demographic, social, and cultural barriers in identifying deepfakes. To identify a human as a human, to distinguish a person from a synthetic entity, the literature faces compelling necessity to introduce deepfake detectors that can withstand all forms of demographic and social biases. (Multiple researches have been conducted in recent times to prove the existence of social and demographic biases in synthetic media detectors.) In this article, we examine human physiological signals as the foundation for robust deepfake detectors, and present a survey of recent developments in deepfake detection research that relies on human physiological signals and facial biomechanics. We perform in-depth analysis of the techniques to understand the contribution of human physiology in deepfake detection. Hence, we comprehend how human physiology based deepfake detectors fare by exploiting the inherent robustness of physiological signals, in contrast to other existing detectors."
}

@incollection{dup_80,
    editor = "Mourtzis, Dimitris",
    author = "Mourtzis, Dimitris",
    title = "2 - Industry 4.0 and smart manufacturing",
    booktitle = "Manufacturing from Industry 4.0 to Industry 5.0",
    publisher = "Elsevier",
    pages = "13-61",
    year = "2024",
    isbn = "978-0-443-13924-6",
    doi = "https://doi.org/10.1016/B978-0-443-13924-6.00002-8",
    url = "https://www.sciencedirect.com/science/article/pii/B9780443139246000028",
    keywords = "Computer science, operations management, information systems, computing, human-centered computing, systems engineering, software engineering, human–computer interaction, robotics, technology management, knowledge management, specific industry, data science, sustainability engineering, applied computing, sustainable development, computing methodology",
    abstract = "Industry 4.0 and smart manufacturing are the latest technological advancements that have revolutionized the manufacturing industry. Industry 4.0 refers to the Fourth Industrial Revolution, which involves the integration of digital technologies such as the Internet of Things, Big Data, and Artificial Intelligence into the manufacturing process. Next, smart manufacturing is the application of Industry 4.0 technologies to improve the efficiency, productivity, and flexibility of manufacturing systems, processes, and services. Industry 4.0 and smart manufacturing have several benefits, such as improved production efficiency, reduced costs, enhanced product quality, and increased agility in responding to market changes. However, implementing these technologies requires significant investment in infrastructure, skilled personnel, and technology upgrades. To address these challenges and fully leverage the potential of Industry 4.0 and smart manufacturing, manufacturers need to develop a clear strategy, which includes identifying the areas of the business that can benefit the most from the technologies. In addition, manufacturers need to train their workforce to use and maintain the new technologies, while also addressing concerns about job displacement. In summary, Industry 4.0 and smart manufacturing offer significant potential for manufacturers to improve their operations, reduce costs, and stay competitive. However, it requires careful planning and investment to fully realize the benefits."
}

@article{dup_81,
    author = "Bernardes, Gabriel and Bozza, Beatriz and Motta, Marina and Mattos, Paulo and Fischer, Ronald",
    title = "Semantic meaning means a lot: Exploring the role of semantics in the development of a Big Five taxonomy",
    journal = "Journal of Research in Personality",
    volume = "115",
    pages = "104570",
    year = "2025",
    issn = "0092-6566",
    doi = "https://doi.org/10.1016/j.jrp.2024.104570",
    url = "https://www.sciencedirect.com/science/article/pii/S0092656624001181",
    keywords = "Personality taxonomy, Big Five taxonomy, Language and personality, Lexical hypothesis, Lexical approach",
    abstract = "Developing a Big Five adjective taxonomy in Brazilian Portuguese, we explored the effects of linguistic properties in our classification processes. The first two studies implement top-down (expert ratings) and bottom-up (self-ratings from a community sample; N = 500) strategies for taxonomy classification and validation. We identified a clear five-factor structure with 171 adjectives supporting the Big Five. Study 3 correlated frequency of use and the semantic dimensions of valence, arousal, and dominance to Big Five measures for each adjective. We found weak effects of frequency, but systematic effects of semantic dimensions with expert ratings and component loadings, that were congruent with differences and overlaps between the five traits. We discuss the potential role of linguistic effects on personality structure and assessment."
}

@article{dup_82,
    author = "Isingizwe, Josiane and Eiris, Ricardo and {Jalil Al-Bayati}, Ahmed",
    title = "Enhancing safety training engagement through immersive storytelling: A case study in the residential construction",
    journal = "Safety Science",
    volume = "179",
    pages = "106631",
    year = "2024",
    issn = "0925-7535",
    doi = "https://doi.org/10.1016/j.ssci.2024.106631",
    url = "https://www.sciencedirect.com/science/article/pii/S0925753524002212",
    keywords = "Immersive storytelling, Residential construction, Safety training, Learning engagement, Fall hazards, Eye-tracking",
    abstract = "Virtual safety training environments are increasingly utilized to support the development of safety knowledge and increase hazard identification skills in construction. One of the emerging techniques for virtual safety training is immersive storytelling. However, current studies have not explored how the inclusion or exclusion of storytelling within immersive safety training systems produces learning gains. Specifically, this study explores learning through the lens of engagement – behavioral, cognitive, and emotional. The residential construction industry was used as a case study to explore this research gap. Residential workers were assessed through a between-subject experimental design. Two safety training conditions were employed for this evaluation using a between-subject experiment – (1) immersive storytelling; and (2) immersive non-storytelling. The experimental comparison revealed that using immersive storytelling led to increases in behavioral learning and cognitive learning, allowing trainees to effectively identify openings and scaffold fall hazard categories. On the other hand, trainee emotional learning engagement did not change between immersive storytelling and immersive non-storytelling conditions. This study contributes to the existing body of knowledge by providing evidence on how using or not using storytelling can affect learning in the context of safety for fall hazards in residential construction. Practical implications for academicians and industry practitioners for the implementation of storytelling in immersive training systems are provided in the study."
}

@article{dup_83,
    author = "Rique, Thiago and Perkusich, Mirko and Gorgônio, Kyller and Almeida, Hyggo and Perkusich, Angelo",
    title = "Constructing the graphical structure of expert-based Bayesian networks in the context of software engineering: A systematic mapping study",
    journal = "Information and Software Technology",
    volume = "177",
    pages = "107586",
    year = "2025",
    issn = "0950-5849",
    doi = "https://doi.org/10.1016/j.infsof.2024.107586",
    url = "https://www.sciencedirect.com/science/article/pii/S0950584924001915",
    keywords = "Bayesian networks, Bayesian network structure, Expert knowledge, Software engineering, Systematic mapping",
    abstract = "Context: In scenarios where data availability issues hinder the applications of statistical causal modeling in software engineering (SE), Bayesian networks (BNs) have been widely used due to their flexibility in incorporating expert knowledge. However, the general understanding of how the graphical structure, i.e., the directed acyclic graph (DAG), of these models is built from domain experts is still insufficient. Objective: This study aims to characterize the SE landscape of constructing the graphical structure of BNs, including their potential for causal modeling. Method: We conducted a systematic mapping study employing a hybrid search strategy that combines a database search with parallel backward and forward snowballing. Results: Our mapping included a total of 106 studies. Different methods are commonly combined to construct expert-based BN structures. These methods span across data gathering \& analysis (e.g., interviews, focus groups, literature research, grounded theory, and statistical analysis) and reasoning mechanisms (e.g., using idioms combined with the adoption of lifecycle models, risk-centric modeling, and other frameworks to guide BN construction). We found a lack of consensus regarding validation procedures, particularly critical when modeling cause–effect relationships from knowledge. Additionally, expert-based BNs are mainly applied at the tactical level to address problems related to software engineering management and software quality. Challenges in creating expert-based structures include validation procedures, experts’ availability, expertise level, and structure complexity handling. Key recommendations involve empirical validation, participatory involvement, and balance between adaptation to organizational constraints and model construction requirements. Conclusion: The construction of expert-based BN structures in SE varies in rigor, with some methods being systematic while others appear ad hoc. To enhance BN application, reducing expert knowledge subjectivity, enhancing methodological rigor, and clearly articulating the construction rationale is essential. Addressing these challenges is crucial for improving the reliability of causal inferences drawn from these models, ultimately leading to better-informed decisions in SE practices."
}

@article{dup_84,
    author = "Baird, Sarah and Choonara, Shakira and Azzopardi, Peter S and Banati, Prerna and Bessant, Judith and Biermann, Olivia and Capon, Anthony and Claeson, Mariam and Collins, Pamela Y and {De Wet-Billings}, Nicole and Dogra, Surabhi and Dong, Yanhui and Francis, Kate L and Gebrekristos, Luwam T and Groves, Allison K and Hay, Simon I and Imbago-Jácome, David and Jenkins, Aaron P and Kabiru, Caroline W and Kennedy, Elissa C and Li, Luo and Lu, Chunling and Ma, Jun and McGovern, Terry and Mensa-Kwao, Augustina and Mojola, Sanyu A and Nagata, Jason M and Olumide, Adesola O and Omigbodun, Olayinka and O'Sullivan, Molly and Prost, Audrey and Requejo, Jennifer H and Shawar, Yusra R and Shiffman, Jeremy and Silverman, Avi and Song, Yi and Swartz, Sharlene and Tamambang, Rita and Urdal, Henrik and Ward, Joseph L and Patton, George C and Sawyer, Susan M and Ezeh, Alex and Viner, Russell M",
    title = "A call to action: the second Lancet Commission on adolescent health and wellbeing",
    journal = "The Lancet",
    volume = "405",
    number = "10493",
    pages = "1945-2022",
    year = "2025",
    issn = "0140-6736",
    doi = "https://doi.org/10.1016/S0140-6736(25)00503-3",
    url = "https://www.sciencedirect.com/science/article/pii/S0140673625005033"
}

@article{dup_85,
    author = "Quintais, João Pedro",
    title = "Generative AI, copyright and the AI Act",
    journal = "Computer Law \& Security Review",
    volume = "56",
    pages = "106107",
    year = "2025",
    issn = "2212-473X",
    doi = "https://doi.org/10.1016/j.clsr.2025.106107",
    url = "https://www.sciencedirect.com/science/article/pii/S0267364925000020",
    keywords = "Generative AI, AI Act, AI, Copyright, Text and data mining, Transparency, Remuneration",
    abstract = "This paper provides a critical analysis of the Artificial Intelligence (AI) Act's implications for the European Union (EU) copyright acquis, aiming to clarify the complex relationship between AI regulation and copyright law while identifying areas of legal ambiguity and gaps that may influence future policymaking. The discussion begins with an overview of fundamental copyright concerns related to generative AI, focusing on issues that arise during the input, model, and output stages, and how these concerns intersect with the text and data mining (TDM) exceptions under the Copyright in the Digital Single Market Directive (CDSMD). The paper then explores the AI Act's structure and key definitions relevant to copyright law. The core analysis addresses the AI Act's impact on copyright, including the role of TDM in AI model training, the copyright obligations imposed by the Act, requirements for respecting copyright law—particularly TDM opt-outs—and the extraterritorial implications of these provisions. It also examines transparency obligations, compliance mechanisms, and the enforcement framework. The paper further critiques the current regime's inadequacies, particularly concerning the fair remuneration of creators, and evaluates potential improvements such as collective licensing and bargaining. It also assesses legislative reform proposals, such as statutory licensing and AI output levies, and concludes with reflections on future directions for integrating AI governance with copyright protection."
}

@article{dup_86,
    author = "Farhan, Muhammad and Shah, Nadir and Wang, Lei and Muntean, Gabriel-Miro and Song, Houbing Herbert",
    title = "RDG-TE: Link reliability-aware DRL-GNN-based traffic engineering in SDN",
    journal = "Expert Systems with Applications",
    volume = "265",
    pages = "125963",
    year = "2025",
    issn = "0957-4174",
    doi = "https://doi.org/10.1016/j.eswa.2024.125963",
    url = "https://www.sciencedirect.com/science/article/pii/S0957417424028306",
    keywords = "Software defined network, Graph Neural Network, Deep Reinforcement Learning, Traffic engineering",
    abstract = "The existing advanced machine learning approaches based on Graph Neural Networks (GNN) for efficient traffic engineering (TE) in Software Defined Networking (SDN) overlook consideration of link reliability values. Link reliability is a very important parameter, directly linked to end-to-end delay for data packet transmission, and can be used to improve the delivery performance. This research article proposes two versions of RDG-TE, a novel model that integrates Deep Reinforcement Learning (DRL) and GNN in order to solve efficiently network TE problems by considering link reliability in both model training and reward computation. The proposed model enables improved performance by more accurately predicting the SDN network behavior in case of link failure. Testing results show that, in comparison to the closest state-of-art approach, our proposed approach reduces the number of disturbed flows by 24.19\% and the hop count by 35.38\%while also increases the reliable route prediction accuracy by 40.17\%."
}

@article{dup_87,
    author = "Wu, Wei and Yang, Yawen and Qiao, Tianlu and Peng, Haipeng",
    title = "Recent development on online public opinion communication and early warning technologies: Survey",
    journal = "Expert Systems with Applications",
    volume = "284",
    pages = "127823",
    year = "2025",
    issn = "0957-4174",
    doi = "https://doi.org/10.1016/j.eswa.2025.127823",
    url = "https://www.sciencedirect.com/science/article/pii/S0957417425014459",
    keywords = "Online public opinion, Public opinion communication, Public opinion analyzing, Public opinion warning, Artificial intelligence",
    abstract = "The rapid development of the Internet and communication technologies has led to the emergence of online public opinion, which plays a crucial role in disseminating information and guiding the public. However, due to its large volume of data and fast-paced changes, automated monitoring of online public opinion is challenging. Currently, advancements in artificial intelligence (AI) technology provides new solutions for detecting and early warning of online public opinion. This paper reviews the literature in the field of online public opinion research over the years. Firstly, it systematically elucidates the formation mechanism and dissemination model of online public opinion. Secondly, it focuses on the analysis of public opinion monitoring technology in the era of artificial intelligence, clarifying the research branches of online public opinion early warning technology. Finally, it identifies the shortcomings in current research on online public opinion and proposes directions for future research."
}

@article{dup_88,
    author = "Khatri, Puja and Duggal, Harshleen Kaur and Lim, Weng Marc and Thomas, Asha and Shiva, Atul",
    title = "Student well-being in higher education: Scale development and validation with implications for management education",
    journal = "The International Journal of Management Education",
    volume = "22",
    number = "1",
    pages = "100933",
    year = "2024",
    issn = "1472-8117",
    doi = "https://doi.org/10.1016/j.ijme.2024.100933",
    url = "https://www.sciencedirect.com/science/article/pii/S1472811724000041",
    keywords = "Higher education, Management education, Student well-being, Scale development, Scale validation, SDG3",
    abstract = "Student well-being (SWB) encompasses the physical, psychological, and social wellness of students, aspects increasingly at risk in the high-pressure environment of higher education. Marked by intense workloads, unmet expectations, and uncertainties around degree completion and employment, the higher education sector faces a growing challenge in maintaining and enhancing SWB. Current instruments for assessing SWB are limited in scope, failing to capture its multifaceted nature comprehensively. Addressing this gap, our research adopts a rigorous multi-study, multi-method, and multi-sample approach to develop and validate a multi-dimensional scale that effectively captures the nuances of SWB. This process encompassed five methodical stages: scale generation, scale purification, scale refinement, scale validation, and scale generalizability. The resulting SWB scale, encompassing five key dimensions—academic well-being, financial well-being, physical well-being, psychological resilience well-being, and relational well-being—provides a sophisticated tool for measuring and improving SWB in higher education contexts. Crucially, this paper extends beyond the scale development to explore the profound implications of this research for management education. By integrating SWB into management curricula and institutional cultures, this study underscores the potential for higher education to significantly contribute to Sustainable Development Goal 3: Good Health and Well-being. It highlights how nurturing SWB in management education can foster more resilient, empathetic, and socially responsible future leaders, addressing a critical need in contemporary business environments and society at large."
}

@incollection{dup_89,
    editor = "Farsangi, Ehsan Noroozinejad and Noori, Mohammad and Yang, T.Y and Sarhosis, Vasilis and Mirjalili, Seyedali and Skibniewski, Mirosław J.",
    author = "Irfan, Muhammad and Musarat, Muhammad Ali and Alaloul, Wesam Salah and Ghufran, Maria",
    title = "Chapter 8 - Energy efficiency solutions in the digitalized construction sector",
    booktitle = "Digital Transformation in the Construction Industry",
    publisher = "Woodhead Publishing",
    pages = "139-164",
    year = "2025",
    series = "Woodhead Publishing Series in Civil and Structural Engineering",
    isbn = "978-0-443-29861-5",
    doi = "https://doi.org/10.1016/B978-0-443-29861-5.00008-1",
    url = "https://www.sciencedirect.com/science/article/pii/B9780443298615000081",
    keywords = "Energy efficiency, digitalization, digitized construction sector, energy efficiency solutions, sustainable development.",
    abstract = "Energy efficiency refers to the optimized utilization of energy by applying energy-efficient solutions. These solutions encompass various strategies, such as the integration of renewable energy sources with artificial intelligence (AI) and generative AI in construction, advancements in energy storage solutions for buildings, the use of AI for predictive maintenance and energy optimization, the incorporation of AI and building information modeling (BIM), the utilization of robotics, and the implementation of blockchain technology for transparent energy transactions. These energy-efficient solutions can potentially guide stakeholders in transforming the conventional construction industry into a digitized one. Given the significance of energy-efficient solutions in digitized construction, this chapter aims to analyze the current trends and opportunities for implementation in the construction sector. This analysis will consider the various procedures, tools, and technologies available to industry stakeholders."
}

@article{dup_90,
    author = "Mustapha, K.B.",
    title = "A survey of emerging applications of large language models for problems in mechanics, product design, and manufacturing",
    journal = "Advanced Engineering Informatics",
    volume = "64",
    pages = "103066",
    year = "2025",
    issn = "1474-0346",
    doi = "https://doi.org/10.1016/j.aei.2024.103066",
    url = "https://www.sciencedirect.com/science/article/pii/S1474034624007171",
    keywords = "Pre-trained language models, Large language models, Generative AI, Generative pre-trained transformer, Mechanical engineering, Engineering design, Manufacturing, Mechanics, Intelligent digital twins, Intelligent maintenance, Creativity",
    abstract = "In the span of three years, the application of large language models (LLMs) has accelerated across a multitude of professional sectors. Amid this development, a new collection of studies has manifested around leveraging LLMs for segments of the mechanical engineering (ME) field. Concurrently, it has become clear that general-purpose LLMs faced hurdles when deployed in this domain, partly due to their training on discipline-agnostic data. Accordingly, there is a recent uptick of derivative ME-specific LLMs being reported. As the research community shifts towards these new LLM-centric solutions for ME-related problems, the shift compels a deeper look at the diffusion of LLMs in this emerging landscape. Consequently, this review consolidates the diversity of ME-tailored LLMs use cases and identifies the supportive technical stacks associated with these implementations. Broadly, the review demonstrates how various categories of LLMs are re-shaping concrete aspects of engineering design, manufacturing and applied mechanics. At a more specific level, it uncovered emerging LLMs’ role in boosting the intelligence of digital twins, enriching bidirectional communication within the human-cyber-physical infrastructure, advancing the development of intelligent process planning in manufacturing and facilitating inverse mechanics. It further spotlights the coupling of LLMs with other generative models for promoting efficient computer-aided conceptual design, prototyping, knowledge discovery and creativity. Finally, it revealed training modalities/infrastructures necessary for developing ME-specific language models, discussed LLMs' features that are incongruent with typical engineering workflows, and concluded with prescriptive approaches to mitigate impediments to the progressive adoption of LLMs as part of advanced intelligent solutions."
}

@article{dup_91,
    author = "Radu, Iulian and Yuan, Josia and Huang, Xiaomeng and Schneider, Bertrand",
    title = "Charting opportunities and guidelines for augmented reality in makerspaces through prototyping and co-design research",
    journal = "Computers \& Education: X Reality",
    volume = "2",
    pages = "100008",
    year = "2023",
    issn = "2949-6780",
    doi = "https://doi.org/10.1016/j.cexr.2023.100008",
    url = "https://www.sciencedirect.com/science/article/pii/S2949678023000028",
    keywords = "Augmented reality, Makerspaces, Co-design, STEM, Classroom integration",
    abstract = "Makerspace environments are becoming popular project-based learning spaces where students interact with physical objects and peer collaboration, while developing 21st century skills and engaging with science, technology, engineering, and math (STEM) topics. At the same time, augmented reality (AR) technology, which combines physical objects with digital visualizations, is becoming increasingly applicable for makerspace activities and has potential to address challenges for student learning in makerspaces. However, there is a lack of understanding of how to use and integrate AR in real makerspace environments. In this research we use a co-design methodology to address the following questions: (1) How can AR be useful for education in makerspaces? (2) How are students impacted by the process of co-designing AR technology? and (3) What are practical considerations for integrating AR in makerspaces? We engaged in a co-design process in a semester-long makerspace course attended by 18 students in a graduate school of education. Through this process, we generated six prototypes with seven student co-designers, exploring AR use in design, fabrication, programming, electronics, and training. We also identified areas where AR technology can benefit makerspaces, such as teaching STEM skills, facilitating construction activities, enhancing contextualization of learning, and debugging. We observed that students participating in co-design demonstrated improved understanding of technology design, enthusiasm for engaging with makerspaces and AR, and increased critical thinking about AR technology. These results suggest considerations and guidelines for integrating AR technology into makerspace environments."
}

@article{dup_92,
    title = "Table of Contents",
    journal = "The Journal of Pharmacology and Experimental Therapeutics",
    volume = "389",
    pages = "i-xxvi",
    year = "2024",
    issn = "0022-3565",
    doi = "https://doi.org/10.1016/S0022-3565(24)17260-6",
    url = "https://www.sciencedirect.com/science/article/pii/S0022356524172606"
}

@article{dup_93,
    author = "Wu, Yijin and Li, Zirun and Guo, Bingrui and He, Shanshan and Liu, Bijing and Liu, Xiaojie and He, Shan and Guo, Donghui",
    title = "New paradigm of distributed artificial intelligence for LLM implementation and its key technologies",
    journal = "Computer Science Review",
    volume = "59",
    pages = "100817",
    year = "2026",
    issn = "1574-0137",
    doi = "https://doi.org/10.1016/j.cosrev.2025.100817",
    url = "https://www.sciencedirect.com/science/article/pii/S1574013725000930",
    keywords = "Distributed artificial intelligence, Cloud computing, Caching, Load-balancing, Reasoning, LLM",
    abstract = "With the Internet’s development and information technology advancement, current network applications and services, such as e-commerce, industrial automation, and vehicular automation, have experienced substantial expansion. Foundation models, represented by large language models (LLMs), have emerged in response to growing demands. Their broad range of applications has brought significant advancements to various industries. While such developments have improved people’s economic lives and social activities, the challenges posed by the rapid growth of data volume and network traffic cannot be overlooked. Intelligent systems aimed at enhancing knowledge computation and learning capabilities are gradually gaining attention. Nevertheless, efficient and flexible intelligent systems are still in their early stages, leaving ample space for further optimization. This study provides an overview of Distributed Artificial Intelligence (DAI) with its related paradigm, briefly introduces the evolution of LLMs, and proposes a novel optimization framework named PCD Tri-Tuning for DAI workflows: leveraging caching-related technologies to enhance perceptual capabilities, adopting load-balancing techniques for computational optimization, and developing reasoning methodologies and cooperation techniques to improve decision-making. Subsequently, the study examines the pivotal role of the proposed optimization framework in practical domains such as e-commerce, smart manufacturing, and vehicular automation while also discussing the challenges and outlining strategies for further development."
}

@article{dup_94,
    author = "Hagl, Christina and Kanitz, Rouven and Gonzalez, Katerina and Hoegl, Martin",
    title = "Change management interventions: Taking stock and moving forward",
    journal = "Human Resource Management Review",
    volume = "34",
    number = "1",
    pages = "101000",
    year = "2024",
    issn = "1053-4822",
    doi = "https://doi.org/10.1016/j.hrmr.2023.101000",
    url = "https://www.sciencedirect.com/science/article/pii/S1053482223000530",
    keywords = "Change management interventions, Change implementation, Change support, Change leadership, Change management",
    abstract = "Change management interventions (CMIs) are intentional activities that managers employ to facilitate planned organizational change by influencing employee receptivity to and adoption of that change. CMIs have been unclearly conceptualized and empirical insights on CMIs have become disjointed across research communities, limiting our understanding of the nature and effects CMIs can have. To address this shortcoming, we integrate and build on existing frameworks to provide an overview of the empirically studied CMI types, their mechanisms, and their outcomes. From our review of 119 empirical studies, we find that there are six overarching CMI types (and 14 sub-types): (1) communication (informing, framing, dialogic), (2) support (training, coaching, organizational change support), (3) involvement (consulting, co-creating, co-deciding), (4) reinforcement (rewards and goal-setting), (5) social influence (role modeling and peer exchange), and (6) coercion. Furthermore, based on our results, we encourage researchers to continue to strengthen an intervention-focused and context-sensitive approach to organizational change in the following underexplored areas: conceptualizing and measuring CMIs, bundles and interactions of CMIs, boundary conditions of CMIs, unintended consequences of CMIs, and the use of digital technology to enhance CMIs."
}

@article{dup_95,
    author = "Somé, Hyacinthe Y. and Valéry, Pascale",
    title = "Heterogeneity in the competition-cost of equity relation",
    journal = "International Review of Economics \& Finance",
    volume = "95",
    pages = "103486",
    year = "2024",
    issn = "1059-0560",
    doi = "https://doi.org/10.1016/j.iref.2024.103486",
    url = "https://www.sciencedirect.com/science/article/pii/S1059056024004787",
    keywords = "Competition, Agency costs, Implied cost of equity, Firm size, Free cash flow",
    abstract = "We explore the effect of firm heterogeneity on the implied cost of equity. To this end, we exploit two opposing effects of competition on the cost of equity: its negative effect on a firm's exposure to systematic risk and its positive effect on a firm's agency costs when it acts as a managerial disciplining device. Using a U.S. sample comprising 4764 firms from 1986 to 2017, we find that, on average, competition reduces equity costs by diminishing managerial expropriation, but increases these costs for small and distressed firms as they are more exposed to systematic risk. This agency costs link holds in developed countries only."
}

@article{dup_96,
    author = "Razaque, Abdul and Hariri, Salim and Alajlan, Abrar M. and Yoo, Joon",
    title = "A comprehensive review of cybersecurity vulnerabilities, threats, and solutions for the Internet of Things at the network-cum-application layer",
    journal = "Computer Science Review",
    volume = "58",
    pages = "100789",
    year = "2025",
    issn = "1574-0137",
    doi = "https://doi.org/10.1016/j.cosrev.2025.100789",
    url = "https://www.sciencedirect.com/science/article/pii/S1574013725000656",
    keywords = "Internet of Things, Cyber security, Real-time, Controlling system, Data mining, Scientific decision-making system, Vulnerabilities, Security attacks",
    abstract = "The proliferation of smart homes, smart logistics, and other technologies has expedited the expansion of Internet-of-Things (IoT) devices. This expansion has heightened the complexity of associated security challenges. Despite extensive research on IoT security, several studies fail to provide a comprehensive examination of both the network and application layers. This is particularly applicable to real-time and mission-critical settings. This review addresses that deficiency by offering a systematic review of IoT across five tiers. It concentrates on the application layer, categorizing it into three domains: real-time control systems, scientific decision-making systems, and query/scan search systems. The study examines vulnerabilities, attack vectors, and security measures in real-time control and query/scan systems. It examines how emerging technologies such as artificial intelligence (AI), Software Defined Networking (SDN), and fog/edge computing can enhance security via improved context awareness and access management. The study ultimately presents recommendations and suggests enhancements to foster trust, scalability, and enhanced security in contemporary IoT systems."
}

@article{dup_97,
    author = "Casheekar, Avyay and Lahiri, Archit and Rath, Kanishk and Prabhakar, Kaushik Sanjay and Srinivasan, Kathiravan",
    title = "A contemporary review on chatbots, AI-powered virtual conversational agents, ChatGPT: Applications, open challenges and future research directions",
    journal = "Computer Science Review",
    volume = "52",
    pages = "100632",
    year = "2024",
    issn = "1574-0137",
    doi = "https://doi.org/10.1016/j.cosrev.2024.100632",
    url = "https://www.sciencedirect.com/science/article/pii/S1574013724000169",
    keywords = "Computational intelligence, Artificial intelligence, Chatbots, Conversational agents, ChatGPT",
    abstract = "This review paper offers an in-depth analysis of AI-powered virtual conversational agents, specifically focusing on OpenAI’s ChatGPT. The main contributions of this paper are threefold: (i) an exhaustive review of prior literature on chatbots, (ii) a background of chatbots including existing chatbots/conversational agents like ChatGPT, and (iii) a UI/UX design analysis of prominent chatbots. Another contribution of this review is the comprehensive exploration of ChatGPT’s applications across a multitude of sectors, including education, business, public health, and more. This review highlights the transformative potential of ChatGPT, despite the challenges it faces such as hallucination, biases in training data, jailbreaks, and anonymous data collection. The review paper then presents a comprehensive survey of prior literature reviews on chatbots, identifying gaps in the prior work and highlighting the need for further research in areas such as chatbot evaluation, user experience, and ethical considerations. The paper also provides a detailed analysis of the UI/UX design of prominent chatbots, including their conversational flow, visual design, and user engagement. The paper also identifies key future research directions, including mitigating language bias, enhancing ethical decision-making capabilities, improving user interaction and personalization, and developing robust governance frameworks. By solving these issues, we can ensure that AI chatbots like ChatGPT are used responsibly and effectively across a broad variety of applications. This review will be a valuable resource for researchers and practitioners in understanding the current state and future potential of AI chatbots like ChatGPT."
}

@article{dup_98,
    author = "Raza, Syed Mohsan and Minerva, Roberto and Crespi, Noel and Alvi, Maira and Herath, Manoj and Dutta, Hrishikesh",
    title = "A comprehensive survey of Network Digital Twin architecture, capabilities, challenges, and requirements for Edge–Cloud Continuum",
    journal = "Computer Communications",
    volume = "236",
    pages = "108144",
    year = "2025",
    issn = "0140-3664",
    doi = "https://doi.org/10.1016/j.comcom.2025.108144",
    url = "https://www.sciencedirect.com/science/article/pii/S014036642500101X",
    keywords = "Edge-Cloud Continuum, Network Digital Twin, Componentization, Containerization, Segment, Microservices, Data modeling, Learning models, Simulation",
    abstract = "Network Digital Twin (NDT) collects data from physical, virtual, and software components and supports real-time network performance analysis, emulation, and intelligent physical network control. This paper surveys the current state of NDT specifications and explores NDT benefits for Network Operators (NOs) and its possible roles in future network management. It discusses the NDT key components, architecture, and integration of Machine Learning and Artificial Intelligence models in the NDT. Further, it covers virtualization technology management, suitability of Software-Defined Networking capabilities, and simulation tools to empower NDT. Two perspectives make the position of this survey different from existing studies; first, it highlights NDT limitations regarding Edge–Cloud Continuum (ECC) contextualization. ECC is a purposeful trending integration of Edge and Cloud Computing, involving multiple stakeholders like Service Providers, Customers, and Platform or Infrastructure Providers. However, current NDT specifications have not mentioned the ways to benefit stakeholders other than NOs. We also discuss notable computing and communication technologies transformations necessary to consider during NDT modeling, the existing data models, and reusable vocabularies that can be extended to achieve a detailed ECC representation for all stakeholders, essentially for Service Providers and Customers. Secondly, a data model is proposed that covers descriptive and prescriptive features and aims to provide a granular representation of ECC components to meet stakeholders’ requirements and render particular user information views. Different explored NDT perspectives, and proposed data model reduces the impact of existing NDT limitations in ECC representation."
}

@article{dup_99,
    author = "Ignacz, Gergo and Bader, Lana and Beke, Aron K. and Ghunaim, Yasir and Shastry, Tejus and Vovusha, Hakkim and Carbone, Matthew R. and Ghanem, Bernard and Szekely, Gyorgy",
    title = "Machine learning for the advancement of membrane science and technology: A critical review",
    journal = "Journal of Membrane Science",
    volume = "713",
    pages = "123256",
    year = "2025",
    issn = "0376-7388",
    doi = "https://doi.org/10.1016/j.memsci.2024.123256",
    url = "https://www.sciencedirect.com/science/article/pii/S0376738824008500",
    keywords = "Deep learning, Predictive models, Generative models, Molecular modeling, Cheminformatics",
    abstract = "Machine learning (ML) has been rapidly transforming the landscape of natural sciences and has the potential to revolutionize the process of data analysis and hypothesis formulation as well as expand scientific knowledge. ML has been particularly instrumental in the advancement of cheminformatics and materials science, including membrane technology. In this review, we analyze the current state-of-the-art membrane-related ML applications from ML and membrane perspectives. We first discuss the ML foundations of different algorithms and design choices. Then, traditional and deep learning methods, including application examples from the membrane literature, are reported. We also discuss the importance of learning data and both molecular and membrane-system featurization. Moreover, we follow up on the discussion with examples of ML applications in membrane science and technology. We detail the literature using data-driven methods from property prediction to membrane fabrication. Various fields are also discussed, such as reverse osmosis, gas separation, and nanofiltration. We also differentiate between downstream predictive tasks and generative membrane design. Additionally, we formulate best practices and the minimum requirements for reporting reproducible ML studies in the field of membranes. This is the first systematic and comprehensive review of ML in membrane science."
}

@article{dup_100,
    author = "Jegatheesan, N. and Ibrahim, Mohd Rasdan and Ahmed, Ali Najah and Koting, Suhana and El-Shafie, Ahmed and Katman, Herda Yati Binti",
    title = "Modeling the properties of terminal blend crumb rubber modified bitumen with crosslinking additives",
    journal = "Construction and Building Materials",
    volume = "444",
    pages = "137648",
    year = "2024",
    issn = "0950-0618",
    doi = "https://doi.org/10.1016/j.conbuildmat.2024.137648",
    url = "https://www.sciencedirect.com/science/article/pii/S0950061824027909",
    keywords = "Machine-learning algorithms, Prediction models, Terminal blend-crumb rubber modified bitumen, Crosslinking additive, Composite modification, High interaction parameters",
    abstract = "This study aimed to develop models assessing 26 machine-learning algorithms in regression analysis to predict the properties of terminal blend crumb rubber-modified bitumen (TB-CRMB) made with crosslinking additives. During the data collection, the properties of the modified binders prepared at 6, 10 and 14\% of crumb rubber (CR), considering three types of modifications and eighteen blending scenarios with different interaction factors, were assessed in terms of penetration, softening point, rotational viscosity, storage stability, rheological parameters, and rutting and fatigue factors. Results showed that the Matern 5/2 Gaussian Process Regression (GPR) model demonstrated efficient performance in predicting physical, viscoelastic, rutting, and fatigue properties whereas wide artificial neural networks exhibited enhanced accuracy in predicting storage stability and rotational viscosity. The results also suggest that it is feasible to implement a single type of model developed using the Matern 5/2 GPR algorithm for accurately predicting all the TB-CRMB properties considered. The best models demonstrated that crosslinking additives significantly influenced TB-CRMB production and performance. In TB-CRMB production, sulfur as a crosslinking additive showed better compatibility than trans-polyoctenamer-rubber and significantly reduced interaction temperatures at lower CR content, leading to energy savings compared to the traditional TB production."
}

@article{dup_101,
    author = "Baassiri, Mohamad and Ranade, Vivek and Padrela, Luis",
    title = "CFD modelling and simulations of atomization-based processes for production of drug particles: A review",
    journal = "International Journal of Pharmaceutics",
    volume = "670",
    pages = "125204",
    year = "2025",
    issn = "0378-5173",
    doi = "https://doi.org/10.1016/j.ijpharm.2025.125204",
    url = "https://www.sciencedirect.com/science/article/pii/S0378517325000407",
    keywords = "CFD, Drug nanoparticles, Atomization, Computational modelling",
    abstract = "Atomization-based techniques are widely used in pharmaceutical industry for production of fine drug particles due to their versatility and adaptability. Key performance measure of such techniques is their ability to provide control over critical quality attributes (CQAs) of produced drug particles. CQAs of drug particles produced via atomization critically depend on fluid dynamics of sprays; resulting mixing, heat and mass transfer; distribution of supersaturation and subsequent nucleation and growth of particles. It is essential to develop and use computational fluid dynamics (CFD) models for adequate understanding of multi-scale transport processes ranging from molecular scale mixing and particle scale processes, and from atomizer nozzle to overall spray chamber scale establishing relationships between CQAs and design and operating parameters of spray nozzle and chamber. In this work, we critically review past and current research efforts on CFD modelling of pharmaceutical atomization-based processes with an objective to provide clear assessment of the state of the art and to provide recommendations. An overview of the key atomization-based methods for producing drug particles with desired CQAs is presented. Key underlying physical processes and relevant concepts are then outlined. This discussion is related to the demands on CFD models; and state of the art is then discussed with respect to the process needs. Recommendations are provided towards higher fidelity and more efficient models of atomized multiphase flow dynamics and turbulence, drying modelling for the produced particles, and validation approaches. We conclude by highlighting a perceived need for numerical atomization studies with a pharmaceutical context; then, we deliver an outlook on current promising active control and machine learning strategies to augment the shift towards quality-by-design approaches in pharmaceutical manufacturing."
}

@article{dup_102,
    author = "Lee, Jihyun and Alonzo, Dennis and Beswick, Kim and Oo, Cherry Zin and Anson, Daniel W.J. and Abril, Jan Michael Vincent",
    title = "Data literacy of principals in K–12 school contexts: A systematic review",
    journal = "Educational Research Review",
    volume = "45",
    pages = "100649",
    year = "2024",
    issn = "1747-938X",
    doi = "https://doi.org/10.1016/j.edurev.2024.100649",
    url = "https://www.sciencedirect.com/science/article/pii/S1747938X24000587",
    keywords = "Principals, Teachers, Data literacy, Data use, Indicators, Dimensions, Decision-making",
    abstract = "This systematic review aims to clarify the concept of principals' data literacy and its various components. After examining 56 empirical studies, we have defined principals' data literacy and identified 63 specific indicators, organized into seven dimensions. Our findings highlight the complex tasks and responsibilities principals undertake to effectively lead with data. Although some data-related activities overlap between principals and teachers, the nature, scope, and purposes of data use differ between these roles. While teachers’ data literacy focuses on hands-on data creation, collection, and analysis, principals' data literacy revolves around leading their school communities and beyond. We argue that three of the seven dimensions—Dimension 3 (“Data use for fostering a data-driven culture”), Dimension 4 (“Data use for school improvement”), and Dimension 5 (“Data use for informing own practices”)—are particularly relevant to school leaders, thereby distinguishing principals' data literacy from that of teachers. We conclude by suggesting several practical implications based on our review, which could benefit the professional development of both school leaders and teachers at various career stages."
}

@article{dup_103,
    author = "Mervin, Lewis H. and Johansson, Simon and Semenova, Elizaveta and Giblin, Kathryn A. and Engkvist, Ola",
    title = "Uncertainty quantification in drug design",
    journal = "Drug Discovery Today",
    volume = "26",
    number = "2",
    pages = "474-489",
    year = "2021",
    issn = "1359-6446",
    doi = "https://doi.org/10.1016/j.drudis.2020.11.027",
    url = "https://www.sciencedirect.com/science/article/pii/S1359644620305110",
    abstract = "Machine learning and artificial intelligence are increasingly being applied to the drug-design process as a result of the development of novel algorithms, growing access, the falling cost of computation and the development of novel technologies for generating chemically and biologically relevant data. There has been recent progress in fields such as molecular de novo generation, synthetic route prediction and, to some extent, property predictions. Despite this, most research in these fields has focused on improving the accuracy of the technologies, rather than on quantifying the uncertainty in the predictions. Uncertainty quantification will become a key component in autonomous decision making and will be crucial for integrating machine learning and chemistry automation to create an autonomous design–make–test–analyse cycle. This review covers the empirical, frequentist and Bayesian approaches to uncertainty quantification, and outlines how they can be used for drug design. We also outline the impact of uncertainty quantification on decision making."
}

@article{dup_104,
    author = "{van den Broek}, Antonius and Gander, Jonathan",
    title = "When strategy is a dirty word: The role of visuals in sensegiving strategy to a skeptical audience",
    journal = "Long Range Planning",
    volume = "57",
    number = "1",
    pages = "102411",
    year = "2024",
    issn = "0024-6301",
    doi = "https://doi.org/10.1016/j.lrp.2023.102411",
    url = "https://www.sciencedirect.com/science/article/pii/S0024630123001188",
    keywords = "Sensegiving, Strategy presentations, Skepticism, Visual communication",
    abstract = "When setting a new strategy for their firm, managers engage in a range of sensegiving activities designed to introduce the new direction and explain the reasons for the change. These communication events commonly involve the use of strategic management terms and concepts to explain and justify the prescribed strategy. Literature thus far assumes that audiences understand and agree that these terms and underlying concepts are appropriate and relevant. Yet such views fail to explain strategy sensegiving in contexts where audiences of strategy presentations are ignorant or skeptical towards strategy concepts and ideas. We examine sensegiving under such conditions by analyzing a manager introducing a new strategy in a creative agency which expressed skepticism towards the concepts and practice of strategizing. Using data from video recordings of a sequence of internal strategy presentations, we identify three strategies designed to overcome prejudice towards strategic thinking while at the same time encouraging its use: winning the right to lead, finding resonance, and enrolling the audience into the strategy. We further find how these three sensegiving strategies are supported by carefully crafted visuals to either emphasize or de-emphasize aspects of the strategy and its supporting rationale. Our findings extend the literature on the practice of strategy by illustrating how the visual supports sensegiving efforts to guide a firm's interpretation of a proposed new strategic direction."
}

@article{dup_105,
    author = "Taherkhani, Katayoon and Ero, Osazee and Liravi, Farima and Toorandaz, Sahar and Toyserkani, Ehsan",
    title = "On the application of in-situ monitoring systems and machine learning algorithms for developing quality assurance platforms in laser powder bed fusion: A review",
    journal = "Journal of Manufacturing Processes",
    volume = "99",
    pages = "848-897",
    year = "2023",
    issn = "1526-6125",
    doi = "https://doi.org/10.1016/j.jmapro.2023.05.048",
    url = "https://www.sciencedirect.com/science/article/pii/S1526612523005212",
    keywords = "Additive manufacturing, Laser powder bed fusion, In-situ sensors, In-situ monitoring, Machine learning",
    abstract = "Laser powder bed fusion (LPBF) is one class of metal additive manufacturing (AM) used to fabricate high-quality complex-shape components. This technology has significantly progressed over the last several years allowing the fabrication of high-value components for a broad range of applications, normally unmatched by other metal AM processes. However, the full adoption of LPBF to serial production is still challenging due to several barriers such as repeatability and reliability of final product quality. The main obstacle could be the high sensitivity of LPBF to environmental and process disturbances. Additionally, LPBF is governed by many process parameters. These factors profoundly affect the process, causing defects formation. To achieve high quality parts, trial and errors are conventionally carried out to obtain optimum parameters that result in good quality for a specific application. However, in recent years attention to the development of quality assurance platforms in LPBF has been the cornerstone of research and development. To this end, researchers have proceeded with three steps: 1) Gaining knowledge from the process by installing in-situ sensing equipment and collecting information from the process. 2) Understanding how the print parameters affect the process, analyzing in-situ datasets and developing defect detection algorithms, and 3) Developing real-time closed-loop control systems using the detection algorithms of Step 2 to automatically adjust the undesired phenomena in the process by changing the print parameters. Although valuable studies were published for the two first steps, the development of real-time controllers has remained challenging. Thus, this study aims to critically review the two first steps to provide insights for researchers into moving toward the development of the control system. In this study, in-situ sensing devices implemented in LPBF are categorized, explained in detail, and mapped to the literature. Then, a comprehensive review is conducted on the latest machine learning (ML) algorithms applied to the in-situ data of LPBF, such as supervised learning, unsupervised learning, and reinforcement learning. Additionally, a comprehensive discussion is provided on in-situ sensors and ML methods applied to LPBF. Lastly, this article specifies trends and future research outlook on this topic."
}

@article{dup_106,
    author = "Liu, Tian-Wei and Bai, Jiang-Bo and Fantuzzi, Nicholas and Zhang, Xiang",
    title = "Thin-walled deployable composite structures: A review",
    journal = "Progress in Aerospace Sciences",
    volume = "146",
    pages = "100985",
    year = "2024",
    issn = "0376-0421",
    doi = "https://doi.org/10.1016/j.paerosci.2024.100985",
    url = "https://www.sciencedirect.com/science/article/pii/S0376042124000113",
    keywords = "Deployable composite structure, Thin-walled, Boom, Tape-spring, Hinge, Reflector, Optimization",
    abstract = "The elastic strain energy-driven thin-walled deployable composite structures, characterized by their integration of structure and functionality, have attracted considerable attention in the field of space applications. These structures utilize the stored strain energy accumulated during the folding process to achieve elastic deployment. Significant progress has been made in the understanding of deformation mechanisms, modeling, design, optimization, and applications of such structures based on existing research. This review critically discusses over 300 papers from the past few decades, providing a comprehensive exploration of the development of three representative types of deployable composite structures: deployable composite hinges, booms, and reflectors. Specifically, it starts by reviewing the structural design, functional mechanisms, theories, finite element modeling methods and experimental investigations for these three types of structures. It then introduces optimization design methods and their applications in deployable composite structures. Additionally, specific practical application cases of deployable composite structures are discussed. Finally, future challenges and prospects for deployable composite structures are outlined. This paper serves as a valuable reference and inspiration for the design and application of deployable composite structures. It is expected to promote further advancements in this field."
}

@article{dup_107,
    author = "Goldschmidt, Patrik and Chudá, Daniela",
    title = "Network intrusion datasets: A survey, limitations, and recommendations",
    journal = "Computers \& Security",
    volume = "156",
    pages = "104510",
    year = "2025",
    issn = "0167-4048",
    doi = "https://doi.org/10.1016/j.cose.2025.104510",
    url = "https://www.sciencedirect.com/science/article/pii/S0167404825001993",
    keywords = "Network intrusion detection, NIDS, Machine learning for intrusion detection, Cybersecurity datasets, NIDS best practices, Comparative dataset analysis",
    abstract = "Data-driven cyberthreat detection has become a crucial defense technique in modern cybersecurity. Network defense, supported by Network Intrusion Detection Systems (NIDSs), has also increasingly adopted data-driven approaches, leading to greater reliance on data. Despite the importance of data, its scarcity has long been recognized as a major obstacle in NIDS research. In response, the community has published many new datasets recently. However, many of them remain largely unknown and unanalyzed, leaving researchers uncertain about their suitability for specific use cases. In this paper, we aim to address this knowledge gap by performing a systematic literature review (SLR) of 89 public datasets for NIDS research. Each dataset is comparatively analyzed across 13 key properties, and its potential applications are outlined. Beyond the review, we also discuss domain-specific challenges and common data limitations to facilitate a critical view on data quality. To aid in data selection, we conduct a dataset popularity analysis in contemporary state-of-the-art NIDS research. Furthermore, the paper presents best practices for dataset selection, generation, and usage. By providing a comprehensive overview of the domain and its data, this work aims to guide future research toward improving data quality and the robustness of NIDS solutions."
}

@article{dup_108,
    title = "Subject Index",
    journal = "Gastrointestinal Endoscopy",
    volume = "101",
    number = "5, Supplement",
    pages = "S729-S756",
    year = "2025",
    note = "ASGE Abstracts - DDW 2025",
    issn = "0016-5107",
    doi = "https://doi.org/10.1016/j.gie.2025.03.150",
    url = "https://www.sciencedirect.com/science/article/pii/S0016510725003190"
}

@article{dup_109,
    author = "{do Canto}, Marcos Weber and Kunrath, Taise Robinson and {Saraiva da Costa}, Antonio Carlos and {dos Santos Martinez}, Marco and {de Almeida}, Gleice Menezes and Neto, Hugo Zeni and Daniel, João Luiz Pratt",
    title = "Analyzing and predicting the response of the signal grass seed crop to plant nitrogen status",
    journal = "European Journal of Agronomy",
    volume = "160",
    pages = "127320",
    year = "2024",
    issn = "1161-0301",
    doi = "https://doi.org/10.1016/j.eja.2024.127320",
    url = "https://www.sciencedirect.com/science/article/pii/S1161030124002417",
    keywords = "Nitrogen status indicators, Nitrogen, Nitrogen remobilization, Seed growth",
    abstract = "Nitrogen (N) deficiency has detrimental effects on productivity and the profit of producers in areas where signal grass [Urochloa decumbens (Stapf) R.D. Webster (syn. Brachiaria decumbens Stapf.)] cv. Basilisk is grown for seed production. The objective of this paper was to clarify the effects of indicators of signal grass plant N status on seed yield (SY), SY components, yield formation, seed quality, panicle growth parameters, and remobilization of vegetative N on seed growth. Germinable pure SY, harvest index (HI), and N harvest index (NHI) were also measured. Different rates of N fertilizer application (0, 50, 100, and 150 kg ha−1) were applied after the cleaning cut to both the first crop (October - January) and the second crop (February - May) in 2010–2011 and 2011–2012, on a sandy loam soil representative of soils used for seed production in Brazil. Although the N nutrition index (NNI) increased at key developmental stages, the highest values were near to 0.85. This suggests that all crops were maintained under N-limiting conditions. In N-limited crops, a strong relationship was detected between NNI and accumulated N deficit throughout the study period with relative SY. A low NNI after the cleaning cut was found to restrict fertile tiller number (FTN), spikelets per panicle, and spikelet density m−2 measured at anthesis. In all crops, at harvest, NNI at anthesis increased germinable pure SY, FTN, number of seeds per panicle, HI, NHI, and amount of remobilized N to seeds, but not thousand seed weight (TSW), seed germination, panicle dry matter (DM) accumulation rate, and individual seed growth rate. Regression analyses suggested that the NNI, accumulated N deficit, aboveground plant biomass (AGPB), and N content were better associated with relative SY than with plant N concentration (PNC). The study shows that the NNI quantifies the intensity and duration of N deficiency in signal grass and should be considered in research studies and for application in seed production fields to improve N fertilization recommendations."
}

@article{dup_110,
    author = "Giordano, Vito and Fantoni, Gualtiero",
    title = "Decomposing maintenance actions into sub-tasks using natural language processing: A case study in an Italian automotive company",
    journal = "Computers in Industry",
    volume = "164",
    pages = "104186",
    year = "2025",
    issn = "0166-3615",
    doi = "https://doi.org/10.1016/j.compind.2024.104186",
    url = "https://www.sciencedirect.com/science/article/pii/S0166361524001143",
    keywords = "Natural language processing, Text mining, Maintenance work order, Industrial applications, Association rule mining, Large language model",
    abstract = "Industry 4.0 has led to a huge increase in data coming from machine maintenance. At the same time, advances in Natural Language Processing (NLP) and Large Language Models provide new ways to analyse this data. In our research, we use NLP to analyse maintenance work orders, and specifically the descriptions of failures and the corresponding repair actions. Many NLP studies have focused on failure descriptions for categorising them, extracting specific information about failure, or supporting failure analysis methodologies (such as FMEA). Whereas, the analysis of repair actions and its relationship with failure remains underexplored. Addressing this gap, our study makes three significant contributions. Firstly, we focused on the Italian language, which presents additional challenges due to the dominance of NLP systems that are mainly designed for English. Secondly, it proposes a method for automatically subdividing a repair action into a set of sub-tasks. Lastly, it introduces an approach that employs association rule mining to recommend sub-tasks to maintainers when addressing failures. We tested our approach with a case study from an automotive company in Italy. The case study provides insights into the current barriers faced by NLP applications in maintenance, offering a glimpse into the future opportunities for smart maintenance systems."
}

@article{dup_111,
    author = "Treanţă, Savin and Calianu, Ramona-Manuela",
    title = "Efficiency criteria and dual techniques for some nonconvex multiple cost minimization models",
    journal = "IFAC Journal of Systems and Control",
    volume = "30",
    pages = "100288",
    year = "2024",
    issn = "2468-6018",
    doi = "https://doi.org/10.1016/j.ifacsc.2024.100288",
    url = "https://www.sciencedirect.com/science/article/pii/S246860182400049X",
    keywords = "Efficiency criteria, Dual techniques, Nonconvex multiple cost minimization models",
    abstract = "In this study, we investigate a class of multi-objective variational control problems governed by nonconvex simple integral functionals. Concretely, we establish and prove (necessary and sufficient) efficiency criteria and dual techniques for some nonconvex multiple cost minimization models. To this aim, we extend and use the concept of (Ψ,ω)-invexity to the case of multi-objective variational control problems. Thereafter, by assuming (Ψ,ω)-invexity, (strictly) (Ψ,ω)-pseudoinvexity and/or (Ψ,ω)-quasiinvexity of the involved functionals, we state the sufficient efficiency criteria and associate a dual problem for the considered model."
}

@article{dup_112,
    author = "Jaiprakash, Sahani Pooja and Prakash, Choudhary Shyam",
    title = "Exploring text-to-image generation models: Applications and cloud resource utilization",
    journal = "Computers and Electrical Engineering",
    volume = "123",
    pages = "110194",
    year = "2025",
    issn = "0045-7906",
    doi = "https://doi.org/10.1016/j.compeleceng.2025.110194",
    url = "https://www.sciencedirect.com/science/article/pii/S0045790625001375",
    keywords = "Text-to-image generation, VAE, GAN, StackGAN, Diffusion model, Cloud resouce utilization, Edge-cloud computing",
    abstract = "Generating images from text presents a significant challenge in computer vision. Moreover, manually acquiring images from multiple perspectives for object or product generation is a resource-intensive and expensive endeavor. However, recent breakthroughs in deep learning and artificial intelligence have opened doors to creating new images from diverse data sources, and cloud resources play a pivotal role in alleviating the resource-intensive nature of this endeavor. As a result, substantial research efforts have been directed toward advancing image generation techniques, yielding impressive results. This paper aims to provide a comprehensive overview of existing image generation methods, offering insights into this evolving field of text-to-image generation. It traces the historical development of this technology. It examines the key models that have shaped its evolution, including Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), Conditional GANs (CGANs), StackGAN, Transformers, and diffusion models. The paper offers insights into the functioning of text-to-image generation within the GAN architecture, elucidating the mechanisms behind transforming textual descriptions into visual content. Additionally, the integration of text-to-image generation with cloud and edge-cloud computing highlights the synergistic potential of these technologies while addressing the challenges and considerations associated with cloud infrastructure. The paper concludes by surveying the diverse applications of text-to-image generation across various domains, such as art, e-commerce, entertainment, and education. It also discusses the evaluation metrics commonly used in assessing the quality of generated images and the challenges that exist both within the methods and in their application across different domains. This review offers a comprehensive overview of the capabilities and limitations of text-to-image generation. Also, we have introduced a new HiResGAN model using a single generator/discriminator pair of networks to produce high-resolution 256 × 256 images from textual descriptions. We illustrate the efficacy of our model in producing high-resolution images based on contextually rich text descriptions that are visually plausible and semantically consistent through a series of experiments and analyses."
}

@incollection{dup_113,
    editor = "Galitsky, Boris",
    author = "Galitsky, Boris",
    title = "Chapter 8 - Identifying large language model hallucinations in health communication",
    booktitle = "Healthcare Applications of Neuro-Symbolic Artificial Intelligence",
    publisher = "Academic Press",
    pages = "283-329",
    year = "2025",
    isbn = "978-0-443-30046-2",
    doi = "https://doi.org/10.1016/B978-0-443-30046-2.00012-0",
    url = "https://www.sciencedirect.com/science/article/pii/B9780443300462000120",
    keywords = "Large language model hallucination, fact-checking, handling inconsistent verification sources, collaborative iterative mode, syntax-semantic alignment",
    abstract = "Large language models (LLMs) sometimes generate texts plagued with inaccuracies and fabricated information. We present a fact-checking system known as “Truth-O-Meter” which detects erroneous facts by cross-referencing generated content with information from the web and reputable sources and then offers appropriate corrections. We employ text mining and web mining techniques to pinpoint accurate corresponding sentences and to employ a syntactic and semantic generalization process to enhance content quality. To effectively handle the challenges posed by inconsistent information sources during fact-checking, we employ an argumentation-analysis framework based on defeasible logic programming. In a comparative evaluation with competitive approaches that rely on reinforcement learning integrated with LLM or token-based hallucination detection, our fact-checking engine demonstrates significant enhancements in the factual accuracy and meaningfulness of LLM-generated content.11https://github.com/bgalitsky/Truth-O-Meter-Making-ChatGPT-Truthful."
}

@incollection{dup_114,
    editor = "Gawronski, Bertram",
    author = "Green, Melanie C. and Appel, Markus",
    title = "Chapter One - Narrative transportation: How stories shape how we see ourselves and the world",
    series = "Advances in Experimental Social Psychology",
    publisher = "Academic Press",
    volume = "70",
    pages = "1-82",
    year = "2024",
    issn = "0065-2601",
    doi = "https://doi.org/10.1016/bs.aesp.2024.03.002",
    url = "https://www.sciencedirect.com/science/article/pii/S0065260124000145",
    keywords = "Narrative, Story, Transportation, Character identification, Attitudes, Persuasion, Emotion, Belongingness, Immersion, Theory of mind",
    abstract = "Scientific interest in the processing and effects of narrative information has substantially increased in recent years. The focus of this chapter is on narrative transportation, an experiential state of immersion in which all mental processes are concentrated on the events occurring in the narrative. We describe and integrate interdisciplinary advances in the study of narrative transportation. After an introduction of the concept and related approaches, we outline antecedents in terms of story factors, individual differences, situational variables, and related interactions. In the following sections, we introduce processes and effects that are facilitated by stories and narrative transportation. This includes research on persuasion, misinformation and its correction, self and identity, social cognitive skills, and the fulfillment of belongingness needs. We close with an outlook on the role of technology and artificial intelligence, meaning making, and climate change communication as emerging and future directions."
}

@incollection{dup_115,
    editor = "Baker, David and Ellis, Lucy",
    booktitle = "Encyclopedia of Libraries, Librarianship, and Information Science (First Edition)",
    publisher = "Academic Press",
    edition = "First Edition",
    address = "Oxford",
    pages = "552-598",
    year = "2024",
    isbn = "978-0-323-95690-1",
    doi = "https://doi.org/10.1016/B978-0-323-95689-5.09001-5",
    url = "https://www.sciencedirect.com/science/article/pii/B9780323956895090015"
}

@article{dup_116,
    author = "Morciano, Matteo and Fasano, Matteo and Chiavazzo, Eliodoro and Mongibello, Luigi",
    title = "Trending applications of Phase Change Materials in sustainable thermal engineering: An up-to-date review",
    journal = "Energy Conversion and Management: X",
    volume = "25",
    pages = "100862",
    year = "2025",
    issn = "2590-1745",
    doi = "https://doi.org/10.1016/j.ecmx.2024.100862",
    url = "https://www.sciencedirect.com/science/article/pii/S2590174524003404",
    keywords = "Phase change materials, Energy storage, Sustainable thermal management, Solar thermal energy, Smart textiles",
    abstract = "The on-going search for increasingly sustainable and efficient thermal energy management across a wide range of sectors leads to continuous exploration of innovative solutions. In this context, phase change materials (PCMs) have emerged as key solutions for thermal energy storage and reuse, offering versatility in addressing contemporary energy challenges. Through this review, we offer a comprehensive critical analysis of the latest developments in PCMs-based technology and their emerging applications within energy systems. First, the conducted investigation highlights the most important drivers stimulating the use of PCMs, namely, the miniaturization of electronic devices, the fluctuating nature of renewable energy sources, and the urge to design smart buildings and textiles. Here, we therefore discuss the integration of PCMs into electronic systems characterized by high heat fluxes, lithium-ion batteries, solar energy systems (including photovoltaic, desalination systems), building materials and textiles to offer wearable solutions for enhanced thermal comfort. Outlining around 100 various cases, PCMs emerge as particularly suitable to ensure optimal operating temperature ranges, to extend lifespan of the devices and ultimately to improve overall system energy efficiency. Beyond potential, challenges such as material leakage, long-term durability, and cost-effectiveness are discussed. By focusing on literature post-2022, the proposed review aims to condense the latest numerical and experimental research findings, spotlight emerging trends, and identify challenges to promote broader and long-term adoption of PCM-based systems. By providing a holistic perspective on PCM applications, we emphasize their potential in achieving sustainable and efficient energy management and provide insights to encourage future cross-disciplinary research and innovation."
}

@article{dup_117,
    author = "Panggabean, Ellis Mardiana and Silalahi, Andri Dayarana K.",
    title = "How do ChatGPT's benefit–risk-coping paradoxes impact higher education in Taiwan and Indonesia?",
    journal = "Computers and Education: Artificial Intelligence",
    volume = "8",
    pages = "100412",
    year = "2025",
    issn = "2666-920X",
    doi = "https://doi.org/10.1016/j.caeai.2025.100412",
    url = "https://www.sciencedirect.com/science/article/pii/S2666920X25000529",
    keywords = "Artificial intelligence, Benefit-coping-risk, chatgpt in education, fsqca, Education, Technology adoption",
    abstract = "The integration of ChatGPT into higher education in Taiwan and Indonesia presents both opportunities and challenges. This integration creates a paradox of benefits and risks that must be carefully managed. While previous studies have explored ChatGPT's applications, its complexities in educational contexts remain partially unaddressed. This study bridges that gap by integrating the Unified Theory of Acceptance and Use of Technology (UTAUT) with Protection Motivation Theory (PMT) to examine ChatGPT's role through a benefit–risk–coping mechanism. Data were collected from higher education users in Taiwan and Indonesia. Structural Equation Modeling (SEM) revealed distinct patterns in the two regions. In Taiwan, perceived severity reduces the intention to use ChatGPT, while self-efficacy fosters adoption. In Indonesia, users emphasize response efficacy and performance expectancy as stronger predictors of usage intention. Task efficiency and performance expectancy enhance usage intention in both settings, with Indonesia showing a stronger link between intention and actual use. Fuzzy sets Qualitative Comparative Analysis (fsQCA) further identifies diverse configurations for actual usage and disusage of ChatGPT. Task efficiency and performance expectancy emerge as key usage drivers in both contexts. Disusage in Taiwan primarily stems from task inefficiency, whereas multiple factors—including low self-efficacy—hinder adoption in Indonesia. These findings provide practical insights for higher education institutions, guiding strategies to optimize ChatGPT's benefits, minimize risks, and ensure its responsible use in educational settings across Taiwan and Indonesia."
}

@incollection{dup_118,
    author = "Vinter, Adrijana and Grgičević, Ivan",
    title = "Artificial intelligence in GPCR drug discovery: A paradigm shift in computational pharmacology",
    booktitle = "Reference Module in Chemistry, Molecular Sciences and Chemical Engineering",
    publisher = "Elsevier",
    year = "2025",
    isbn = "978-0-12-409547-2",
    doi = "https://doi.org/10.1016/B978-0-443-29808-0.00047-9",
    url = "https://www.sciencedirect.com/science/article/pii/B9780443298080000479",
    keywords = "G protein-coupled receptors, Artificial intelligence, Drug discovery, Machine learning, Deep learning, Graph neural networks, Reinforcement learning, AlphaFold2, Biased signaling, Allosteric modulators, Multi-omics integration, Virtual screening, De novo drug design, Precision medicine, Explainable AI (XAI)",
    abstract = "This Chapter explores the transformative role of artificial intelligence in GPCR-targeted drug discovery, highlighting how machine learning, deep learning, and reinforcement learning are reshaping ligand screening, structure prediction, and personalized medicine. AI models such as AlphaFold2, graph neural networks, and generative adversarial networks have significantly accelerated hit identification, improved functional selectivity, and enabled allosteric modulator discovery. Integrated with multi-omics data, AI enhances the precision and efficiency of therapeutic development while reducing cost and time. The Chapter also addresses the challenges of data scarcity, model interpretability, and experimental validation, offering potential solutions through explainable AI and hybrid workflows. These advancements position AI not just as a supportive tool but as a central driver in next-generation GPCR pharmacology and precision drug design."
}

@article{dup_119,
    author = "Xiao, Yuehai and Zhang, Tianyu and He, Jingyi",
    title = "RETRACTED: The promises and challenges of AI-based chatbots in language education through the lens of learner emotions",
    journal = "Heliyon",
    volume = "10",
    number = "18",
    pages = "e37238",
    year = "2024",
    issn = "2405-8440",
    doi = "https://doi.org/10.1016/j.heliyon.2024.e37238",
    url = "https://www.sciencedirect.com/science/article/pii/S2405844024132690",
    abstract = "This article has been retracted: please see Elsevier policy on article withdrawal (https://www.elsevier.com/about/policies-and-standards/article-withdrawal). This article has been retracted at the request of the Editor-in-Chief. Post-publication, the journal identified references that are irrelevant to the article. The authors were asked to comment upon the presence of these references in their work but were unable to satisfactorily address the reason for the references. Consequently, the editor no longer has confidence in the integrity and the findings of the article and has decided to retract it. The scientific community takes a very strong view on this matter and apologies are offered to readers of the journal that this was not detected during the submission process. The authors disagree with retraction and dispute the grounds for it."
}

@article{dup_120,
    author = "Zahra, Anam and Qureshi, Rizwan and Sajjad, Muhammad and Sadak, Ferhat and Nawaz, Mehmood and Khan, Haris Ahmad and Uzair, Muhammad",
    title = "Current advances in imaging spectroscopy and its state-of-the-art applications",
    journal = "Expert Systems with Applications",
    volume = "238",
    pages = "122172",
    year = "2024",
    issn = "0957-4174",
    doi = "https://doi.org/10.1016/j.eswa.2023.122172",
    url = "https://www.sciencedirect.com/science/article/pii/S095741742302674X",
    keywords = "Imaging spectroscopy, Hyperspectral imaging, Image processing, Computer vision, Remote sensing, Deep learning",
    abstract = "Imaging spectroscopy integrates traditional computer vision and spectroscopy into a single system and has gained widespread acceptance as a non-destructive scientific instrument for a wide range of applications. The current state of imaging spectroscopy spans diverse applications including but not limited to air-borne and ground-based computer vision systems. This paper presents the current state of research and industrial applications including precision agriculture, material classification, medical science, forensic science, face recognition and document image analysis, environment monitoring, and remote sensing, which can be aided through imaging spectroscopy. In this regard, we further discuss a comprehensive list of applications of imaging spectroscopy, pre-processing techniques, and spectral image acquisition systems. Likewise, publicly available databases and current software tools for spectral data analysis are also documented in this review. This review paper, therefore, could potentially serve as a reference and roadmap for people looking for literature, databases, applications, and tools to undertake additional research in imaging spectroscopy."
}

@article{dup_121,
    author = "Lu, Yinbin and Wang, Alan",
    title = "Integrating language into medical visual recognition and reasoning: A survey",
    journal = "Medical Image Analysis",
    volume = "102",
    pages = "103514",
    year = "2025",
    issn = "1361-8415",
    doi = "https://doi.org/10.1016/j.media.2025.103514",
    url = "https://www.sciencedirect.com/science/article/pii/S1361841525000623",
    keywords = "Vision language Model, Medical imaging analysis, Multimodal learning, Visual recognition and reasoning",
    abstract = "Vision-Language Models (VLMs) are regarded as efficient paradigms that build a bridge between visual perception and textual interpretation. For medical visual tasks, they can benefit from expert observation and physician knowledge extracted from textual context, thereby improving the visual understanding of models. Motivated by the fact that extensive medical reports are commonly attached to medical imaging, medical VLMs have triggered more and more interest, serving not only as self-supervised learning in the pretraining stage but also as a means to introduce auxiliary information into medical visual perception. To strengthen the understanding of such a promising direction, this survey aims to provide an in-depth exploration and review of medical VLMs for various visual recognition and reasoning tasks. Firstly, we present an introduction to medical VLMs. Then, we provide preliminaries and delve into how to exploit language in medical visual tasks from diverse perspectives. Further, we investigate publicly available VLM datasets and discuss the challenges and future perspectives. We expect that the comprehensive discussion about state-of-the-art medical VLMs will make researchers realize their significant potential."
}

@article{dup_122,
    author = "Casprini, Elena and Palumbo, Rocco and {De Massis}, Alfredo",
    title = "Untangling the yarn: A contextualization of human resource management to the family firm setting",
    journal = "Journal of Family Business Strategy",
    volume = "15",
    number = "3",
    pages = "100621",
    year = "2024",
    issn = "1877-8585",
    doi = "https://doi.org/10.1016/j.jfbs.2024.100621",
    url = "https://www.sciencedirect.com/science/article/pii/S1877858524000160",
    keywords = "Family firm, Human resource management, Family resource management, Nonfamily resource management, People management",
    abstract = "Despite the efforts to contextualize human resource management to family firms, scientific literature addressing this study domain suffers from limited systematization. The article arranges an integrative framework to make sense of the challenges faced by family firms in designing and implementing human resource management practices. Bibliographic coupling was run on an intellectual core of 69 papers to illuminate dominant research streams. Besides, co-citation was executed to determine the conceptual roots nurturing recent scholarly advancements. A dance between formality and informality of human resource management practices characterizes extant research, calling for developments to understand how family firms can deal with it."
}

@article{dup_123,
    author = "Pitakaso, Rapeepan and Khonjan, Surajet and Srichok, Thanatkij and Nanthasamroeng, Natthapong and Khampukka, Paweena and Sawettham, Arunrat and Dinkoksung, Sairoong and Supasarn, Chawapot and Jungvimutipan, Kanya and Boonarree, Yong and Jirasirilerd, Ganokgarn and Mongkhonngam, Pornpimol",
    title = "AI-driven cultural urbanism: A data-integrated model for learning city development in emerging heritage contexts",
    journal = "Social Sciences \& Humanities Open",
    volume = "12",
    pages = "102011",
    year = "2025",
    issn = "2590-2911",
    doi = "https://doi.org/10.1016/j.ssaho.2025.102011",
    url = "https://www.sciencedirect.com/science/article/pii/S2590291125007399",
    keywords = "Learning cities, Generative AI, Cultural heritage Design, Persona-based planning, Participatory urbanism",
    abstract = "This study introduces an AI-enhanced framework for designing culturally rooted Learning Cities, demonstrated through Warinchamrap, Thailand—a heritage-rich secondary city overlooked by conventional urban development. Addressing gaps in smart city models that neglect symbolic landscapes, community narratives, and intergenerational learning, this research merges AI modeling with participatory cultural mapping and spatial analytics to create eight location-specific learning nodes.The methodology comprised five phases: (1) integrating multi-source data (archival, oral history, geospatial, social media); (2) applying AI clustering and natural language processing to identify user personas and spatial patterns; (3) employing generative AI (GPT-4, diffusion models) for culturally appropriate design concepts; (4) evaluating designs via a Design Suitability Score (DSS) framework combining AI metrics and stakeholder validation; and (5) refining architectural designs based on community feedback.Initial AI concepts achieved DSS scores averaging 0.866. After prompt refinement, version 2 designs improved to 0.908. Final architectural designs, informed by AI outputs, maintained strong community alignment with a DSS of 0.893. Projects like Songsarn x Rails of Memory and Warin Light Avenue successfully integrated spatial storytelling, cultural heritage, and adaptive learning design. Findings demonstrate that culturally embedded AI can serve as an effective co-designer for inclusive, memory-driven urban learning environments. This research provides a replicable framework for Learning Cities discourse, synthesizing generative AI, local heritage, and spatial intelligence. It offers valuable insights for developing culturally sustainable smart cities, adaptive tourism, and community-driven urban design, establishing AI as a responsive tool when anchored in cultural semantics and participatory engagement."
}

@article{dup_124,
    author = "Zhang, Teng and Peng, Fangyu and Yang, Zhao and Tang, Xiaowei and Yuan, Jiangmiao and Yan, Rong",
    title = "Digital twin-driven staged error prediction and compensation framework for the whole process of robotic machining",
    journal = "Journal of Manufacturing Systems",
    volume = "83",
    pages = "252-283",
    year = "2025",
    issn = "0278-6125",
    doi = "https://doi.org/10.1016/j.jmsy.2025.09.009",
    url = "https://www.sciencedirect.com/science/article/pii/S0278612525002365",
    keywords = "Robotic machining, Error prediction and compensation, Staged strategies, Digital twins",
    abstract = "Robotic machining has become another important machining paradigm after CNC machine tools. However, robot error has always been an important constraint in its progress towards high quality demand scenarios due to characteristics such as weak rigidity and pose dependence. Numerous scholars have carried out rich work around errors in robotic machining systems, and these studies have achieved excellent results in robot localization, trajectory continuous motion, and machining operations. However, due to the complexity of the robot machining system, the robot error has differentiated performance at different stages, and it is difficult to guarantee the global accuracy of the robot by focusing on and controlling a certain kind of error in a discrete manner. For this reason, a digital twin-driven staged error prediction and compensation framework for the whole robot machining process is constructed. In this framework, the whole process of robot machining is divided into three stages with significant differences: point planning, trajectory planning and material removal. And the error prediction function block in each stage is constructed for the error characteristics (distribution skew, error step, spatial-temporal coupling). For error compensation, a staged error compensation strategy is constructed from three aspects: offline point position, robot body and external three-axis platform, respectively. The constructed system was case-validated in the robotic machining of curved parts. All stages of the error prediction models show high prediction accuracy, and the excellent performance of the staged prediction models is verified by comparing with the classical prediction models. For the error compensation, the designed system is utilized to ensure that the robotic machining system provides a double guarantee on the robot end and the machining quality, the point position absolute error is controlled at 0.109 mm, the orientation error is controlled at 0.028°, the trajectory position error is controlled at 0.067 mm, the orientation error is controlled at 0.031°, and the final part machining error is controlled at 0.036 mm, which is almost approximates the repeatable positioning accuracy of the robot. The proposed framework realizes the system-level sensing and control of the robot machining system error, and provides a unified system framework for the subsequent research of related unit methods, which is conducive to promoting the development of robot machining to high-quality requirement scenarios."
}

@incollection{dup_125,
    author = "Safari, Ashkan and Oshnoei, Arman and Nadeem, Ahsan and Blaabjerg, Frede",
    title = "Blockchain innovations for transparent energy transactions",
    booktitle = "Reference Module in Materials Science and Materials Engineering",
    publisher = "Elsevier",
    year = "2025",
    isbn = "978-0-12-803581-8",
    doi = "https://doi.org/10.1016/B978-0-443-29210-1.00038-8",
    url = "https://www.sciencedirect.com/science/article/pii/B9780443292101000388",
    keywords = "Artificial intelligence, Blockchain technology, Smart grids, Transactive energy systems",
    abstract = "Blockchain is among the key technologies in transforming trade by creating a secure, transparent, and decentralized platform for transactions. It eliminates intermediaries, reducing costs and increasing efficiency in supply chains, cross-border payments, and contract execution in transactive energy system (TES). By using distributed ledger systems, blockchain facilitates peer-to-peer (P2P) energy transactions, allowing prosumers to buy/sell excess energy, such as from renewable energy sources (RES), without intermediaries. To this end, this article presents a detailed explanation and different frameworks for blockchain-based TES markets in a complete perspective. Firstly, the concept of TES, its integration with distributed energy resource (DER), and different considered objective functions are presented. Then, the fundamentals of blockchain, its different types, algorithms, and each type's integration in TES are taken into account. Following this concept, the smart contracts structure, algorithms, as well as different hash function, their mathematical forms, and overall processes are exemplified. Therefore, different transaction logs of direct producer-consumer and marketplace are considered to provide the context for potential applications of artificial intelligence (AI). An extensive literature review of AI is conducted, and three example AI integrations in blockchain-based TES are manifested, as a selection for security-focused (federated learning [FL], dynamic-dependence [Deep Reinforcement Learning (DRL)], and data-dependence [long-short term memory (LSTM)]) models. Therefore, a discussion is provided upon the long-term sustainability goals and also TES alliance with sustainability standards. Finally, challenges and future works on security and user privacy aspects of blockchain-based TES are presented. The blockchain and AI integration in TES enhance grid resilience, promotes adoption, and empowers consumers, making TES markets more accessible and scalable for a sustainable energy future."
}

@article{dup_126,
    author = "Herbosch, Maarten",
    title = "Fraud by generative AI chatbots: On the thin line between deception and negligence",
    journal = "Computer Law \& Security Review",
    volume = "52",
    pages = "105941",
    year = "2024",
    issn = "2212-473X",
    doi = "https://doi.org/10.1016/j.clsr.2024.105941",
    url = "https://www.sciencedirect.com/science/article/pii/S0267364924000086",
    keywords = "Artificial intelligence, Contract law, Fraud, Law of obligations, Vice of consent",
    abstract = "The use of generative AI systems is on the rise. As a result, we are increasingly often conversing with AI chatbots rather than with fellow humans. This increasing use of AI systems leads to legal challenges as well, particularly when the chatbot provides incorrect information. In this article, we study whether someone who decides to contract on the basis of incorrect information provided by a generative AI chatbot might invoke the fraud regime to annul the resulting contract in various legal systems. During this analysis, it becomes clear that some of the requirements that are currently being put forward from a public law perspective, such as in the European AI Act, may also naturally arise from existing private law figures. In the same vein, this analysis highlights the interesting intradisciplinary feedback between instruments of public law and other legal domains."
}

@article{dup_127,
    author = "Wei, Xiaochao and She, Qiping",
    title = "Cooperative supervision of livestreaming e-commerce based on stochastic evolutionary game and overconfidence",
    journal = "Technology in Society",
    volume = "84",
    pages = "103049",
    year = "2026",
    issn = "0160-791X",
    doi = "https://doi.org/10.1016/j.techsoc.2025.103049",
    url = "https://www.sciencedirect.com/science/article/pii/S0160791X25002398",
    keywords = "Livestreaming e-commerce, Cooperative supervision, Streamer type, Overconfidence, Evolutionary game",
    abstract = "The rapid development of livestreaming e-commerce has been accompanied by an increasing number of misleading marketing behaviors (MIBs) that require adequate regulations. To reveal the impact of irrational behavior (overconfidence) and to explore effective supervision strategies tailored to different types of streamers. We have classified streamers into brand-affiliated streamers and professional streamers (including internet celebrity streamers and ordinary streamers), then four types overconfidence are identified and integrated into a stochastic evolutionary game framework to investigate the regulatory effectiveness. The findings indicate that platform overconfidence positively affects supervision, while overconfidence among streamers and consumers has the opposite effect. For brand-affiliate streamers, the reputation mechanism exerts the most significant regulatory influence and should be heightened; additionally, enhancing platform penalties proves effective in cases of streamer overconfidence, whereas reducing supervision costs works better in other scenarios. Regarding professional streamers, a combination of platform penalties and incentive mechanisms leads to more stable and effective regulatory outcomes, especially in cases of streamer or consumer overconfidence. Furthermore, for internet celebrity streamers, the reputation mechanism serves as a beneficial supplement; for ordinary streamers, reducing regulatory costs proves to be more effective. Therefore, this study provides insights for classified and tiered regulation policy formulation regarding livestreaming e-commerce and provides a new perspective for supervision research by integrating overconfidence and evolutionary games."
}

@article{dup_128,
    author = "Caliskan, Aylin and Dangwal, Seema and Dandekar, Thomas",
    title = "Metadata integrity in bioinformatics: Bridging the gap between data and knowledge",
    journal = "Computational and Structural Biotechnology Journal",
    volume = "21",
    pages = "4895-4913",
    year = "2023",
    issn = "2001-0370",
    doi = "https://doi.org/10.1016/j.csbj.2023.10.006",
    url = "https://www.sciencedirect.com/science/article/pii/S2001037023003616",
    keywords = "Meta-data, Error, Annotation, Error-transfer, Wrong labelling, Patient data, Control group, Tools overview",
    abstract = "In the fast-evolving landscape of biomedical research, the emergence of big data has presented researchers with extraordinary opportunities to explore biological complexities. In biomedical research, big data imply also a big responsibility. This is not only due to genomics data being sensitive information but also due to genomics data being shared and re-analysed among the scientific community. This saves valuable resources and can even help to find new insights in silico. To fully use these opportunities, detailed and correct metadata are imperative. This includes not only the availability of metadata but also their correctness. Metadata integrity serves as a fundamental determinant of research credibility, supporting the reliability and reproducibility of data-driven findings. Ensuring metadata availability, curation, and accuracy are therefore essential for bioinformatic research. Not only must metadata be readily available, but they must also be meticulously curated and ideally error-free. Motivated by an accidental discovery of a critical metadata error in patient data published in two high-impact journals, we aim to raise awareness for the need of correct, complete, and curated metadata. We describe how the metadata error was found, addressed, and present examples for metadata-related challenges in omics research, along with supporting measures, including tools for checking metadata and software to facilitate various steps from data analysis to published research."
}

@article{dup_129,
    author = "Friston, Karl J. and Parr, Thomas and Heins, Conor and Constant, Axel and Friedman, Daniel and Isomura, Takuya and Fields, Chris and Verbelen, Tim and Ramstead, Maxwell and Clippinger, John and Frith, Christopher D.",
    title = "Federated inference and belief sharing",
    journal = "Neuroscience \& Biobehavioral Reviews",
    volume = "156",
    pages = "105500",
    year = "2024",
    issn = "0149-7634",
    doi = "https://doi.org/10.1016/j.neubiorev.2023.105500",
    url = "https://www.sciencedirect.com/science/article/pii/S0149763423004694",
    keywords = "Active inference, Distributed cognition, Federated learning, Structure learning, Message passing",
    abstract = "This paper concerns the distributed intelligence or federated inference that emerges under belief-sharing among agents who share a common world—and world model. Imagine, for example, several animals keeping a lookout for predators. Their collective surveillance rests upon being able to communicate their beliefs—about what they see—among themselves. But, how is this possible? Here, we show how all the necessary components arise from minimising free energy. We use numerical studies to simulate the generation, acquisition and emergence of language in synthetic agents. Specifically, we consider inference, learning and selection as minimising the variational free energy of posterior (i.e., Bayesian) beliefs about the states, parameters and structure of generative models, respectively. The common theme—that attends these optimisation processes—is the selection of actions that minimise expected free energy, leading to active inference, learning and model selection (a.k.a., structure learning). We first illustrate the role of communication in resolving uncertainty about the latent states of a partially observed world, on which agents have complementary perspectives. We then consider the acquisition of the requisite language—entailed by a likelihood mapping from an agent's beliefs to their overt expression (e.g., speech)—showing that language can be transmitted across generations by active learning. Finally, we show that language is an emergent property of free energy minimisation, when agents operate within the same econiche. We conclude with a discussion of various perspectives on these phenomena; ranging from cultural niche construction, through federated learning, to the emergence of complexity in ensembles of self-organising systems."
}

@article{dup_130,
    author = "Mantelero, Alessandro",
    title = "The Fundamental Rights Impact Assessment (FRIA) in the AI Act: Roots, legal obligations and key elements for a model template",
    journal = "Computer Law \& Security Review",
    volume = "54",
    pages = "106020",
    year = "2024",
    issn = "2212-473X",
    doi = "https://doi.org/10.1016/j.clsr.2024.106020",
    url = "https://www.sciencedirect.com/science/article/pii/S0267364924000864",
    keywords = "AI Act, Fundamental rights impact assessment, FRIA, Fundamental Rights, AI",
    abstract = "What is the context which gave rise to the obligation to carry out a Fundamental Rights Impact Assessment (FRIA) in the AI Act? How has assessment of the impact on fundamental rights been framed by the EU legislator in the AI Act? What methodological criteria should be followed in developing the FRIA? These are the three main research questions that this article aims to address, through both legal analysis of the relevant provisions of the AI Act and discussion of various possible models for assessment of the impact of AI on fundamental rights. The overall objective of this article is to fill existing gaps in the theoretical and methodological elaboration of the FRIA, as outlined in the AI Act. In order to facilitate the future work of EU and national bodies and AI operators in placing this key tool for human-centric and trustworthy AI at the heart of the EU approach to AI design and development, this article outlines the main building blocks of a model template for the FRIA. While this proposal is consistent with the rationale and scope of the AI Act, it is also applicable beyond the cases listed in Article 27 and can serve as a blueprint for other national and international regulatory initiatives to ensure that AI is fully consistent with human rights."
}

@article{dup_131,
    author = "Peng, Feiyan and Long, Anhua and Chen, Juan and Kang, Khloe Qi",
    title = "A narrative review of Environmentally Oriented Anti-consumption: Definitions, dimensions, and research framework",
    journal = "Sustainable Production and Consumption",
    volume = "51",
    pages = "199-221",
    year = "2024",
    issn = "2352-5509",
    doi = "https://doi.org/10.1016/j.spc.2024.07.001",
    url = "https://www.sciencedirect.com/science/article/pii/S2352550924001933",
    keywords = "Anti-consumption, Environmental concerns, Environmentally Oriented Anti-consumption, Sustainable development, Policy enlightenment",
    abstract = "In the context of political uncertainty, environmental degradation, and resource scarcity, significant changes in individual consumption attitudes underscore the necessity of sustainability and anti-consumption research. Environmentally-oriented anti-consumption (EOA) represents a pivotal research direction that integrates these elements. Utilizing the PRISMA method, we conducted a comprehensive analysis of 428 articles. Our findings indicate that while qualitative methods have traditionally been favored, quantitative research is rapidly increasing. However, the dimensions, measurements, and frameworks employed in quantitative research remain fragmented, signaling a need for further refinement in EOA studies. To advance the theoretical framework of EOA, we rigorously selected and systematically analyzed 36 articles. Following identification, refinement, and expert validation, we proposed a comprehensive taxonomy categorizing EOA into seven major types, each with various sub-dimensions and measurement items. Furthermore, we developed a framework to measure the antecedents and consequences of EOA, incorporating motivational explanatory mechanisms. Our research provides a more precise definition and scope of EOA, thereby enhancing academic understanding. It offers novel tools for businesses and policymakers to implement sustainable practices, positioning on target groups through classification and dimensional measurement. This study aligns policies, marketing, and consumer behavior with sustainability goals, promoting societal development and addressing challenges in evolving social and environmental contexts."
}

@article{dup_132,
    author = "Veldhuis, Annemiek and Lo, Priscilla Y. and Kenny, Sadhbh and Antle, Alissa N.",
    title = "Critical Artificial Intelligence literacy: A scoping review and framework synthesis",
    journal = "International Journal of Child-Computer Interaction",
    volume = "43",
    pages = "100708",
    year = "2025",
    issn = "2212-8689",
    doi = "https://doi.org/10.1016/j.ijcci.2024.100708",
    url = "https://www.sciencedirect.com/science/article/pii/S2212868924000771",
    keywords = "Artificial intelligence, Critical literacy, AI ethics, AI literacy, Computational empowerment, Literature review",
    abstract = "The proliferation of Artificial Intelligence (AI) in everyday life raises concerns for children, other marginalized groups, and the general public. As new AI implementations continue to emerge, it is crucial to enable children to engage critically with AI. Critical literacy objectives and practices can encourage children to question, critique, and transform the social, political, cultural, and ethical implications of AI. As an initial step towards critical AI education, we conducted a 10-year scoping review to identify publications reporting on activities that engage children, between the ages of 5 and 18, to address the critical implications of AI. Our review identifies a wide range of participants, content, and pedagogical approaches. Through framework synthesis guided by an established critical literacy model, we examine the critical literacy learning objectives embedded in the reported activities and propose a critical AI literacy framework. This paper outlines future opportunities for critical AI literacies in the field of child–computer interaction including inspiring new learning activities, encouraging inclusive perspectives, and supporting pragmatic curriculum integration."
}

@incollection{dup_133,
    editor = "Bohr, Adam and Memarzadeh, Kaveh",
    author = "Bohr, Adam and Memarzadeh, Kaveh",
    title = "Chapter 2 - The rise of artificial intelligence in healthcare applications",
    booktitle = "Artificial Intelligence in Healthcare",
    publisher = "Academic Press",
    pages = "25-60",
    year = "2020",
    isbn = "978-0-12-818438-7",
    doi = "https://doi.org/10.1016/B978-0-12-818438-7.00002-2",
    url = "https://www.sciencedirect.com/science/article/pii/B9780128184387000022",
    keywords = "Artificial intelligence, healthcare applications, machine learning, precision medicine, ambient assisted living, natural language programming, machine vision",
    abstract = "Big data and machine learning are having an impact on most aspects of modern life, from entertainment, commerce, and healthcare. Netflix knows which films and series people prefer to watch, Amazon knows which items people like to buy when and where, and Google knows which symptoms and conditions people are searching for. All this data can be used for very detailed personal profiling, which may be of great value for behavioral understanding and targeting but also has potential for predicting healthcare trends. There is great optimism that the application of artificial intelligence (AI) can provide substantial improvements in all areas of healthcare from diagnostics to treatment. It is generally believed that AI tools will facilitate and enhance human work and not replace the work of physicians and other healthcare staff as such. AI is ready to support healthcare personnel with a variety of tasks from administrative workflow to clinical documentation and patient outreach as well as specialized support such as in image analysis, medical device automation, and patient monitoring. In this chapter, some of the major applications of AI in healthcare will be discussed covering both the applications that are directly associated with healthcare and those in the healthcare value chain such as drug development and ambient assisted living."
}

@article{dup_134,
    author = "Xu, Xuesong and Xu, Kai and Zeng, Ziyang and Tang, Jiale and He, Yuanxing and Shi, Guangze and Zhang, Tao",
    title = "Collaborative optimization of multi-energy multi-microgrid system: A hierarchical trust-region multi-agent reinforcement learning approach",
    journal = "Applied Energy",
    volume = "375",
    pages = "123923",
    year = "2024",
    issn = "0306-2619",
    doi = "https://doi.org/10.1016/j.apenergy.2024.123923",
    url = "https://www.sciencedirect.com/science/article/pii/S0306261924013060",
    keywords = "Multi-microgrid system, Integrated multi-energy network, Collaboration optimization, Flexible retraining mechanism, Hierarchical multi-agent reinforcement learning",
    abstract = "In the context of the expanding diversity of energy demands, an increasing number of heterogeneous Multi-energy Microgrids (MEMGs) are engaging in the collaborative framework of the Multi-energy Multi-microgrid System (MEMMG). However, following this trend, the existing centralized Integrated Energy Management System (IEMS) control strategy is unreliable for future energy systems, characterized by more complex optimization control and a flexible system structure. This paper introduces a hierarchical Multi-agent Deep Reinforcement Learning (HMADRL) approach for distributed IEMS in MEMMG. Firstly, by employing a hierarchical approach, this method simplifies control complexity by segmenting the overarching control challenge into tasks of collaborative planning and action control, which are distributed across varied multi-agent scenes. Considering both macro and microeconomic factors, alongside carbon emissions, the optimal operation of MEMMG is realized through a bottom-up edge multi-agent control approach, in contrast to traditional top-down centralized methods. Secondly, in the phase of the inter-MEMG collaborative strategy, the Centralized Training Decentralized Execution (CTDE) framework is adopted to overcome the problems of unstable training environments and large-scale agent training, and each heterogeneous microgrid can develop local strategies independently with the assurance that their internal data will not be overly exposed. Thirdly, within each MEMG, the Trust-Region (TR) model is introduced for multi-agent action control, adeptly addressing the effects of mutual exclusion in decision-making time series. Simultaneously, an initialized Hot Experience Pool (HEP) is implemented, efficiently reducing exploration in complex, high-dimensional spaces. Finally, the off-time agent model is integrated into the HMADRL environment and undergoes secondary training based on real interactions, thereby deriving the optimal energy management policy. The proposed method markedly reduces reliance on exact physical modeling systems. Comparative simulations validate the proposed control scheme’s efficacy."
}

@article{dup_135,
    author = "Smimou, K. and Bosch, D. and Filbeck, G.",
    title = "Commodities and Policy Uncertainty Channel(s)",
    journal = "International Review of Economics \& Finance",
    volume = "92",
    pages = "351-379",
    year = "2024",
    issn = "1059-0560",
    doi = "https://doi.org/10.1016/j.iref.2024.01.065",
    url = "https://www.sciencedirect.com/science/article/pii/S1059056024000650",
    keywords = "Hedgers, Speculators, Commodity stock markets, Commodity futures, Policy uncertainty, Financialization of commodities",
    abstract = "Based on a proposed linked theoretical model, this study dissects the contributory role of policy uncertainty on commodity futures contracts and pertinent commodity equity sectors. Within an economically connected framework, we elucidate the dynamic relationship between these groups of assets while allowing for policy uncertainty shock. Findings show that commodity hedgers altered trading positions in metals in response to a high policy uncertainty shock before 2004. In contrast, speculators account for that shock after that date purely via crude oil. Both monetary policy and regulatory uncertainties influence the pricing dynamics of metals and energy commodities. Given the inextricable commodity–stock relationship, we offer evidence to support the triple effect of economic policy uncertainty on the intensiveness of financialization of commodities and commodity stock returns through (1) change of institutional holdings, (2) managers’ alteration of CAPEX investment of commodity firms, and (3) the interactive causality channel between commodity futures and commodity stocks."
}

@article{dup_136,
    author = "Yan, Jin and Zhang, Jun and Xu, Tiansheng and Gao, Jing and Li, Ni and Gong, Guanghong",
    title = "Representing similarities of map projections: An approach to approximate integrations and dimensionality reductions",
    journal = "Expert Systems with Applications",
    volume = "274",
    pages = "126743",
    year = "2025",
    issn = "0957-4174",
    doi = "https://doi.org/10.1016/j.eswa.2025.126743",
    url = "https://www.sciencedirect.com/science/article/pii/S0957417425003653",
    keywords = "Map projection, Distance matrix, Distortion, Integrals calculation, Approximation, Dimensionality reduction",
    abstract = "This study addresses key limitations in structured or hierarchical classification and pairwise comparison methods for analyzing map projections, which often fail to capture the intricate relationships among them. It introduces an innovative approach that automates and simplifies the approximation of complex results from an improved integration metric for measuring (dis)similarities between projections. This enhances the understanding of over 340 map projections comprehensively. The study combines formula-based and image-based methodologies within a hybrid sampling scheme, effectively handling complex integrations, particularly for projections with intricate formulas. Using NASA’s G.Projector mapping software, an 87 GB image dataset is generated for 175 map projections, while an additional 170 projections are processed through a formula-based approach. The approximate integral calculations closely align with theoretical values, with an acceptable error margin of a few thousandths. To visually represent map projections in two-dimensional space, multiple dimensionality reduction techniques are employed, incorporating features such as distortions. The resulting quantitative metrics demonstrate that global, local, and category-based features are reasonably preserved. A clear and intuitive visual representation simplifies the complexity of map projection relationships, offering valuable insights. Additionally, an interactive web application prototype is developed to showcase the relationships among map projections. To the best of our knowledge, this research is the first to comprehensively evaluate such a large number of map projections using automated calculations combined with dimensionality reduction and visualization techniques. This methodology represents a significant advancement in cartography, providing a robust framework for comparing and analyzing map projections in practice."
}

@article{dup_137,
    author = "Abadie, Amelie and Chowdhury, Soumyadeb and Mangla, Sachin Kumar and Malik, Shaily",
    title = "Impact of carbon offset perceptions on greenwashing: Revealing intentions and strategies through an experimental approach",
    journal = "Industrial Marketing Management",
    volume = "117",
    pages = "304-320",
    year = "2024",
    issn = "0019-8501",
    doi = "https://doi.org/10.1016/j.indmarman.2024.01.001",
    url = "https://www.sciencedirect.com/science/article/pii/S0019850124000014",
    keywords = "Carbon offset, Greenwashing, Agency theory, Revealed preferences, Experiment",
    abstract = "Organizations operating in the Business-to-Business (B2B) ecosystem across the globe are committed to net zero initiatives to achieve sustainability across business processes. In this context, carbon carbon credits have emerged as a carbon offsetting mechanism to help organizations invest in low-carbon initiatives. However, existing studies are yet to examine whether carbon offsetting practices will influence the sustainability behavior of B2B organizations and whether it could lead to greenwashing propensity. In this vein, we adopt agency and revealed pereferences theories to conduct two experiments with B2B small and medium-sized enterprises (SMEs) managers operating in the UK process intensive sectors to reveal that affordability of carbon credits can motivate managers to engage in sustainable attitudes and practices. We also found that organizations willing to buy carbon credits at high price to are likely to engage in high greenwashing propensity. Considering these novel findings, we provide recommendations that will help organizations to become more responsible in their carbon offesteing investments, and for policy makers to adopt stringent assessment of such investments and carbon disclosures made by firms."
}

@article{dup_138,
    author = "Abualigah, Laith and Almomani, Mohammad H. and Alomari, Saleh Ali and Zitar, Raed Abu and Snasel, Vaclav and Saleem, Kashif and Smerat, Aseel and Ezugwu, Absalom E.",
    title = "A control-driven transition strategy for enhanced multi-level threshold image segmentation optimization",
    journal = "Egyptian Informatics Journal",
    volume = "30",
    pages = "100646",
    year = "2025",
    issn = "1110-8665",
    doi = "https://doi.org/10.1016/j.eij.2025.100646",
    url = "https://www.sciencedirect.com/science/article/pii/S1110866525000398",
    keywords = "Flood Algorithm, Non-Monopolize search, Multi-level threshold, Image segmentation, Transition mechanism",
    abstract = "This work proposes an image segmentation approach based on a multi-threshold segmentation method and the enhanced Flood Algorithm combined with the Non-Monopolize search (named Improved IFLANO). The introduced approach, depending on IFLANO, offers much better segmentation quality for various images. Based on the existing structure, two different types of optimization techniques are added within IFLANO to enhance the update dynamics during optimization. The random strategy used in the Aquila optimization procedure enhances the performance of FLA, and a self-transition adaptation enhances the exploration ability of the image analysis. IFLANO framework is implemented for multi-level threshold image segmentation wherein the evaluation metric is Kapur’s entropy-based between-class variance. Benchmarking studies against standard test images show that IFLANO works not only faster but also yields better, more stable outcomes in image segmentations within similar time frames. IFLANO is shown to put any solution a step forward in its search for more accurate alternatives than any of the considered techniques by getting 96\% improvement. We also find that the proposed method got better results in solving large medical clustering applications."
}

@article{dup_139,
    author = "Forouzanfar, Fatemeh and Ahmadzadeh, Amir Mahmoud and Pourbagher-Shahri, Ali Mohammad and Gorji, Ali",
    title = "Significance of NMDA receptor-targeting compounds in neuropsychological disorders: An in-depth review",
    journal = "European Journal of Pharmacology",
    volume = "999",
    pages = "177690",
    year = "2025",
    issn = "0014-2999",
    doi = "https://doi.org/10.1016/j.ejphar.2025.177690",
    url = "https://www.sciencedirect.com/science/article/pii/S0014299925004443",
    keywords = "Excitotoxicity, Glutamate receptors, Neurological diseases, Brain, Synaptic plasticity",
    abstract = "N-methyl-D-aspartate receptors (NMDARs), a subclass of glutamate-gated ion channels, play an integral role in the maintenance of synaptic plasticity and excitation-inhibition balance within the central nervous system (CNS). Any irregularities in NMDAR functions, whether hypo-activation or over-activation, can destabilize neural networks and impair CNS function. Several decades of experimental and clinical investigations have demonstrated that NMDAR dysfunction is implicated in the pathophysiology of various neurological disorders. Despite designing a long list of compounds that differentially modulate NMDARs, success in developing drugs that can selectively and effectively regulate various NMDAR subtypes while showing encouraging efficacy in clinical settings remains limited. A better understanding of the basic mechanism of NMDAR function, particularly its selective regulation in pathological conditions, could aid in designing effective drugs for the treatment of neurological conditions. Here, we reviewed the experimental and clinical investigations that studied the effects of available NMDAR modulators in various neurological disorders and weighed up the pros and cons of the use of these substances on the improvement of functional outcomes of these disorders. Despite numerous efforts to develop NMDAR modulatory drugs that did not produce the desired outcomes, NMDARs remain a significant target for advancing novel drugs to treat neurological disorders. This article reviews the complexity of NMDAR signaling dysfunction in different neurological diseases, the efforts taken to examine designed compounds targeting specific subtypes of NMDARs, including challenges associated with using these substances, and the potential enhancements in drug discovery for NMDAR modulatory compounds by innovative technologies."
}

@article{dup_140,
    author = "{De Martino}, Vincenzo and Palomba, Fabio",
    title = "Classification and challenges of non-functional requirements in ML-enabled systems: A systematic literature review",
    journal = "Information and Software Technology",
    volume = "181",
    pages = "107678",
    year = "2025",
    issn = "0950-5849",
    doi = "https://doi.org/10.1016/j.infsof.2025.107678",
    url = "https://www.sciencedirect.com/science/article/pii/S0950584925000175",
    keywords = "Software engineering for artificial intelligence, Non-functional requirements, Systematic literature reviews",
    abstract = "Context: Machine learning (ML) is nowadays so pervasive and diffused that virtually no application can avoid its use. Nonetheless, its enormous potential is often tempered by the need to manage non-functional requirements (NFRs) and navigate pressing, contrasting trade-offs. Objective: In this respect, we notice a lack of systematic synthesis of challenges explicitly tied to achieving and managing NFRs in ML-enabled systems. Such a synthesis may not only provide a comprehensive summary of the state of the art but also drive further research on the analysis, management, and optimization of NFRS of ML-enabled systems. Method: In this paper, we propose a systematic literature review targeting two key aspects such as (1) the classification of the NFRs investigated so far, and (2) the challenges associated with achieving and managing NFRs in ML-enabled systems during model development Through the combination of well-established guidelines for conducting systematic literature reviews and additional search criteria, we survey a total amount of 130 research articles. Results: Our findings report that current research identified 31 different NFRs, which can be grouped into six main classes. We also compiled a catalog of 26 software engineering challenges, emphasizing the need for further research to systematically address, prioritize, and balance NFRs in ML-enabled systems. Conclusion: We conclude our work by distilling implications and a future outlook on the topic."
}

@article{dup_141,
    author = "Pesqueira, Antonio and {de Bem Machado}, Andreia and Bolog, Sama and Pereira, Rúben and Sousa, Maria José",
    title = "Exploring the impact of EU tendering operations on future AI governance and standards in pharmaceuticals",
    journal = "Computers \& Industrial Engineering",
    volume = "198",
    pages = "110655",
    year = "2024",
    issn = "0360-8352",
    doi = "https://doi.org/10.1016/j.cie.2024.110655",
    url = "https://www.sciencedirect.com/science/article/pii/S0360835224007770",
    keywords = "Artificial Intelligence (AI), Pharmaceutical Industry, Tender Management (TM), Governance, Ethics, Operational Efficiency",
    abstract = "This research examines the incorporation of artificial intelligence (AI) into the domain of tender management (TM) within the pharmaceutical industry, with a particular emphasis on operational efficiency, governance, and compliance with European regulatory standards. A comparative analysis of four companies—two that have adopted AI and two that have not—reveals significant discrepancies in the management of TM processes between AI-driven and traditional companies. The study employs the Delphi method to ascertain expert consensus on eight critical areas of AI governance, including data privacy, transparency, and ethical AI use. The findings indicate that companies integrating AI demonstrate enhanced decision-making capabilities, accelerated processing times, and enhanced stakeholder engagement. However, they also encounter challenges pertaining to ethical governance and regulatory compliance. The research highlights the necessity of aligning the adoption of AI with the latest European directives, such as the AI Act and General Data Protection Regulation (GDPR), to ensure both operational efficiency and adherence to ethical standards. The broader implications of the study underscore the necessity for pharmaceutical companies to develop robust governance frameworks, prioritize ethical considerations, and maintain regulatory compliance to fully leverage the potential of AI. Additionally, the study contributes to the ongoing scholarly discourse by providing empirical evidence on the interplay between AI, ethics, and governance, thereby encouraging further interdisciplinary research. This work emphasizes the critical role of strategic AI adoption in maintaining competitive advantage while safeguarding societal trust and adhering to legal requirements."
}

@article{dup_142,
    author = "Oyelade, Olaide N. and Wang, Hui and Rafferty, Karen",
    title = "SMAR + NIE IdeaGen: A knowledge graph based node importance estimation with analogical reasoning on large language model for idea generation",
    journal = "Expert Systems with Applications",
    volume = "279",
    pages = "127455",
    year = "2025",
    issn = "0957-4174",
    doi = "https://doi.org/10.1016/j.eswa.2025.127455",
    url = "https://www.sciencedirect.com/science/article/pii/S0957417425010772",
    keywords = "Knowledge graphs (KGs), Large language model (LLMs), Idea generation, Novelty, Analogical reasoning, Node importance estimation, Natural language processing (NLP), Isomorphic subgraphs",
    abstract = "Idea generation describes a creative process involving reasoning over some knowledge to derive new information. Traditional approaches such as mind-map and brainstorming are limited and often fail due to lack of quality ideas and ineffective methods. The reasoning capability of large language models (LLMs) have been investigated for ideation tasks and have reported interesting performance. However, these models suffer from limited logical reasoning capability which hinders the use of structural and factual real-world knowledge in discovery of latent insight and predict possible outcome when applied to ideation. In addition, the possibility of LLMs regurgitating knowledge learnt from datasets might adversely impact the degree of novel ideas the models can generate. In this paper, a two-stage logical reasoning approach is applied to initiate the search for candidate idea pathways based on the knowledge graphs (KGs) to address the problem of reasoning, domain-specificity and novelty. The divergence stage this reasoning explores utilizes a new node importance estimation (NIE) technique over KGs to discover latent connections supporting idea generation. In the convergence stage of this reasoning, subgraph matching using analogical reasoning (SMAR) is applied to find matching patterns to describe a new idea. The use of SMAR + NIE and KGs helps to achieve an improvement in reasoning over KGs before transferring such reasoning to LLMs for translation of idea into natural language. To evaluate the degree of novelty of ideas generated, a relevance-to-novelty scoring metrics is proposed based on multiple premise entailment (MPE). We combined this metric with other popular metrics to evaluate the performance of SMAR + NIE on benchmark datasets, and as well on the quality of ideas generated. Findings from the study showed that this approach demonstrates competitive performance with mainstream LLMs in idea generation tasks."
}

@article{dup_143,
    author = "Dewitte, Pierre",
    title = "Better alone than in bad company: Addressing the risks of companion chatbots through data protection by design",
    journal = "Computer Law \& Security Review",
    volume = "54",
    pages = "106019",
    year = "2024",
    issn = "2212-473X",
    doi = "https://doi.org/10.1016/j.clsr.2024.106019",
    url = "https://www.sciencedirect.com/science/article/pii/S0267364924000852",
    keywords = "Privacy, Data protection, GDPR, AI Act, Data protection by design, Data protection impact assessments, Companion chatbots, Enforcement",
    abstract = "Recent years have seen a surge in the development and use of companion chatbots, conversational agents specifically designed to act as virtual friends, romantic partners, life coaches or even therapists. Yet, these tools raise many concerns, especially when their target audience is comprised of vulnerable individuals. While the recently adopted AI Act is expected to address some of these concerns, both compliance and enforcement are bound to take time. Since the development of companion chatbots involves the processing of personal data at nearly every step of the process, from training to fine-tuning to deployment, this paper argues that the General Data Protection Regulation (“GDPR”), and data protection by design more specifically, already provides a solid ground for regulators and courts to force controllers to mitigate these risks. In doing so, it sheds light on the broad material scope of Articles 24(1) and 25(1) GDPR, highlights the role of these provisions as proxies to Fundamental Rights Impact Assessments (“FRIAs”), and peels off the many layers of personal data processing involved in the companion chatbots supply chain. That reasoning served as the basis for a complaint lodged with the Belgian data protection authority, the full text and supporting evidence of which are provided as supplementary materials."
}

@article{dup_144,
    author = "Waqas, Muhammad and Ahmed, Syed Umaid and Tahir, Muhammad Atif and Wu, Jia and Qureshi, Rizwan",
    title = "Exploring Multiple Instance Learning (MIL): A brief survey",
    journal = "Expert Systems with Applications",
    volume = "250",
    pages = "123893",
    year = "2024",
    issn = "0957-4174",
    doi = "https://doi.org/10.1016/j.eswa.2024.123893",
    url = "https://www.sciencedirect.com/science/article/pii/S0957417424007590",
    keywords = "Multiple Instance Learning (MIL), Multi-Instance Learning(MIL), SUpervised MIL, Unsupervised MIL, Bag and Instance Classification, Review, MIL Applications",
    abstract = "Multiple Instance Learning (MIL) is a learning paradigm, where training instances are arranged in sets, called bags, and only bag-level labels are available during training. This learning paradigm has been successfully applied in various real-world scenarios, including medical image analysis, object detection, image classification, drug activity prediction, and many others. This survey paper presents a comprehensive analysis of MIL, highlighting its significance, recent advancements, methodologies, applications, and evolving trends across diverse domains. The survey begins by explaining the core principles that form the basis of MIL and how it differs from traditional learning approaches. This sets the foundation for comprehending the distinct challenges and techniques of solving MIL problems. Next, we discuss how supervised learning algorithms are tailored to support MIL and combine this discussion with a review of seminal MIL algorithms as well as the latest innovations that incorporate neural networks, deep learning architectures, and attention techniques. This comprehensive analysis helps to understand the strengths, limitations, and adaptability of these methods across diverse data modalities, complexities, and applications. In summary, this survey paper provides an essential resource for researchers, practitioners, and enthusiasts seeking a comprehensive understanding of Multiple Instance Learning. It covers foundational concepts, traditional methods, recent advancements, and future directions. By providing a holistic view of MIL’s dynamic landscape, this paper aims to inspire further innovation and exploration in this ever-evolving field."
}

@incollection{dup_145,
    editor = "Vacca, John R.",
    title = "Index",
    booktitle = "Computer and Information Security Handbook (Fourth Edition)",
    publisher = "Morgan Kaufmann",
    edition = "Fourth Edition",
    pages = "II1-II29",
    year = "2024",
    isbn = "978-0-443-13223-0",
    doi = "https://doi.org/10.1016/B978-0-443-13223-0.20002-7",
    url = "https://www.sciencedirect.com/science/article/pii/B9780443132230200027"
}

@incollection{dup_146,
    editor = "Brown, Steven and Tauler, Romà and Walczak, Beata",
    author = "Todeschini, Roberto and Consonni, Viviana and Ballabio, Davide and Grisoni, Francesca",
    title = "4.25 - Chemometrics for QSAR Modeling☆",
    booktitle = "Comprehensive Chemometrics (Second Edition)",
    publisher = "Elsevier",
    edition = "Second Edition",
    address = "Oxford",
    pages = "599-634",
    year = "2020",
    isbn = "978-0-444-64166-3",
    doi = "https://doi.org/10.1016/B978-0-12-409547-2.14703-1",
    url = "https://www.sciencedirect.com/science/article/pii/B9780124095472147031",
    keywords = "Applicability domain, Consensus modelling, Molecular descriptors, QSAR, QSPR, Ranking, Validation, Variable selection",
    abstract = "Chemometrics plays a fundamental role in quantitative structure-activity relationships (QSARs) and quantitative structure-property relationships (QSPRs) methods, which aim at empirically linking the molecular structure of chemicals to experimentally-measurable properties. In fact, chemometrics statistics and chemoinformatics are the basic tools for finding meaningful mathematical relationships between the molecular structure and biological, physico-chemical, toxicological and environmental properties of chemicals. The key elements of QSAR/QSPR are molecular descriptors, which are numerical indices encoding information related to the structure of chemicals and are used as independent variables in the subsequent modeling, thus connecting the QSAR approaches to the multivariate and chemometric world. In this article, historical and novel QSAR modeling approaches are presented. After describing the historical background of QSAR and the classical approaches, molecular descriptors are illustrated, with state-of-the-art as well as novel description methodologies. Additionally, the key principles of QSAR are introduced, along with specific elements of the QSAR modeling workflow, e.g., variable reduction and selection, similarity-based approaches, validation, the definition of applicability domain and consensus modeling."
}

@article{dup_147,
    author = "{Cantero Gamito}, Marta",
    title = "The influence of China in AI governance through standardisation",
    journal = "Telecommunications Policy",
    volume = "47",
    number = "10",
    pages = "102673",
    year = "2023",
    issn = "0308-5961",
    doi = "https://doi.org/10.1016/j.telpol.2023.102673",
    url = "https://www.sciencedirect.com/science/article/pii/S0308596123001842",
    abstract = "Artificial intelligence systems (AIS) are subject to technical standardisation. Technical standards are primarily developed within standard developing organisations (SDOs) traditionally operating under consensus-based, community- and largely industry-driven processes. Governments are increasingly interested in technical standards’ development, accentuating the political dimension of standardisation. This article explores the contribution of technical standardisation to the governance of artificial intelligence (AI) and asks whose views are being implemented in the development of non-state rules for AI. The article, based on empirical research, focuses on the changing governance structure of the International Telecommunications Union (ITU). Overall, the discussion offers an overview of the existing geopolitics in AI-related standardisation and contributes to the scholarship on AI and digital governance by exploring the role of technical standardisation as a tool in AI governance. The research finds an increasing Chinese representation in international standardisation and argues that the political use of standardisation can lead to China establishing its own vision of digital governance. Consequently, the article suggest that China is using participation in recognised SDOs to legitimate its vision for digital governance calling for a re-examination of standardisation considering its implications for democracy and the protection of human rights."
}

@article{dup_148,
    author = "Sievi, Luzia and Pawelec, Maria",
    title = "(How) Should security authorities counter false information on social media in crises? A democracy-theoretical and ethical reflection",
    journal = "International Journal of Disaster Risk Reduction",
    volume = "116",
    pages = "105093",
    year = "2025",
    issn = "2212-4209",
    doi = "https://doi.org/10.1016/j.ijdrr.2024.105093",
    url = "https://www.sciencedirect.com/science/article/pii/S2212420924008550",
    keywords = "Disinformation, Fake news, Security authority, Crisis communication, Debunking, Disaster ethics",
    abstract = "False information on social media accompanies most crises and exacerbates their complexity and consequences. If security authorities and organisations (SAO) want to ensure security in crises, they must therefore curb the spread of false information. However, in liberal democracies, state authorities, but also aid organisations taking on state tasks have a special responsibility to ensure that they do not unjustifiably impair public communication and citizens' constitutionally protected rights when combating false information. (How) Should SAO therefore react to false information? Which ethical questions and value conflicts arise? More concretely, how can SAO implement countermeasures without harming pluralist deliberation and violating democratic principles or values constitutive to their self-understanding? This paper assesses these questions, combining both descriptive and normative ethics and focusing on values such as liberty, autonomy, neutrality, privacy, non-discrimination, and security. It ethically evaluates four countermeasures for SAO to combat false information: Media literacy trainings, social media monitoring, preventive and reactive crisis communication, and community management. It also draws on various methods of qualitative social science research and evidence from the relevant scientific literature to uncover underlying values and value conflicts when it comes to SAO's reactions to false information on social media, and to contextualize the presented ethical considerations with regard to SAO's daily work and challenges. The paper contributes disaster, security, and media ethics and, more practically, to more effective and ethically informed strategies for democratic actors responding to disinformation and misinformation on social media."
}

@article{dup_149,
    author = "Czech, Herwig and Hildebrandt, Sabine and Reis, Shmuel P and Chelouche, Tessa and Fox, Matthew and González-López, Esteban and Lepicard, Etienne and Ley, Astrid and Offer, Miriam and Ohry, Avi and Rotzoll, Maike and Sachse, Carola and Siegel, Sari J and Šimůnek, Michal and Teicher, Amir and Uzarczyk, Kamila and {von Villiez}, Anna and Wald, Hedy S and Wynia, Matthew K and Roelcke, Volker",
    title = "The Lancet Commission on medicine, Nazism, and the Holocaust: historical evidence, implications for today, teaching for tomorrow",
    journal = "The Lancet",
    volume = "402",
    number = "10415",
    pages = "1867-1940",
    year = "2023",
    issn = "0140-6736",
    doi = "https://doi.org/10.1016/S0140-6736(23)01845-7",
    url = "https://www.sciencedirect.com/science/article/pii/S0140673623018457"
}

@article{dup_150,
    author = "Piccoli, Gabriele and Grover, Varun and Rodriguez, Joaquin",
    title = "Digital transformation requires digital resource primacy: Clarification and future research directions",
    journal = "The Journal of Strategic Information Systems",
    volume = "33",
    number = "2",
    pages = "101835",
    year = "2024",
    issn = "0963-8687",
    doi = "https://doi.org/10.1016/j.jsis.2024.101835",
    url = "https://www.sciencedirect.com/science/article/pii/S0963868724000179",
    keywords = "Digital transformation, IT-enabled transformation, Digital ontology, Digital organization, Digital resources",
    abstract = "Responding to recent calls, this essay offers a commentary on the framing and definition of organizational digital transformation. We focus on the unique ontology of digital transformation and delineate it from neighboring concepts.Our contention is that, despite its volume, current research remains unclear about how the digital transformation of organizations differs from their IT-enabled transformation. We advocate definitional precision to foster knowledge accumulation and to enable scholars to pursue important research questions that are unique to digital transformation. Our perspective, grounded in the notion of digital resources, defines digital transformation as the metamorphosis of an IT-enabled organization into a digital organization – one with a specific digital architecture and design principles.A key departure from previous conceptualization is that we characterize digital transformation as a change in digital technology architecture rather than a change from digital technology use. Our paper achieves the following: describes the constructs underpinning this formulation, digital resources and digital organization; justifies their use; and describes what research directions the new perspective promotes. With sound definitions of key constructs, Information Systems scholars have the unprecedented opportunity to lead the way in digital “x” research, making our discipline the reference point for the burgeoning “digital research” literature in related business fields."
}

@article{dup_151,
    author = "Bays, Harold Edward and Fitch, Angela and Cuda, Suzanne and Gonsahn-Bollie, Sylvia and Rickey, Elario and Hablutzel, Joan and Coy, Rachel and Censani, Marisa",
    title = "Artificial intelligence and obesity management: An Obesity Medicine Association (OMA) Clinical Practice Statement (CPS) 2023",
    journal = "Obesity Pillars",
    volume = "6",
    pages = "100065",
    year = "2023",
    issn = "2667-3681",
    doi = "https://doi.org/10.1016/j.obpill.2023.100065",
    url = "https://www.sciencedirect.com/science/article/pii/S2667368123000116",
    keywords = "Adiposopathy, Artificial intelligence, Education, Obesity",
    abstract = "Background This Obesity Medicine Association (OMA) Clinical Practice Statement (CPS) provides clinicians an overview of Artificial Intelligence, focused on the management of patients with obesity. Methods The perspectives of the authors were augmented by scientific support from published citations and integrated with information derived from search engines (i.e., Chrome by Google, Inc) and chatbots (i.e., Chat Generative Pretrained Transformer or Chat GPT). Results Artificial Intelligence (AI) is the technologic acquisition of knowledge and skill by a nonhuman device, that after being initially programmed, has varying degrees of operations autonomous from direct human control, and that performs adaptive output tasks based upon data input learnings. AI has applications regarding medical research, medical practice, and applications relevant to the management of patients with obesity. Chatbots may be useful to obesity medicine clinicians as a source of clinical/scientific information, helpful in writings and publications, as well as beneficial in drafting office or institutional Policies and Procedures and Standard Operating Procedures. AI may facilitate interactive programming related to analyses of body composition imaging, behavior coaching, personal nutritional intervention \& physical activity recommendations, predictive modeling to identify patients at risk for obesity-related complications, and aid clinicians in precision medicine. AI can enhance educational programming, such as personalized learning, virtual reality, and intelligent tutoring systems. AI may help augment in-person office operations and telemedicine (e.g., scheduling and remote monitoring of patients). Finally, AI may help identify patterns in datasets related to a medical practice or institution that may be used to assess population health and value-based care delivery (i.e., analytics related to electronic health records). Conclusions AI is contributing to both an evolution and revolution in medical care, including the management of patients with obesity. Challenges of Artificial Intelligence include ethical and legal concerns (e.g., privacy and security), accuracy and reliability, and the potential perpetuation of pervasive systemic biases."
}

@article{dup_152,
    author = "Ma, Rui and Wang, Xueqing and Yang, Guo-Rui",
    title = "Fighting fake news in the age of generative AI: Strategic insights from multi-stakeholder interactions",
    journal = "Technological Forecasting and Social Change",
    volume = "216",
    pages = "124125",
    year = "2025",
    issn = "0040-1625",
    doi = "https://doi.org/10.1016/j.techfore.2025.124125",
    url = "https://www.sciencedirect.com/science/article/pii/S0040162525001568",
    keywords = "Artificial intelligence (AI)-generated fake news, Fake news governance, Adaptive governance theory, User-generated content (UGC) platform, Opinion leader, Public opinion monitor agency (POMA)",
    abstract = "The advancements in algorithm technology have led to a proliferation of artificial intelligence-generated fake news, resulting in significant social harm. Promoting multi-stakeholder engagement in fake news governance is beneficial for establishing a robust information ecosystem. The primary stakeholders, including the government at the policy-making end, user-generated content platforms at the algorithm development end, and opinion leaders at the news dissemination end, possess varying degrees of initiative and roles in governance. The main objective of this study is to investigate the evolutionary process of behaviors among multi-stakeholders in fake news governance and their influencing factors under different news environments. This study constructs an evolutionary game model to identify the conditions for the realization of five models of fake news governance. Stakeholders' behaviors in different states are affected by external factors, such as news environment, penalties, and incentives, as well as internal factors, such as governance capability deficiencies and platform algorithm reliability. The research findings expand the boundary of adaptive governance theory by revealing the mechanisms of stakeholder collaboration and the interaction between stakeholders and the news environment in fake news governance. These insights offer valuable guidance for advancing the transformation and enhancement of fake news governance models."
}

@article{dup_153,
    author = "Ashik, Farhan and {Marc Lim}, Weng and Vassallo, Jarrod P. and Voola, Ranjit",
    title = "Can marketing reduce inequality? Evidence from marketing science",
    journal = "Journal of Business Research",
    volume = "188",
    pages = "115053",
    year = "2025",
    issn = "0148-2963",
    doi = "https://doi.org/10.1016/j.jbusres.2024.115053",
    url = "https://www.sciencedirect.com/science/article/pii/S0148296324005575",
    keywords = "Inequality, Marketing, Systematic Literature Review, Sustainable Development Goals",
    abstract = "Reducing inequality is integral to ensuring that no one is left behind. As a discipline, marketing can play a significant role in addressing inequality. To understand the current status and potential of marketing theory and practice to reduce inequality, a comprehensive and systematic literature review is needed. Addressing this gap, we conduct a systematic review of 313 marketing studies on inequalities. Our review highlights that inequality manifests in numerous ways—including consumption, culture, digital, economic, education, gender, geographical, health, income, power, racial, social, socioeconomic, structural, wealth, and general inequalities—and identifies five broad categories of antecedents and outcomes (individual, family, environmental, organization, and country). However, many studies lack specificity in defining and examining these inequalities, hindering the development of targeted interventions. To address this, we propose new definitions for each type of inequality and outline clear pathways for future research. These contributions not only highlight current progress in the field but also establish a roadmap for advancing marketing scholarship on inequality."
}

@article{dup_154,
    author = "Zivic, Fatima and Malisic, Ana Kaplarevic and Grujovic, Nenad and Stojanovic, Boban and Ivanovic, Milos",
    title = "Materials informatics: A review of AI and machine learning tools, platforms, data repositories, and applications to architectured porous materials",
    journal = "Materials Today Communications",
    volume = "48",
    pages = "113525",
    year = "2025",
    issn = "2352-4928",
    doi = "https://doi.org/10.1016/j.mtcomm.2025.113525",
    url = "https://www.sciencedirect.com/science/article/pii/S2352492825020379",
    keywords = "Traditional computational models, Data-driven AI material models, Smart materials, Deep Tech, Structure-property-processing relationships, High-throughput screening, Electrospinning, 3D printed biomimetic porosity",
    abstract = "This review presents the key aspects and development directions of materials informatics, emphasizing the role of artificial intelligence (AI) and machine learning (ML) in materials science research. The objective is to provide a comprehensive overview of materials informatics tools, workflows, and case studies, particularly aimed at experimental researchers unfamiliar with AI frameworks. Basic concepts are introduced and traditional modelling methods compared to AI/ML-assisted models. Existing material models serve as a foundation for advanced modelling and simulations aimed at reducing the time required for characterisation and discovery, with physics-based models gaining importance in the development of AI-supported surrogate models. This review also covers currently available resources, including: (i) software for solving complex mathematical equations and material modelling; (ii) web-based platforms and tools designed for both expert and non-expert users; and (iii) materials data repositories, prioritising standardisation. Case examples involving materials with architectured macro-, micro-, and nano-porosity are reviewed across three material types: metal-organic frameworks (MOFs), electrospun PVDF piezoelectrics, and 3D printed mechanical metamaterials. Traditional computational models offer interpretability and physical consistency, AI/ML excels in speed and complexity handling but may lack transparency. Hybrid models combining both approaches show excellent results in prediction, simulation, and optimisation, offering both speed and interpretability. Progress depends on modular, interoperable AI systems, standardised FAIR data, and cross-disciplinary collaboration. Addressing data quality and integration challenges will resolve issues related to metadata gaps, semantic ontologies, and data infrastructures, especially for small datasets and unlock transformative advances in fields like nanocomposites, MOFs, and adaptive materials."
}

@article{dup_155,
    author = "Yu, Zhao and Zhang, Peize and Shi, Jing",
    title = "Transformation of industrial robotics with natural language models: Recent progress and future prospects",
    journal = "Robotics and Computer-Integrated Manufacturing",
    volume = "97",
    pages = "103113",
    year = "2026",
    issn = "0736-5845",
    doi = "https://doi.org/10.1016/j.rcim.2025.103113",
    url = "https://www.sciencedirect.com/science/article/pii/S073658452500167X",
    keywords = "Natural language models, Industrial robots, Industry 4.0/5.0, Human-robot interactions, Regulatory considerations",
    abstract = "Integration of Natural Language Models (NLMs) into industrial robots enhances operational efficiency and intuitive human-robot interactions, and thus it represents a significant opportunity in the pursuit of Industry 4.0/5.0. This paper provides a comprehensive survey on the technological advancements and applications in this area, by emphasizing their role in improving task execution, cognitive capabilities, and communication in the industrial environments. Meanwhile, related challenges are analyzed and discussed. In particular, NLMs inherently struggle with contextual understanding, which can lead to inappropriate or impractical outputs in complex industrial environments. Also, the external noise and the need for real-time responsiveness present further complications to the effectiveness of NLMs. Concerns regarding safety, transparency, privacy, and ethical usage amplify the need for regulatory considerations. In addition, standardized approaches to interpreting vague human instructions are called for to improve the interaction between humans and robots. It is pointed out that the broader impacts of NLMs can extend beyond industrial environments into commercial and social settings, thereby enhancing service quality and customer interactions. As a result, the review is expected to provide insights on how to effectively integrate NLMs with robotic systems, stimulate research to address the remaining challenges, and enhance transparency to improve social acceptability."
}

@article{dup_156,
    author = "Weimann, Arved and Bezmarevic, Mihailo and Braga, Marco and Correia, M. Isabel T.D. and Funk-Debleds, Pamela and Gianotti, Luca and Gillis, Chelsia and Hübner, Martin and Inciong, Jesus Fernando B. and Jahit, Mohammad Shukri and Klek, Stanislaw and Kori, Takayuki and Laviano, Alessandro and Ljungqvist, Olle and Lobo, Dileep N. and Segurola, Carmelo Loinaz and Montroni, Isacco and Reddy, B. Ravinder and Saur, Nicole M. and Schweinlin, Anna and Shi, Han-Ping and Takeuchi, Hiroya and Waitzberg, Dan L. and Wallengren, Ola and Wischmeyer, Paul E. and Ysebaert, Dirk and Bischoff, Stephan C.",
    title = "ESPEN guideline on clinical nutrition in surgery – Update 2025",
    journal = "Clinical Nutrition",
    volume = "53",
    pages = "222-261",
    year = "2025",
    issn = "0261-5614",
    doi = "https://doi.org/10.1016/j.clnu.2025.08.029",
    url = "https://www.sciencedirect.com/science/article/pii/S0261561425002432",
    keywords = "Enhanced recovery after surgery, Enteral nutrition, Parenteral nutrition, Perioperative nutrition, Prehabilitation, Surgery",
    abstract = "Summary Early oral feeding is the preferred mode of nutrition for surgical patients. Avoidance of any nutritional therapy bears the risk of underfeeding during the postoperative course after major surgery. Considering that malnutrition and underfeeding are risk factors for postoperative complications, nutritional therapy is mandatory for any surgical patient at nutritional risk, especially for those undergoing upper gastrointestinal surgery. The focus of this guideline is to cover nutritional aspects of the Enhanced Recovery After Surgery (ERAS) concept and the special nutritional needs of patients undergoing major surgery, e.g. for cancer, and of those developing severe complications despite best perioperative care. From a metabolic and nutritional point of view, the key aspects of perioperative care include: a) Integration of nutrition into the overall management of the patient, b) avoidance of long periods of preoperative fasting c) re-establishment of oral feeding as early as possible after surgery d) start of nutritional therapy early, as soon as a nutritional risk becomes apparent e) metabolic control e.g. of blood glucose, f) reduction of factors which exacerbate stress-related catabolism or impair gastrointestinal function, g) minimized time on paralytic agents in the postoperative period, and h) early mobilization to facilitate protein synthesis and muscle function. The guideline presents 44 recommendations for clinical practice in patients undergoing elective and non-elective surgery, including new recommendations for frailty assessment, sarcopenia diagnosis, and prehabilitation. As in the former ESPEN practical guideline, the recommendations were additonally presented in decision-making flowcharts."
}

@article{dup_157,
    author = "Bennehalli, Basavaraju and Poyil, Suresh Subramanyam and Lokesh, Budigi and Nagaraja, Santhosh and Basavaraju, Sunil and Rispandi and Ammarullah, Muhammad Imam",
    title = "A review on the formation, recovery, and properties of coal fly ash (CFA)-derived microspheres for sustainable technologies and biomedical applications",
    journal = "Next Materials",
    volume = "9",
    pages = "101172",
    year = "2025",
    issn = "2949-8228",
    doi = "https://doi.org/10.1016/j.nxmate.2025.101172",
    url = "https://www.sciencedirect.com/science/article/pii/S2949822825006902",
    keywords = "Coal fly ash (CFA), Cenospheres (CS), Plerospheres (PS), Ferrospheres (FS), Microspheres",
    abstract = "Coal fly ash (CFA), a by-product of coal combustion in thermal power plant (TPP), is an environmental concern due to its massive production and improper disposal. Among its components, microspheres like cenospheres (CS), plerospheres (PS), and ferrospheres (FS) hold significant industrial value. CS are lightweight, hollow particles with unique properties such as low density, high mechanical strength, and thermal stability, making them suitable for composites, ceramics, and insulation. PS, with their porous structures, are useful in construction and ceramics, while FS, rich in iron, are applied in catalysis and magnetic materials. Additionally, CFA-derived microspheres, such as CS and FS, exhibit promising potential in biomedical applications due to their unique structural and chemical features. Their suitability for drug delivery, tissue engineering, and diagnostic tools highlights their emerging role in sustainable healthcare solutions. This review focuses on the formation, recovery, and properties of these microspheres, highlighting their sustainable applications in lightweight composites, environmental clean-up, and advanced materials. Various recovery methods, including wet and dry techniques, are discussed to optimize extraction processes. The study emphasizes the potential of these microspheres in reducing CFA waste while supporting innovative and eco-friendly technologies. This work contributes to developing sustainable solutions for managing CFA, with the goal of reducing environmental impacts and enhancing industrial utility, particularly in sustainable and biomedical applications."
}

@incollection{dup_158,
    editor = "Chou, Ting-Chao",
    author = "Chou, Ting-Chao",
    title = "Chapter I - A new alternative concept for cost-effective R\&D: The MAL-dynamics/algorithms/digital informatics⊛⊛This book has a companion website hosting complementary materials. Visit this URL to access it: https://www.elsevier.com/books-and-journals/book-companion/9780443288746.",
    booktitle = "Mass-Action Law Dynamics Theory and Algorithm for Translational and Precision Medicine Informatics",
    publisher = "Academic Press",
    pages = "1-37",
    year = "2024",
    isbn = "978-0-443-28874-6",
    doi = "https://doi.org/10.1016/B978-0-443-28874-6.00001-9",
    url = "https://www.sciencedirect.com/science/article/pii/B9780443288746000019",
    keywords = "Mass-action law dynamics, Bioinformatics algorithms, Biodynamics simulation, Pharmacodynamics, Median-effect equation, Median-effect plot and simulation, Doctrine of the median, Combination index equation, Combination index computer simulation, CompuSyn software, CalcuSyn software, Dose-reduction index equation, Dose-reduction index computer simulation, Definition of synergism, Definition of pharmacodynamics",
    abstract = "This chapter provides a comprehensive overview, illustrations, and updates of the mass-action law (MAL) based on unified general dose-effect pharmacodynamics, biodynamics, bioinformatics, and the combination index theorem for synergy definition and quantification (MAL-PD/BD/BI/CI). The general system analysis was developed with pattern analysis, combinatory analysis, and mathematical induction and deduction on the MAL principle, which resulted in (i) The general median-effect equation (MEE) for each entity with two basic dynamic parameters of potency (Dm) and dynamics-order (m), for the potency and the shape of dose-effect curves; (ii) the combination index equation (CIE) theorem/algorithm, determines the drugs or entities interaction, where CI < 1, =1, and >1 indicate synergism, additive-effect, and antagonism, respectively; (iii) the dose-reduction index equation (DRIE) that digitally determines the outcomes of how many folds of dose-reduction for each drug in synergistic combinations. Since all terms of MAL-general-equations (MEE, CIE, and DRIE) are dimensionless-relativity ratios, they are equally applicable in vitro, in animals, and in clinical trials. They are also valid regardless of drug entities, units, mechanisms, or physical states. To date, this MAL-PD/BD/BI/CI theory-based “Top-Down” approach and quantitative method has received multidisciplinary research popularity globally, with citations in over 1500 journals and 1268 citing patents, encompassing nearly all disciplines of biomedical sciences and beyond, the subjects including material, agricultural, marine, environmental and food sciences. Original applications were mainly in vitro; however, in vivo PD applications are on the rise. The MAL-BD/PD unified theory/method has the features of simplicity, efficiency, and cost-effectiveness, allows automated computer simulation with only a few dose-data points, and shares the same basic MAL principle. In vitro, in vivo, or other physical states in animal studies and clinical trial protocol design, automated computerized data analysis and simulation to single drug and drug combinations. With the same MAL-PD principle, thus enabling comparisons and rankings. This book illustrates the MAL-dynamics theory to update the increasing applications in recent years and to provide specific real sample analysis, including data entries and automated computer report print-outs in Appendixes and Supplementary Materials in PDF slides illustrations. The MAL-theory-based Top Down approach (traditional biomedical R\&D) is an observation and statistics-based “Bottom-Up” approach with specific aims, proposals, and methods to reach feasible hypotheses or conclusions. This open approach is usually accomplished with multiple experimental evidence and results, using unbiased statistics or other methods to reach a hypothesis, mechanism, or interpretive conclusion. However, the best curve fitting for dose-effect relationship data is frequently empirical and requires many dose-data points. The primary purpose of this book is to indicate that the MAL theory/algorithm-based “Top-Down” digital approach is the opposite and yet a complementary alternative to the observation/statistics-based “Bottom-Up” traditional approach in R\&D."
}

@article{dup_159,
    author = "Ammarullah, Muhammad Imam and Kozin, Muhammad and Maula, Mohamad Izzur and {Danny Pratama Lamura}, M. and Wicaksono, Hasyid Ahmad and Bayuseno, Athanasius Priharyoto and Jamari, Jamari and Ramlee, Muhammad Hanif",
    title = "A review of enhanced total hip prosthesis design and material bearing combination to accommodate Muslim prayer (Salat) movements: Biomechanical, biotribological, and biological perspectives",
    journal = "Tribology International",
    volume = "205",
    pages = "110518",
    year = "2025",
    issn = "0301-679X",
    doi = "https://doi.org/10.1016/j.triboint.2025.110518",
    url = "https://www.sciencedirect.com/science/article/pii/S0301679X25000131",
    keywords = "Total hip prosthesis, Design, Bearing, Muslim prayer (Salat)",
    abstract = "Total hip prostheses have greatly improved mobility and quality of life for patients with hip disorders. However, the unique biomechanical demands of Muslim prayer (Salat), involving complex, repetitive movements, pose challenges for standard designs. This review highlights advancements in prosthesis design, emphasizing dual mobility bearings for enhanced stability and range of motion, and Ceramic-on-Polymer (CoP) bearings for durability and reduced wear. By addressing biomechanical, biotribological, and biological factors, these innovations optimize prosthetic performance, meeting the functional and cultural needs of Muslim patients while ensuring long-term durability and satisfaction."
}

@article{dup_160,
    author = "Ferrag, Mohamed Amine and Alwahedi, Fatima and Battah, Ammar and Cherif, Bilel and Mechri, Abdechakour and Tihanyi, Norbert and Bisztray, Tamas and Debbah, Merouane",
    title = "Generative AI in cybersecurity: A comprehensive review of LLM applications and vulnerabilities",
    journal = "Internet of Things and Cyber-Physical Systems",
    volume = "5",
    pages = "1-46",
    year = "2025",
    issn = "2667-3452",
    doi = "https://doi.org/10.1016/j.iotcps.2025.01.001",
    url = "https://www.sciencedirect.com/science/article/pii/S2667345225000082",
    keywords = "Generative AI, LLM, Transformer security, Cybersecurity",
    abstract = "This paper provides a comprehensive review of the future of cybersecurity through Generative AI and Large Language Models (LLMs). We explore LLM applications across various domains, including hardware design security, intrusion detection, software engineering, design verification, cyber threat intelligence, malware detection, and phishing detection. We present an overview of LLM evolution and its current state, focusing on advancements in models such as GPT-4, GPT-3.5, Mixtral-8x7B, BERT, Falcon2, and LLaMA. Our analysis extends to LLM vulnerabilities, such as prompt injection, insecure output handling, data poisoning, DDoS attacks, and adversarial instructions. We delve into mitigation strategies to protect these models, providing a comprehensive look at potential attack scenarios and prevention techniques. Furthermore, we evaluate the performance of 42 LLM models in cybersecurity knowledge and hardware security, highlighting their strengths and weaknesses. We thoroughly evaluate cybersecurity datasets for LLM training and testing, covering the lifecycle from data creation to usage and identifying gaps for future research. In addition, we review new strategies for leveraging LLMs, including techniques like Half-Quadratic Quantization (HQQ), Reinforcement Learning with Human Feedback (RLHF), Direct Preference Optimization (DPO), Quantized Low-Rank Adapters (QLoRA), and Retrieval-Augmented Generation (RAG). These insights aim to enhance real-time cybersecurity defenses and improve the sophistication of LLM applications in threat detection and response. Our paper provides a foundational understanding and strategic direction for integrating LLMs into future cybersecurity frameworks, emphasizing innovation and robust model deployment to safeguard against evolving cyber threats."
}

@article{dup_161,
    author = "Al-kfairy, Mousa and Ahmed, Soha and Khalil, Ashraf",
    title = "Factors impacting users’ willingness to adopt and utilize the metaverse in education: A systematic review",
    journal = "Computers in Human Behavior Reports",
    volume = "15",
    pages = "100459",
    year = "2024",
    issn = "2451-9588",
    doi = "https://doi.org/10.1016/j.chbr.2024.100459",
    url = "https://www.sciencedirect.com/science/article/pii/S2451958824000927",
    keywords = "Metaverse education, Intention to use, Acceptance, Systematic review, Information systems theories",
    abstract = "Purpose This study explores the factors influencing the adoption and acceptance of Metaverse technologies in educational settings. Despite the growing interest in immersive educational environments provided by the Metaverse, there is a lack of comprehensive understanding regarding the elements that affect user engagement and acceptance. This paper aims to bridge this gap through a systematic review of empirical studies that apply Information Systems theories such as TAM, UTAUT, TPB, and their extensions. Methods A total of 35 empirical studies were analyzed using a methodical review approach. The research methodologies employed in these studies include surveys, structural equation modeling, and interviews, providing a broad spectrum of data on how different factors influence educational outcomes in the Metaverse. Results The findings reveal that user adoption of the Metaverse in educational contexts is influenced by multiple factors at individual, technological, and environmental levels. Key factors identified include effort expectancy, behavioral intention, self-efficacy, enjoyment, and immersion. These factors are subject to moderating effects, suggesting that the dynamics of Metaverse adoption are highly context-dependent. Conclusion The insights gained from this review provide valuable guidelines for educators, policymakers, and technology developers aiming to effectively integrate Metaverse technologies into educational frameworks. The study also outlines limitations and suggests directions for future research, highlighting the need for further investigations into the longitudinal impacts and cultural adaptability of Metaverse applications in education."
}

@article{dup_162,
    author = "Beck, Tammy E. and Solansky, Stephanie T. and Davis, Daniel J. and Ford-Eickhoff, Karen and Plowman, Donde",
    title = "Boundary work and high-reliability organizing in interorganizational collaborations",
    journal = "Information and Organization",
    volume = "34",
    number = "3",
    pages = "100524",
    year = "2024",
    issn = "1471-7727",
    doi = "https://doi.org/10.1016/j.infoandorg.2024.100524",
    url = "https://www.sciencedirect.com/science/article/pii/S1471772724000241",
    keywords = "High reliability organizing, HRO collaboration, Boundary work, Boundary object",
    abstract = "Consider the massive recovery response that included over 25,000 professionals and volunteers representing more than 120 organizations tasked with locating both human remains and vehicle debris following the Columbia Space Shuttle tragedy. Despite the daunting scope of the initial search area – 2.28 million acres of land – participating members were successful in their efforts to achieve the collective's goals. We contend that the response effort was effective because relatively disparate organizations and governmental agencies came together and ultimately exemplified the hallmarks of high reliability organizing (HRO). Our study explores how the transition in boundaries made this possible. Using interview and secondary data from our case study, we explore how individuals engaged in boundary work that facilitated boundary transformation. Specifically, we document how individuals interacted with a data visualization system to temper the physical, social, temporal, and scope boundary tensions initially present following the disaster. Amidst an emergent, messy, and complex setting, the interaction with a boundary object allowed for unity in diversity of participating organizations, a common language through mapping, a form of trichordal temporal and rapid sensemaking, and a foundation for dynamic decision making. Therefore, our study yields critical insights into how organizational members engage in boundary work to aid HRO collaborations."
}

@article{dup_163,
    author = "Sanchez-Wells, David and Andrade-Pineda, José L. and Gonzalez-R, Pedro L.",
    title = "Truck-multidrone same-day delivery strategies: On-road resupply vs depot return",
    journal = "Expert Systems with Applications",
    volume = "272",
    pages = "126757",
    year = "2025",
    issn = "0957-4174",
    doi = "https://doi.org/10.1016/j.eswa.2025.126757",
    url = "https://www.sciencedirect.com/science/article/pii/S0957417425003793",
    keywords = "Truck-Multidrone Logistics, Genetic Algorithm, Makespan, Truck Mileage, Last-mile Delivery, Resupply",
    abstract = "This paper explores an enhanced two-waved same-day delivery (SDD) system that leverages a mothership truck equipped with multiple drones supported by an auxiliary “resupply” truck. Under standard SDD operations, this mothership truck, also capable of performing deliveries, must return to the depot to reload, incurring extra travel time and mileage. In contrast, the proposed resupply strategy enables the second delivery wave by dispatching a secondary vehicle to meet the mothership truck on-road, reloading parcels without interrupting ongoing deliveries by the drones. A single unified routing framework, the Genetic Algorithm with Iterated Estimations for Resupply (GAIER), is presented to optimise both strategies under two selectable criteria: minimising total service time or total truck mileage. In tests with benchmark networks of different sizes (20, 50, and 75 nodes), incorporating a resupply truck reduced every selected criterion when compared to the strategy where the mothership vehicle returns to the depot. Subsequent comparative analysis points an average reduction of 17 \% in service time and 21 \% in truck mileage while statistical analyses support the strategy choice significancy, confirming resupply strategy’s potential for cost savings and reduced environmental impact. These findings bolster our proposition that incorporating a resupply truck into hybrid truck-multidrone systems enhances flexibility in drone delivery scheduling and improves the system’s ability to meet urban demand."
}

@article{dup_164,
    author = "Deng, Ruiqi and Jiang, Maoli and Yu, Xinlu and Lu, Yuyan and Liu, Shasha",
    title = "Does ChatGPT enhance student learning? A systematic review and meta-analysis of experimental studies",
    journal = "Computers \& Education",
    volume = "227",
    pages = "105224",
    year = "2025",
    issn = "0360-1315",
    doi = "https://doi.org/10.1016/j.compedu.2024.105224",
    url = "https://www.sciencedirect.com/science/article/pii/S0360131524002380",
    keywords = "Teaching/learning strategies, Improve classroom teaching, Elementary education, Secondary education, Post-secondary education",
    abstract = "Chat Generative Pre-Trained Transformer (ChatGPT) has generated excitement and concern in education. While cross-sectional studies have highlighted correlations between ChatGPT use and learning performance, they fall short of establishing causality. This review examines experimental studies on ChatGPT's impact on student learning to address this gap. A comprehensive search across five databases identified 69 articles published between 2022 and 2024 for analysis. The findings reveal that ChatGPT interventions are predominantly implemented at the university level, cover various subject areas focusing on language education, are integrated into classroom environments as part of regular educational practices, and primarily involve direct student use of ChatGPT. Overall, ChatGPT improves academic performance, affective-motivational states, and higher-order thinking propensities; it reduces mental effort and has no significant effect on self-efficacy. However, methodological limitations, such as the lack of power analysis and concerns regarding post-intervention assessments, warrant cautious interpretation of results. This review presents four propositions from the findings: (1) distinguish between the quality of ChatGPT outputs and the positive effects of interventions on academic performance by shifting from well-defined problems in post-intervention assessments to more complex, project-based assessments that require skill demonstration, adopting proctored assessments, or incorporating metrics such as originality alongside quality; (2) evaluate long-term impacts to determine whether the positive effects on affective-motivational states are sustained or merely owing to novelty effect; (3) prioritise objective measures to complement subjective assessments of higher-order thinking; and (4) use power analysis to determine adequate sample sizes to avoid Type II errors and provide reliable effect size estimates. This review provides valuable insights for researchers, instructors, and policymakers evaluating the effectiveness of generative AI integration in educational practice."
}

@article{dup_165,
    author = "Buja, L. Maximilian",
    title = "Pathobiology of myocardial and cardiomyocyte injury in ischemic heart disease: Perspective from seventy years of cell injury research",
    journal = "Experimental and Molecular Pathology",
    volume = "140",
    pages = "104944",
    year = "2024",
    issn = "0014-4800",
    doi = "https://doi.org/10.1016/j.yexmp.2024.104944",
    url = "https://www.sciencedirect.com/science/article/pii/S0014480024000649",
    keywords = "Cardiomyocyte, Myocardial ischemia, Calcium measurements, Pathology, Reperfusion, Conditioning, Oncosis, Apoptosis, Autophagy",
    abstract = "This review presents a perspective on the pathobiology of acute myocardial infarction, a major manifestation of ischemic heart disease, and related mechanisms of ischemic and toxic cardiomyocyte injury, based on advances and insights that have accrued over the last seventy years, including my sixty years of involvement in the field as a physician-scientist-pathologist. This analysis is based on integration of my research within the broader context of research in the field. A particular focus has been on direct measurements in cardiomyocytes of electrolyte content by electron probe X-ray microanalysis (EPXMA) and Ca2+ fluxes by fura-2 microspectrofluorometry. These studies established that increased intracellular Ca2+ develops at a transitional stage in the progression of cardiomyocyte injury in association with ATP depletion, other electrolyte alterations, altered cell volume regulation, and altered membrane phospholipid composition. Subsequent increase in total calcium with mitochondrial calcium accumulation can occur. These alterations are characteristic of oncosis, which is an initial pre-lethal state of cell injury with cell swelling due to cell membrane dysfunction in ATP depleted cells; oncosis rapidly progresses to necrosis/necroptosis with physical disruption of the cell membrane, unless the adverse stimulus is rapidly reversed. The observed sequential changes fit a three-stage model of membrane injury leading to irreversible cell injury. The data establish oncosis as the primary mode of cardiomyocyte injury in evolving myocardial infarcts. Oncosis also has been documented to be the typical form of non-ischemic cell injury due to toxins. Cardiomyocytes with less energy impairment have the capability of undergoing apoptosis and autophagic death as well as oncosis, as is seen in pathological remodeling in chronic heart failure. Work is ongoing to apply the insights from experimental studies to better understand and ameliorate myocardial ischemia and reperfusion injury in patients. The perspective and insights in this review are derived from basic principles of pathology, an integrative discipline focused on mechanisms of disease affecting the cell, the organizing unit of living organisms."
}
