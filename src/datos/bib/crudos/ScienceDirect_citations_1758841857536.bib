@article{MENG2025104166,
title = {Personal information organization literacy in the academic context: Scale development, performance assessment, and influence exploration},
journal = {Information Processing & Management},
volume = {62},
number = {5},
pages = {104166},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104166},
url = {https://www.sciencedirect.com/science/article/pii/S0306457325001074},
author = {Gaohui Meng and Chang Liu},
keywords = {Personal information management, Information literacy, Scale development and validation, Learning performance, Academic procrastination},
abstract = {Personal information management literacy (PIML) is a literacy that has been increasingly valued and highlighted in the emerging knowledge society, yet the related research is insufficient. This study focuses on personal information organization literacy (PIOL) as an essential component of PIML, examining its measurement, assessment, and influence in the academic context. We conducted two linked studies to address the research questions. In Study 1, we developed a scale to measure PIOL in the academic context through three phases: generating a sample of items, exploring the factorial structure, and examining the reliability and validity. In Study 2, based on the developed scale, we assessed the performance of college students in PIOL and explored the influence of PIOL on their learning performance. The results indicate that PIOL in the academic context is a five-dimensional construct. There is a gap between college students’ real performance and the ideal level of PIOL in the academic context, and their PIOL performance differ significantly, allowing them to be categorized into four groups. Moreover, it is verified that college students’ PIOL has a beneficial effect on their learning performance, including mitigating procrastination, alleviating passive procrastination, and elevating academic grades. This study takes a pioneering step in measuring PIOL and discovering its effect, with the potential to inspire educators to incorporate more PIOL elements into information literacy standards and to define PIOL education.}
}
@article{LV2025113417,
title = {MDF-FND: A dynamic fusion model for multimodal fake news detection},
journal = {Knowledge-Based Systems},
volume = {317},
pages = {113417},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113417},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125004642},
author = {Hongzhen Lv and Wenzhong Yang and Yabo Yin and Fuyuan Wei and Jiaren Peng and Haokun Geng},
keywords = {Fake news detection, Dynamic fusion, Dempster–Shafer evidence theory, Information fusion},
abstract = {Fake news detection has received increasing attention from researchers in recent years, especially in the area of multimodal fake news detection involving both text and images. However, many previous studies have simply fed the semantic features of both text and image modalities into a binary classifier after applying basic concatenation or attention mechanisms, where these features often contain a significant amount of inherent noise. This, in turn, leads to both intra- and inter-modal uncertainty. In addition, while methods based on simple concatenation of the two modalities have achieved notable results, they often ignore the drawback of applying fixed weights across modalities, which causes some high-impact features to be ignored. To address these issues, we propose a novel semantic-level multimodal dynamic fusion framework for fake news detection (MDF-FND). To the best of our knowledge, this is the first attempt to develop a dynamic fusion framework for semantic-level multimodal fake news detection. Specifically, our model consists of two main components: (1) the Uncertainty Estimation Module (UEM), which is an uncertainty modeling module that uses a multi-head attention mechanism to model intra-modal uncertainty, and (2) the Dynamic Fusion Network, which is based on Dempster–Shafer evidence theory (DFN) and is designed to dynamically integrate the weights of both text and image modalities. To further enhance the dynamic fusion framework, a graph attention network is employed for inter-modal uncertainty modeling before DFN. Extensive experiments have demonstrated the effectiveness of our model across three datasets, with a performance improvement of up to 4% on the Twitter dataset, achieving state-of-the-art performance. We also conducted a systematic ablation study to gain insights into our motivation and architectural design. Our model is publicly available at https://github.com/CoisiniStar/MDF-FND.}
}
@article{FAMTA202530,
title = {Despicable role of epithelial–mesenchymal transition in breast cancer metastasis: Exhibiting de novo restorative regimens},
journal = {Cancer Pathogenesis and Therapy},
volume = {3},
number = {1},
pages = {30-47},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2024.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S2949713224000016},
author = {Paras Famta and Saurabh Shah and Biswajit Dey and Kondasingh Charan Kumar and Deepkumar Bagasariya and Ganesh Vambhurkar and Giriraj Pandey and Anamika Sharma and Dadi A. Srinivasarao and Rahul Kumar and Santosh Kumar Guru and Rajeev Singh Raghuvanshi and Saurabh Srivastava},
keywords = {Breast cancer, Epithelial-to-mesenchymal transition, Metastases, Cancer stem cells, Epigenetics},
abstract = {Breast cancer (BC) is the most prevalent cancer in women globally. Anti-cancer advancements have enabled the killing of BC cells through various therapies; however, cancer relapse is still a major limitation and decreases patient survival and quality of life. Epithelial-to-mesenchymal transition (EMT) is responsible for tumor relapse in several cancers. This highly regulated event causes phenotypic, genetic, and epigenetic changes in the tumor microenvironment (TME). This review summarizes the recent advancements regarding EMT using de-differentiation and partial EMT theories. We extensively review the mechanistic pathways, TME components, and various anti-cancer adjuvant and neo-adjuvant therapies responsible for triggering EMT in BC tumors. Information regarding essential clinical studies and trials is also discussed. Furthermore, we also highlight the recent strategies targeting various EMT pathways. This review provides a holistic picture of BC biology, molecular pathways, and recent advances in therapeutic strategies.}
}
@article{REHMAN2024112111,
title = {Bioclimatic and remote sensing factors are better key indicators than local topography and soil: Vegetation composition variability in forests of Pakistan's Spin Ghar Mountain range},
journal = {Ecological Indicators},
volume = {163},
pages = {112111},
year = {2024},
issn = {1470-160X},
doi = {https://doi.org/10.1016/j.ecolind.2024.112111},
url = {https://www.sciencedirect.com/science/article/pii/S1470160X24005685},
author = {Sabith Rehman and Zafar Iqbal and Rahmatullah Qureshi and Arshad Mahmood Khan and Mirza Faisal Qaseem and Manzer H. Siddiqui},
keywords = {Vegetation analysis, Diversity and distribution, Habitat complexity, Habitat fragmentation, Species extinction risk},
abstract = {The composition, structure and distribution of vegetation are influenced by diverse environmental factors. Such research inquiries provide the initial data for future conservation and management efforts. The study area of North Waziristan district, Khyber Pakhtunkhwa, Pakistan comprises diverse forests of the Spin Ghar Mountain Range (at the border areas of Pakistan and Afghanistan), and a highly remote, mountainous, and unexplored region. There was little information on the complex relationships that existed between the study area's ambient environment and vegetation. This study hypothesized that the varying environmental complexity in the study area and vegetation variety may be significantly correlated, and the ranking of leading influencing factors might enhance our ecological understanding. A total of 61 study sites comprising 183 transects (50 m each) were randomly selected to record the vegetation-environment data from January-2018 to December-2020 (3 years). Monte Carlo permutation testing, hierarchical clustering of study samples, indicator species analysis, and ordination were applied to assess the sampling data. The results indicated that there were a total of 391 vascular plant species which were further classified into seven significantly different (p < 0.05) plant assemblages, each comprising of a distinct species makeup. A variety of different environmental variables (topographic (06), bioclimatic (19), edaphic (09), remote sensing, and anthropogenic predictors (16)) were considered. Simple term effects testing results depicted the significant (p(adj) < 0.05) role of 39 variables initially, whereas, conditional term effects testing (with variance inflation factor (VIF) threshold value of < 10, and forward selecting variables that provided the most unique information) results highlighted the prominent role of eight (08) contributors. The results of the latter analysis ranked the mean temperature of the warmest quarter (Bio10) as the most influencing factor, followed by Normalized Difference Vegetation Index (NDVI), longitude, continuous heat insulation load index (CHILI), precipitation of the warmest quarter (Bio18), global human modification of the terrestrial systems (gHM), organic carbon density (OCD), and annual precipitation (Bio12). This study concluded that the vegetation variability in the study area was significantly correlated with the prevailing environment, and considered bioclimatic and remote sensing factors were better key indicators for any vegetation distribution when the study was conducted on a large spatial scale. Based on these results, the anticipated future variations in climate, particularly global warming, lengthy drought spells, and population explosion might remarkably lead to decline in local plant species richness and distribution. For the study area to guard its priceless biodiversity for future generations, careful and prompt conservation and management planning are required.}
}
@article{MAJRASHI2024,
title = {Determinants of Public Sector Managers’ Intentions to Adopt AI in the Workplace},
journal = {International Journal of Public Administration in the Digital Age},
volume = {11},
number = {1},
year = {2024},
issn = {2334-4520},
doi = {https://doi.org/10.4018/IJPADA.342849},
url = {https://www.sciencedirect.com/science/article/pii/S2334452024000018},
author = {Khalid Majrashi},
keywords = {AI Adoption, AI Ethics, Artificial Intelligence, Attitudes, Behavioral Intentions, Managers, Public Sector, Technology Acceptance Model, Trust in AI, Workplace},
abstract = {ABSTRACT
This study investigated the determinants of public sector managers' intentions to adopt artificial intelligence (AI) systems within their organizations. An extended technology acceptance model (TAM) was developed, incorporating additional constructs including fairness, humanity, reliability, safety, transparency, accountability, privacy, security, trust, social norms, tolerance, impact, and isomorphic pressure. A survey was conducted among 330 public sector managers, and the data were analyzed using linear regression tests to evaluate the model. The results showed significant positive influences of both perceived usefulness and perceived impact on managers' attitudes and behavioral intentions toward AI adoption. Isomorphic pressure was also a significant determinant of managers' behavioral intentions toward adopting AI systems. Our findings also indicated that perceptions related to AI ethical principles, such as transparency, privacy, and security, influenced managers' trust in AI systems.}
}
@article{AYTAR2025100179,
title = {A synergistic multi-stage RAG architecture for boosting context relevance in data science literature},
journal = {Natural Language Processing Journal},
volume = {13},
pages = {100179},
year = {2025},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2025.100179},
url = {https://www.sciencedirect.com/science/article/pii/S294971912500055X},
author = {Ahmet Yasin Aytar and Kamer Kaya and Kemal Kılıç},
keywords = {Retrieval-Augmented Generation (RAG), Data science, Literature retrieval, Academic insights, Large Language Models (LLM)},
abstract = {Navigating the voluminous and rapidly evolving data science literature presents a significant bottleneck for researchers and practitioners. Standard Retrieval-Augmented Generation (RAG) systems often struggle with retrieving precisely relevant context from this dense academic corpus. This paper introduces a synergistic multi-stage RAG architecture specifically tailored to overcome these challenges. Our approach integrates structured document parsing (GROBID), domain-specific embedding fine-tuning derived from textbooks, semantic chunking for coherence, and proposes a novel ’Abstract First’ retrieval strategy that prioritizes concise, high-signal summaries. Through rigorous evaluation using the RAGAS framework and a custom data science query set, we demonstrate that this integrated architecture significantly boosts Context Relevance by over 15-fold compared to baseline RAG, surpassing configurations using only subsets of these enhancements. These findings underscore the critical importance of multi-stage optimization and highlight the surprising efficacy of the abstract-centric retrieval method for specialized academic domains, offering a validated pathway to more effective literature navigation in data science.}
}
@incollection{MOURTZIS2024465,
title = {15 - Outlook, trends, and future directions toward Industry 5.0},
editor = {Dimitris Mourtzis},
booktitle = {Manufacturing from Industry 4.0 to Industry 5.0},
publisher = {Elsevier},
pages = {465-492},
year = {2024},
isbn = {978-0-443-13924-6},
doi = {https://doi.org/10.1016/B978-0-443-13924-6.00015-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780443139246000156},
author = {Dimitris Mourtzis},
keywords = {Computer in society, operations management, information systems, specific industry, network (computer science), computer systems organization, technology management, robotics, human-centered computing, computer science, sustainable development, operations research, management, computer security, manufacturing engineering, human–computer interaction, cognitive process, technological change, industrial organization, sustainability engineering, knowledge management, urban planning, manufacturing, mixed social research methods, control engineering},
abstract = {As artificial intelligence (AI) continues to transform various industries, including manufacturing, healthcare, and finance, the ethical implications of AI are becoming increasingly important. In this chapter an overview of AI ethics is provided, extending to the discussion on cornerstone aspects, among other being: (1) key ethical principles and issues, (2) governance and regulation, and (3) future directions. In particular, emphasis is given in the implications of AI ethics for Industry 5.0 and Society 5.0, which represent the integration of technology and society aiming toward a human-centered sustainable and resilient development. Further to that, a discussion on how ethical considerations in AI can contribute to the development of Industry 5.0 and Society 5.0 is conducted. The discussion follows a multifaceted context regarding the promotion of fairness, accountability, transparency, safety, and social responsibility of AI. In the closure of this chapter, and by extension this book, ongoing challenges and limitations of AI governance and regulation, as well as potential solutions and mitigations are discussed.}
}
@article{LI2024103484,
title = {Signing auditors’ experience gap and audit quality},
journal = {International Review of Economics & Finance},
volume = {95},
pages = {103484},
year = {2024},
issn = {1059-0560},
doi = {https://doi.org/10.1016/j.iref.2024.103484},
url = {https://www.sciencedirect.com/science/article/pii/S1059056024004763},
author = {Minghui Li and Xin Yang and Kerui Zhai},
keywords = {Audit team, Signing auditor, Auditor experience, Experience gap, Audit quality},
abstract = {This study investigates how interactions between signing auditors with different levels of experience affect audit outcomes. Using the unique data from China, we find that a higher experience gap between signing auditors is associated with higher audit quality, as indicated by lower absolute discretionary accruals and a smaller likelihood of restatements. Further analyses suggest that the positive association between signing auditors' experience gap and audit quality is more pronounced for client firms that are more complex, have weaker corporate governance and higher information asymmetry, are audited by smaller audit firms, and are more economically important to auditors. Our results are robust to alternative research designs, alternative measures of auditor experience and audit quality, and other sensitivity tests. We contribute to the literature on auditor experience and audit team diversity with implications for audit firms’ personnel assignment.}
}
@article{KANG2023100824,
title = {Learner innovativeness, course interaction, and the use of a new educational technology system after the COVID-19 pandemic},
journal = {The International Journal of Management Education},
volume = {21},
number = {3},
pages = {100824},
year = {2023},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2023.100824},
url = {https://www.sciencedirect.com/science/article/pii/S1472811723000629},
author = {Dongsuk Kang and Min Jae Park},
keywords = {Learner innovativeness, Learning interaction, Blended learning, Educational management, Educational innovation},
abstract = {Due to the global COVID-19 pandemic and social distancing policies, higher education has adopted a new online learning system (e.g., viewing recorded lectures at one's own pace or participating in online streaming courses) as a necessary education service. Although many universities have switched to face-to-face courses in light of the reduced spread of the coronavirus, the new system could be a meaningful complement to the traditional learning method. This study focuses on identifying factors that influence students' utilization of new lecture systems in universities. This research investigated undergraduates majoring in management and other fields in South Korea through structural questionnaires. It analyzes the data using the partial least squares methodology of structural equation analysis. The results show that learners' innovativeness could increase their willingness to use the system, and the learning interaction in a course could improve students' learning satisfaction. Furthermore, the innovativeness could lead to a positive relationship between learning satisfaction, intention to use, and the system's potential impact. These findings suggest that instructors and universities need to offer new opportunities to promote students' willingness and motivation, as well as their preparation for online courses and learning interactions.}
}
@article{YIN2025105434,
title = {The association between groups' interactions with the Visual-GenAI learning analytics feedback and student engagement in CSCL},
journal = {Computers & Education},
volume = {239},
pages = {105434},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105434},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525002027},
author = {Xinghan Yin and Junmin Ye and Shuang Yu and Honghui Li and Qingtang Liu and Gang Zhao},
keywords = {Cooperative/collaborative learning, Distance education and online learning, Data science applications in education, Evaluation methodologies},
abstract = {Promoting student engagement has long been a vital subject in the research of Computer-Supported Collaborative Learning (CSCL). Previous research has indicated the potential of AI-based visual learning analytics feedback and generative AI (GenAI) feedback in this context. However, there is currently a lack of definitive research on the combined impact of these two types of intelligent feedback in CSCL. Additionally, limited attention has been paid to how groups utilize these tools in CSCL practice and the differences that may exist. In this study, we developed an Visual-GenAI learning analytics feedback tool that integrates AI-based visual learning analytics feedback and GenAI-based feedback. We then evaluated the differences in groups' interactions with this Visual-GenAI learning analytics feedback and its association with student engagement and academic performance. The study employed a mixed-methods approach, combining quantitative analysis of feedback interaction log data, content analysis of group discussion data, and qualitative analysis of students' perceptions of different feedback tools through surveys. Our results show that groups exhibit four distinct levels of feedback interaction behavior patterns with the Visual-GenAI learning analytics feedback. These four patterns exhibit significant differences in behavioral engagement, emotional engagement, cognitive engagement, and academic performance. This study's significance lies in its potential contribution to future research on examining group behavior and optimizing learning using AI-based visual learning analytics feedback and GenAI-based feedback.}
}
@article{LI2024142589,
title = {Can the cumulative effect of technological resources promote green technology collaborative innovation in resource-based regions?},
journal = {Journal of Cleaner Production},
volume = {461},
pages = {142589},
year = {2024},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2024.142589},
url = {https://www.sciencedirect.com/science/article/pii/S0959652624020377},
author = {Yingming Li and Xiangjie Cao and Mingyue Wang},
keywords = {Green technology collaborative innovation, Enterprises participation, Patent collaboration network, Network evolution, Resource-based region, ERGM},
abstract = {Resource-based regions are encountering increasingly severe challenges in their green transformation and development. Urgent action is required from innovation entities to achieve more sustainable green technology innovation through Green technology collaborative innovation (GTCI). To enhance the driving mechanism of GTCI, this study categorizes technological resources into tangible and intangible categories and examines their cumulative effects on GTCI from the perspective of innovation entities. Using a network evolution perspective, this research builds multi-stage GTCI networks by utilizing green joint invention authorized patent data from 2000 to 2020, and empirically examines them using exponential random graph models. The study finds that the cumulative effect of intangible resources of technology can promote GTCI in resource-based areas, but it needs a certain period of quantitative change to trigger the qualitative change of the cumulative effect; the cumulative effect of technology tangible resources does not promote GTCI in resource-based regions and inhibits GTCI in some stages of development. This study contributes to the advancement of the resource-based view theory and broadens the research scope of the GTCI network. It also facilitates the establishment of a market-oriented green technology innovation system with enterprises as the primary focus, thereby promoting the optimized development of GTCI in resource-based regions.}
}
@article{DATTA2024104060,
title = {Cybersecurity end-user compliance: Password management versus update compliance},
journal = {Information & Management},
volume = {61},
number = {8},
pages = {104060},
year = {2024},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2024.104060},
url = {https://www.sciencedirect.com/science/article/pii/S0378720624001423},
author = {Pratim Milton Datta and Oliver Krancher},
keywords = {End-user compliance, Behavioral economics, Biases, Diligence, IT security knowledge, Social networking activity},
abstract = {In today's world, organizations rely on cybersecurity end-user compliance as an essential practical parameter. Yet cybersecurity compliance remains a challenge, and failures are commonplace. But why? In addressing this question, we argue that ISP compliance is neither too monolithic nor too granular a construct but needs respecification. We empirically investigate cybersecurity antecedents leading to (i) user protection-centric password management and (ii) system protection-centric update compliance dimensions. The results of our survey of 241 users show differentiating behavioral strands intertwined across different types of compliance, highlighting a unique interplay of attitudes, knowledge, and social factors as antecedents to password and update compliance.}
}
@article{GAO2025102907,
title = {Time-frequency dependence and dynamic linkages between digital economy and education markets},
journal = {Technology in Society},
volume = {82},
pages = {102907},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.102907},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25000971},
author = {Wang Gao},
keywords = {Digital economy, Education, Time-frequency},
abstract = {This study utilizes a comprehensive analytical framework, incorporating both time and frequency domain methodologies, to investigate the complex interdependencies between the digital economy and the education market. The evaluation encompasses several critical dimensions, including return, volatility, and liquidity interconnectedness. The principal findings of this research are as follows: (1) There is a substantial co-dependence observed between the digital economy and the education sector, with a particular focus on components such as mobile internet, artificial intelligence, and big data—elements that exhibit the most pronounced linkages to educational infrastructures. Frequency domain analysis indicates that return spillover effects are potent in the short term, whereas spillovers related to volatility become increasingly significant in the long term. (2) The analysis reveals cloud computing and big data as the principal sources of spillover effects, while artificial intelligence, mobile internet, virtual reality, and online education serve as critical intermediaries. Importantly, vocational and K-12 education emerge as the primary beneficiaries of these spillover phenomena. (3) The interrelationships between the digital economy and educational markets exhibit time-varying characteristics, particularly marked by heightened fluctuations during pivotal events such as the COVID-19 pandemic and the implementation of the "Double Reduction" policy. Additionally, a notable strengthening of these trends has been observed after 2022. (4) The study demonstrates that assets associated with cloud computing, 5G technology, big data, artificial intelligence, and online education possess robust hedging effectiveness. The findings of this research aspire to inform educational policymakers regarding optimal resource allocation strategies, facilitate the seamless integration of digital technologies within educational frameworks, and provide strategic insights for asset investors seeking to navigate cross-market investments while enhancing risk management practices.}
}
@article{BRICE2024101159,
title = {Selected bibliography of recent scholarship in second language writing},
journal = {Journal of Second Language Writing},
volume = {66},
pages = {101159},
year = {2024},
issn = {1060-3743},
doi = {https://doi.org/10.1016/j.jslw.2024.101159},
url = {https://www.sciencedirect.com/science/article/pii/S1060374324000663},
author = {Colleen Brice and Carolina Pelaez-Morales}
}
@incollection{BRAGHIN2025871,
title = {Chapter 53 - Online Privacy},
editor = {John R. Vacca},
booktitle = {Computer and Information Security Handbook (Fourth Edition)},
publisher = {Morgan Kaufmann},
edition = {Fourth Edition},
pages = {871-890},
year = {2025},
isbn = {978-0-443-13223-0},
doi = {https://doi.org/10.1016/B978-0-443-13223-0.00053-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443132230000539},
author = {Chiara Braghin and Marco Cremonini},
keywords = {Cookies, Data protection, Generative AI, Informed consent, Online privacy, Predictive technology, Regulations, Surveillance, Web tracking},
abstract = {Privacy is fading away from the online world, with powerful actors that have worked to invade everyone's privacy for commercial and surveillance purposes. However, limiting the analysis on the role of those actors is overly simplistic because the state of online privacy is the result of many different contributions and an historical trend. In this chapter, we analyze several facets of the lack of online privacy, some idiosyncrasies exhibited by privacy advocates, together with characteristics of the industry mostly responsible of massive data collecting. An issue not sufficiently debated is the asserted effectiveness of data-centered predictive technologies, which should be openly inquired. We also introduce the prevalent market-oriented assumption and individualistic approach at the base of online privacy. The regulatory approach to online privacy is also considered. EU's GDPR is commonly considered the reference case of modern privacy regulations, but its success hinders critical aspects that require a close examination, from the quirks of the institutional decision process, to the flaws of the informed consent principle. A glimpse on the likely problematic future is provided with a discussion on privacy related aspects of European Union, United Kingdom, and China's proposed generative AI policies. The last part of this chapter is dedicated to discuss some privacy technologies, their ambitious goals, the actual effectiveness, and the limitations, which often have been severely underestimated. There is no technical silver bullet for privacy and it seems highly unlikely that it could ever exist, because it is too multifaceted as a problem, often contradictory, strained between contrasting interests.}
}
@incollection{DAVILADELGADO2025463,
title = {Chapter 23 - Demystifying machine learning for predictive analytics in construction},
editor = {Ehsan Noroozinejad Farsangi and Mohammad Noori and T.Y Yang and Vasilis Sarhosis and Seyedali Mirjalili and Mirosław J. Skibniewski},
booktitle = {Digital Transformation in the Construction Industry},
publisher = {Woodhead Publishing},
pages = {463-486},
year = {2025},
series = {Woodhead Publishing Series in Civil and Structural Engineering},
isbn = {978-0-443-29861-5},
doi = {https://doi.org/10.1016/B978-0-443-29861-5.00023-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443298615000238},
author = {Juan Manuel {Davila Delgado}},
keywords = {Machine learning, artificial intelligence, computer vision, construction, AEI.},
abstract = {This is a horizontal analysis on the state of research of machine learning (ML) for construction applications. The objective is to identify relevant topics in the research area and clarify the actual capabilities and limitations of ML approaches for construction. A literature review and thematic analyses were conducted to identify significant topics as well as an analysis of the most cited papers and use cases. A discussion of relevant applications and challenges is presented as well. The key findings are (1) there has been a massive increase on research efforts in the area; however, research is still behind in the use of state-of-the-art models, such as large language models, transformers, and reinforcement learning. Most importantly, it is usually limited to the use of relatively small datasets. (2) There are still significant challenges regarding the creation of sufficiently large datasets, but there are effective manners to address those challenges including the creation of synthetic data. This study provides construction practitioners and researchers with an overview of the key aspects of research on ML in construction that will help improve the understanding in this research area.}
}
@incollection{REVURI2025,
title = {Artificial intelligence (AI) technologies and tools for accelerated software development},
series = {Advances in Computers},
publisher = {Elsevier},
year = {2025},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2025.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0065245825001111},
author = {Jaswanth Revuri and Rakesh Kumar Sakthivel and Gayathri Nagasubramanian},
keywords = {Artificial intelligence, Software development, Machine learning, Debugging, Software development life cycle (SDLC)},
abstract = {The rapid advancement of Artificial Intelligence (AI) is reshaping the field of software development, marking the beginning of a transformative era of automation and efficiency. This chapter provides a view of the shift to an AI-assisted approach to software development that moves beyond historical paradigms of development as we explore practices that utilize novel AI technologies. Exploring the use of AI technologies to automate processes can result in higher productivity and better collaboration, which create greater project efficiency. The chapter includes a thorough examination of certain key AI capabilities that automate aspects of coding and testing, such as automated code generation, bug detection, and test case generation. These artificial intelligence applications-electronic agents that don’t even require the presence of a developer-provide convenience and higher levels of quality, reliability and assurance. The overwhelming impact is improved productivity and collaboration through valuable AI technologies in the Software Development Lifecycle (SDLC) and ultimately improvement in every stage of the SDLC, such as idea generation, requirement gathering, design improvements and continuous deployment. This chapter finds that AI will drive collaboration where human creativity is utilized, aided by machine processing efficacies. Ultimately, the chapter provides a summative overview of the compelling promise of AI for automated software development and the changes that AI means for the software development industry. Developers who make use of these advancements can better situate themselves at the forefront of a developing technological revolution that will reshape the way that software is imagined, developed, and delivered.}
}
@article{ZHANG2024104911,
title = {Strategies and conditions for crafting managerial responses to online reviews},
journal = {Tourism Management},
volume = {103},
pages = {104911},
year = {2024},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2024.104911},
url = {https://www.sciencedirect.com/science/article/pii/S026151772400030X},
author = {Xin Zhang and Lei La and GuoQiong Ivanka Huang and Haoxiang Xie},
keywords = {Managerial response, Customer reviews, Helpfulness votes, Uncertainty reduction theory, Rapport management model},
abstract = {The present study investigates how managerial responses to online reviews can help managers maintain relationships with past and future customers, exploring the question through the lens of the uncertainty reduction theory and the rapport management model. The present work crawled 446,663 customer reviews and 96,633 tour managerial responses on Ctrip.com using Python. Through randomly selecting 1000 responses, Study 1 manually identified nine managerial response strategies to customer online reviews. The Bidirectional Encoder Representations from Transformers (BERT) model was then adopted to automatically label the strategies used in all of the managerial responses. Employing negative binomial regression models, Study 2 then examined the interactions between attributes of customer reviews and managerial responses as a method for estimating helpfulness votes. The results indicate that excessively lengthy, highly templated, and unfocused managerial responses to customer reviews can dampen the relationship between customers’ information processing and their perception of the helpfulness of online reviews.}
}
@article{FAGEEH2025101996,
title = {The rise of chatbots in higher education: Exploring user profiles, motivations, and integration strategies},
journal = {Social Sciences & Humanities Open},
volume = {12},
pages = {101996},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101996},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125007247},
author = {Abdulaziz Fageeh},
keywords = {AI chatbots, Higher education, Student engagement, Personalized learning, Integration strategies, Activity theory, Systematic review, Mixed methods, Saudi Arabia},
abstract = {This mixed-methods study examines the incorporation of AI-powered chatbots in higher education, analyzing user profiles, motivations, and integration tactics. A systematic review of 45 studies, complemented by a survey of 86 graduate students in Saudi Arabian language and translation programs, grounded in Activity Theory, indicates that undergraduates are the predominant users, utilizing chatbots for skill enhancement, knowledge acquisition, and motivation improvement. Primary factors for adoption encompass tailored education, simulated human engagement, and secure learning settings. Although mostly supplementary instruments for academic assistance, writing, and speaking practice, chatbots are being incorporated into self-directed learning and online courses. Gamification demonstrates potential for improving motivation, although the effects of multimodal integration necessitate additional research. Qualitative analysis underscores student apprehensions about accuracy, depth of responses, and technical constraints, highlighting the necessity for continuous improvement and investigation into long-term effects and ethical considerations. The study highlights the significance of context-specific factors, especially within the Saudi Arabian educational framework, for the successful and fair integration of chatbots.}
}
@article{2024A6,
title = {Table of Contents},
journal = {American Journal of Kidney Diseases},
volume = {83},
number = {4, Supplement 2},
pages = {A6-A29},
year = {2024},
note = {National Kidney Foundation 2024 Spring Clinical Meeting Abstracts},
issn = {0272-6386},
doi = {https://doi.org/10.1053/S0272-6386(24)00588-2},
url = {https://www.sciencedirect.com/science/article/pii/S0272638624005882}
}
@article{NG20241113,
title = {Megatrends affecting the world of work: Implications for human resource management},
journal = {Personnel Review},
volume = {54},
number = {5},
pages = {1113-1149},
year = {2024},
issn = {0048-3486},
doi = {https://doi.org/10.1108/PR-02-2025-0100},
url = {https://www.sciencedirect.com/science/article/pii/S0048348624000049},
author = {Eddy S. Ng and Pauline Stanton and Chidozie Umeh and Greg J. Bamber and Dianna Stone and Kimberly Lukaszewski and Sherry Aw and Sean Lyons and Linda Schweitzer and Shuang Ren and Mustafa F. Özbilgin and Arup Varma},
keywords = {Megatrends, Technological change, Artificial intelligence, Demographic shift, Globalization, Climate change, Populism, Future of work},
abstract = {Purpose
The purpose of the anthology is to explore how major societal shifts or “megatrends” are impacting the world of work and to provide guidance for human resource management (HRM) professionals.
Design/methodology/approach
The anthology adopts a varied approach encompassing literature reviews, empirical research and conceptual frameworks to offer informed perspectives on identifying and interpreting megatrends' impact on HRM.
Findings
The synthesis highlights several key impacts on the future of work: the transformative power of technological advancements, particularly AI and other new technologies; the challenges posed by globalization and shifting demographics; the lasting effects of the COVID-19 pandemic on work practices; the significant risks of climate change; the negative influence of populism and political polarization on diversity, equity and inclusion (DEI) initiatives; and the need for nuanced HRM approaches to address generational differences.
Research limitations/implications
There is inherent subjectivity in identifying and interpreting megatrends. Individual authors’ perspectives and biases might influence their analyses of megatrends and their recommendations for HRM. The analyses predominantly focus on Western contexts, limiting the generalizability of findings to other geographical regions and cultures.
Practical implications
The anthology encourages a more proactive, adaptable and inclusive approach to HRM, emphasizing the need for strategic foresight, investment in employee development and a focus on building organizational resilience in the face of significant societal changes.
Social implications
The anthology underscores the social responsibility of organizations and policymakers to mitigate negative social consequences arising from megatrends, promoting social justice, equity and the well-being of all members of society, particularly those most vulnerable to disruption. The findings highlight a need for societal adaptation and proactive measures to address potential inequities.
Originality/value
The anthology offers a comprehensive and insightful exploration of the significant transformations in the world of work, offering actionable guidance and laying the groundwork for future research into how HRM can successfully adapt to the evolving landscape.}
}
@article{CAMERON2024108564,
title = {DEXPI process: Standardizing interoperable information for process design and analysis},
journal = {Computers & Chemical Engineering},
volume = {182},
pages = {108564},
year = {2024},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2023.108564},
url = {https://www.sciencedirect.com/science/article/pii/S0098135423004349},
author = {David B. Cameron and Wilhelm Otten and Heiner Temmen and Monica Hole and Gregor Tolksdorf},
keywords = {DEXPI, Digitalization, Interoperability, Process design, Standards},
abstract = {DEXPI Process is a proposed standard for modelling information about process design, as it is presented on block flow and process flow diagrams. It was developed by the DEXPI+ working group and builds upon the DEXPI (Data Exchange in the Process Industry) standard for piping and instrumentation diagrams. Digitalization is making increasing demands on the exchange of information in the process facility lifecycle. Industry 4.0 methods require shared terminology and knowledge models to exchange information. Standards, such as ISO15926, CFIHOS and DEXPI, try to address this need. All these focus on the physical plant items, as shown on a PID or 3D model. There is a lack of standards for early-phase, top-down process design. DEXPI Process fills this gap. This paper presents the development of DEXPI Process in the context of knowledge modelling of process systems and previews how the model is a foundation for applications of automated reasoning and decision support for design and operations.}
}
@article{UPSHAW2024108725,
title = {Electrophysiological effects of smartphone notifications on cognitive control following a brief mindfulness induction},
journal = {Biological Psychology},
volume = {185},
pages = {108725},
year = {2024},
issn = {0301-0511},
doi = {https://doi.org/10.1016/j.biopsycho.2023.108725},
url = {https://www.sciencedirect.com/science/article/pii/S0301051123002454},
author = {Joshua D. Upshaw and Grant S. Shields and Matt R. Judah and Darya L. Zabelina},
keywords = {Theta/beta ratio, Spectral frequency, Mindfulness, Cognitive control, Reaction time, Smartphone, Notification},
abstract = {Smartphone use is nearly ubiquitous, with 93% of adults among economically developed countries, including the United States, Canada, Israel, and South Korea owning a smartphone (Taylor & Silver, 2019). Multiple studies have demonstrated the distracting effects of smartphone notifications on behavioral measures of cognition. Fewer studies have examined the effects of notifications on neural activity underlying higher-level cognitive processes or behavioral inductions to reduce smartphone-related distraction. Using EEG spectral frequency power densities, we assessed the effects of smartphone notifications (vs. control trials) on engagement of attentional shifting processes involved in cognitive control during a Navon Letter visual oddball task. Participants were randomly assigned to a brief mindfulness induction (N = 44) or a neutral narration control condition (N = 43). Overall, participants had lower theta-band power, but higher alpha- and beta-band power densities on target letter trials preceded by smartphone notifications. Additionally, participants in the mindfulness (vs. control) condition had a larger attention shifting oddball assessed via theta power density and theta/beta ratio (TBR) values—reflecting increased engagement of cognitive control—particularly on smartphone notification (vs. control) trials. Altogether, these results provide evidence supporting the idea that smartphone notifications can decrease activity of neural correlates of cognitive control, and offer the promise of a brief mindfulness induction to buffer against the effects of smartphone notifications on cognitive control. The findings indicate a need for further research on mindfulness inductiosn as a means to reduce potential distraction caused by smartphones.}
}
@article{K20252996,
title = {AI-Driven Multi-Modal Information Synthesis: Integrating PDF Querying, Speech Summarization, and Cross-Language Text Summarization},
journal = {Procedia Computer Science},
volume = {258},
pages = {2996-3018},
year = {2025},
note = {International Conference on Machine Learning and Data Engineering},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.04.559},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925016631},
author = {Suresh Manic K and Ahmed-Al Balushi and Al-Bemani A.S. and Saleh {Al Araimi} and Balaji G and Uma Suresh and Asiya Najeeb},
keywords = {Artifical Intelligence (AI), PDF Question Answering System, Speech-to-Text Summarization, Multisource Text Summarization, Natural Language Processing (NLP)},
abstract = {This research presents an innovative AI-powered system designed to revolutionize information retrieval and summarization by integrating multiple data modalities. The system is composed of three key components: a PDF Question Answering System, Speech-to-Text Summarization, and Multi-Source Text Summarization with Cross-Language Translation capabilities. The PDF Question Answering System processes documents by segmenting them into 5000-word chunks and generating embeddings using the all-MiniLM-L6-v2 model. These embeddings are then stored in ChromaDB, a specialized vector database, enabling precise querying through similarity searches. The Speech-to-Text Summarization feature converts audio files or live streams into text using the OpenAI Whisper model. It then creates a summary of the text, which can be translated into different languages, making it easier for users to access the information. The Multi-Source Text Summarization and Translation module further broadens the system’s capabilities by processing content from various sources, including PDFs, YouTube videos, and websites. This content is summarized using the Gemma-7b-It model, with additional translation options available to the user. Test results showed that the system accurately converts speech to text, even in difficult audio conditions, with very few mistakes. It creates clear and concise summaries that keep the important details and processes tasks quickly. For example, it converts 5 minutes of audio into text in about 2 seconds and answers questions from PDF documents in less than 12 seconds. These results demonstrate the system’s ability to handle large amounts of data and different types of content efficiently, making it a flexible tool for users who need to collect and summarize information from multiple sources. It also supports multiple languages through its built-in translation feature.}
}
@article{DHAIGUDE2025100293,
title = {Supply chain integration and culture under globalization: A systematic review and global research agenda},
journal = {Research in Globalization},
volume = {11},
pages = {100293},
year = {2025},
issn = {2590-051X},
doi = {https://doi.org/10.1016/j.resglo.2025.100293},
url = {https://www.sciencedirect.com/science/article/pii/S2590051X25000267},
author = {Amol S. Dhaigude and Debmallya Chatterjee and Giridhar B Kamath},
keywords = {Supply chain integration, Culture, Cross-cultural supply chains, Global operations management, Systematic literature review, SPAR-4 SLR},
abstract = {Cultural peculiarities affect how corporations in global supply chains integrate, but unfortunately, there has been a lack of systematic documentation of this amalgamation. This study explores a complex global-level relationship among supply chain integration (SCI) and culture. This study synthesized current research from premier academic publications (A and A* levels) through text analysis, the SPAR-4 systematic literature review (SLR), and the theory, characteristics, context, and methodology(TCCM) framework to elucidate the intricacies of cross-cultural collaboration. This study proposes 60 research questions spread across the theoretical development, context, characteristics, and methodology to enhance the research on the amalgamation of SCI and culture at a global level. This study also proposes a research framework to guide future research on chaotic global supply networks. This study provides comprehensive knowledge of cross-cultural collaborative dynamics for practitioners and scholars, laying the groundwork for future empirical research and strategic management.}
}
@article{SONTADRACZKOWSKA2025321,
title = {Co-creating innovations with users: A systematic literature review and future research agenda for project management},
journal = {European Management Journal},
volume = {43},
number = {2},
pages = {321-339},
year = {2025},
issn = {0263-2373},
doi = {https://doi.org/10.1016/j.emj.2024.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0263237324000902},
author = {Ewa Sońta-Drączkowska and Marzenna Cichosz and Patrycja Klimas and Tomasz Pilewicz},
keywords = {NPD, User-driven innovation, User engagement, Co-innovation, PM, Domain-based review, Meta-systematic review},
abstract = {This study aimed to systematically review the extensive literature on user innovation co-creation and connect the findings to the project management domain. It focused specifically on new product development, offering a domain-based systematic review of methods, tools, and user types involved in the co-creation process. Analyzing a total of 266 articles, the authors synthesize the types of users and methods discussed in the domain of user innovation, aligning them across the new product development cycle and specific phases of co-innovation. Additionally, the authors formulate research questions and propositions that may inspire the project management domain. This study provides insights into innovation-oriented, exploratory project management and enhances the configuration approach to project management. From a practical perspective, it provides a comprehensive overview of methods that can enrich a managerial toolkit for leading innovative projects.}
}
@article{RATHER2023102088,
title = {Therapeutic efficacy and promise of stem cell-derived extracellular vesicles in Alzheimer’s disease and other aging-related disorders},
journal = {Ageing Research Reviews},
volume = {92},
pages = {102088},
year = {2023},
issn = {1568-1637},
doi = {https://doi.org/10.1016/j.arr.2023.102088},
url = {https://www.sciencedirect.com/science/article/pii/S1568163723002477},
author = {Hilal Ahmad Rather and Sameh Almousa and Suzanne Craft and Gagan Deep},
keywords = {Extracellular vesicles, Stem cell, Mesenchymal stem cell, Aging, Alzheimer’s disease},
abstract = {The term extracellular vesicles (EVs) refers to a variety of heterogeneous nanovesicles secreted by almost all cell types, primarily for intercellular communication and maintaining cellular homeostasis. The role of EVs has been widely reported in the genesis and progression of multiple pathological conditions, and these vesicles are suggested to serve as ‘liquid biopsies’. In addition to their use as biomarkers, EVs secreted by specific cell types, especially with stem cell properties, have shown promise as cell-free nanotherapeutics. Stem cell-derived EVs (SC-EVs) have been increasingly used as an attractive alternative to stem cell therapies and have been reported to promote regeneration of aging-associated tissue loss and function. SC-EVs treatment ameliorates brain and peripheral aging, reproductive dysfunctions and inhibits cellular senescence, thereby reversing several aging-related disorders and dysfunctions. The anti-aging therapeutic potential of SC-EVs depends on multiple factors, including the type of stem cells, the age of the source stem cells, and their physiological state. In this review, we briefly describe studies related to the promising effects of SC-EVs against various aging-related pathologies, and then we focus in-depth on the therapeutic benefits of SC-EVs against Alzheimer’s disease, one of the most devastating neurodegenerative diseases in elderly individuals. Numerous studies in transgenic mouse models have reported the usefulness of SC-EVs in targeting the pathological hallmarks of Alzheimer’s disease, including amyloid plaques, neurofibrillary tangles, and neuroinflammation, leading to improved neuronal protection, synaptic plasticity, and cognitive measures. Cell culture studies have further identified the underlying molecular mechanisms through which SC-EVs reduce amyloid beta (Aβ) levels or shift microglia phenotype from pro-inflammatory to anti-inflammatory state. Interestingly, multiple routes of administration, including nasal delivery, have confirmed that SC-EVs could cross the blood-brain barrier. Due to this, SC-EVs have also been tested to deliver specific therapeutic cargo molecule/s (e.g., neprilysin) to the brain. Despite these promises, several challenges related to quality control, scalability, and biodistribution remain, hindering the realization of the vast clinical promise of SC-EVs.}
}
@article{ITO2024105169,
title = {Understanding urban perception with visual data: A systematic review},
journal = {Cities},
volume = {152},
pages = {105169},
year = {2024},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2024.105169},
url = {https://www.sciencedirect.com/science/article/pii/S0264275124003834},
author = {Koichi Ito and Yuhao Kang and Ye Zhang and Fan Zhang and Filip Biljecki},
keywords = {Urban visual perception, Systematic review, Natural language processing},
abstract = {Visual characteristics of the built environment affect how people perceive and experience cities. For a long time, many studies have examined visual perception in cities. Such efforts have accelerated in recent years due to advancements in technologies and the proliferation of relevant data (e.g., street view imagery, geo-tagged photos, videos, virtual reality, and aerial imagery). There has not been a comprehensive systematic review paper on this topic to reveal an overarching set of research trends, limitations, and future research opportunities. Such omission is plausibly due to the difficulty in reviewing a large number of relevant papers on this popular topic. In this study, we utilized machine learning techniques (i.e., natural language processing and large language models) to semi-automate the review process and reviewed 393 relevant papers. Through the review, we found that these papers can be categorized into the physical aspects of cities: greenery and water, street design, building design, landscape, public space, and the city as a whole. We also revealed that many studies conducted quantitative analyses with a recent trend of increasingly utilizing big data and advanced technologies, such as combinations of street view imagery and deep learning models. Limitations and research gaps were also identified as follows: (1) a limited scope in terms of study areas, sample size, and attributes; (2) low quality of subjective and visual data; and (3) the need for more controlled and sophisticated methods to infer more closely examined impacts of visual features on human perceptions. We suggest that future studies utilize and contribute to open data and take advantage of existing data and technologies to examine the causality of visual features on human perception. The approach developed to accelerate this review proved to be accurate, efficient, and insightful. Considering its novelty, we also describe it to enable replications in the future.}
}
@article{TAMAYO202535,
title = {Bifidobacterium longum CECT 30763 improves depressive- and anxiety-like behavior in a social defeat mouse model through the immune and dopaminergic systems},
journal = {Brain, Behavior, and Immunity},
volume = {125},
pages = {35-57},
year = {2025},
issn = {0889-1591},
doi = {https://doi.org/10.1016/j.bbi.2024.12.028},
url = {https://www.sciencedirect.com/science/article/pii/S0889159124007578},
author = {M. Tamayo and A. Agusti and G.V. Molina-Mendoza and V. Rossini and C. Frances-Cuesta and V. Tolosa-Enguís and Y. Sanz},
keywords = {Gut-brain axis, Microbiota, , Stress, Depression},
abstract = {Adolescence is a crucial period marked by profound changes in the brain. Exposure to psychological stressors such as bullying, abuse or maltreatment during this developmental period may increase the risk of developing depression, anxiety and comorbid cardiometabolic conditions. Chronic psychological stress is associated with behavioral changes and disruption of the hypothalamic–pituitary–adrenal axis, leading to corticosterone overproduction in rodents and changes in both the immune system and the gut microbiome. Here, we demonstrate the ability of Bifidobacterium longum CECT 30763 (B. longum) to ameliorate adolescent depressive and anxiety-like behaviors in a chronic social defeat (CSD) mouse model. The mechanisms underlying this beneficial effect are related to the ability of B. longum to attenuate the inflammation and immune cell changes induced by CSD after the initial stress exposure through the induction of T regulatory cells with enduring effects that may prevent and mitigate the adverse consequences of repeated stress exposure on mental and cardiometabolic health. B. longum administration also normalized dopamine release, metabolism and signaling at the end of the intervention, which may secondarily contribute to the reversal of behavioral changes. The anti-inflammatory effects of B. longum could also explain its cardioprotective effects, which were reflected in an amelioration of the oxidative stress-induced damage in the heart and improved lipid metabolism in the liver. Overall, our findings suggest that B. longum regulates the links between the immune and dopaminergic systems from the gut to the brain, potentially underpinning its beneficial psychobiotic and physiological effects in CSD.}
}
@article{HARWOOD2024104013,
title = {“Anything you can do, I can do”: Examining the use of ChatGPT in situational judgement tests for professional program admission},
journal = {Journal of Vocational Behavior},
volume = {154},
pages = {104013},
year = {2024},
issn = {0001-8791},
doi = {https://doi.org/10.1016/j.jvb.2024.104013},
url = {https://www.sciencedirect.com/science/article/pii/S000187912400054X},
author = {Harley Harwood and Nicolas Roulin and Muhammad Zafar Iqbal},
keywords = {Generative AI, ChatGPT, Situational judgement tests, Faking},
abstract = {We explored the transformative impact of ChatGPT on applicants' responses and performance in situational judgement tests (SJTs), as well as the role played by faking-prevention mechanisms, in two complementary studies. Study 1 examined how the availability of ChatGPT influenced response content and performance of real applicants (N = 107,805), who completed an SJT for admission before vs. after the release of the technology. We found only small differences in content (e.g., slightly less “authentic” words used) and performance (slight score improvements when controlling for response length, no differences otherwise). In Study 2, we used an experimental approach with (N = 138) Prolific participants completing a mock SJT, while being instructed to use ChatGPT when responding (vs. use online resources or no resources). We found only slightly higher SJT scores for the ChatGPT users, but no difference in response content. Additionally, GPTZero (i.e., a popular AI detection tool) struggled to detect ChatGPT content, and generated many false positives, in both studies. This research advances our understanding of how the release and popularization of ChatGPT can influence applicant behaviors. Given the “arms race” nature of applicant selection, they also highlight the importance of designing assessments to prevent or limit faking. Yet, the ever-evolving nature of AI calls for continuous research on the topic.}
}
@article{2023A5,
title = {Guide for Authors},
journal = {Journal of the American Society of Echocardiography},
volume = {36},
number = {7},
pages = {A5-A13},
year = {2023},
note = {34th ASE Annual Scientific Sessions},
issn = {0894-7317},
doi = {https://doi.org/10.1016/S0894-7317(23)00276-6},
url = {https://www.sciencedirect.com/science/article/pii/S0894731723002766}
}
@article{HIGGINS2025103630,
title = {Evaluating empathic responses to bimodal realism in emotionally expressive virtual humans: An eye-tracking and facial electromyography study},
journal = {International Journal of Human-Computer Studies},
volume = {205},
pages = {103630},
year = {2025},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2025.103630},
url = {https://www.sciencedirect.com/science/article/pii/S1071581925001879},
author = {Darragh Higgins and Benjamin R. Cowan and Rachel McDonnell},
keywords = {Virtual humans, Emotion perception, Empathy, Realism},
abstract = {With the expanding range of uses for advancements in animation and voice synthesis, more opportunities arise for interactions with animated virtual humans. Such interactions may be influenced by improved portrayals of character features such as emotion and realism. The present study aimed to examine how variations in animated facial detail and vocal prosody shape user perception of emotion in virtual characters. This impact was assessed via facial electromyography and eye-tracking measures, as well as self-reports of state empathy and character appeal. Results indicate that participants were influenced by emotional valence in terms of zygomaticus major and corrugator supercilii muscle activation. Survey data appear to show greater empathy for conditions of increased facial detail and more human-like vocal prosody. Moreover, eye tracking results suggest a preference for eye contact regardless of detail or prosody, with participants fixating more on facial areas of interest overall for the positively valenced conditions. Finally, there is evidence that trait empathy and mismatches between higher facial detail and lower vocal human-likeness may influence zygomaticus major activity in response to positively valenced stimuli. These results are discussed in the context of virtual character design, contemporary understandings of empathy and the phenomenon of the Uncanny Valley.}
}
@article{LI2025175,
title = {Generative AI-powered planning: A hybrid graph-diffusion approach for demand-driven flexible manufacturing systems},
journal = {Journal of Manufacturing Systems},
volume = {83},
pages = {175-195},
year = {2025},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2025.08.016},
url = {https://www.sciencedirect.com/science/article/pii/S0278612525002109},
author = {Chen Li and Qing Chang},
keywords = {Flexible smart manufacturing systems (FSMS), Generative AI, Diffusion model, Graph neural network (GNN), Manufacturing system planning, Robot assignment},
abstract = {Flexible Smart Manufacturing Systems (FSMS) are critical to achieving mass customization and operational agility under Industry 4.0. However, planning effective FSMS configurations remains challenging due to fluctuating market demands, heterogeneous system components, complex interdependencies, and the need to optimize resource utilization. Conventional planning methods often require predefined line configurations and lack adaptability, scalability, and awareness of dynamic system properties. This paper presents a novel Hybrid Graph-Diffusion Based Planning Framework that integrates generative AI with system-theoretic modeling to autonomously generate optimal FSMS configurations based on different market demands. Specifically, we introduce a system model-embedded Heterogeneous Graph (HG) to represent the structure and properties of an FSMS and infuse it within a system property-tailored diffusion model to generate reconfigurable plan configurations. The final system property-guided refinement guarantees that the final plan configuration is optimal in both demand satisfaction and resource use. Furthermore, our ablation studies validate that our framework significantly outperforms conventional approaches in both demand satisfaction and resource efficiency. Furthermore, our ablation studies validate the effectiveness of the system property guidance and HG-based representation in enhancing planning feasibility, robustness, and adaptability.}
}
@article{2025iii,
title = {Contents},
journal = {Procedia Computer Science},
volume = {258},
pages = {iii-xxvi},
year = {2025},
note = {International Conference on Machine Learning and Data Engineering},
issn = {1877-0509},
doi = {https://doi.org/10.1016/S1877-0509(25)01840-X},
url = {https://www.sciencedirect.com/science/article/pii/S187705092501840X}
}
@incollection{TAC2024432,
title = {4.18 - A Modeler׳s Guide to Soft Tissue Mechanics},
editor = {Vadim Silberschmidt},
booktitle = {Comprehensive Mechanics of Materials (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {432-451},
year = {2024},
isbn = {978-0-323-90647-0},
doi = {https://doi.org/10.1016/B978-0-323-90646-3.00053-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323906463000538},
author = {Vahidullah Tac and Adrian B. Tepole},
keywords = {Continuum damage mechanics, Data-driven material modeling., Fractional viscoelasticity, Growth and remodeling, Hyperelasticity, Hyper-viscoelasticity, Mechanobiology, Multiscale modeling, Reactive mixtures, Tissue biomechanics},
abstract = {Soft tissue mechanical behavior and its change with age, physiological adaption, and disease, are key to our health and survival. Soft tissues are divided in four main categories, epithelial, muscle, connective, and nervous system tissues. Different types of tissues have unique composition and microstruture to perform their specific functions. Musculoskeletal and connective soft tissues, in particular, have evolved to address important mechano-physiological needs. All soft tissues, whether or not their primary function is mechanical in nature, show extreme mechanics, with large deformation, nonlinear stress-strain stiffening, various modes of energy dissipation such as viscoelasticity and damage, and, most remarkably, show the ability to adapt to external stimulus through growth and remodeling. This chapter outlines the essential theoretical frameworks for modeling the complex behavior of soft tissue. The role of data-driven tools as well as the soft tissues that have received increasing attention in recent years are also discussed.}
}
@article{DAVIS2025102833,
title = {Shaping extra-role security behaviors through employee-agent relations: A dual-channel motivational perspective},
journal = {International Journal of Information Management},
volume = {80},
pages = {102833},
year = {2025},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2024.102833},
url = {https://www.sciencedirect.com/science/article/pii/S0268401224000811},
author = {Joshua M. Davis and Deepti Agrawal and Obi Ogbanufe},
keywords = {Extra-role security behaviors, Social exchange theory, Identity theory, Leader-member exchange, User-IS exchange},
abstract = {Organizational information security performance increasingly depends on employees’ extra-role security behaviors (ERBs), which go beyond the scope of formal organizational prescription and control. At the same time, however, the literature suggests ERBs are largely unresponsive to traditional outline-and-control approaches to behavioral security. Instead, this stream finds that ERBs are primarily cultivated through social interactions with other organizational agents, namely the IS department and the direct supervisor. While important progress has been made in explicating the social nature of ERBs and the organizational agents that shape it, little is currently understood about the attributes of these employee-agent relationships that give rise to their influence on ERB enactment. Tied to this void, review of the literature reveals two separate and fundamentally different explanations of relational influence in this context which, according to theory, are associated with different relational attributes. Responding to these gaps, the current study presents a mixed-method examination of the relational antecedents of ERB enactment. We first theoretically develop and quantitatively examine a dual-channel model of socially motivated ERB enactment that highlights two co-existing motivational channels—an exchange-based channel rooted in norms of reciprocity and an identity-based channel rooted in self-verification. Then, applying the findings from quantitative examination of the dual-channel model, we qualitatively examine the specific attributes of these employee-agent relationships that promote ERB enactment. In doing so, this study makes multiple contributions to the literature including unification of prior work in this stream and introduction of detailed profiles of effective employee-agent relationships in this context.}
}
@article{BARWEY2025118072,
title = {Mesh-based super-resolution of fluid flows with multiscale graph neural networks},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {443},
pages = {118072},
year = {2025},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2025.118072},
url = {https://www.sciencedirect.com/science/article/pii/S0045782525003445},
author = {Shivam Barwey and Pinaki Pal and Saumil Patel and Riccardo Balin and Bethany Lusch and Venkatram Vishwanath and Romit Maulik and Ramesh Balakrishnan},
keywords = {Graph neural networks, Super-resolution, Fluid dynamics, Taylor–green vortex, Backward-facing step, Deep learning},
abstract = {A graph neural network (GNN) approach is introduced in this work which enables mesh-based three-dimensional super-resolution of fluid flows. In this framework, the GNN is designed to operate not on the full mesh-based field at once, but on localized meshes of elements (or cells) directly. To facilitate mesh-based GNN representations in a manner similar to spectral (or finite) element discretizations, a baseline GNN layer (termed a message passing layer, which updates local node properties) is modified to account for synchronization of coincident graph nodes, rendering compatibility with commonly used element-based mesh connectivities. The architecture is multiscale in nature, and is comprised of a combination of coarse-scale and fine-scale message passing layer sequences (termed processors) separated by a graph unpooling layer. The coarse-scale processor embeds a query element (alongside a set number of neighboring coarse elements) into a single latent graph representation using coarse-scale synchronized message passing over the element neighborhood, and the fine-scale processor leverages additional message passing operations on this latent graph to correct for interpolation errors. Demonstration studies are performed using hexahedral mesh-based data from Taylor–Green Vortex and backward-facing step flow simulations at Reynolds numbers of 1600 and 3200. Through analysis of both global and local errors, the results ultimately show how the GNN is able to produce accurate super-resolved fields compared to targets in both coarse-scale and multiscale model configurations. Reconstruction errors for fixed architectures were found to increase in proportion to the Reynolds number. Geometry extrapolation studies on a separate cavity flow configuration show promising cross-mesh capabilities of the super-resolution strategy.}
}
@article{CORLATESCU2024108154,
title = {The automated model of comprehension version 4.0 – Validation studies and integration of ChatGPT},
journal = {Computers in Human Behavior},
volume = {154},
pages = {108154},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108154},
url = {https://www.sciencedirect.com/science/article/pii/S0747563224000219},
author = {Dragos-Georgian Corlatescu and Micah Watanabe and Stefan Ruseti and Mihai Dascalu and Danielle S. McNamara},
keywords = {Natural language processing, Reading comprehension, Automated model of comprehension, ChatGPT, Large language models},
abstract = {Modeling reading comprehension processes is a critical task for Learning Analytics, as accurate models of the reading process can be used to match students to texts, identify appropriate interventions, and predict learning outcomes. This paper introduces an improved version of the Automated Model of Comprehension, namely version 4.0. AMoC has its roots in two theoretical models of the comprehension process (i.e., the Construction-Integration model and the Landscape model), and the new version leverages state-of-the-art Large Language models, more specifically ChatGPT, to have a better contextualization of the text and a simplified construction of the underlying graph model. Besides showcasing the usage of the model, the study introduces three in-depth psychological validations that argue for the model's adequacy in modeling reading comprehension. In these studies, we demonstrated that AMoC is in line with the theoretical background proposed by the Construction-Integration and Landscape models, and it is better at replicating results from previous human psychological experiments than its predecessor. Thus, AMoC v4.0 can be further used as an educational tool to, for example, help teachers design better learning materials personalized for student profiles. Additionally, we release the code from AMoC v4.0 as open source in a Google Collab Notebook and a GitHub repository.}
}
@article{XUE202369,
title = {A Review on the Security of the Ethereum-Based DeFi Ecosystem},
journal = {CMES - Computer Modeling in Engineering and Sciences},
volume = {139},
number = {1},
pages = {69-101},
year = {2023},
issn = {1526-1492},
doi = {https://doi.org/10.32604/cmes.2023.031488},
url = {https://www.sciencedirect.com/science/article/pii/S1526149223000978},
author = {Yue Xue and Dunqiu Fan and Shen Su and Jialu Fu and Ning Hu and Wenmao Liu and Zhihong Tian},
keywords = {Blockchain, smart contract, decentralized finance, DeFi, security},
abstract = {Decentralized finance (DeFi) is a general term for a series of financial products and services. It is based on blockchain technology and has attracted people’s attention because of its open, transparent, and intermediary free. Among them, the DeFi ecosystem based on Ethereum-based blockchains attracts the most attention. However, the current decentralized financial system built on the Ethereum architecture has been exposed to many smart contract vulnerabilities during the last few years. Herein, we believe it is time to improve the understanding of the prevailing Ethereum-based DeFi ecosystem security issues. To that end, we investigate the Ethereum-based DeFi security issues: 1) inherited from the real-world financial system, which can be solved by macro-control; 2) induced by the problems of blockchain architecture, which require a better blockchain platform; 3) caused by DeFi invented applications, which should be focused on during the project development. Based on that, we further discuss the current solutions and potential directions of DeFi security. According to our research, we could provide a comprehensive vision to the research community for the improvement of Ethereum-based DeFi ecosystem security.}
}
@article{JAYAGOPAL2025111992,
title = {A multi-task domain-adapted model to predict chemotherapy response from mutations in recurrently altered cancer genes},
journal = {iScience},
volume = {28},
number = {3},
pages = {111992},
year = {2025},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2025.111992},
url = {https://www.sciencedirect.com/science/article/pii/S2589004225002524},
author = {Aishwarya Jayagopal and Robert J. Walsh and Krishna Kumar Hariprasannan and Ragunathan Mariappan and Debabrata Mahapatra and Patrick William Jaynes and Diana Lim and David Shao {Peng Tan} and Tuan Zea Tan and Jason J. Pitt and Anand D. Jeyasekharan and Vaibhav Rajan},
keywords = {Biocomputational method, Genomic analysis, Pharmacoinformatics, Cancer, Machine learning},
abstract = {Summary
Next-generation sequencing (NGS) is increasingly utilized in oncological practice; however, only a minority of patients benefit from targeted therapy. Developing drug response prediction (DRP) models is important for the “untargetable” majority. Prior DRP models typically use whole-transcriptome and whole-exome sequencing data, which are clinically unavailable. We aim to develop a DRP model toward the repurposing of chemotherapy, requiring only information from clinical-grade NGS (cNGS) panels of restricted gene sets. Data sparsity and limited patient drug response information make this challenging. We firstly show that existing DRPs perform equally with whole-exome versus cNGS (∼300 genes) data. Drug IDentifier (DruID) is then described, a DRP model for restricted gene sets using transfer learning, variant annotations, domain-invariant representation learning, and multi-task learning. DruID outperformed state-of-the-art DRP methods on pan-cancer data and showed robust response classification on two real-world clinical datasets, representing a step toward a clinically applicable DRP tool.}
}
@article{LIU2026107910,
title = {Singular Value Decomposition-based lightweight LSTM for time series forecasting},
journal = {Future Generation Computer Systems},
volume = {174},
pages = {107910},
year = {2026},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2025.107910},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X25002055},
author = {Changwei Liu and Hao Ren and Guoqiang Li and Haojie Ren and Xiaojun Liang and Chunhua Yang and Weihua Gui},
keywords = {Long–short-term memory, LSTM lightweight, Singular Value Decomposition, Model compression},
abstract = {Long–short-term memory (LSTM) neural networks are known for their exceptional performance in various domains, particularly in handling time series data and managing long-term dependencies. However, deploying LSTM often faces challenges due to limitations in memory and computational resources, especially in edge computing and real-time processing scenarios. To maximize the advantages of LSTM in resource-constrained environments, this paper presents a lightweight LSTM method that uses weight matrix decomposition. Specifically, it employs Singular Value Decomposition (SVD) to decompose the weight matrices within the LSTM Cell and fully connected layers. Then, an optimization method is addressed to enable the efficient development of a lightweight model by dynamically assessing and enhancing storage and computational efficiency through adjustments of the learning rate and weight parameters. The experimental results indicate that this method reduces the parameters of the LSTM model by 45%, compresses the model size to 45% of its original size, and maintains prediction accuracy without decline. It means that the proposed method based on weight matrix decomposition allows LSTM to operate with less computational power and memory, making them more feasible for deploying resource-constrained devices.}
}
@article{LEE2024102520,
title = {Data Collection, data mining and transfer of learning based on customer temperament-centered complaint handling system and one-of-a-kind complaint handling dataset},
journal = {Advanced Engineering Informatics},
volume = {60},
pages = {102520},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102520},
url = {https://www.sciencedirect.com/science/article/pii/S147403462400168X},
author = {Ching-Hung Lee and Xuejiao Zhao},
keywords = {Customer Complaint Handling System, Customer Temperament, Data Mining, Correspondence Analysis, Interactive marketing},
abstract = {One of the most significant sources of information from customers is customer complaints. Successful and effective complaint management can end complaint crises and ensure client loyalty, which is a sign of great service performance. In this paper, we proposed a novel customer temperament-centered and e-CCH system-based data collection and data mining method titled “3D” model for customer complaint data analysis. Three phases are (1) Development and launch of e-Customer Complaint Handling system, (2) Data collection and transfer of learning by e-Customer Complaint Handling system, and (3) Data mining by e-Customer Complaint Handling system. An advanced electronic Customer Complaint Handling System called the e-CCH system was then developed and launched. This system adapts the seasonal associations model based on Hippocrates's customer temperament theory to the whole stages of customer complaint reporting and handling. With this system, we conducted a dataset collection work from restaurant chains of two brands over four years. As a result, we collect thousands of real-world temperament-centred customer complaint cases by four years to form the one-of-a-kind CCH dataset. This one-of-a-kind CCH dataset was open-sourced with detailed customer complaint attributes and heuristic decision-making for valuable industrial handling manner. After further analysis of this dataset, we found that customers with different temperament types tend to have different types of complaints. In addition, adapting the temperament theory to the e-CCH system can classify customer types better and provide personalized solutions. To our best knowledge, this rich and the one-of-a-kind CCH dataset reported in this paper is the first comprehensive study of customer complaint handling in an industrial service management context. Meanwhile, data mining with cross analysis and correspondence analysis and an ChatGPT experiment for transfer of learning based on this yearly and one-of-a-kind industrial customer complaint dataset was analyzed and discussed. In addition, how this dataset may contribute to more realistic complaint-handling theoretic studies for better service failure recovery and interactive marketing is discussed in-depth.}
}
@article{SHIAU2025,
title = {Exploring Core Knowledge in Mobile Payment Research},
journal = {Journal of Organizational and End User Computing},
volume = {37},
number = {1},
year = {2025},
issn = {1546-2234},
doi = {https://doi.org/10.4018/JOEUC.379684},
url = {https://www.sciencedirect.com/science/article/pii/S1546223425000292},
author = {Wen-Lung Shiau and Chia-Hsing Shih and Chien-Liang Lin and Shan-Ze Jiang and Yogesh K. Dwivedi and Wen-Pin Yu and Kuanchin Chen},
keywords = {Co-Citation Analysis, Core Knowledge, Digital Banking, Mobile Money, Mobile Payment, Trust},
abstract = {ABSTRACT
This study investigates the intellectual core of mobile payment (MP) research through citation analysis, co-citation analysis, cluster analysis, and multidimensional scaling (MDS), based on 111 highly cited articles published between January 1996 and December 2023 in the Web of Science (WoS) database. The analysis reveals 13 core knowledge clusters: (1) mobile money, (2) trust in mobile banking, (3) risk factors in digital banking, (4) service quality, (5) UTAUT-based decision frameworks, (6) beliefs, (7) IT adoption decision-making, (8) trust, (9) perceived value, (10) compatibility, (11) relative advantage, (12) social influence, and (13) intention to use and continued use of information systems. These clusters reflect the evolution of MP research from foundational theories to practical, user-oriented applications. By mapping key themes and identifying influential research directions, this study offers valuable insights for scholars and practitioners, contributing to a deeper understanding of the field and providing a structured basis for future research.}
}
@article{KARAKOLTZIDIS2025100012,
title = {AI-driven parametrization of Michaelis–Menten maximal velocity: Advancing in silico new approach methodologies (NAMs)},
journal = {NAM Journal},
volume = {1},
pages = {100012},
year = {2025},
issn = {3050-6204},
doi = {https://doi.org/10.1016/j.namjnl.2025.100012},
url = {https://www.sciencedirect.com/science/article/pii/S3050620425000077},
author = {Achilleas Karakoltzidis and Spyros P. Karakitsios and Dimosthenis Α. Sarigiannis},
keywords = {Deep learning, , Maximal velocity, Enzyme structure, QSPR, NAMs},
abstract = {The development of mechanistic systems biology models necessitates the utilization of numerous kinetic parameters once the enzymatic mode of action has been identified. Simultaneously, wet lab experimentation is associated with particularly high costs, does not adhere to principles of reducing the number of animal tests, and is a time-consuming procedure. Alternatively, an artificial intelligence-based method is proposed that utilizes enzyme amino acid structures as input data. This method combines NLP techniques with molecular fingerprints of the catalysed reaction to determine Michaelis–Menten maximal velocities (Vmax). The molecular fingerprints employed include RCDK standard fingerprints (1024 bits), MACCS keys (166 bits), PubChem fingerprints (881 bits), and E-States fingerprints (79 bits). These were integrated to produce reaction fingerprints. The data entries were sourced from SABIO RK, providing a concrete framework to support training procedures. After the data preprocessing stage, the dataset was randomly split into the training set (70 %), validation set (10 %), and test set (20 %) ensuring unique amino acid sequences for each subset. The data points with structures similar to the ones used to train the model as well as uncommon reactions were employed to further test the model. The developed models were optimized during the training procedure to predict Vmax values efficiently and reliably. Utilizing a fully connected neural network, these models can be applied to all organisms. Amino acid proportions of enzymes were also tested resulting in an unreliable predictor for the Vmax value. During testing, the model demonstrated better performance on known structures compared to unseen data. In the given use case, the model trained solely on enzyme representations achieved an R-squared of 0.45 on unseen data and 0.70 on known structures. When enzyme representations were integrated with RCDK fingerprints, the model achieved an R-squared of 0.46 on unseen data and 0.62 on known structures.}
}
@article{LO2024102435,
title = {Understanding momentary engagement in university students: Exploring the interaction between competence and value beliefs on emotions and cognitive engagement – A multilevel investigation},
journal = {Learning and Individual Differences},
volume = {111},
pages = {102435},
year = {2024},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2024.102435},
url = {https://www.sciencedirect.com/science/article/pii/S1041608024000281},
author = {Meng-Ting Lo},
keywords = {Momentary engagement, Achievement emotions, Cognitive engagement, Situated competence and value beliefs, Experience sampling method},
abstract = {Using an intensive longitudinal design, this study investigated the predictive role of and interaction between competence beliefs and task value in relation to four achievement emotions (enthusiasm, excitement, anxiety, and irritation) as well as cognitive engagement. Data were collected using an experience sampling method to capture the momentary experiences of 81 university students over 14 days. Using a multilevel modeling approach, the study disentangled variations between and within individuals across learning situations. The results indicated that associations between competence and value beliefs and emotions were primarily observed at the situational level. Both competence and value beliefs played important roles in predicting cognitive engagement. In addition, high competence beliefs acted as a buffer, mitigating the positive association between opportunity cost and anxiety and reducing the negative impact of low intrinsic value on irritation. Positive value beliefs emerged as instrumental in fostering cognitive engagement, particularly in situations characterized by limited competence beliefs.
Educational relevance statement
The motivation and engagement displayed by university students in diverse learning events offer valuable insights into their dedication and academic involvement in pursuing their degrees. This study highlights the importance of perceiving both high competence beliefs and intrinsic value, which results in stronger associations with enthusiasm and excitement during learning. Conversely, high opportunity cost is linked to greater anxiety, but high competence beliefs act as a protective factor, mitigating this effect. High competence beliefs also counteract the negative impact of low intrinsic value on irritation. Value beliefs, particularly importance and intrinsic value, have a compensatory effect on cognitive engagement. Positive value beliefs play a crucial role in driving cognitive engagement, especially when competence beliefs are lacking. Gaining insight into changes within individuals and variations between students enables educators to effectively tailor instructional strategies and provide support, which in turn fosters students' motivation and engagement.}
}
@article{KANG2025111189,
title = {A trust and bundling-based task allocation scheme to enhance completion rate and data quality for mobile crowdsensing},
journal = {Computer Networks},
volume = {262},
pages = {111189},
year = {2025},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2025.111189},
url = {https://www.sciencedirect.com/science/article/pii/S1389128625001574},
author = {Yunchuan Kang and Houbing Herbert Song and Tian Wang and Shaobo Zhang and Mianxiong Dong and Anfeng Liu},
keywords = {Mobile crowdsensing, Task bundling, Task assignment scheme, Truth discovery, Multi-objective optimization},
abstract = {In Mobile CrowdSensing (MCS), task bundling has shown promise in improving task completion rate by pairing unpopular tasks with popular ones. However, existing methods often assume truthful data from workers, an assumption misaligned with real-world MCS scenarios. Workers tend to submit low-quality or false data to maximize their rewards, particularly given the Information Elicitation Without Verification (IEWV) problem, which hinders the detection of dishonest behavior. To address this, we propose a Trust and Bundling-based Task Allocation (TBTA) scheme to enhance task completion rates and data quality at a low cost. The TBTA scheme includes three main strategies: (1) a trusted worker identification algorithm that evaluates workers' trust degrees by considering the IEWV challenge, allowing for the selection of reliable workers and thus ensuring higher data quality; (2) a task bundling method using the Non-dominated Sorting Genetic Algorithm II to bundle unpopular tasks with popular ones strategically, maximizing platform utility and completion rates; and (3) an optimal allocation algorithm that assigns trusted workers to tasks best suited to their capabilities, thus improving data reliability and minimizing costs. Experimental results demonstrate that compared to the state-of-the-art methods, the TBTA scheme achieves a 15.54 % improvement in task completion rate, and a 1.83 % reduction in worker travel distance.}
}
@article{RAPP2025103471,
title = {How do people react to ChatGPT's unpredictable behavior? Anthropomorphism, uncanniness, and fear of AI: A qualitative study on individuals’ perceptions and understandings of LLMs’ nonsensical hallucinations},
journal = {International Journal of Human-Computer Studies},
volume = {198},
pages = {103471},
year = {2025},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2025.103471},
url = {https://www.sciencedirect.com/science/article/pii/S107158192500028X},
author = {Amon Rapp and Chiara {Di Lodovico} and Luigi {Di Caro}},
keywords = {AI, Generative AI, LLM, Anthropomorphizing, Humanness, Uncanny valley},
abstract = {Large Language Models (LLMs) have shown impressive capabilities in producing texts of quality and fluency that are similar to those created by humans. Despite their increasing use, however, the broader population's experience of many aspects of interaction with LLMs remains underexplored. This study investigates how diverse individuals perceive and account for “nonsensical hallucinations”, namely, an LLM's unpredictable and meaningless behavior provided as a response to a user's request. We asked 20 participants to interact with ChatGPT 3.5 and experience its hallucinations. Through semi-structured interviews, we found that participants with a computer science background or consistent previous use of LLMs interpret unpredictable nonsensical responses as an error, while novices perceive them as model's autonomous behaviors. Moreover, we discovered that such responses produce an abrupt modification of participants’ perceptions and understandings of the LLM's nature. From a soothing and polite entity, ChatGPT becomes either an obscure and unfamiliar “alien”, or a human-like being potentially hostile to humankind, making also emerge unsettling feelings, which may unveil an underlying fear of Artificial Intelligence. The study contributes to literature on how people react to the unfamiliarity of a technology that may be perceived as alien and yet extremely human-like, generating “uncanny effects,” as well as to research on the anthropomorphizing of technology.}
}
@article{SAXENA2025532,
title = {COMPARATIVE ANALYSIS OF LARGE LANGUAGE MODELS FOR THE APPLICATION OF SCIENTIFIC ARTICLE SUMMARIZATION},
journal = {Procedia Computer Science},
volume = {259},
pages = {532-542},
year = {2025},
note = {Sixth International Conference on Futuristic Trends in Networks and Computing Technologies (FTNCT06), held in Uttarakhand, India},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925010993},
author = {Rishabh Saxena and Shubhangi Singh and Preeti Dubey},
keywords = {LLMs, LLaMa-3, GPT-3, Mixtral, Gemma, ROUGE, BLEU, BERT, Automatic text summarization},
abstract = {Automatic text summarization has become an essential tool for academics to stay up to date with the newest advancements due to the high rise of scientific publications. Abstractive text summarisation tasks can be done using LLMs. However current summarization methods often struggle to capture the nuanced and technical details present in research papers and there are prevalent research gaps in the realm of abstractive summarisation using generative AI. This study aims to analyse the efficiency of LLM models – GPT-3.5, LLaMa 3, Mixtral 8x7b and Gemma-2, in condensing detailed scientific literature into manageable summaries, and their further evaluation based on ROUGE, BERT and BLEU scores. The results show that GPT-3.5 and LLaMa 3 generate more coherent and contextually accurate summaries with a BERT score of 0.21 and 0.19 respectively, even though Mixtral 8x7B performs exceptionally well in quantitative measurements. Despite its coherence, Gemma-2 receives poorer performance in both qualitative and quantitative assessments. These findings bring out the value of integrating quantitative and qualitative evaluations to gain a thorough understanding of summarization.}
}
@article{ZHENG2025113524,
title = {Comprehensive survey of large models-driving intelligent decision making},
journal = {Applied Soft Computing},
volume = {181},
pages = {113524},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2025.113524},
url = {https://www.sciencedirect.com/science/article/pii/S156849462500835X},
author = {Yuanhang Zheng and Tong Wu and Xiangyu Xiao and Zeshui Xu},
keywords = {Intelligent decision making, Large models, Survey, Interaction, Multi-modal information, Interpretability},
abstract = {In recent years, intelligent decision making has become a national strategic level to attach great importance to the focus of the fields, in medicine, business, manufacturing, agriculture, etc. Exemplified by breakthroughs such as GPT-4, LLaMA, Deepseek, and multimodal systems like AlphaFold, large models have catalyzed a paradigm shift in artificial intelligence—from perceptual tasks to complex decision-making scenarios. This paper presents a comprehensive survey on large models (LMs)-driving intelligent decision making, where the main contributions are as follows: 1) innovatively give a definition of LM-driving intelligent decision making, and establish a novel multi-role functional framework distinguishing LMs as data synthesizers (preparers), contextual reasoners (facilitators), and ethical validators (reflectors). 2) cross-disciplinary bibliometric analysis reveals the current research landscape in this field, demonstrating a wide range of interests within the community. 3) conduct a profound and comprehensive analysis of key components and applications of LMs-driving intelligent decision making, and deeply analyze the advantages, limitations, and challenges associated with this approach while also suggesting future research directions. Furthermore, we recommend three priority research directions: 1) Develop reasoning-enhanced LMs overcoming parameter limits via non-parametric activation. 2) Create interpretable LMs mirroring human decision processes (intuition vs. systematic thought) through problem-solving transparency. 3) Combine fuzzy/probabilistic methods with Transformers for real-world adaptability and adaptive evaluation frameworks. This work advances both theoretical understanding through its interdisciplinary perspective and offers concrete implementation blueprints for industry practitioners navigating LM adoption in decision-critical contexts.}
}
@article{ALLALCHERIF2025123906,
title = {Stepping out of the innovation race to embrace outnovation: Fostering well-being and responsible consumption through sustainability, simplicity, authenticity, and nostalgia},
journal = {Technological Forecasting and Social Change},
volume = {210},
pages = {123906},
year = {2025},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2024.123906},
url = {https://www.sciencedirect.com/science/article/pii/S0040162524007042},
author = {Oihab Allal-Chérif and José Fernando Gallego-Nicholls and Agustin Carrilero-Castillo and Francisco Javier {Sendra Garcia}},
keywords = {Outnovation, Innovation, Sustainability, Simplicity, Authenticity, Nostalgia, Excellence},
abstract = {This article theorizes and characterizes the concept of “outnovation” as an alternative or a complement to innovation within the framework of grounded theory. Outnovation consists of stepping out of the unrelenting innovation race and removing all unnecessary innovations from a product, focusing instead on sustainability, simplicity, authenticity, and nostalgia. After presenting the dangers and limits of innovative strategies and disasters resulting from poorly mastered innovations, the research studies four different cases, which examples demonstrate that not innovating or suppressing innovations is not synonymous with bankruptcy. At a time when customers are looking for more sustainable products and when many economists advocate degrowth and less unbridled consumption, companies are looking for new forms of differentiation and value creation. Outnovating is a way of getting out of the vicious circle of endless innovation and meeting United Nations' Sustainable Development Goals.}
}
@article{ZHANG2024106553,
title = {Pre-gating and contextual attention gate — A new fusion method for multi-modal data tasks},
journal = {Neural Networks},
volume = {179},
pages = {106553},
year = {2024},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2024.106553},
url = {https://www.sciencedirect.com/science/article/pii/S0893608024004775},
author = {Duoyi Zhang and Richi Nayak and Md Abul Bashar},
keywords = {Multi-modal data learning, Cross-attention module, Neural networks},
abstract = {Multi-modal representation learning has received significant attention across diverse research domains due to its ability to model a scenario comprehensively. Learning the cross-modal interactions is essential to combining multi-modal data into a joint representation. However, conventional cross-attention mechanisms can produce noisy and non-meaningful values in the absence of useful cross-modal interactions among input features, thereby introducing uncertainty into the feature representation. These factors have the potential to degrade the performance of downstream tasks. This paper introduces a novel Pre-gating and Contextual Attention Gate (PCAG) module for multi-modal learning comprising two gating mechanisms that operate at distinct information processing levels within the deep learning model. The first gate filters out interactions that lack informativeness for the downstream task, while the second gate reduces the uncertainty introduced by the cross-attention module. Experimental results on eight multi-modal classification tasks spanning various domains show that the multi-modal fusion model with PCAG outperforms state-of-the-art multi-modal fusion models. Additionally, we elucidate how PCAG effectively processes cross-modality interactions}
}
@article{MUSARAT2024102057,
title = {Automated monitoring innovations for efficient and safe construction practices},
journal = {Results in Engineering},
volume = {22},
pages = {102057},
year = {2024},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2024.102057},
url = {https://www.sciencedirect.com/science/article/pii/S2590123024003116},
author = {Muhammad Ali Musarat and Abdul Mateen Khan and Wesam Salah Alaloul and Noah Blas and Saba Ayub},
keywords = {Construction monitoring, Traditional, Automation, Photogrammetry, Sensors, BIM},
abstract = {As construction projects increase in complexity, there are growing challenges with conventional monitoring methods in terms of efficiency, safety, and competitiveness. Traditional supervision techniques are labour-intensive, intermittent, and prone to errors. Hence, this study statistically evaluates the potential advantages of photogrammetry, sensors, and algorithms to enable continuous automated monitoring. The results of this survey were analysed to compare manual and automated monitoring systems. The outcome shows that the Malaysian construction industry is aware of Automated Monitoring Innovations for Efficient and Safe Construction Practices. The top ranked factor was Photogrammetry which had a relative importance index (RII) of 0.821 for straightforward site monitoring and 0.812 for accelerated 3D BIM modelling. The RII for sensors to track labourers, apparatus, and progress in real time was 0.82, while the RII for hazard anticipation was 0.796. Automation achieved a reduction in fatigue by 0.784, labour intensity by 0.792, and time demands by 0.768, as measured by the RII. A conceptual framework was developed that incorporates measurable improvements in schedules, safety, and quality control. Automated solutions, as opposed to human examinations which are prone to error, provided exhaustive geographical data and ongoing surveillance notwithstanding obstacles pertaining to cost, cybersecurity, privacy, and integration. Construction monitoring must incorporate new technology, strategic change management, data investments, and supporting regulations to increase profitability, safety, and efficiency as competition and complexity increase.}
}
@article{MOBARAK2023100523,
title = {Scope of machine learning in materials research—A review},
journal = {Applied Surface Science Advances},
volume = {18},
pages = {100523},
year = {2023},
issn = {2666-5239},
doi = {https://doi.org/10.1016/j.apsadv.2023.100523},
url = {https://www.sciencedirect.com/science/article/pii/S2666523923001575},
author = {Md Hosne Mobarak and Mariam Akter Mimona and Md. Aminul Islam and Nayem Hossain and Fatema Tuz Zohura and Ibnul Imtiaz and Md Israfil Hossain Rimon},
keywords = {Machine learning, Materials research, Machine learning methods, Material synthesis, Image processing},
abstract = {This comprehensive review investigates the multifaceted applications of machine learning in materials research across six key dimensions, redefining the field's boundaries. It explains various knowledge acquisition mechanisms starting with supervised, unsupervised, reinforcement, and deep learning techniques. These techniques are transformative tools for transforming unactionable data into insightful actions. Moving on to the materials synthesis, the review emphasizes the profound influence of machine learning, as demonstrated by predictive models that speed up material selection, structure-property relationships that reveal crucial connections, and data-driven discovery that fosters innovation. Machine learning reshapes our comprehension and manipulation of materials by accelerating discovery and enabling tailored design through property prediction models and structure-property relationships. Machine learning extends its influence to image processing, improving object detection, classification, and segmentation precision and enabling methods like image generation, revolutionizing the potential of image processing in materials research. The most recent developments show how machine learning can have a transformative impact at the atomic level by enabling precise property prediction and intricate data extraction, representing significant advancements in material understanding and innovation. The review highlights how machine learning has the potential to revolutionize materials research by accelerating discovery, improving performance, and stimulating innovation. It does so while acknowledging obstacles like poor data quality and complicated algorithms. Machine learning offers a wide range of exciting prospects for scientific investigation and technological advancement, positioning it as a powerful force for influencing the future of materials research.}
}
@article{LEI2023110491,
title = {Prior knowledge-embedded meta-transfer learning for few-shot fault diagnosis under variable operating conditions},
journal = {Mechanical Systems and Signal Processing},
volume = {200},
pages = {110491},
year = {2023},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2023.110491},
url = {https://www.sciencedirect.com/science/article/pii/S0888327023003990},
author = {Zihao Lei and Ping Zhang and Yuejian Chen and Ke Feng and Guangrui Wen and Zheng Liu and Ruqiang Yan and Xuefeng Chen and Chunsheng Yang},
keywords = {Intelligent fault diagnosis, Prior knowledge embedding, Few-shot learning, Meta-transfer learning, Variable operating conditions},
abstract = {In recent years, intelligent fault diagnosis based on deep learning has achieved vigorous development thanks to its powerful feature representation ability. However, scarcity of high-quality data, especially samples under severe fault states, and variable operating conditions have limited the industrial application of intelligent fault diagnosis. To alleviate this predicament, a novel prior knowledge-embedded meta-transfer learning (PKEMTL) is proposed for few-shot fault diagnosis with limited training data and scarce test data. The method focuses on the problem of few-shot fault diagnosis under variable operating conditions to improve adaptability. Different from traditional models, the PKEMTL employs a metric-based meta-learning framework and embeds prior knowledge to enable cross-task learning under variable operating conditions. Specifically, order tracking is firstly introduced as preliminary prior information for data augmentation, and then the augmented data are divided into a series of meta-tasks. Secondly, the meta-tasks are performed by lightweight multiscale feature encoding to obtain high-level feature representations. Next, the meta-learning module based on diagnostic knowledge embedding guides the model to acquire meta-knowledge of speed generalization by constructing the self-supervised task to embed additional prior knowledge into the meta-training process. The generalization performance of the model is further improved by adaptive information fusion learning as a comprehensive decision-making module. Two case studies under variable operating conditions are implemented to validate the effectiveness and superiority of the proposed few-shot fault diagnosis method.}
}
@article{AKKEM2024107881,
title = {A comprehensive review of synthetic data generation in smart farming by using variational autoencoder and generative adversarial network},
journal = {Engineering Applications of Artificial Intelligence},
volume = {131},
pages = {107881},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.107881},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624000393},
author = {Yaganteeswarudu Akkem and Saroj Kumar Biswas and Aruna Varanasi},
keywords = {Variational autoencoders, Generative adversarial networks, Smart farming},
abstract = {In this study, we propose the use of Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) to generate synthetic data for crop recommendation (CR). CR is critical in agriculture, assisting farmers in making informed decisions about crop cultivation, considering factors like soil conditions, weather patterns etc. Unfortunately, the availability of labeled data for CR is often limited, posing a significant challenge in training accurate recommendation models. VAEs and GANs are employed to create synthetic data that closely mirrors real-world crop data. VAEs are utilized to extract latent representation from the input data, enabling the generation of new samples with similar characteristics. GANs play a crucial role in generating data by training a generator network to produce synthetic samples that closely resemble real data, while a discriminator network distinguishes between genuine and synthetic data. The generated synthetic data serves as a valuable resource to prepare datasets for CR, enhancing the performance of recommendation models. Our research explores the effectiveness of VAEs and GANs in producing high-quality synthetic CR data, facilitating improved training and evaluation of recommendation systems. This paper presents the architecture and training process of the proposed models and evaluates the quality and utility of the generated synthetic data using various experiments, including visualizations such as heatmaps, scatter plots, cumulative sum per feature plots, and distribution per feature plots. The results of this study hold the potential to make a significant contribution to the field of agriculture by providing a reliable and abundant source of training data for CR systems.}
}
@article{ZHANG2025226,
title = {Targeting cuproptosis for cancer therapy: Focus on the anti-tumor immune system},
journal = {Cancer Pathogenesis and Therapy},
volume = {3},
number = {3},
pages = {226-243},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2024.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S2949713224000569},
author = {Xuan Zhang and Xiaohong Han},
keywords = {Cuproptosis, Copper homeostasis, Immunotherapy, Drug synergism},
abstract = {Copper (Cu) is an indispensable micronutrient that maintains signaling pathways and biological homeostasis in almost all cell types; however, its excess affects the tricarboxylic acid cycle, causes the accumulation of fatty acylated proteins, destabilization of iron–sulfur cluster proteins, and increases the levels of intracellular reactive oxygen species, leading to proteotoxic stress and cell death. Cuproptosis, a form of Cu-dependent cell death, differs from other types of regulated cell death (RCD) and was first reported in Science in 2022. Recently, the RCD pathways have been targeted in cancer therapy. However, the escape of apoptosis in tumor cells causes resistance to treatment and tumor recurrence. Therefore, there is an urgent need to study the alternative mechanisms of cancer cell mortality. Compared to normal patients, a significant increase in serum Cu ion levels has been observed in patients with tumors. Moreover, tumor cell proliferation, angiogenesis, and metastasis are associated with cuproptosis. Thus, exploring cancer signaling pathways related to cuproptosis will provide a new perspective for the development of anti-cancer drugs. Importantly, cuproptosis is closely associated with the modulation of anti-tumor immunity. The expression of cuproptosis-related genes (CRGs) is significantly correlated with immune cell infiltration and the immune checkpoint programmed cell death protein 1 (PD-1)/programmed death-ligand 1 (PD-L1). Based on these findings, a series of cuproptosis-related drugs have been used in tumor-targeted combination therapy or as immune synergists. Therefore, elucidating the role of cuproptosis per cancer stage and in the tumor immune microenvironment (TIME) is helpful in clarifying the potential value of Cu in the treatment of specific cancers. In this review, we summarize specific cancer signaling pathways related to cuproptosis and cancer treatment based on the regulation of Cu concentration. The combination of these two approaches may help researchers develop more therapies targeting cuproptosis-related pathways. Importantly, we focused on the effect of cuproptosis on the TIME and systematically discussed the role of CRGs in tumor immunity considering CRG-related anti-tumor immune signaling pathways, tumor prognosis scoring system, anti-tumor immunotherapy, and biological experiments and bioinformatics prediction models, to provide new ideas for the development of anticancer therapy targeting cuproptosis-related pathways.}
}
@article{DASGUPTA2025117425,
title = {Conditional score-based diffusion models for solving inverse elasticity problems},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {433},
pages = {117425},
year = {2025},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2024.117425},
url = {https://www.sciencedirect.com/science/article/pii/S0045782524006807},
author = {Agnimitra Dasgupta and Harisankar Ramaswamy and Javier Murgoitio-Esandi and Ken Y. Foo and Runze Li and Qifa Zhou and Brendan F. Kennedy and Assad A. Oberai},
keywords = {Conditional generative models, Inverse problems, Bayesian inference, Diffusion-based modeling, Uncertainty quantification, Elastography},
abstract = {We propose a framework to perform Bayesian inference using conditional score-based diffusion models to solve a class of inverse problems in mechanics involving the inference of a specimen’s spatially varying material properties from noisy measurements of its mechanical response to loading. Conditional score-based diffusion models are generative models that learn to approximate the score function of a conditional distribution using samples from the joint distribution. More specifically, the score functions corresponding to multiple realizations of the measurement are approximated using a single neural network, the so-called score network, which is subsequently used to sample the posterior distribution using an appropriate Markov chain Monte Carlo scheme based on Langevin dynamics. Training the score network only requires simulating the forward model. Hence, the proposed approach can accommodate black-box forward models and complex measurement noise. Moreover, once the score network has been trained, it can be re-used to solve the inverse problem for different realizations of the measurements. We demonstrate the efficacy of the proposed approach on a suite of high-dimensional inverse problems in mechanics that involve inferring heterogeneous material properties from noisy measurements. Some examples we consider involve synthetic data, while others include data collected from actual elastography experiments. Further, our applications demonstrate that the proposed approach can handle different measurement modalities, complex patterns in the inferred quantities, non-Gaussian and non-additive noise models, and nonlinear black-box forward models. The results show that the proposed framework can solve large-scale physics-based inverse problems efficiently.}
}
@article{MIRONE2024108754,
title = {Combined rate-temperature effects in postnecking plasticity of A2-70 stainless steel},
journal = {International Journal of Mechanical Sciences},
volume = {262},
pages = {108754},
year = {2024},
issn = {0020-7403},
doi = {https://doi.org/10.1016/j.ijmecsci.2023.108754},
url = {https://www.sciencedirect.com/science/article/pii/S0020740323006562},
author = {Giuseppe Mirone and Raffaele Barbagallo and Luca Corallo},
keywords = {Thermal softening, Strain rate effect, Flow stress, Hopkinson bar, Necking},
abstract = {In this paper, a comprehensive study that integrates theoretical, experimental and FE analyses, elucidates the combined effect of strain, strain rate, and temperature on the mechanical response of A2-70 stainless steel. A wide series of tensile experiments on cylindrical specimens is presented, including low to high temperatures and quasi-static to dynamic rates. Opportune combinations of temperatures and strain rates are imposed in order to possibly separate and identify their respective effects on the flow curve of the material. The adopted experimental procedures based on neck-related measurements revealed the onset of secondary phenomena affecting dynamic tensile tests. Classical material models were found not suitable to correctly predict the complex elastoplastic deformation of this material. Thus, a new general material model is presented and used to account for the complex interplay between strain, temperature, and rate-dependent effects. Finite element simulations are conducted using both the proposed constitutive model and another classical model of dynamic hardening, to investigate and compare their predictive capability over the entire experimental campaign.}
}
@article{RUCHAWAPOL2022154324,
title = {A review on computational approaches that support the researches on traditional Chinese medicines (TCM) against COVID-19},
journal = {Phytomedicine},
volume = {104},
pages = {154324},
year = {2022},
issn = {0944-7113},
doi = {https://doi.org/10.1016/j.phymed.2022.154324},
url = {https://www.sciencedirect.com/science/article/pii/S0944711322004032},
author = {Chattarin Ruchawapol and Wen-Wei Fu and Hong-Xi Xu},
keywords = {Computational approaches, Traditional Chinese Medicine (TCM), Structure-based approach, Knowledge-mining, Network-based approach},
abstract = {Background
COVID-19 highly caused contagious infections and massive deaths worldwide as well as unprecedentedly disrupting global economies and societies, and the urgent development of new antiviral medications are required. Medicinal herbs are promising resources for the discovery of prophylactic candidate against COVID-19. Considerable amounts of experimental efforts have been made on vaccines and direct-acting antiviral agents (DAAs), but neither of them was fast and fully developed.
Purpose
This study examined the computational approaches that have played a significant role in drug discovery and development against COVID-19, and these computational methods and tools will be helpful for the discovery of lead compounds from phytochemicals and understanding the molecular mechanism of action of TCM in the prevention and control of the other diseases.
Methods
A search conducting in scientific databases (PubMed, Science Direct, ResearchGate, Google Scholar, and Web of Science) found a total of 2172 articles, which were retrieved via web interface of the following websites. After applying some inclusion and exclusion criteria and full-text screening, only 292 articles were collected as eligible articles.
Results
In this review, we highlight three main categories of computational approaches including structure-based, knowledge-mining (artificial intelligence) and network-based approaches. The most commonly used database, molecular docking tool, and MD simulation software include TCMSP, AutoDock Vina, and GROMACS, respectively. Network-based approaches were mainly provided to help readers understanding the complex mechanisms of multiple TCM ingredients, targets, diseases, and networks.
Conclusion
Computational approaches have been broadly applied to the research of phytochemicals and TCM against COVID-19, and played a significant role in drug discovery and development in terms of the financial and time saving.}
}
@article{VALASIADIS2024112727,
title = {Wide-characterization of high and low dry matter kiwifruit through spatiotemporal multi-omic approach},
journal = {Postharvest Biology and Technology},
volume = {209},
pages = {112727},
year = {2024},
issn = {0925-5214},
doi = {https://doi.org/10.1016/j.postharvbio.2023.112727},
url = {https://www.sciencedirect.com/science/article/pii/S092552142300488X},
author = {Dimitrios Valasiadis and Marios Georgios Kollaros and Michail Michailidis and Chrysanthi Polychroniadou and Georgia Tanou and Christos Bazakos and Athanassios Molassiotis},
keywords = {Dry matter, Gene expression, Kiwifruit ripening, Non-destructive, Primary metabolites, 1-MCP},
abstract = {Despite the widespread use of dry matter content (DMC) as an indicator of kiwifruit quality, the physiological and molecular impact of DMC in fruit ripening remains unknown. Herein, the post-harvest physiological, metabolomic, and transcriptomic influence of DMC status on the pericarp and placenta tissue of ‘Hayward’ kiwifruit at harvest and at the onset of post-cold ripening was investigated. A segregation strategy based on DMC in commercially harvested kiwifruit was achieved with near-infrared spectroscopy for the estimation of DMC in individual fruits. Additionally, kiwifruits with distinct DMC levels were treated with 1-methylcyclopropene (1-MCP) and systematically monitored for ripening changes (20 °C) at various intervals after cold storage (0 °C). Following 90 and 120 days of cold exposure, high DMC kiwifruit generally exhibited superior physiological characteristics, such as increased pericarp and placenta firmness, and soluble solid and starch contents compared to low DMC kiwifruit, regardless of the 1-MCP application. Evidence is also presented for 1-MCP delaying the ripening of low-DMC fruit to the level of the untreated high-DMC kiwifruit. An accumulation of primary metabolites, particularly sugars and polyphenolic compounds, such as catechin, chlorogenic acid and procyanidin B1/B2 was evidenced in the high DMC group. At harvest, gene expression analysis revealed minor differences between DMC groups, with beta-amylase being the highest up-regulated gene in high DMC kiwifruit. Moreover, the gene expression patterns between DMC groups became more distinct after cold storage. Genes related to starch biosynthesis (i.e., glucose-1-phosphate adenyltransferase), water movement (i.e., aquaporin), polyphenolic biosynthesis (i.e., chalcone synthase) and lipid metabolism (i.e., diacylglycerol acyltransferase) showed strong variations between low and high DMC. Interestingly, the placenta tissue displayed almost 4 times more than DMC-affected differentially expressed genes compared to the pericarp, highlighting the key role of the placenta in kiwifruit ripening, notably following 1-MCP treatment. This study provides insights into the tissue-specific ripening response between kiwifruit with distinct DMC, as well as the gene expression influenced by an interaction of 1-MCP and DMC level, thereby helping develop postharvest programs aimed at improving kiwifruit quality traits.}
}
@article{FAN2024100082,
title = {A survey of emerging applications of diffusion probabilistic models in MRI},
journal = {Meta-Radiology},
volume = {2},
number = {2},
pages = {100082},
year = {2024},
issn = {2950-1628},
doi = {https://doi.org/10.1016/j.metrad.2024.100082},
url = {https://www.sciencedirect.com/science/article/pii/S2950162824000353},
author = {Yuheng Fan and Hanxi Liao and Shiqi Huang and Yimin Luo and Huazhu Fu and Haikun Qi},
keywords = {Diffusion probabilistic models, Score based generative modeling, MRI},
abstract = {Diffusion probabilistic models (DPMs) which employ explicit likelihood characterization and a gradual sampling process to synthesize data, have gained increasing research interest. Despite their huge computational burdens due to the large number of steps involved during sampling, DPMs are widely appreciated in various medical imaging tasks for their high-quality and diversity of generation. Magnetic resonance imaging (MRI) is an important medical imaging modality with excellent soft tissue contrast and superb spatial resolution, which possesses unique opportunities for DPMs. Although there is a recent surge of studies exploring DPMs in MRI, a survey paper of DPMs specifically designed for MRI applications is still lacking. This review article aims to help researchers in the MRI community to grasp the advances of DPMs in different applications. We first introduce the theory of two dominant kinds of DPMs, categorized according to whether the diffusion time step is discrete or continuous, and then provide a comprehensive review of emerging DPMs in MRI, including reconstruction, image generation, image translation, segmentation, anomaly detection, and further research topics. Finally, we discuss the general limitations as well as limitations specific to the MRI tasks of DPMs and point out potential areas that are worth further exploration.}
}
@article{SEO2025,
title = {Impact of Perception of Intelligent Information Technology (IIT) on IIT-Based Policy Decision-Making in the Public Sector:},
journal = {Journal of Organizational and End User Computing},
volume = {37},
number = {1},
year = {2025},
issn = {1546-2234},
doi = {https://doi.org/10.4018/JOEUC.379768},
url = {https://www.sciencedirect.com/science/article/pii/S1546223425000309},
author = {HyungJun Seo and HyoungSuk Lee and Fu-Sheng Tsai},
keywords = {Artificial Intelligence, Digital Government, Digital Transformation, Intelligent Information Technology (IIT), Policy Decision Making, Social Capital},
abstract = {ABSTRACT
Many governments have adopted information intelligent technology (IIT) policies to enhance efficiency and responsiveness. This study examines key factors influencing IIT-based decision making in Korean central and local governments. The research model includes perceived usefulness and risk of IIT, leaders’ and peers’ IIT, and social capital as moderators. Using quota sampling, regression analysis reveals that perceived usefulness, perceived risk, and leaders’ IIT positively affect decision making. While bonding social capital has no moderating effect, bridging social capital enhances the impact of peers’ IIT but weakens the effects of perceived risk and leaders’ IIT. These findings highlight the role of personal perception, social influence, and social capital in IIT adoption, offering insights for future digital governance research.}
}
@article{ACERORUGE2025102434,
title = {Inteligencia artificial para el abordaje integral de las enfermedades huérfanas/raras: revisión sistemática exploratoria},
journal = {Medicina de Familia. SEMERGEN},
volume = {51},
number = {5},
pages = {102434},
year = {2025},
issn = {1138-3593},
doi = {https://doi.org/10.1016/j.semerg.2024.102434},
url = {https://www.sciencedirect.com/science/article/pii/S1138359324002442},
author = {L.M. {Acero Ruge} and D.A. {Vásquez Lesmes} and E.H. {Hernández Rincón} and L.P. {Avella Pérez}},
keywords = {Enfermedad huérfana, Enfermedad rara, Inteligencia artificial, Aprendizaje profundo, Aprendizaje automático, Diagnóstico por ordenador, Diagnóstico por imagen, Redes neuronales de la computación, Orphan diseases, Rare diseases, Artificial intelligence, Deep learning, Machine learning, Diagnosis, Computer assisted, Diagnostic imaging, Neuronal networks computer},
abstract = {Resumen
Introducción
Las enfermedades huérfanas (EH) son raras, pero colectivamente comunes, presentan desafíos como diagnósticos tardíos, progresión de la enfermedad y escasa oferta terapéutica. Recientemente, la inteligencia artificial (IA) ha ganado interés en la investigación de estas enfermedades.
Objetivo
Sintetizar la evidencia disponible sobre el uso de la IA en el abordaje integral de las enfermedades huérfanas.
Métodos
Se realizó una revisión sistemática exploratoria tipo «Scoping Review» en PubMed, Bireme, Scopus entre 2019 al 2024.
Resultados
Se identificaron 56 artículos con un 21,4% de estudios experimentales; 28 documentos no especifican una EH, 8 documentos tenían como grupo más estudiado enfermedades genéticas; el 53,57% se enfocaban en diagnóstico y se encuentran 36 algoritmos diferentes.
Conclusiones
La información encontrada muestra el desarrollo de algoritmos de IA en diferentes escenarios clínicos, los resultados confirman los potenciales beneficios en tiempo de diagnósticos, opciones terapéuticas y mayor sensibilización de los profesionales de la salud.
Introduction
Orphan diseases (OD) are rare but collectively common, presenting challenges such as late diagnoses, disease progression, and limited therapeutic options. Recently, artificial intelligence (AI) has gained interest in the research of these diseases.
Objective
To synthesize the available evidence on the use of AI in the comprehensive approach to orphan diseases.
Methods
An exploratory systematic review of the Scoping Review type was conducted in PubMed, Bireme, and Scopus from 2019 to 2024.
Results
fifty-six articles were identified, with 21.4% being experimental studies; 28 documents did not specify an OD, 8 documents focused primarily on genetic diseases; 53.57% focused on diagnosis, and 36 different algorithms were identified.
Conclusions
The information found shows the development of AI algorithms in different clinical settings, confirming the potential benefits in diagnosis times, therapeutic options, and greater awareness among health professionals.}
}
@article{TESSELAAR2025106325,
title = {Psychiatric comorbidity in substance use disorders, a systematic review of neuro-imaging findings},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {177},
pages = {106325},
year = {2025},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2025.106325},
url = {https://www.sciencedirect.com/science/article/pii/S0149763425003264},
author = {Debbie R.M. Tesselaar and Arnt F.A. Schellekens and Judith R. Homberg and Jan Booij and Cyprien Guerrin},
keywords = {SUD, Addiction, Psychopathology, Comorbidity, Co-occurring psychiatric disorders, Neuro-imaging},
abstract = {Substance use disorder (SUD) have negative consequences for affected individuals and society. Current treatments are moderately effective, partly due to the large heterogeneity in SUDs, including co-occurring psychopathology. A better understanding of the mechanisms underlying these frequently co-occurring psychiatric conditions is required to develop individualized treatments to increase treatment success rates. We systematically reviewed case-control studies investigating neurobiological differences measured using neuroimaging between participants with SUD only and participants with SUD and co-occurring psychiatric disorders. We searched articles in four databases. Inclusion criteria further existed of an ICD and/or DSM diagnoses based on interview assessment or Fagerström test for Nicotine Dependence scores ≥ 5. We hypothesised that co-occurring psychopathology could (1) amplify the neurobiological effects of SUD, (2) attenuate it, (3) have unique neurobiological effects, or (4) have no additional neurobiological effects. From 10,076 unique records screened, we included a total of 26 articles investigating the effect of personality disorder cluster B and/or C (6), depression (4), PTSD (4), ADHD (4), schizophrenia (8), bipolar disorder (1) or anxiety disorders (1) on SUD. We found amplifying effects of co-occurring schizophrenia and personality disorder, unique effects of schizophrenia, ADHD and personality disorder, and attenuating or no effect of depression on SUD. Findings on PTSD were contradictory. In conclusion, different co-occurring psychiatric disorder have distinct effects on the neurobiology of SUD.}
}
@article{CHEN2025116702,
title = {Modelling of lithium-ion battery electrode calendering: A critical review},
journal = {Journal of Energy Storage},
volume = {123},
pages = {116702},
year = {2025},
issn = {2352-152X},
doi = {https://doi.org/10.1016/j.est.2025.116702},
url = {https://www.sciencedirect.com/science/article/pii/S2352152X2501415X},
author = {Jiashen Chen and Maryam Asachi and Ali Hassanpour and Meisam Babaie and Masoud Jabbari},
keywords = {Lithium-ion batteries, Electrode calendering, Numerical modelling, Machine learning, Electrode microstructure, Battery performance},
abstract = {Lithium-ion Batteries (LIBs) are central to modern energy storage, with growing demands for improved performance, safety, and cost efficiency. Electrode calendering, a critical step in LIBs manufacturing, significantly influences the microstructure and electrochemical properties of electrodes. This review explores advances in the modelling of the calendering process over the past few years, focusing on empirical, numerical, and machine learning approaches. Empirical models, though computationally efficient, are limited by oversimplification, while numerical methods, such as Discrete Element Method (DEM) and Finite Element Method (FEM), offer more detailed insights into the structural evolution during calendering but require intensive computational resources. The growing application of machine learning introduces novel data-driven methods for optimising the process by effectively handling multiscale phenomena and high-dimensional data. A comparative analysis of these modelling strategies highlights the need for hybrid approaches that integrate empirical, numerical, and data-driven models to accurately predict electrode behaviour and optimise calendering conditions. Future research should aim to bridge the gap between computational accuracy and practical application to improve the performance and cost-efficiency of LIBs manufacturing.}
}
@article{SEPULVEDAOVIEDO2025100942,
title = {A review of operational factors affecting photovoltaic system performance},
journal = {Energy Conversion and Management: X},
volume = {26},
pages = {100942},
year = {2025},
issn = {2590-1745},
doi = {https://doi.org/10.1016/j.ecmx.2025.100942},
url = {https://www.sciencedirect.com/science/article/pii/S2590174525000741},
author = {Edgar Hernando Sepúlveda-Oviedo},
keywords = {Performance evaluation, Degradation, Efficiency, Tilt angle, Photovoltaic (PV)},
abstract = {The reduction in manufacturing costs of photovoltaic (PV) systems has driven significant growth in the PV industry. This expansion has shifted the current challenge from constructing new PV systems to maximizing the performance and longevity of installed PV modules. PV performance is influenced by two major categories of factors: environmental and operational. While environmental factors, such as dust and temperature, have been extensively studied, operational factors — critical for optimizing system efficiency — have not received the same level of attention. This study analyzes 102 articles focusing on operational factors such as PV technology, tilt and orientation angles, surface properties, height, and component aging, while also examining their interaction with environmental factors, particularly dust. In addition, the study compiles a set of standardized metrics aimed at quantifying efficiency losses and enabling consistent comparisons across studies. Finally, this review outlines a roadmap identifying key research gaps and provides recommendations for improving PV system performance. This roadmap offers valuable insights for researchers, engineers, and policymakers to better understand and address the operational factors that influence the efficiency and lifespan of PV systems.}
}
@article{THOMAS2024121823,
title = {Leaf traits of Central-European beech (Fagus sylvatica) and oaks (Quercus petraea/robur): Effects of severe drought and long-term dynamics},
journal = {Forest Ecology and Management},
volume = {559},
pages = {121823},
year = {2024},
issn = {0378-1127},
doi = {https://doi.org/10.1016/j.foreco.2024.121823},
url = {https://www.sciencedirect.com/science/article/pii/S037811272400135X},
author = {Frank M. Thomas and Sebastian Preusser and Bernhard Backes and Willy Werner},
keywords = {Climatic water balance, Compositional Nutrient Diagnosis, Drought stress, Leaf morphology, Nutrient concentration, Summer drought},
abstract = {In 2018—2020, Central-European forests suffered from extremely hot and dry summers. We used data from long-term forest monitoring of six stands of European beech (Fagus sylvatica) and two stands of oak (Quercus petraea/Q. robur) growing on different geological substrates in the climatically uniform state of Saarland (south-western Germany) for analyzing leaf traits of the period 2004—2021. We aimed at detecting overall effects of the drought on foliar morphology, nutrient concentrations, and injury, and long-term alterations in these traits. Across sites, drought resulted in a decrease in leaf size and specific leaf area (SLA) and increased fruiting in the beech and a decrease in the foliar nitrogen (N) concentrations in both tree genera. During drought, foliar calcium and manganese concentrations were lower and potassium (K) concentrations higher across the beech stands, whereas in the oak stands, drought led to a reduction in the foliar phosphorus (P) and magnesium (Mg) concentrations. High rates of anthropogenic N deposition during recent decades have resulted in high foliar N concentrations and low to deficient concentrations of P and, in the beech, of Mg. However, a significant (negative) long-term trend in leaf traits across the study sites was only found for the K concentration and necroses of the beech leaves. Foliar N correlated positively with SLA in the beech and with leaf size in the oak but was not related to herbivory. Chlorosis was the only leaf trait that, in the beech, correlated (negatively) with the climatic water balance. We conclude that even severe drought during three consecutive years does not seem to critically affect the nutrient supply to the two most important deciduous forest tree genera of Central Europe. In the beech, a decrease in leaf size and SLA might be used as an early indication of severe drought stress effects in regular monitoring programs.}
}
@article{FANG2025105264,
title = {Understanding the gender divide in digital literacy in four European countries: A comprehensive decomposition analysis using unconditional quantile regression},
journal = {Computers & Education},
volume = {229},
pages = {105264},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105264},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525000326},
author = {Guangbao Fang and Jiaxin Wang and Philip Wing Keung Chan and Penelope Kalogeropoulos},
keywords = {Gender divide, Computer and information literacy, Computational thinking, Oaxaca-Blinder decomposition, Unconditional quantile regression decomposition},
abstract = {Digital literacy is crucial for adolescents’ future, yet significant gender divides persist, particularly in Computer and Information Literacy (CIL) and Computational Thinking (CT). This study examines the gender divide in CIL and CT among adolescents in four European countries, highlighting the gender-based disparities in digital literacy development. Based on ICILS 2018 data, this research identifies factors contributing to gender divides in CIL and CT using regression and decomposition methods. Findings indicate that females outperform males in CIL, while males excel in CT. Gender divides decrease as the percentiles of students’ proficiency levels increase. The explained portion of the gender divide in CIL and CT is consistently smaller than the unexplained portion across countries, suggesting that gender divide or unobserved factors may drive these divides. A comparison of OLS regression results with decomposition approaches indicates that the factors influencing digital literacy development differ from those contributing to the gender divide. Variation in the factors contributing to gender divides is greater across countries than within countries for both CIL and CT. These findings highlight the need to consider national digital environments and socio-cultural contexts in addressing gender divides in digital literacy. This study offers insights for policymakers and educators to address the gender divide in digital literacy.}
}
@article{ZHONG2025130791,
title = {A comprehensive methodological review of human mobility simulation and modelling: Current trends, challenges, and future directions},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {674},
pages = {130791},
year = {2025},
issn = {0378-4371},
doi = {https://doi.org/10.1016/j.physa.2025.130791},
url = {https://www.sciencedirect.com/science/article/pii/S0378437125004431},
author = {Zhihua Zhong and Hongzeng Zhang and Jun’ichi Ozaki and Yang Zhou and Xinjie Zhao and Daniel Dan and Chaofan Wang},
keywords = {Human mobility simulation and modelling, Transport system, Deep learning, Agent-based model},
abstract = {Human mobility, reflecting the behaviour and movement patterns of individuals or groups in space, presents intricate characteristics and impacts various dimensions of urban life. Having increasingly caught the attention of disciplinary scholars, this field has evolved into a confused mixture of various modelling theories and methodologies, creating challenges in selecting appropriate methods when dealing with data with different structures and applications with varying scales of observation and scenarios. Moreover, disruptive techniques such as big data and artificial intelligence have tremendously revolutionised the traditional research paradigms in human mobility simulation and modelling. To scrutinise the various emerging methods, this study comprehensively reviews state-of-the-art research in the field, particularly focusing on research over the past decades. Here, we holistically collect, classify, and summarise existing methodologies into two categories: data-driven vs. mechanism-driven. These methods are organised following key clues, including modelling focus (aggregated flow vs. individual trajectory), typical application scenarios (regular vs. irregular), and model complexity (simple vs. complex), and are presented chronologically. Notably, deep learning (DL), agent-based model (ABM), and their combinations are emphasised as the most cutting-edge directions. We also reveal the future trends and opportunities for model evolution, transitioning from single-model, single-modality, and single-agent to multi-model, multi-modality, and multi-agent systems. Meanwhile, challenges in data ethics and bias, and models’ scalability, predictability, interpretability, and verifiability should be addressed in the future. The discoveries will serve as a reference for scholars and practitioners in the field, contributing to a systematic methodological framework that clarifies the complex research landscape and establishes a baseline for future model development.}
}
@article{XIE2024123022,
title = {A joint learning method with consistency-aware for low-resolution facial expression recognition},
journal = {Expert Systems with Applications},
volume = {244},
pages = {123022},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.123022},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423035248},
author = {Yuanlun Xie and Wenhong Tian and Liang Song and Ruini Xue and Zhiyuan Zha and Bihan Wen},
keywords = {Facial expression recognition, Image super-resolution, Deep learning, High-level vision task},
abstract = {Existing facial expression recognition (FER) methods are mainly devoted to learning discriminative features from high-resolution images. However, when applied to low-resolution images, their performance drops rapidly. This paper proposes a unified learning framework (namely SR-FER) by cascading the image super-resolution (SR) task and FER task to alleviate the low-resolution challenge. It effectively feeds back expression-related information from the FER network to the SR network, and returns the quality-enhanced expression images via a SR network. Specifically, a multi-stage attention-aware consistency loss module is introduced to help the SR network achieve discriminative feature restoration guided by attention information. Furthermore, a prediction consistency loss module is also developed to encourage the SR network to restore discriminative features by reducing the difference in prediction information between the restored and original normal-resolution images. Therefore, more accurate results are obtained by performing FER on the restored images. We conduct extensive experiments to demonstrate that the proposed low-resolution FER solution can help SR methods restore features favorable for FER while maintaining acceptable FER performance in various resolution degradation scenarios. The proposed method effectively improves the FER challenge under resolution degradation conditions, which is of good reference value for real-world applications.}
}
@article{KSHETRI2024101931,
title = {Metaverse for advancing government: Prospects, challenges and a research agenda},
journal = {Government Information Quarterly},
volume = {41},
number = {2},
pages = {101931},
year = {2024},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2024.101931},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X24000236},
author = {Nir Kshetri and Yogesh K. Dwivedi and Marijn Janssen},
keywords = {Augmented reality, Digital avatars, Electronic government, Digital government, Metaverse, Cityverse, Virtual reality},
abstract = {A number of government agencies have started deploying the Metaverse to connect better with their constituents. The Metaverse provides a rich interaction environment and has the potential to engage with, especially, the younger generation. However, the Metaverse's potential impact on the government sector has been given limited attention. This discussion paper aims to fill this void by reviewing the state of the art, analyzing possible roles of the Metaverse for governments and providing research directions. We found six facilitators and nine barriers and risks. The Metaverse offers much more than a virtual presence or copy of the physical world; significant transformations are needed in government to reap the benefits. Given the evolution of the Metaverse, government presence also needs to evolve, and different governments make different decisions about their Metaverse presence. We recommend more research into the nature, use, applications, transformations, and implications of the Metaverse on government functioning.}
}
@article{NGUYEN2024112059,
title = {GPTSniffer: A CodeBERT-based classifier to detect source code written by ChatGPT},
journal = {Journal of Systems and Software},
volume = {214},
pages = {112059},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112059},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224001043},
author = {Phuong T. Nguyen and Juri {Di Rocco} and Claudio {Di Sipio} and Riccardo Rubei and Davide {Di Ruscio} and Massimiliano {Di Penta}},
keywords = {ChatGPT, Code classification, CodeBERT, Pre-trained Models},
abstract = {Since its launch in November 2022, ChatGPT has gained popularity among users, especially programmers who use it to solve development issues. However, while offering a practical solution to programming problems, ChatGPT should be used primarily as a supporting tool (e.g., in software education) rather than as a replacement for humans. Thus, detecting automatically generated source code by ChatGPT is necessary, and tools for identifying AI-generated content need to be adapted to work effectively with code. This paper presents GPTSniffer– a novel approach to the detection of source code written by AI – built on top of CodeBERT. We conducted an empirical study to investigate the feasibility of automated identification of AI-generated code, and the factors that influence this ability. The results show that GPTSniffer can accurately classify whether code is human-written or AI-generated, outperforming two baselines, GPTZero and OpenAI Text Classifier. Also, the study shows how similar training data or a classification context with paired snippets helps boost the prediction. We conclude that GPTSniffer can be leveraged in different contexts, e.g., in software engineering education, where teachers use the tool to detect cheating and plagiarism, or in development, where AI-generated code may require peculiar quality assurance activities.}
}
@article{WANG2024104004,
title = {Travel photography is important to me! The impact of merchants' photo editing behavior on destination clothes rental intention},
journal = {Journal of Retailing and Consumer Services},
volume = {81},
pages = {104004},
year = {2024},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2024.104004},
url = {https://www.sciencedirect.com/science/article/pii/S096969892400300X},
author = {Yuchen Wang and Rui Guo},
keywords = {Travel photography, Photo editing, Clothes rental intention, Social comparison, Destination marketing},
abstract = {The rise of travel selfies has fueled the development of destination clothes rental programs, yet there is scant research on this phenomenon. Therefore, this study, grounded in social comparison theory, constructs a model of the complex influence mechanism of merchants' photo editing behavior on tourist clothes rental intention. By employing a mixed-method approach that includes grounded theory and scenario experiments, this study verifies the proposed mechanism. The findings are as follows: first, finely editing photos, as opposed to roughly editing ones, are more likely to inspire tourist clothes rental intention. Second, the differential impact of photo editing behavior on tourist clothes rental intention is less pronounced in arriving at tourism destinations than in social media contexts. Third, cultural factors and individual differences, such as collectivism, face consciousness, and social comparison orientation, moderate the main effects. Fourth, considering tourists' comparative mindset, finely editing photos, compared to roughly editing ones, are more likely to stimulate state appearance comparison, leading to varying degrees of mutability, and ultimately affecting clothes rental intentions. This study contributes to the understanding of how photo editing influences tourist project participation behavior, providing valuable insights for marketers in the destination clothing rental industry.}
}
@article{YAN2025101729,
title = {Scientometric analysis of emerging trends and research landscape of ERNIE Bot's potentials as an educational tool: A mixed method study of a large language model},
journal = {Social Sciences & Humanities Open},
volume = {12},
pages = {101729},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101729},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125004577},
author = {Yang Yan and Bosede Iyiade Edwards and Mageswaran Sanmugam},
keywords = {Generative AI, AI in education, Scientometric analysis, Bibliometric analysis, ERNIE Bot, PRISMA model},
abstract = {This paper presents findings from a mixed-method analysis of a generative AI tool, ERNIE Bot's research status and role in education based on research from 2019–May 2025. Leveraging scientometric analysis, the study explored a combination of bibliometric and discourse analyses to uncover trends and language use. Using the PRISMA model, 147 publications from Scopus database were analyzed and insights from CiteSpace and VOSviewer were combined with thematic analysis. Findings indicate that Chinese researchers, and China-based funding bodies are the most prominent in ERNIE-bot-related research with all the top 5 countries concentrated in the global north. Top themes include ‘Natural Language Model’, ‘Semantics’, and ‘Human’. Topmost publishers were Applied Sciences (Switzerland), IEEE Access and PLOS ONE with top average citations by Sensors (12.67 citations/publication). The study confirms Bradford and Price laws. ERNIE Bot's application in education has attracted notable attention, with 22.4 % of the analyzed studies focusing on this area, highlighting its strong potential in personalized learning and human-computer interaction. Findings from discourse analysis shows that it’s Chinese origin is often framed as a symbol of contextual leadership and basis for positioning ERNIE Bot as a key player in China's technological competition with global models like ChatGPT. ERNIE Bot's strengths in Chinese language processing and innovations are also highlighted regarding power relations and knowledge hierarchies. However, ERNIE Bot lags global counterparts in overall competitiveness; limitations in data diversity, political censorship, and accessibility further restricts its global applicability. Future research should explore ERNIE Bot's knowledge base, its educational potentials, especially in adaptive learning systems and the significance of contextual leadership as an educational technology.}
}
@article{CHAN2025112330,
title = {Effectiveness of symmetric metamorphic relations on validating the stability of code generation LLM},
journal = {Journal of Systems and Software},
volume = {222},
pages = {112330},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112330},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224003741},
author = {Pak Yuen Patrick Chan and Jacky Keung and Zhen Yang},
keywords = {Metamorphic testing, Metamorphic relation, True satisfaction, Large language model, Code generation},
abstract = {Pre-trained large language models (LLMs) are increasingly used in software development for code generation, with a preference for private LLMs over public ones to avoid the risk of exposing corporate secrets. Validating the stability of these LLMs’ outputs is crucial, and our study proposes using symmetric Metamorphic Relations (MRs) from Metamorphic Testing (MT) for this purpose. Our study involved an empirical experiment with ten LLMs (eight private and two public) and two publicly available datasets. We defined seven symmetric MRs to generate “Follow-up” datasets from “Source” datasets for testing. Our evaluation aimed to detect violations (inconsistent predictions) between “Source” and “Follow-up” datasets and assess the effectiveness of MRs in identifying correct and incorrect non-violated predictions from ground truths. Results showed that one public and four private LLMs did not violate “Case transformation of prompts” MR. Furthermore, effectiveness and performance results indicated that proposed MRs are effective tools for explaining the instability of LLM's outputs by “Case transformation of prompts”, “Duplication of prompts”, and “Paraphrasing of prompts”. The study underscored the importance of enhancing LLMs’ semantic understanding of prompts for better stability and highlighted potential future research directions, including exploring different MRs, enhancing semantic understanding, and applying symmetry to prompt engineering.}
}
@article{WANG2023109593,
title = {Verifying empirical predictive modeling of societal vulnerability to hazardous events: A Monte Carlo experimental approach},
journal = {Reliability Engineering & System Safety},
volume = {240},
pages = {109593},
year = {2023},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2023.109593},
url = {https://www.sciencedirect.com/science/article/pii/S0951832023005070},
author = {Yi Victor Wang and Seung Hee Kim and Menas C. Kafatos},
keywords = {Hazard loss, Machine learning, Simulation, Social vulnerability, Societal system},
abstract = {With the emergence of large amounts of historical records on adverse impacts of hazardous events, empirical predictive modeling has been revived as a foundational paradigm for quantifying disaster vulnerability of societal systems. This paradigm models societal vulnerability to hazardous events as a vulnerability curve indicating an expected loss rate of a societal system with respect to a possible spectrum of intensity measure (IM) of an event. Although the empirical predictive models (EPMs) of societal vulnerability are calibrated on historical data, they should not be experimentally tested with data derived from field experiments on any societal system. Alternatively, in this paper, we propose a Monte Carlo simulation-based approach to experimentally test EPMs of societal vulnerability. Our study applied an eigenvalue-based method to generate data on societal experiences of IM and pre-event vulnerability indicators. True models were designed to simulate event loss data. Supervised machine learning (ML) models were then trained on simulated data and were found to provide similar predictive performances as the true models. Our results suggested that the calibrated ML-EPMs could effectively quantify societal vulnerability given a normally experienced IM. To extrapolate a vulnerability curve for large IMs, however, simple models should be preferred.}
}
@article{TAO2024361,
title = {Research of Preventive Maintenance Plans for Wind Power Equipment Based on Maintenance Knowledge Fusion Large Model},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {29},
pages = {361-366},
year = {2024},
note = {7th IFAC Conference on Engine and Powertrain Control, Simulation and Modeling E-COSM 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.11.171},
url = {https://www.sciencedirect.com/science/article/pii/S2405896324023127},
author = {Laifa Tao and Shangyu Li and Qixuan Huang and Zhengduo Zhao and Xuanyuan Su and Kaixin Jin},
keywords = {Fault prediction and health management, Wind power equipment, Large language models, Preventive maintenance, Supervised fine-tuning, Prompt learning},
abstract = {As an important energy equipment, wind power equipment have a wide range of applications worldwide. But its high equipment maintenance costs seriously affect the profits of wind power generation enterprises. Fault prediction and health management technology, as key technologies for optimizing maintenance methods and reducing maintenance costs, are of great significance for reduce the failure rate of wind power equipment, reduce maintenance costs, and promote the rapid development of the clean energy industry to generate excellent preventive maintenance plans for wind power equipment. However, the current development of wind power equipment maintenance plans heavily relies on expert experience and lacks reliable explanatory support. In this case, we propose a preventive maintenance plan generation method for wind power equipment based on maintenance knowledge fusion large model. Our solution generation process no longer relies on expert experience, but relies on the reasoning ability of the latest artificial intelligence technology large language model. We fine tune the pretrained base large model using data and knowledge from wind power equipment fault manuals and maintenance manuals, and design reasonable question and answer prompts to achieve intelligent generation of wind power equipment preventive maintenance plans. Finally, the effectiveness of the above method was verified through the manual materials of UP77 and UP82 fan equipment.}
}
@article{DENG2025127500,
title = {Research on intelligent prediction method of supersonic flow field in scramjet based on deep learning: A review},
journal = {Expert Systems with Applications},
volume = {279},
pages = {127500},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.127500},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425011224},
author = {Xue Deng and Ye Tian and Erda Chen and Maotao Yang and Hua Zhang and Jialing Le},
keywords = {Deep learning, Flow field prediction, Model lightweight, Physical constraints, Scramjet},
abstract = {Direct numerical simulation (DNS) serves as a crucial method for optimizing and validating scramjets, significantly advancing their design process. Nonetheless, solving the Navier-Stokes equations numerically entails substantial computational expenses, particularly for large-scale projects characterized by intricate hysteresis and high-precision thermochemical reactions. In recent years, numerous studies have demonstrated the rationality and efficacy of deep learning in reconstructing the evolutionary characteristics of flow fields. To reduce neural network models’ dependence on high-fidelity data and prevent the generation of non-physical solutions, neural networks incorporating physical information constraints offer a novel learning paradigm. This approach encodes prior knowledge and physical interpretability, which traditional neural networks lack. Based on this, this study investigates, analyzes, and summarizes traditional prediction methods for supersonic combustion flow, data-driven intelligent solution algorithms for supersonic flow fields, lightweight neural network models, and intelligent prediction algorithms for flow fields using physical information neural networks.}
}
@article{ERRAZURIZ2025101057,
title = {Prevalence of anxiety disorders in Latin America: a systematic review and meta-analysis},
journal = {The Lancet Regional Health - Americas},
volume = {45},
pages = {101057},
year = {2025},
issn = {2667-193X},
doi = {https://doi.org/10.1016/j.lana.2025.101057},
url = {https://www.sciencedirect.com/science/article/pii/S2667193X25000675},
author = {Antonia Errazuriz and Dalia Avello-Vega and Alvaro Passi-Solar and Rafael Torres and Felix Bacigalupo and Nicolas A. Crossley and Eduardo A. Undurraga and Peter B. Jones},
keywords = {Anxiety disorders, Prevalence, Latin America, Systematic review, Meta-analysis, Global mental health},
abstract = {Summary
Background
The prevalence of anxiety disorders among the adult population in Latin America (LATAM) and its association with development indicators is insufficiently characterised. We estimated pooled regional, country, and sex-specific prevalence rates of anxiety disorders in LATAM based on International Classification of Diseases (ICD) or Diagnostic and Statistical Manual of Mental Disorders (DSM) criteria. Additionally, we examined the association between its prevalence and four country-level development indicators: Human Development Index (HDI), income inequality (Gini coefficient), Gender Inequality Index (GII), and Intentional Homicide Rate (IHR).
Methods
We conducted a systematic review and meta-analysis of population-based studies on the prevalence of ICD/DSM anxiety disorders in LATAM from 1990 to 2024, irrespective of language. We searched PubMed, PsycINFO, Cochrane Library, SciELO, LILACS, and grey literature. Study quality was assessed using JBI's critical appraisal tools. Pooled estimates were generated using random-effects meta-analysis, and heterogeneity was evaluated using the I-squared (I2) statistic. Meta-regression analyses were performed to examine the ecological association between anxiety disorders prevalence and four development indicators. The study was registered with PROSPERO (CRD42020190238).
Findings
Using data from 36 studies in LATAM, we calculated the lifetime, 12-month, and current prevalence of ICD/DSM anxiety disorders at 14.55% (95% Confidence Interval 12.32%–17.11%; I2 = 97.9%); 6.61% (5.20–8.37; I2 = 98.1%), and 3.27% (2.34–4.56; I2 = 97.5%), respectively. Heterogeneity was high across prevalence periods, sexes, and countries (all I2 ≥ 91.4%), warranting caution in interpreting pooled estimates. Elevated 12-month and current prevalence rates of anxiety disorders were associated with higher Gini coefficients (p ≤ 0.0013). Additionally, higher current prevalence was associated with lower HDI (p = 0.0103) and higher GII (p = 0.0023), while elevated 12-month prevalence was associated with higher IHR (p = 0.011).
Interpretation
This study shows that approximately one in seven people in LATAM experience anxiety disorders at some point in their lives. These findings highlight the need to strengthen mental health systems in the region, and evidence the association between prevalence of anxiety disorders and development indicators. Our results can serve as a baseline for tracking anxiety disorders and for informed decision-making at the national and regional levels. The substantial heterogeneity between studies and the underrepresentation of some countries underscore the imperative for enhancing regional mental health capacities.
Funding
Pfizer Independent Medical Education Grant (69879319).}
}
@article{ROWE2025101474,
title = {Integrating computational and experimental advances in bone multiscale mechanics},
journal = {Progress in Materials Science},
volume = {153},
pages = {101474},
year = {2025},
issn = {0079-6425},
doi = {https://doi.org/10.1016/j.pmatsci.2025.101474},
url = {https://www.sciencedirect.com/science/article/pii/S0079642525000490},
author = {James Rowe and Sabrina Shen and Amadeus C.S. {de Alcântara} and Munir S. Skaf and Daniele Dini and Nicholas M. Harrison and Ulrich Hansen and Markus J. Buehler and Richard L. Abel},
abstract = {Decades of bone research have revealed the intricate hierarchical structures in bone, from the nanoscale building blocks of collagen and mineral to the complex micro-architecture and macro-geometry. Multiscale architecture confers bones their incredible toughness and strength that enables us to move through our daily lives. However, childhood and adult diseases can cause bone fragility and subsequent fractures, leading to disability, and mortality. A foundational understanding of bone mechanics across disparate scales is critical to improve the diagnosis and management of such diseases. At present, we have limited knowledge of how macroscale deformations that occur during everyday movement are transferred down to the nanoscale in order to resist fracture, especially due to historic limitations in measuring nanoscale mechanics experimentally. Recent advances in both experimental and computational tools are equipping researchers to probe the nanoscale for the first time. Here we provide a timely review of existing and next-generation experimental and computational tools and offer new perspectives on how to leverage the strengths of each approach to overcome the limitations of others. We focus on bone structure ranging from atomistic phenomena to microscale mineralized fibril interactions to build a bottom-up understanding of continuum bone mechanics and accelerate research towards impactful clinical translation.}
}
@article{JACOB2025,
title = {AI for IMPACTS Framework for Evaluating the Long-Term Real-World Impacts of AI-Powered Clinician Tools: Systematic Review and Narrative Synthesis},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/67485},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125001797},
author = {Christine Jacob and Noé Brasier and Emanuele Laurenzi and Sabina Heuss and Stavroula-Georgia Mougiakakou and Arzu Cöltekin and Marc K Peter},
keywords = {eHealth, assessment, adoption, implementation, artificial intelligence, clinician, efficiency, health technology assessment, clinical practice},
abstract = {Background
Artificial intelligence (AI) has the potential to revolutionize health care by enhancing both clinical outcomes and operational efficiency. However, its clinical adoption has been slower than anticipated, largely due to the absence of comprehensive evaluation frameworks. Existing frameworks remain insufficient and tend to emphasize technical metrics such as accuracy and validation, while overlooking critical real-world factors such as clinical impact, integration, and economic sustainability. This narrow focus prevents AI tools from being effectively implemented, limiting their broader impact and long-term viability in clinical practice.
Objective
This study aimed to create a framework for assessing AI in health care, extending beyond technical metrics to incorporate social and organizational dimensions. The framework was developed by systematically reviewing, analyzing, and synthesizing the evaluation criteria necessary for successful implementation, focusing on the long-term real-world impact of AI in clinical practice.
Methods
A search was performed in July 2024 across the PubMed, Cochrane, Scopus, and IEEE Xplore databases to identify relevant studies published in English between January 2019 and mid-July 2024, yielding 3528 results, among which 44 studies met the inclusion criteria. The systematic review followed PRISMA (Preferred Reporting Items for Systematic reviews and Meta-Analyses) guidelines and the Cochrane Handbook for Systematic Reviews. Data were analyzed using NVivo through thematic analysis and narrative synthesis to identify key emergent themes in the studies.
Results
By synthesizing the included studies, we developed a framework that goes beyond the traditional focus on technical metrics or study-level methodologies. It integrates clinical context and real-world implementation factors, offering a more comprehensive approach to evaluating AI tools. With our focus on assessing the long-term real-world impact of AI technologies in health care, we named the framework AI for IMPACTS. The criteria are organized into seven key clusters, each corresponding to a letter in the acronym: (1) I—integration, interoperability, and workflow; (2) M—monitoring, governance, and accountability; (3) P—performance and quality metrics; (4) A—acceptability, trust, and training; (5) C—cost and economic evaluation; (6) T—technological safety and transparency; and (7) S—scalability and impact. These are further broken down into 28 specific subcriteria.
Conclusions
The AI for IMPACTS framework offers a holistic approach to evaluate the long-term real-world impact of AI tools in the heterogeneous and challenging health care context and lays the groundwork for further validation through expert consensus and testing of the framework in real-world health care settings. It is important to emphasize that multidisciplinary expertise is essential for assessment, yet many assessors lack the necessary training. In addition, traditional evaluation methods struggle to keep pace with AI’s rapid development. To ensure successful AI integration, flexible, fast-tracked assessment processes and proper assessor training are needed to maintain rigorous standards while adapting to AI’s dynamic evolution.
Trial Registration
reviewregistry1859; https://tinyurl.com/ysn2d7sh}
}
@article{LASTAUSKAS2024106918,
title = {Labor market policies in high- and low-interest rate environments: Evidence from the euro area},
journal = {Economic Modelling},
volume = {141},
pages = {106918},
year = {2024},
issn = {0264-9993},
doi = {https://doi.org/10.1016/j.econmod.2024.106918},
url = {https://www.sciencedirect.com/science/article/pii/S026499932400275X},
author = {Povilas Lastauskas and Julius Stakėnas},
keywords = {Labor market policies, Non-linear responses, Mallow’s  criterion, Average local projections, Low and high interest rate environments},
abstract = {Do labor market policies initiated in periods of loose monetary policy yield different outcomes from those introduced when monetary tightening prevails? Using data from 11 euro-area members up to 2010 – and extending to 17 countries up to 2020 – we analyze three labor market policies: replacement rates, spending on active labor market policies (ALMPs), and employment protection. We find that these policies deliver different macroeconomic outcomes in low- and high-interest rate environments. In particular, ALMPs reduce unemployment if implemented under a loose monetary policy but not otherwise, whereas higher employment protection delivers expansionary effects under a tight monetary policy. These findings highlight that the effectiveness of labor market policies is significantly influenced by the monetary policy environment, emphasizing the need for coordinated policy design. Methodologically, we contribute by proposing to average local projections using Mallow’s Cp criterion, allowing for inferences that are robust to mis-specification and accommodate non-linearities.}
}
@article{HASAN2025,
title = {Mushrooms as Potent Autophagy Modulators in Cancer Therapy: Current Evidence and Therapeutic Prospects},
journal = {Cancer Pathogenesis and Therapy},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2025.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S2949713225000916},
author = {Md.Mahmudul Hasan and Eva Azme and Rashedul Alam and Md.Jahirul Islam Mamun and Md.Tanvir Chowdhury and Md.Hossain Rasel and Md.Safayat Hossen Momen and Neamul Hoque and Md.Ekramul Haque Ekram and Nazmul Hasan Eshaque and Shakil Ahmed and Md.Tashrif Rahman Tipu and Sanjida Shahid Juthi and Mohammad Fazlul Kabir and Ahsan Ullah and Md.Liakot Ali and S.M.Moazzem Hossen and Hea-Jong Chung},
keywords = {Mushroom, autophagy, cancer, traditional medicine, functional food, Endoplasmic reticulum stress},
abstract = {Mushrooms, recognized for their culinary and medicinal applications, are emerging as potential sources of autophagy modulators in cancer treatment. Autophagy is cellular degradation triggered by organelle damage, protein aggregation, metabolic disturbances, or nutrient scarcity. It contributes to the suppression of early tumor development and the promotion of cancer cell survival at advanced stages. This review systematically assesses the current evidence on the anticancer potential of mushrooms and their bioactive compounds, focusing on their ability to modulate autophagy. The review lists over 18 mushroom species (e.g., Ganoderma lucidum, Cordyceps, Phellinus) and 28 bioactive compounds (such as Ganoderic acid DM, Cordycepin, Hispidin) that affect autophagy, demonstrating efficacy against 15 cancer types, including colorectal, lung, breast, and liver cancers. Essential compounds modulate autophagy through phosphoinositide 3-kinase (PI3K)/protein kinase B (Akt)/mechanistic target of rapamycin (mTOR), AMP-activated protein kinase (AMPK), and Beclin-1 pathways, resulting in notable anticancer effects. G. lucidum extracts quantitatively reduced colorectal tumor growth by up to 60% in vivo. Additionally, Cordycepin induced autophagic cell death in lung cancer cells, with IC50 values as low as 25 μmol/L.The findings highlight the potential of mushrooms as low-toxicity adjuvants to conventional therapies, providing advantages such as immune modulation and antioxidant activity. Mushrooms and their bioactive components present promising avenues for cancer therapy through the modulation of autophagy. The context-dependent effects of autophagy, along with the limited clinical evidence, present considerable challenges. Future clinical trials must focus on developing standardized extracts and personalized approaches to effectively translate this potential into clinical practice.}
}
@article{SPRUTE2025101609,
title = {Land use and land cover classification on high-resolution UAV images for heavy rainfall hazard maps using deep neural networks},
journal = {Remote Sensing Applications: Society and Environment},
volume = {38},
pages = {101609},
year = {2025},
issn = {2352-9385},
doi = {https://doi.org/10.1016/j.rsase.2025.101609},
url = {https://www.sciencedirect.com/science/article/pii/S2352938525001624},
author = {Dennis Sprute and Hanne Hendrickx and Pedro Zamboni and Muhtasimul Islam Rushdi and Florian Brodrecht and Anette Eltner and Holger Flatt},
keywords = {Land use/cover classification, UAV, RGB images, Heavy rainfall hazard maps, Semantic segmentation, Deep neural networks},
abstract = {The increasing frequency and intensity of extreme weather events due to climate change highlight the need for accurate hazard mapping for heavy rainfall. Land use and land cover (LULC) maps, along with digital elevation models (DEMs) and meteorological data, are essential to construct these hazard maps. For this purpose, LULC maps must be of high resolution to capture small hydrodynamically relevant structures and up-to-date to reflect constant changes driven by human activities. Uncrewed aerial vehicles (UAVs) are ideal for acquiring these high-resolution images because of their cost effectiveness, flexibility, and detail. However, no publicly available datasets and approaches currently provide urban LULC maps at this level of detail (<5 cm) while considering classes relevant for constructing heavy rainfall hazard maps. Therefore, this article presents a novel approach for LULC classification using high-resolution UAV imagery to enhance the generation of heavy rainfall hazard maps. We develop a comprehensive processing pipeline that includes UAV data collection, orthophoto creation, and LULC classification using advanced deep learning architectures. Our method tackles challenges such as differing between 22 LULC classes with objects of varying sizes and managing imbalanced datasets. Additionally, we create a high-resolution UAV image dataset with more than 12K annotated images. A comprehensive evaluation of 29 deep learning architectures reveals that CFNet with an EfficientNetB4 backbone achieves the best performance, with an accuracy of 0.911 and a Mean Intersection over Union (IoU) of 0.738. The results demonstrate that our approach effectively classifies hydrodynamically relevant structures, such as different roof types, street materials, and drainage facilities. This work establishes a solid foundation for future research and practical applications in the automated generation of accurate heavy rainfall hazard maps, ultimately aiming to improve risk management strategies in the context of climate change.}
}
@article{SHONUBI2025100971,
title = {Innovation challenges of digital transformation: Transitioning legacy to the future},
journal = {Sustainable Futures},
volume = {10},
pages = {100971},
year = {2025},
issn = {2666-1888},
doi = {https://doi.org/10.1016/j.sftr.2025.100971},
url = {https://www.sciencedirect.com/science/article/pii/S2666188825005350},
author = {Ololade A. Shonubi},
keywords = {Digital transformation, Innovation challenges, Legacy systems, Emerging digital technologies, Organisational innovation, Process innovation, Product innovation, Service innovation, Asia, Africa, AI, IOT, I4.0, Data Analytics, Cloud Computing},
abstract = {Considering rapid technological advancement and global competitive pressures, organisations are seeking alternatives to traditional business models through digital transformation initiatives. Legacy systems were not isolated from this change, where reliance on emerging technologies such as AI has become imperative for organisational survival. A related challenge is "innovation integration", which refers to the simultaneous adoption of organisational innovation, process innovation, and product/service innovation during digital transitions. Accordingly, this research examines innovation challenges faced by enterprises transitioning from legacy systems to digital futures by empirically testing relationships between emerging technology integration and multiple innovation types across Asian and African contexts using structural equation modelling with quantitative data from managers across two continents. Emerging technology integration demonstrated significant positive relationships with organisational innovation, process innovation, and product/service innovation across both continents. Regional variations influenced innovation capabilities, with African enterprises showing superior process innovation adaptability despite digital infrastructure limitations. Gender differences significantly impacted product and service innovation perceptions amongst managers. Results contribute to academia by enriching digital transformation and innovation management research in emerging economies. Findings contribute to policy and practice by providing strategic insights to enterprise leaders, policymakers, and technology developers regarding innovation strategy, digital capability development, and resource allocation for organisations navigating complex digital transformation challenges whilst leveraging regional innovation strengths and competitive advantages.}
}
@article{LIU2025120968,
title = {Intelligent decision and planning for unmanned surface vehicle: A review of machine learning techniques},
journal = {Ocean Engineering},
volume = {327},
pages = {120968},
year = {2025},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2025.120968},
url = {https://www.sciencedirect.com/science/article/pii/S002980182500681X},
author = {Zongyang Liu and Qin Zhang and Xianbo Xiang and Shaolong Yang and Yi Huang and Yanji Zhu},
keywords = {USV, Machine learning, Mission planning, Dynamic decision, Path planning},
abstract = {With the increasing demand for unmanned surface vehicles (USVs) in fields such as marine environmental monitoring, resource exploration, and emergency rescue, the development of intelligent decision and planning technologies has become critical. However, the complexity and dynamic nature of marine environments pose significant challenges to traditional methods in practical applications. In recent years, the rapid advancement of machine learning (ML) has offered novel solutions for the intelligent decision and planning of USVs. This paper systematically reviews the research progress in USV decision and planning based on ML. First, it reviews the classification of USV autonomy levels and the historical development of ML in unmanned marine systems. Then, the paper proposes and elaborates on the “ML-MDP” framework (a ML-based Mission planning, Dynamic decision, and Path planning framework) for USVs, analyzing the latest research outcomes in these areas and explores the suitability of various ML algorithms in addressing these challenges. Finally, the paper analyzes the challenges faced by ML in USV applications and its future development directions. This review aims to provide a valuable reference for researchers in related fields, highlighting the potential of ML in marine unmanned systems and promoting advancements in USV intelligence.}
}
@article{ZHU2024110268,
title = {Threshold-based earthquake early warning for high-speed railways using deep learning},
journal = {Reliability Engineering & System Safety},
volume = {250},
pages = {110268},
year = {2024},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2024.110268},
url = {https://www.sciencedirect.com/science/article/pii/S0951832024003405},
author = {Jingbao Zhu and Wentao Sun and Shanyou Li and Kunpeng Yao and Jindong Song},
keywords = {Earthquake early warning, High-speed railway, Deep learning, Magnitude, Peak ground acceleration, Accuracy of alert},
abstract = {Earthquakes are disasters that threaten the operational safety of high-speed railways. To obtain reliable alerts for the earthquake monitoring and early warning systems of high-speed railways, based on magnitude and peak ground acceleration (PGA) thresholds (M = 5.5 and PGA = 40 cm/s2), an earthquake early warning (EEW) method for high-speed railways using deep learning is proposed. And the application of deep learning method in EEW for high-speed railway is explored. We design a single-station deep learning network architecture (named the CT architecture) by combining convolutional neural and transformer networks, and with that architecture, we train two separate models (CT-M and CT-PGA models) using the strong motion data recorded from the Kyoshin Network in Japan, which are used to predict whether the magnitude and PGA exceed the thresholds for issuing an alert. To verify the robustness of the method, we apply it to the M7.3 earthquake and M7.4 earthquake off the coast of Fukushima in 2021–2022. Results show that within 10 s after P-wave arrival, the accuracy of the alert reaches 90 %, and the average observed lead time reaches 18 s. The proposed method displays potential application on EEW systems for high-speed railways.}
}
@article{BAABDULLAH2024122951,
title = {Generative conversational AI agent for managerial practices: The role of IQ dimensions, novelty seeking and ethical concerns},
journal = {Technological Forecasting and Social Change},
volume = {198},
pages = {122951},
year = {2024},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2023.122951},
url = {https://www.sciencedirect.com/science/article/pii/S0040162523006364},
author = {Abdullah M. Baabdullah},
keywords = {Generative conversational AI agent, Information quality, Novelty seeking, Ethical concerns, Decision-making efficiency, Innovation performance},
abstract = {This study aims to identify and empirically examine the influence of the main factors related to the content quality of generative conversational AI agents on decision-making efficiency. Additionally, this study explores the ramifications of decision-making efficiency facilitated by generative conversational AI agents in organisational innovation performance. This study proposes a model based on the information quality model as well as other factors, such as novelty seeking and ethical concerns. Data from this study was collected using online questionnaires from a purposive sample size of 228 employees in business organisations. Based on Structural Equation Modelling (SEM) analyses using AMOS, the results support the significant impact of information quality (intrinsic information quality, contextual information quality, representational information quality, and accessibility of information quality) on decision-making efficiency. The results also support the significant impact of novelty seeking and ethical concerns on decision-making efficiency. Decision-making efficiency was also found to have a significant positive impact on innovation performance. This empirical study makes a considerable contribution as it is among the first to expand the current understanding of the effective use of generative conversational AI agents in managerial practices (i.e. decision-making and innovation).}
}
@article{JENKINSON2024114908,
title = {Pizza3: A general simulation framework to simulate food-mechanical and food-deconstruction problems},
journal = {Food Research International},
volume = {194},
pages = {114908},
year = {2024},
issn = {0963-9969},
doi = {https://doi.org/10.1016/j.foodres.2024.114908},
url = {https://www.sciencedirect.com/science/article/pii/S0963996924009785},
author = {William Jenkinson and Brian Guthrie and Denis Flick and Olivier Vitrac},
keywords = {Food Micromechanics, Hybrid numerical simulation, Smoothed Particle Hydrodynamics, Molecular Dynamics-like simulation, LAMMPS, Oral processing, Texture Perception, Mesoscopic modeling, Soft matter, Granular flow},
abstract = {Current mesh-based simulation approaches face significant challenges in continuously modeling the mechanical behaviors of foods through processing, storage, deconstruction, and digestion. This is primarily due to the limitations of continuum mechanics in dealing with systems characterized by free boundaries, substantial deformations, mechanical failures, and non–homogenized mechanical properties. The dynamic nature of food microstructure and the transformation of the food bolus, in relation to its composition, present formidable obstacles in computer-aided food design. In response, the Pizza3 project adopts an innovative methodology, utilizing an explicit microstructural representation to construct and subsequently deconstruct food products in a modular, Lego-like fashion. Central to this simulation approach are “food atoms”, conceptualized from the principles of smoothed particle hydrodynamics. These units are significantly larger than actual atoms but are finely scaled to represent both solid and liquid states of food faithfully. In solid phases, food atoms interact via pairwise forces akin to bond-peridynamic methods, thus extending the capabilities of continuum mechanics to encompass large deformations and fracturing phenomena. For liquids, the model employs artificial conservative and dissipative forces, enabling the simulation of a variety of phenomena within the framework of partial compressibility. The interaction dynamics between rigid and soft objects and fluids are accurately captured through Hertzian contact mechanics, offering a versatile parameterization applicable to impermeable (but possibly penetrable) surfaces and enforcing no-slip conditions. The efficacy of this framework is showcased through the successful modeling of three time-dependent 3D scenarios, each rigorously validated against established analytical and experimental models. Advancing beyond these initial applications, the framework is further extended to more intricate cases inadequately addressed in current literature. This extension sheds light on the underlying mechanisms of in-mouth texture perception, offering new insights and tools for food engineering and design.}
}
@article{NANDI2023123550,
title = {Development of long-acting injectable suspensions by continuous antisolvent crystallization: An integrated bottom-up process},
journal = {International Journal of Pharmaceutics},
volume = {648},
pages = {123550},
year = {2023},
issn = {0378-5173},
doi = {https://doi.org/10.1016/j.ijpharm.2023.123550},
url = {https://www.sciencedirect.com/science/article/pii/S0378517323009717},
author = {Snehashis Nandi and Luis Padrela and Lidia Tajber and Alain Collas},
keywords = {Itraconazole, Microsuspension, Continuous antisolvent crystallization, Microchannel reactor, Dissolution, LAI},
abstract = {Our present work elucidated the operational feasibility of direct generation and stabilization of long-acting injectable (LAI) suspensions of a practically insoluble drug, itraconazole (ITZ), by combining continuous liquid antisolvent crystallization with downstream processing (i.e., centrifugal filtration and reconstitution). A novel microchannel reactor-based bottom-up crystallization setup was assembled and optimized for the continuous production of micro-suspension. Based upon the solvent screening and solubility study, N-methyl pyrrolidone (NMP) was selected as the optimal solvent and an impinging jet Y-shaped microchannel reactor (MCR) was selected as the fluidic device to provide a reproducible homogenous mixing environment. Operating parameters such as solvent to antisolvent ratio (S/AS), total jet liquid flow rates (TFRs), ITZ feed solution concentration and the maturation time in spiral tubing were tailored to 1:9 v/v, 50 mL/min, 10 g/100 g solution, and 96 h, respectively. Vitamin E TPGS (0.5% w/w) was found to be the most suitable excipient to stabilize ITZ particles amongst 14 commonly used stabilizers screened. The effect of scaling up from 25 mL to 15 L was evaluated effectively with in situ monitoring of particle size distribution (PSD) and solid-state form. Thereafter, the suspension was subjected to centrifugal filtration to remove excess solvent and increase ITZ solid fraction. As an alternative, an even more concentrated wet pellet was reconstituted with an aqueous solution of 0.5% w/w Vitamin E TPGS as resuspending agent. The ITZ LAI suspension (of 300 mg/mL solid concentration) has the optimal PSD with a D10 of 1.1 ± 0.3 µm, a D50 of 3.53 ± 0.4 µm and a D90 of 6.5 ± 0.8 µm, corroborated by scanning electron microscopy (SEM), as remained stable after 548 days of storage at 25 °C. Finally, in vitro release methods using Dialyzer, dialysis membrane sac were investigated for evaluation of dissolution of ITZ LAI suspensions. The framework presented in this manuscript provides a useful guidance for development of LAI suspensions by an integrated bottom-up approach using ITZ as model API.}
}
@article{SILVA2024107698,
title = {Mapping the landscape of energy markets research: A bibliometric analysis and predictive assessment using machine learning},
journal = {Energy Economics},
volume = {136},
pages = {107698},
year = {2024},
issn = {0140-9883},
doi = {https://doi.org/10.1016/j.eneco.2024.107698},
url = {https://www.sciencedirect.com/science/article/pii/S0140988324004067},
author = {Thiago Christiano Silva and Tercio Braz and Benjamin Miranda Tabak},
keywords = {Clean energy, Bibliometrics, Machine learning, Volatility spillover, Energy markets, Crude-oil},
abstract = {This study examines the evolving dynamics of research on the energy market that focuses on understanding its interactions and interdependencies with other markets. Using published articles from 2002 to 2022 indexed by the Web of Science, we employ bibliometric methods, complex network measurements, and machine learning algorithms to analyze trends and predict academic success or interest. Our bibliometric analysis highlights the growing emphasis on new topics, such as clean energy, over traditional energy topics like crude oil and volatility spillovers. In a horse-race setup, we use supervised regression techniques to predict the paper’s academic success, measured in terms of the average number of citations over the years. We use meta-information from the paper, including keywords, as predictive attributes. The Random Forest achieves the best out-of-sample performance. We complement this analysis by using Shapley Additive Explanations to assess the contribution of each attribute to the overall prediction, thus allowing model interpretability. We find non-linear relationships between some numeric attributes, such as the number of keywords in the paper, and the target variable, highlighting the flexibility of non-linear methods compared to linear ones. Our findings offer valuable insights into emerging research trends and provide educators, policymakers, and finance professionals with critical information to navigate the evolving landscape of energy market research.}
}
@article{202584,
title = {Guide for Authors},
journal = {Intelligent Medicine},
volume = {5},
number = {1},
pages = {84-90},
year = {2025},
issn = {2667-1026},
doi = {https://doi.org/10.1016/S2667-1026(25)00007-5},
url = {https://www.sciencedirect.com/science/article/pii/S2667102625000075}
}
@article{WANG2024105965,
title = {Do not go gentle into that good night: The European Union's and China's different approaches to the extraterritorial application of artificial intelligence laws and regulations},
journal = {Computer Law & Security Review},
volume = {53},
pages = {105965},
year = {2024},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2024.105965},
url = {https://www.sciencedirect.com/science/article/pii/S0267364924000323},
author = {Yan Wang},
keywords = {Artificial intelligence, Extraterritorial effects, Global governance},
abstract = {The extraterritorial application of artificial intelligence (AI) laws and regulations is a form of global AI governance. The EU and China serve as two different examples of how to achieve the extraterritorial applicability of AI laws and regulations. The former shows an explicit territorial extension with more trigger factors, whereas the latter shows vertical regulation with a narrower territorial scope. Both countries’ legislative motivations differ but also have some commonalities. One of the primary goals of extraterritorial application of domestic laws is to protect citizens within their territory. The digital economy's characteristics make it necessary for AI laws to have extraterritorial effects. Without international conventions or treaties, there is a legal vacuum in AI regulation. Additionally, the extraterritorial application of AI laws and regulations helps a state become a global standard-setter and gain an international sphere of influence. However, the extraterritorial application of AI laws and regulations sometimes functions as a form of legal imperialism. This exacerbates the injustice between great powers and weak countries in AI competition. To justify the legitimacy of the extraterritorial application of AI laws and regulations, it is beneficial to adopt the ‘inner morality of extraterritoriality’, a theoretical framework proposed by Professor Dan Svantesson. In fact, extraterritorial applicability depends on the market size and attractiveness. For other countries, whether their AI laws and regulations are endowed with extraterritorial effects is their prerogative. However, they should consider their soft power before implementing legislation.}
}
@article{COSCIA2025104397,
title = {APIARY: An API-based automatic rule generator for yara to enhance malware detection},
journal = {Computers & Security},
volume = {153},
pages = {104397},
year = {2025},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2025.104397},
url = {https://www.sciencedirect.com/science/article/pii/S0167404825000860},
author = {Antonio Coscia and Roberto Lorusso and Antonio Maci and Giuseppe Urbano},
keywords = {API, Intrusion detection and prevention, Malware detection, Security tool, YARA rule},
abstract = {Cyber threats, primarily malware, have increased with rapid technological advancements in various fields. This growing complexity requires sophisticated and automated malware detection tools because traditional methods cannot keep up with the sheer volume of threats and their evolution. Detection mechanisms that are resilient against evolved malware behaviors, which are typically described by application programming interface (API) functions, are essential for real-time system protection. This paper presents APIARY, an innovative API-based Automatic Rule generator for the YARA tool, designed to enhance malware identification through customized signatures based on peculiar API-based patterns. It discovers distinctive APIs that distinguish malware from goodware, regardless of input data coming from dynamic and static analyses of Windows-like executable files. The algorithm assigns relevance scores to each variable and discards less significant features to identify critical malware indicators. In addition, the generation process optimizes the identified malware model categories to increase the detection rate while minimizing the number of rules produced. The experimental results obtained on nine datasets sourced from the literature demonstrate the potential of APIARY to automatically produce highly effective YARA rules in a short time. Moreover, the rules generated outperform those obtained using alternative state-of-the-art algorithms in terms of detection performance. Lastly, unlike competitors, the proposed procedure does not rely on additional malware analysis data, such as network connection attempts or API parameters, achieving a more streamlined and efficient detection process.}
}
@article{SUNMOLA2024813,
title = {Artificial Intelligence Opportunities for Resilient Supply Chains},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {19},
pages = {813-818},
year = {2024},
note = {18th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.09.195},
url = {https://www.sciencedirect.com/science/article/pii/S2405896324016148},
author = {Funlade Sunmola and George Baryannis},
keywords = {supply chain resilience, artificial intelligence, explainability, industry 5.0},
abstract = {The need for supply chains to be resilient is increasingly being recognised, following recent disruptions caused by global socioeconomic crises. Supply chain resilience allows for sustainable growth and development through adaptive capabilities, principally including the ability to effectively respond to disruptions to maintain consistent operations. This paper explores the opportunities presented by Artificial Intelligence (AI) in enhancing supply chain resilience. We first conceptualise resilience through a 4-C model: context, capabilities, choices, and contingencies. We then explore a range of AI approaches and develop a research roadmap that attempts to map particular technologies holding potential to the 4-C model.}
}
@article{GUO2025104804,
title = {The impact of parental involvement, social support, and peer relationships on L2 learning motivation: A mixed-methods study of Chinese university EFL students},
journal = {Acta Psychologica},
volume = {254},
pages = {104804},
year = {2025},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2025.104804},
url = {https://www.sciencedirect.com/science/article/pii/S0001691825001179},
author = {Zikai Guo and Chen Chen and Ruifang Guo},
keywords = {Parental involvement, Social support, Peer relationships, L2 learning motivation, EFL, Mixed-methods approach, Chinese university students},
abstract = {This mixed-methods study investigated the impact of parental involvement, social support, and peer relationships on L2 learning motivation among Chinese university students learning English as a foreign language (EFL). Quantitative data from 326 students and qualitative data from semi-structured interviews with 20 students were analyzed. Hierarchical regression analyses revealed that parental involvement significantly predicted all three components of L2 motivation: ideal L2 self, ought-to L2 self, and L2 learning experience. Peer relationships also positively predicted ideal L2 self and L2 learning experience. While social support was not a significant predictor in the quantitative analyses, the analysis of the qualitative data revealed its nuanced role, with students emphasizing the importance of diverse sources of support, including peers, teachers, mentors, and online communities, in fostering a sense of belonging and enhancing motivation. The study highlights the complex interplay of familial and social influences on L2 motivation, offering valuable insights for educators and parents in supporting EFL learners.}
}
@article{GUEVARA2025101090,
title = {Trends and perspectives on bacterial nanocellulose: A comprehensive analysis from the three helixes of innovation},
journal = {Materials Today Sustainability},
volume = {30},
pages = {101090},
year = {2025},
issn = {2589-2347},
doi = {https://doi.org/10.1016/j.mtsust.2025.101090},
url = {https://www.sciencedirect.com/science/article/pii/S2589234725000193},
author = {Kleber Mora Guevara and Gustavo Martínez-Valenzuela and Viviana Sánchez-Vásquez and Keyla Guerrero-Ruiz and Manuel Fiallos-Cárdenas},
keywords = {Bacterial cellulose, Sustainability, Biorefinery, Bioprocesses, Waste biomass, Bibliometry},
abstract = {Bacterial nanocellulose (BNC) stands out as a nanocrystalline material with a wide range of unique properties, including high mechanical strength, biodegradability, biocompatibility, and transparency. This versatility has attracted great interest in various fields, from biomedicine and materials engineering to the food industry and environmental technology. The present study focused on assessing the impact of BNC's scientific production within the framework of the three helixes of innovation and identifying trends in research and technological development. To this end, a comprehensive bibliometric analysis of 4814 peer-reviewed articles published between 2013 and 2023 was conducted, using the SCOPUS database and analyzing the information through Rstudio's Bibliometrix package. The results revealed an approximate annual growth of 15.67% in BNC's scientific output, with an average of 33.56 citations per paper. China was positioned as a leader in this output, backed by strong government commitment and considerable funding for sustainability-focused research. It is notable that BNC studies contribute mainly to the Sustainable Development Goals (SDGs), with SDGs 3, 6, 7, 9, 12, and 17 standing out. Despite the current trend towards process optimization and exploration of BNC-producing microorganisms, a lack of research in life cycle analysis and techno-economic analysis was identified. It is suggested that the implementation of biorefinery approaches, the utilization of residual biomass, and the evaluation of energy efficiency and exergy analysis could potentially significantly improve the process of obtaining BNC, providing a more sustainable and efficient approach to its production with multiple applications in various industrial sectors.}
}
@article{ZHANG2024103140,
title = {Media opinion divergence and stock returns: Evidence from China},
journal = {International Review of Financial Analysis},
volume = {93},
pages = {103140},
year = {2024},
issn = {1057-5219},
doi = {https://doi.org/10.1016/j.irfa.2024.103140},
url = {https://www.sciencedirect.com/science/article/pii/S1057521924000723},
author = {Zuochao Zhang and John W. Goodell and Dehua Shen and Oumaima Lahmar},
keywords = {Media opinion divergence, Textual analysis, Latent Dirichlet Allocation, Generative probabilistic modeling},
abstract = {We construct a proxy for media opinion divergence using Latent Dirichlet Allocation. With this proxy, we investigate the impact of media opinion divergence on Chinese stocks. Findings indicate that higher media opinion divergence results in higher stock returns, but leads to lower future stock returns, consistent with Miller (1987). Additionally, we similarly explore the impact of divergence between traditional media and new media on stock returns, obtaining similar results. Findings are robust to controlling for firm characteristics and the number of news articles. Our study provides valuable insights into how the media can influence investor opinions and in turn the stock market in the digital media era.}
}
@article{MARTINEZPANDIANI2025100317,
title = {‘Toxic’ memes: A survey of computational perspectives on the detection and explanation of meme toxicities},
journal = {Online Social Networks and Media},
volume = {47},
pages = {100317},
year = {2025},
issn = {2468-6964},
doi = {https://doi.org/10.1016/j.osnem.2025.100317},
url = {https://www.sciencedirect.com/science/article/pii/S2468696425000187},
author = {Delfina S. {Martinez Pandiani} and Erik {Tjong Kim Sang} and Davide Ceolin},
keywords = {Internet memes, Toxicity, Information quality, Multimodal discourse},
abstract = {Internet memes are multimodal, highly shareable cultural units that condense complex messages into compact forms of communication, making them a powerful vehicle for information spread. Increasingly, they are used to propagate hateful, extremist, or otherwise ‘toxic’ narratives, symbols, and messages. Research on computational methods for meme toxicity analysis has expanded significantly over the past five years. However, existing surveys cover only studies published until 2022, resulting in inconsistent terminology and overlooked trends. This survey bridges that gap by systematically reviewing content-based computational approaches to toxic meme analysis, incorporating key developments up to early 2024. Using the PRISMA methodology, we extend the scope of prior analyses, resulting in a threefold increase in the number of reviewed works. This study makes four key contributions. First, we expand the coverage of computational research on toxic memes, reviewing 158 content-based studies, including 119 newly analyzed papers, and identifying over 30 datasets while examining their labeling methodologies. Second, we address the lack of clear definitions of meme toxicity in computational research by introducing a new taxonomy that categorizes different toxicity types, providing a more structured foundation for future studies. Third, we observe that existing content-based studies implicitly focus on three key dimensions of meme toxicity—target, intent, and conveyance tactics. We formalize this perspective by introducing a structured framework that models how these dimensions are computationally analyzed across studies. Finally, we examine emerging trends and challenges, including advancements in cross-modal reasoning, the integration of expert and cultural knowledge, the increasing demand for automatic toxicity explanations, the challenges of handling meme toxicity in low-resource languages, and the rising role of generative AI in both analyzing and generating ‘toxic’ memes.}
}
@article{GRUENBICHLER20251473,
title = {Exploring AI frontiers: Insights from Austria’s Industrial Sector on Enhancing Control Functions},
journal = {Procedia Computer Science},
volume = {253},
pages = {1473-1484},
year = {2025},
note = {6th International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.01.209},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925002170},
author = {Rudolf Gruenbichler and Alexander Sitter and Thomas Fenzl},
keywords = {Artificial Intelligence, Controlling, Management Accounting, Application, Knowledge Acquisition, Industry, Implementation barriers},
abstract = {Industrial companies have their own controlling departments that provide information for corporate management. These activities can also be supported by artificial intelligence in the future. In an in-depth interview study of eleven controllers from internationally operating large industrial companies in Austria, the current status of the use of artificial intelligence technologies in the controlling environment is surveyed and the barriers to implementation are analyzed. Furthermore, it is investigated how controllers prepare themselves in this new area, which information channels are used and which information is processed in which form in order to use artificial intelligence in controlling. The results show that the implementation barriers are located at different levels, namely employee, organizational and resource levels. Furthermore, we found that personal, web-based and institutional channels are used to acquire knowledge, with exchange with other companies being the most popular. For the preparation and distribution of content, application examples are preferred, which are made available via video tutorials.}
}