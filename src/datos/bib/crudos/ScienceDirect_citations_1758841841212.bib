@article{CHIOSA2024114802,
title = {A portable application framework for energy management and information systems (EMIS) solutions using Brick semantic schema},
journal = {Energy and Buildings},
volume = {323},
pages = {114802},
year = {2024},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2024.114802},
url = {https://www.sciencedirect.com/science/article/pii/S0378778824009186},
author = {Roberto Chiosa and Marco Savino Piscitelli and Marco Pritoni and Alfonso Capozzoli},
keywords = {Energy management and information systems, Portable application, Brick metadata schema, Anomaly detection, Machine learning},
abstract = {This paper introduces a portable framework for developing, scaling and maintaining energy management and information systems (EMIS) applications using an ontology-based approach. Key contributions include an interoperable layer based on Brick schema, the formalization of application constraints pertaining metadata and data requirements, and a field demonstration. The framework allows for querying metadata models, fetching data, preprocessing, and analyzing data, thereby offering a modular and flexible workflow for application development. Its effectiveness is demonstrated through a case study involving the development and implementation of a data-driven anomaly detection tool for the photovoltaic systems installed at the Politecnico di Torino, Italy. During eight months of testing, the framework was used to tackle practical challenges including: (i) developing a machine learning-based anomaly detection pipeline, (ii) replacing data-driven models during operation, (iii) optimizing model deployment and retraining, (iv) handling critical changes in variable naming conventions and sensor availability (v) extending the pipeline from one system to additional ones.}
}
@article{SHARMA2024102500,
title = {Intra-pulse modulation discrimination using a self-supervised attention-driven CNN-BiLSTM-VAE combination},
journal = {Physical Communication},
volume = {67},
pages = {102500},
year = {2024},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2024.102500},
url = {https://www.sciencedirect.com/science/article/pii/S1874490724002180},
author = {Purabi Sharma and Kandarpa Kumar Sarma},
keywords = {Intra-pulse modulation, CNN, Self-attention, BiLSTM, Variational autoencoder},
abstract = {Identification of intra-pulse modulation (IPM) of radar signals is a crucial part of contemporary electronic support systems and electronic intelligence reconnaissance. Artificial intelligence (AI)-based methods can be very effective in recognising the IPM of radar signals. In this direction, an automatic method is proposed for recognising a few IPMs of radar signals based on continuous wavelet transform (CWT) and a hybrid model of self-attention (SA)-aided convolutional neural network (CNN) and bidirectional long short-term memory (BiLSTM). Firstly, time–frequency attributes of different radar signals are obtained using CWT, and thereafter CNN-SA-BiLSTM is utilised for feature extraction from the 2D scalograms formed by the time–frequency components. The CNN extracts features from the scalograms, SA enhances the discriminative power of the feature map, and BiLSTM detects radar signals based on these features. Additionally, the study addresses real-world data imbalance issues by incorporating a generative AI model, namely the Variational Autoencoder (VAE). The VAE-based approach effectively mitigates challenges arising from data imbalance situations. This method is tested at varying noise levels to give a proper representation of the actual electronic warfare environment. The simulation results demonstrate that the best overall recognition accuracy of the proposed method is 98.4%, even at low signal-to-noise ratios (SNR).}
}
@article{GHOTB2024122008,
title = {Scheduling of log logistics using a metaheuristic approach},
journal = {Expert Systems with Applications},
volume = {238},
pages = {122008},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.122008},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423025101},
author = {Salar Ghotb and Taraneh Sowlati and Joel Mortyn},
keywords = {Decomposition approach, Scheduling, Synchronization, Heterogeneous trucks, Simulated annealing, Taguchi method},
abstract = {An efficient log logistics plan results in log procurement cost savings. In practice, log logistics presents complexities such as synchronization of different machines, sorting of logs, and compatibility requirements. To address these complexities, this research proposes a decomposition approach for optimization of log logistics considering synchronization of log loaders and heterogeneous trucks at both cut blocks and sort yards. In the first phase, the daily number of truckloads between cut blocks and sort yards for each trucking contractor is determined, while allocation of the truckloads to compatible trucks and detailed routing and scheduling decisions are addressed in the second phase. Furthermore, a simulated annealing algorithm is developed for the second phase to obtain the schedules for large-sized problems. Additionally, the parameters of the algorithm are tuned using the Taguchi method. The algorithm is then applied to a case of a large Canadian forest company in British Columbia, Canada with a 1-month planning horizon. The results show that the proposed solution approach can successfully satisfy synchronization requirements and generate detailed schedules in a reasonable time. Also, cost savings for contractors are possible by assigning overtime rather than utilizing more trucks to fulfill their transportation tasks.}
}
@article{HAN2024103946,
title = {Do mobile device icons help or hurt? Evidence from empirical analyses and design via interpretable machine learning},
journal = {Information & Management},
volume = {61},
number = {3},
pages = {103946},
year = {2024},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2024.103946},
url = {https://www.sciencedirect.com/science/article/pii/S0378720624000284},
author = {Maoxin (Molson) Han},
keywords = {Mobile device icons, Review helpfulness, Perceived effort, Empirical analyses, Interpretable machine learning},
abstract = {Although the extant literature demonstrates that mobile device icons change consumers’ cognition of review helpfulness, it reports contradictory findings: displaying mobile device icons either helps or hurts review helpfulness. Drawing on the instability of peripheral routes (ELM) and perceived effort, we found that the impact of mobile device icons on review helpfulness is contingent on review writing effort, represented by review length. Econometric and experimental analyses ensured the external and internal validity of results, respectively. Moreover, we applied interpretable machine learning to designing mobile device icons varying with review writing effort, aiming at maximizing their effects on review helpfulness.}
}
@article{KEMBRO2025163,
title = {Why review papers get rejected: common pitfalls and how to avoid them},
journal = {International Journal of Physical Distribution & Logistics Management},
volume = {55},
number = {11},
pages = {163-192},
year = {2025},
issn = {0960-0035},
doi = {https://doi.org/10.1108/IJPDLM-03-2025-0125},
url = {https://www.sciencedirect.com/science/article/pii/S0960003525000017},
author = {Joakim Hans Kembro and Sven Kunisch and Christian F. Durach},
keywords = {Literature review, Systematic literature review, Structured literature review, Review research, Research methods, Academic writing, Publishing},
abstract = {Purpose
In this paper, we discuss common pitfalls in producing review articles for publication in academic journals, offering guidance to minimize rejection rates. We highlight the dual core features of systematicity (i.e. rigor and transparency) and generativity (i.e. advancing knowledge) in review papers. Thereby, we aim to help researchers deal with the abundance of guidelines and create publishable literature reviews that meaningfully contribute to their fields. Additionally, we discuss the prospects and perils of incorporating advanced technologies, such as artificial intelligence (AI), in review research.
Design/methodology/approach
Drawing from an analysis of editorial guidelines, desk-rejection decisions and reviewer feedback, as well as our experience as authors, reviewers and editors, we identify six common pitfalls of literature reviews. For each pitfall, we discuss typical manifestations and mitigation strategies. We also incorporate illustrative examples of literature reviews that have successfully navigated these pitfalls.
Findings
We identify and discuss six common pitfalls: (1) lack of compelling motivation, (2) weak conceptual foundation, (3) poor research design, (4) flawed research method, (5) insufficient knowledge contributions and (6) poor paper crafting – which undermine systematicity and generativity. For each of the pitfalls, we put forward mitigation strategies, which collectively help improve systematicity and generativity. Additionally, we anticipate and discuss two (emerging) pitfalls related to AI and digital technologies in review research: irresponsible and ineffective use of AI. Again, we propose mitigation strategies.
Originality/value
We offer a structured framework to help researchers overcome common challenges in literature reviews and reduce the likelihood of rejection by leading academic journals.}
}
@article{HARMS2024114364,
title = {Dark clouds on the horizon: Dark personality traits and the frontiers of the entrepreneurial economy},
journal = {Journal of Business Research},
volume = {171},
pages = {114364},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2023.114364},
url = {https://www.sciencedirect.com/science/article/pii/S0148296323007233},
author = {P.D. Harms and Joshua V. White and Tyler N.A. Fezzey},
keywords = {Dark personality, Gig economy, Remote work, Dark triad, Entrepreneurship, Self-employment},
abstract = {Recent developments in technology and shifting societal patterns threaten to upend norms surrounding the world of work. The present paper introduces the idea of an emerging entrepreneurial economy and describes how it is reshaping our understanding of work, provides a framework for understanding whether and why individuals with dark personality traits may be attracted to careers in this new occupational frontier. Specifically, we will discuss how dark traits shape interest in remote work, the gig economy, social media and podcasting careers, and occupations related to cryptocurrencies, blockchain technologies, and crowdfunding. We also note how technologies enhanced by artificial intelligence (AI) might contribute to uncertainty concerning how individuals with dark traits may function in these vocational contexts. We finish by making arguments for how future research can be improved in order to attain a more comprehensive understanding of dark personality in the entrepreneurial economy.}
}
@article{MUNUZURI202264,
title = {Unified representation of Life's basic properties by a 3-species Stochastic Cubic Autocatalytic Reaction-Diffusion system of equations},
journal = {Physics of Life Reviews},
volume = {41},
pages = {64-83},
year = {2022},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2022.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S1571064522000185},
author = {Alberto P. Muñuzuri and Juan Pérez-Mercader},
keywords = {Living systems, Turing instability, Top-down approach, Bottom-up approach, Non-linear reaction-diffusion equations, Properties of life},
abstract = {Today we can use physics to describe in great detail many of the phenomena intervening in the process of life. But no analogous unified description exists for the phenomenon of life itself. In spite of their complexity, all living creatures are out of equilibrium chemical systems sharing four fundamental properties: they (1) handle information, (2) metabolize, (3) self-reproduce and (4) evolve. This small number of features, which in terran life are implemented with biochemistry, point to an underlying simplicity that can be taken as a guide to motivate and implement a theoretical physics style unified description of life using tools from the non-equilibrium physical-chemistry of extended systems. Representing a system with general rules is a well stablished approach to model building and unification in physics, and we do this here to provide an abstract mathematical description of life. We start by reviewing the work of previous authors showing how the properties in the above list can be individually represented with stochastic reaction-diffusion kinetics using polynomial reaction terms. These include “switches” and computation, the kinetic representation of autocatalysis, Turing instability and adaptation in the presence of both deterministic and stochastic environments. Thinking of these properties as existing on a space-time lattice each of whose nodes are subject to a common mass-action kinetics compatible with the above, leads to a very rich dynamical system which, just as natural life, unifies the above properties and can therefore be interpreted as a high level or “outside-in” theoretical physics representation of life. Taking advantage of currently available advanced computational techniques and hardware, we compute the phase plane for this dynamical system both in the deterministic and stochastic cases. We do simulations and show numerically how the system works. We review how to extract useful information that can be mapped into emergent physical phenomena and attributes of importance in life such as the presence of a “membrane” or the time evolution of an individual system's negentropy or mass. Once these are available, we illustrate how to perform some basic phenomenology based on the model's numerical predictions. Applying the above to the idealization of the general Cell Division Cycle (CDC) given almost 25 years ago by Hunt and Murray, we show from the numerical simulations how this system executes a form of the idealized CDC. We also briefly discuss various simulations that show how other properties of living systems such as migration towards more favorable regions or the emergence of effective Lotka-Volterra populations are accounted for by this general and unified view from the “top” of the physics of life. The paper ends with some discussion, conclusions, and comments on some selected directions for future research. The mathematical techniques and powerful simulation tools we use are all well established and presented in a “didactical” style. We include a very rich but concise SI where the numerical details are thoroughly discussed in a way that anyone interested in studying or extending the results would be able to do so.}
}
@article{AZZONE2023101841,
title = {Evaluation of sight deposits and central bank digital currency},
journal = {Journal of International Financial Markets, Institutions and Money},
volume = {88},
pages = {101841},
year = {2023},
issn = {1042-4431},
doi = {https://doi.org/10.1016/j.intfin.2023.101841},
url = {https://www.sciencedirect.com/science/article/pii/S1042443123001099},
author = {Michele Azzone and Emilio Barucci},
keywords = {Central bank digital currency, Bank deposit, Interest rate, Bank run},
abstract = {We provide a market-based evaluation of sight deposits of banks when Central Bank Digital Currency (CBDC) is issued. We investigate the effects of different adoption rates (moderate, large or capped adoption), of different remuneration schemes and of the possibility of a bank-run. We perform the analysis at the aggregate level for the Euro area and the United States. We show that the effect of CBDC on deposit market value is small unless a large adoption rate is considered. The remuneration scheme plays a significant role only in the moderate/capped adoption scenario in relative terms and in a high interest rate environment. Instead, the possibility of a bank-run calibrated on the experience of the Euro area and of Greece during the debt crisis has little effect on the value of deposits even if a CBDC is introduced.}
}
@article{XIAO2024102679,
title = {UI semantic component group detection: Grouping UI elements with similar semantics in mobile graphical user interface},
journal = {Displays},
volume = {83},
pages = {102679},
year = {2024},
issn = {0141-9382},
doi = {https://doi.org/10.1016/j.displa.2024.102679},
url = {https://www.sciencedirect.com/science/article/pii/S014193822400043X},
author = {Shuhong Xiao and Yunnong Chen and Yaxuan Song and Liuqing Chen and Lingyun Sun and Yankun Zhen and Yanfang Chang and Tingting Zhou},
keywords = {UI element grouping, UI object detection, UI-related software application, Transformer},
abstract = {Texts, widgets, and images on a UI page do not work separately. Instead, they are partitioned into groups to achieve certain interaction functions or visual information. Existing studies on UI elements grouping mainly focus on a specific single UI-related software engineering task, and their groups vary in appearance and function. In this case, we propose our semantic component groups that pack adjacent text and non-text elements with similar semantics. In contrast to those task-oriented grouping methods, our semantic component group can be adopted for multiple UI-related software tasks, such as retrieving UI perceptual groups, improving code structure for automatic UI-to-code generation, and generating accessibility data for screen readers. To recognize semantic component groups on a UI page, we propose a robust, deep learning-based vision detector, UISCGD, which extends the SOTA deformable-DETR by incorporating UI element color representation and a learned prior on group distribution. The model is trained on our UI screenshots dataset of 1988 mobile GUIs from more than 200 apps in both iOS and Android platforms. The evaluation shows that our UISCGD achieves 6.1% better than the best baseline algorithm and 5.4 % better than deformable-DETR in which it is based.}
}
@article{GARZA2024e31144,
title = {Photoluminescence research of the graphene quantum dots (GQD) interaction on the zinc oxide (ZnO) surface for application as H2O2 photosensor},
journal = {Heliyon},
volume = {10},
number = {11},
pages = {e31144},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e31144},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024071755},
author = {Rolando Efraín Ramírez Garza and Sara Luisa {Rodríguez de Luna} and Idalia Gómez},
keywords = {Zinc oxide, Graphene quantum dots, Photoluminescence, HO detection, Oxygen-vacancies ZnO},
abstract = {Photoluminescence (PL) spectroscopy is one of the best methods to detect molecules due to its easiness, fast time of analysis and high sensitivity. In addition, zinc oxide (ZnO) possesses good optical properties and particularly PL emission in these materials have been exploited for their potential use as photocatalyst, light harvesting and photosensor. These PL properties enhance when graphene quantum dots (GQD) are added to ZnO. For these reasons, we investigated the PL performance of ZnO-GQD nanocomposites. In one experiment we evaluated the PL emission of solid samples ZnO and ZnO-GQD. In a second experiment, these samples were also evaluated in aqueous phase to investigate the H2O2 effect during an experiment lasting 170 minutes. Both experiments displayed six peaks and they were related to the same PL emission source. The PL emission peak around 415 nm was found to be principal source where GQD are interacting. By varying the GQD amount to low, medium, and high concentration, the effect of H2O2 acted consequently, altering the PL emission during experiment in aqueous phase. An oxygen rich environment (ORE) occurred due to H2O2 which oxides the ZnO surface. Low GQD concentration resulted affected by an ORE weakening the GQD-ZnO contact, decreasing PL emission. In high GQD concentration, H2O2 induced GQD to reach the ZnO surface, increasing the PL emission. Only medium GQD concentration prevented oxidation of ZnO and maintained the PL emission intensity constant. When H2O2 concentration increased, for the medium GQD concentration, an excess of charge by peroxides inhibited the charge transfer from GQD to ZnO. This inhibition produces a quenching of the PL emission.}
}
@article{JI2026116159,
title = {A systematic review of electricity demand for large language models: evaluations, challenges, and solutions},
journal = {Renewable and Sustainable Energy Reviews},
volume = {225},
pages = {116159},
year = {2026},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2025.116159},
url = {https://www.sciencedirect.com/science/article/pii/S1364032125008329},
author = {Zhenya Ji and Ming Jiang},
keywords = {Electricity consumption, Artificial intelligence, Large language model, Power grid, Energy sustainability},
abstract = {Large language models (LLMs) are revolutionizing technology landscapes, transforming production workflows, and deeply embedding themselves into our daily lives. Their unparalleled capabilities, fueled by extensive training on vast datasets and intensive utilizations, underpin this transformation. However, this achievement comes at a significant cost: the immense electricity demand required for their training and inference poses an urgent and critical challenge. As the reliance on LLMs grows, ensuring a reliable and sustainable power supply becomes paramount for their uninterrupted progress and widespread adoption. This comprehensive review paper thoroughly examines the intricacies of LLMs' lifecycle, focusing on both training and inference stages. It critically assesses various parameters and approaches for accurately estimating their electricity consumption and associated carbon emissions, drawing upon representative statistical data spanning diverse LLM products and task types. By delving into the complexities, the paper uncovers the fundamental challenges in forecasting and fulfilling LLMs’ extensive electricity demand, which are intricately linked to controversies within four bottom-up tiers: soft-and-hardware, data center, power grid, and external societal factors. Crucially, this paper offers a suite of tailored solutions for each tier, aimed at not only addressing the immediate electricity demand challenge but also fostering the long-term sustainability of LLMs. The insights outlined herein endeavor to alleviate the power shortage crisis facing LLMs, paving the way for their widespread adoption while minimizing their environmental impact and contributing to a greener future.}
}
@article{SIINO2025104281,
title = {Integrating Large Language Models into network testbeds: A novel approach for automated experimentation and optimization},
journal = {Journal of Network and Computer Applications},
volume = {243},
pages = {104281},
year = {2025},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2025.104281},
url = {https://www.sciencedirect.com/science/article/pii/S108480452500178X},
author = {Marco Siino and Fabrizio Giuliano and Ilenia Tinnirello},
keywords = {Large Language Models (LLMs), Wireless networking, Networking testbed, Few-shot learning, Prompt engineering, System configuration, LoRaWAN, Anomaly detection, Network optimization, Experimentation efficiency},
abstract = {This manuscript introduces a novel approach to integrate Large Language Models (LLMs) into wireless network testbeds for automated experimentation and optimization. We propose a framework that leverages LLMs to define system configurations using a structured format called Blueprint and analyse network behaviour through user-prompted queries. Our methodology combines few-shot prompting and prompt engineering to enable automated analysis of network configurations, enhancing decision-making and experimentation efficiency. We validated our approach in both simulated and real-world wireless environments and demonstrated its efficacy in streamlining experiment processes and extracting actionable insights.}
}
@article{DIMAKOU20251310,
title = {The predictive nature of spontaneous brain activity across scales and species},
journal = {Neuron},
volume = {113},
number = {9},
pages = {1310-1332},
year = {2025},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2025.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S0896627325001278},
author = {Anastasia Dimakou and Giovanni Pezzulo and Andrea Zangrossi and Maurizio Corbetta},
keywords = {spontaneous brain activity, predictive brains, behavioral priors, task-rest similarity, metabolic priors},
abstract = {Summary
Emerging research suggests the brain operates as a “prediction machine,” continuously anticipating sensory, motor, and cognitive outcomes. Central to this capability is the brain's spontaneous activity—ongoing internal processes independent of external stimuli. Neuroimaging and computational studies support that this activity is integral to maintaining and refining mental models of our environment, body, and behaviors, akin to generative models in computation. During rest, spontaneous activity expands the variability of potential representations, enhancing the accuracy and adaptability of these models. When performing tasks, internal models direct brain regions to anticipate sensory and motor states, optimizing performance. This review synthesizes evidence from various species, from C. elegans to humans, highlighting three key aspects of spontaneous brain activity’s role in prediction: the similarity between spontaneous and task-related activity, the encoding of behavioral and interoceptive priors, and the high metabolic cost of this activity, underscoring prediction as a fundamental function of brains across species.}
}
@article{TAN2025100355,
title = {Artificial intelligence in teaching and teacher professional development: A systematic review},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100355},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100355},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001589},
author = {Xiao Tan and Gary Cheng and Man Ho Ling},
keywords = {Artificial intelligence (AI), AI in education, Systematic review, Teaching, Professional development},
abstract = {The application of Artificial Intelligence (AI) technology in education is increasingly recognized as a key driver of educational innovation. While extensive literature exists on the integration of AI technologies in educational settings, less emphasis has been placed on the critical role of teachers and their professional development needs. This study systematically reviews research conducted between 2015 and 2024 on teachers' use of AI technology in their teaching and professional development, focusing on the relationship between the supply of professional development opportunities and the demand for AI integration among teachers. Using PRISMA principles and protocols, this review identified and synthesized 95 relevant research articles. The findings reveal a significant imbalance in research focus. Specifically, 65% of the studies examined the application of AI in teaching, including technologies such as conversational AI and related technologies, AI-driven learning and assessment systems, immersive technologies, visual and auditory computing, and teaching and learning analytics. In contrast, only 35% of the studies explored AI's role in enhancing teacher professional development. This review highlights a gap in research addressing the development needs of teachers as they integrate AI technologies into their teaching practices. It emphasizes the need for future research to focus more on the potential of AI in teacher professional development and to investigate how AI technologies can be applied in education from both the perspectives of student learning and teacher instruction. Furthermore, research on AI in professional development should prioritize addressing technological and ethical challenges to ensure the responsible and effective integration of AI in education.}
}
@article{SUNGE2024e39869,
title = {The COVID-19 pandemic and economic recovery: The mediating role of governance, a global perspective},
journal = {Heliyon},
volume = {10},
number = {22},
pages = {e39869},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e39869},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024159002},
author = {Regret Sunge and Calvin Mudzingiri and Nkosingiphile Mkhize},
keywords = {COVID-19 pandemic, Governance, Economic recovery, Mediation analysis, Structural equation modelling},
abstract = {The COVID-19 pandemic, arguably the most extensive economic shock after the Great Depression, has drawn attention from policy custodians over the past three years. Governments’ response brought to the limelight the role that governance plays in mitigating the economic shrinking effects of a pandemic. This study investigated the mediating role of governance in the post-pandemic recovery process using structural equation modelling of cross-sectional data from 125 countries for the years 2020 and 2021. The results show that governance did not mediate economic recovery at the global level. However, regional analysis reveals a full mediation effect in Africa and for low-income countries in 2021. Disaggregating governance by indicators in Africa reveals complete mediation for control of corruption, government effectiveness, regulatory quality, and the rule of law. Achieving sustainable economic recovery requires strengthening local governance structures and encouraging international cooperation. The research motivates the establishment of international governance institutions in the spirit of United Nations-driven frameworks. This can be complemented by country-specific, multi-agency, cross-sector collaborations led by the state, the development of governance systems that reduce mistrust among stockholders, and investment in artificial intelligence and e-governance systems.}
}
@article{2024105859,
title = {DLA Piper EU update},
journal = {Computer Law & Security Review},
volume = {52},
pages = {105859},
year = {2024},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2023.105859},
url = {https://www.sciencedirect.com/science/article/pii/S0267364923000699}
}
@article{NGUYEN2024,
title = {Usability, Engagement, and Report Usefulness of Chatbot-Based Family Health History Data Collection: Mixed Methods Analysis},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/55164},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124006101},
author = {Michelle Hoang Nguyen and João Sedoc and Casey Overby Taylor},
keywords = {family health history, chatbots, conversational agents, digital health tools, usability, engagement, report usefulness, evaluation, crowdsourcing, mixed methods},
abstract = {Background
Family health history (FHx) is an important predictor of a person’s genetic risk but is not collected by many adults in the United States.
Objective
This study aims to test and compare the usability, engagement, and report usefulness of 2 web-based methods to collect FHx.
Methods
This mixed methods study compared FHx data collection using a flow-based chatbot (KIT; the curious interactive test) and a form-based method. KIT’s design was optimized to reduce user burden. We recruited and randomized individuals from 2 crowdsourced platforms to 1 of the 2 FHx methods. All participants were asked to complete a questionnaire to assess the method’s usability, the usefulness of a report summarizing their experience, user-desired chatbot enhancements, and general user experience. Engagement was studied using log data collected by the methods. We used qualitative findings from analyzing free-text comments to supplement the primary quantitative results.
Results
Participants randomized to KIT reported higher usability than those randomized to the form, with a mean System Usability Scale score of 80.2 versus 61.9 (P<.001), respectively. The engagement analysis reflected design differences in the onboarding process. KIT users spent less time entering FHx information and reported more conditions than form users (mean 5.90 vs 7.97 min; P=.04; and mean 7.8 vs 10.1 conditions; P=.04). Both KIT and form users somewhat agreed that the report was useful (Likert scale ratings of 4.08 and 4.29, respectively). Among desired enhancements, personalization was the highest-rated feature (188/205, 91.7% rated medium- to high-priority). Qualitative analyses revealed positive and negative characteristics of both KIT and the form-based method. Among respondents randomized to KIT, most indicated it was easy to use and navigate and that they could respond to and understand user prompts. Negative comments addressed KIT’s personality, conversational pace, and ability to manage errors. For KIT and form respondents, qualitative results revealed common themes, including a desire for more information about conditions and a mutual appreciation for the multiple-choice button response format. Respondents also said they wanted to report health information beyond KIT’s prompts (eg, personal health history) and for KIT to provide more personalized responses.
Conclusions
We showed that KIT provided a usable way to collect FHx. We also identified design considerations to improve chatbot-based FHx data collection: First, the final report summarizing the FHx collection experience should be enhanced to provide more value for patients. Second, the onboarding chatbot prompt may impact data quality and should be carefully considered. Finally, we highlighted several areas that could be improved by moving from a flow-based chatbot to a large language model implementation strategy.}
}
@article{MENG202532,
title = {“Design nature”: A color interpretation of Bauhaus school building in Dessau and its conceptual origins},
journal = {Frontiers of Architectural Research},
volume = {14},
number = {1},
pages = {32-61},
year = {2025},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2024.06.012},
url = {https://www.sciencedirect.com/science/article/pii/S2095263524001043},
author = {Yuan Meng and Wei Liu},
keywords = {Dessau Bauhaus, Walter Gropius, Architectural space color design, Educational philosophy, Origin tracing research},
abstract = {In modernist architecture, color serves as a crucial tool in shaping spatial experiences. However, due to historical reasons, the color design of early modernist architecture has not been fully explored. The paper focuses on the iconic modernist work, the Bauhaus school building in Dessau. Through historical investigation and theoretical research, it elucidates the evolution of color cognition from the perspectives of color theory development, architectural color characteristics, and the interaction between visual perception and color. On this basis, it explores the color theory origins of the Bauhaus and Gropius, dissecting the conceptual framework and methods behind the color design of the Bauhaus school building in Dessau. Additionally, this article analyzes the spatial characteristics of architectural color from an experiential standpoint. The paper argues that Gropius conveyed his concept of “natural perspective” through color design, emphasizing the eternal value of natural internal logic. The Bauhaus redefined the role of color in architectural expression, based on natural laws, and deduced a scientifically designed method related to perception, promoting a shift in color design from subjective to objective and injecting deeper connotations into architectural color.}
}
@article{ZHANG2025108457,
title = {Flow in ChatGPT-based logic learning and its influences on logic and self-efficacy in English argumentative writing},
journal = {Computers in Human Behavior},
volume = {162},
pages = {108457},
year = {2025},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108457},
url = {https://www.sciencedirect.com/science/article/pii/S074756322400325X},
author = {Ruofei Zhang and Di Zou and Gary Cheng and Haoran Xie},
keywords = {AI in education, ChatGPT-based learning, Engagement, Flow experience, Learning affection and cognition, Logic learning},
abstract = {Flow is a state of full engagement in an activity. Learning environments featured by Skill-challenge balance, Clear goal, Feedback, and Playability — collectively known as flow antecedents – can induce flow experiences and improve learning outcomes. ChatGPT-based environment seems to encourage a flow in learners: By customising tasks to match students' abilities, aligning materials with clear objectives, providing instant feedback, and ensuring ease of use, ChatGPT can help learners enter a flow state, which, in turn, leads to improved learning. However, there hasn't been much research on flow in ChatGPT-based learning. To bridge the gap, we developed a ChatGPT-based environment for developing logic in English argumentative writing. We studied 40 Chinese university English-as-a-foreign-language (EFL) students in the learning using questionnaires, eye-tracking data, knowledge tests, essay writing tasks, and semi-structured interviews to understand how they experienced flow and how it affected their learning. Our findings showed that the ChatGPT-based environment strongly supports flow antecedents. Skill-challenge balance and Playability were particularly influential for inducing flow experiences. Students who experienced a deeper flow showed better understanding of argumentative writing logic, although their writing self-efficacy became lower. Drawing from the findings, our study highlights how AI like ChatGPT can influence experiences and outcomes of logic learning and language learning, which may be applicable across various domains and disciplines.}
}
@article{UZOCHUKWU2023101820,
title = {Optimizing feed utilization and reducing deterioration of African catfish feed with sodium propionate supplementation},
journal = {Aquaculture Reports},
volume = {33},
pages = {101820},
year = {2023},
issn = {2352-5134},
doi = {https://doi.org/10.1016/j.aqrep.2023.101820},
url = {https://www.sciencedirect.com/science/article/pii/S2352513423003599},
author = {Ifeanyi Emmanuel Uzochukwu and Patrick Emeka Aba and Nelson Ike Ossai and Hillary Chukwuemeka Ugwuoke and Krisztián Nyeste and Ndubuisi Samuel Machebe},
keywords = {Sodium propionate, African catfish, Growth performance, Feed quality, Feed deterioration, Aquaculture production},
abstract = {A 56-day, two-phased experiment was conducted to investigate the effect of sodium propionate (NaP) on the growth performance of African catfish and the feed quality. One hundred juveniles with an average body weight of 50.47 g ( ± 4.60) were procured and used for the study’s first phase. Fish were randomly assigned to five groups (A, control group), B, C, D, and E) and replicated four times with five fish each. Respective groups were fed diets containing NaP at 0, 1.67, 3.33, 5.00, and 6.67 g kg−1 feed, respectively. For the second trial, the individual diets were analyzed for quality characteristics on 0-, 28- and 56-days of storage, using a mixed-model analysis of variance. Results showed significant differences in most growth performance parameters among groups except for the final body length and condition factor. Group C had lower final body weight (FW), weight gain (WG), average feed intake (AFI), specific growth rate (SGR), and higher feed conversion ratio (FCR) than the control. However, these parameters did not differ in Group D, which also showed lower AFI compared to the control. Increasing NaP decreased the sensory attribute scores of the feed and its crude protein (CP), ether, and ash levels while increasing moldiness, crude fiber, nitrogen-free extract, and thiobarbituric acid reactive substances (TBARs). NaP inclusion in feed resulted in a dose-dependent reduction in the feed deterioration, as seen in the lowered aggregate changes in sensory attributes, CP, moisture, and ash levels, with Group D having an optimal effect. The TBARs level (rancidity) decreased in Group B but increased in Group E during the study. The study concludes that there was a loss of fish feed quality with increasing storage time and that NaP particularly at 5.0 g kg−1 feed optimally improves feed utilization and effectively lowers feed deterioration for 56 days. Therefore, the use of NaP is recommended for improved aquaculture production.}
}
@article{ZARCHI2025113698,
title = {Explainable nature-inspired optimization via virtual and actual multi-objective strategies to establish a smart earthquake early warning system},
journal = {Applied Soft Computing},
volume = {184},
pages = {113698},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2025.113698},
url = {https://www.sciencedirect.com/science/article/pii/S1568494625010099},
author = {Milad Zarchi and Reza A. Nazari and Kong Fah Tee},
keywords = {Geosynthetic reinforced soil structures, Seismic sliding displacement, Newmark method, Multiobjective optimization, Feature learning, Risk assessment, Early warning system, Nondominated sorting genetic algorithm, Particle swarm optimization, Reliability analysis},
abstract = {Geosynthetic-reinforced soil (GRS) structures are considered for reducing displacement and providing economical reinforcement solutions. The risk assessment of these structures against earthquakes, based on the prediction of seismic sliding displacement, is a major challenge in this field. Multi-objective optimization is a powerful machine learning tool for selecting efficient features for high-performance forecasting. This research investigates two strategies based on swarm intelligence and genetic programming for a comprehensive evaluation. These frameworks integrate multiobjective optimization algorithms and Newmark methods for utilizing effective physics-informed features. The first strategy is virtual multi-objective (VMO) optimization by applying particle swarm optimization (PSO) based on minimizing one function via variations of other functions. In this approach, the error function, as a computational error object, is minimized versus the nomination of interpretable feature space as a computational cost object through the virtual Pareto front. The second strategy is actual multi-objective (AMO) optimization by exploiting nondominated sorting genetic algorithm II (NSGA-II) based on minimizing several functions simultaneously with two various approaches, including bi-objective and many-objective algorithms through actual Pareto-optimal solutions. In this approach, the computational error value, computational cost value, and computational time value are minimized at the same time. The main novelty of the first technique is low computational complexity, resulting in high speed due to definite search space dimension-based exploration and exploitation to forecast seismic sliding displacement, whereas the major achievement of the second technique is high computational accuracy due to multiobjective structure-assisted exploitation and exploitation. Through numerical validation by employing the Newmark methods, the resultant model predicts the seismic sliding displacement of these structures using two algorithms efficiently. Nevertheless, both strategies have good performance for intelligent forecasting. The actual many-objective optimization algorithm is a more effective switchable machine learning tool based on the proposed adaptable performance index for developing a smart earthquake early warning software that can precisely detect imminent natural hazards.}
}
@article{LI2025106509,
title = {Movement behavior of rock strata in multi-level sublevel filling mining and forecasting of differential surface subsidence},
journal = {Results in Engineering},
volume = {27},
pages = {106509},
year = {2025},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2025.106509},
url = {https://www.sciencedirect.com/science/article/pii/S2590123025025782},
author = {Fei Li and Yihui Feng and Haitao Ma and Yongming Yin and Xinai Lu and Chaoyu Zan},
keywords = {Mining rock mechanics, Filling mining method, Strata control, Stress arch, Multi-level backfill mining},
abstract = {To address issues such as ground pressure manifestation, rock beam fracture, and overburden displacement caused by multi-level sublevel filling mining of gently inclined medium-thick ore bodies, this study adopts the Fankou Lead-Zinc Mine as the engineering background. Through a combination of numerical simulation and theoretical analysis, it systematically reveals the movement behavior and the mechanism of surface subsidence of the overburden under the disturbance of multi-level sublevel filling mining. Mechanical models of the stress “pressure relief arch” and “bearing arch” are established, along with a mechanical model of the filling body and roof under combined disturbance effects. The results indicate that multi-level sublevel filling mining induces nonlinear superposition effects in the stress unloading-loading cycles. The disturbance of adjacent stopes induces an alternating development pattern of “pressure relief arch” and “bearing arch”. The activation of potential slip surfaces under combined disturbance is a key controlling factor contributing to asymmetric surface settlement. The disturbance zone can be divided into three types: a direct disturbance zone influencing the settlement magnitude of the overburden; a compound disturbance zone that alters the transmission pattern of mining-induced stress and the height of the stress arch; and a potential slip zone prone to shear and tensile failure. The stope layout pattern significantly influences the transmission pattern of mining-induced stress and the disturbance range. Under the intermittent mining mode, the overburden experiences uneven deformation within a height range of less than 150 m, whereas under the continuous filling-mining mode, uneven deformation extends to a height of up to 220 m.}
}
@article{HUSSAIN2024344,
title = {Temperature, topography, woody vegetation cover and anthropogenic disturbance shape the orchids distribution in the western Himalaya},
journal = {South African Journal of Botany},
volume = {166},
pages = {344-359},
year = {2024},
issn = {0254-6299},
doi = {https://doi.org/10.1016/j.sajb.2024.01.042},
url = {https://www.sciencedirect.com/science/article/pii/S0254629924000541},
author = {Karamit Hussain and Muhammad Ejaz-Ul-Islam Dar and Arshad Mahmood Khan and Taskeen Iqbal and Ansar Mehmood and Tariq Habib and Ihab Mohamed Moussa and Ryan Casini and Hosam O. Elansary},
keywords = {Climate variability, Orchids microhabitats, Community ecology, Species interactions, Diversity and distribution},
abstract = {Orchid species require unique microhabitat conditions and are globally distributed from the tropics to alpine regions. These plant species are important both ecologically and economically but are facing multiple threats, especially habitat destruction, climate change, and overexploitation. Therefore, documenting species richness, diversity, distribution, and important driving factors is crucial for biodiversity conservation. The orchid species distribution patterns and order of importance of the main driving environmental factors in the western Himalayas of Azad Jammu and Kashmir remain unclear. The main aims of this study were to explore the richness and distribution of orchids and neighboring vascular flora and to identify the principal driving environmental factors, as no study has yet targeted these plant species specifically in the study area. Field data collection surveys were conducted from August 2018 to July 2021 using the vegetation sampling method. The presence of ≥ two individuals belonging to any orchid species in a 20 × 20 m² land area criterion was used to select the study sites along the elevation gradient for data collection. Multivariate statistical tools, such as hierarchical classification and ordination, were used to analyze the data. A total of 32 orchid species belonging to 18 different Orchidaceae genera were recorded at the 57 study sites. Only one individual each of Herminium monorchis, Habenaria furcifera, and Malaxis muscifera was collected, depicting these orchids as extremely rare in the study area. A total of 324 vascular plant species (including orchids and their neighboring plant species in the studied plots) were classified into seven significantly (p < 0.05) different plant associations, each with a unique species composition. The results of canonical correspondence analysis showed that temperature variability was the most influential among the 28 environmental factors considered. Different microhabitats with an elevation range of ≥1500–3500 m a.s.l. in the central part of the study area are moister and richer in organic matter and support high orchid diversity. It was observed that a higher density of co-existing tree and shrub species and a higher geographic slope were supporting the growth and survival of orchid species as well. Conversely, higher deforestation activities and potassium levels in the soil were observed as negatively influencing factors. The influence of non-native plant species on orchid species distribution was not significant, indicating that the local orchid species were not remarkably affected when growing in microhabitats with optimal conditions. This study concluded that the central part of the study area is richer in orchid abundance and diversity and needs effective conservation and management planning.}
}
@article{HUYNH2025114159,
title = {Joint state-parameter estimation for the reduced fracture model via the united filter},
journal = {Journal of Computational Physics},
volume = {538},
pages = {114159},
year = {2025},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2025.114159},
url = {https://www.sciencedirect.com/science/article/pii/S0021999125004425},
author = {Phuoc Toan Huynh and Thi-Thao-Phuong Hoang and Guannan Zhang and Feng Bao},
keywords = {Reduced fracture model, Data assimilation, Joint state-parameter estimation, Ensemble score filter, Bayesian inference},
abstract = {In this paper, we introduce an effective United Filter method for jointly estimating the solution state and physical parameters in flow and transport problems within fractured porous media. Fluid flow and transport in fractured porous media are critical in subsurface hydrology, geophysics, and reservoir geomechanics. Reduced fracture models, which represent fractures as lower-dimensional interfaces, enable efficient multi-scale simulations. However, reduced fracture models also face accuracy challenges due to modeling errors and uncertainties in physical parameters such as permeability and fracture geometry. To address these challenges, we propose a United Filter method, which integrates the Ensemble Score Filter (EnSF) for state estimation with the Direct Filter for parameter estimation. EnSF, based on a score-based diffusion model framework, produces ensemble representations of the state distribution without deep learning. Meanwhile, the Direct Filter, a recursive Bayesian inference method, estimates parameters directly from state observations. The United Filter combines these methods iteratively: EnSF estimates are used to refine parameter values, which are then fed back to improve state estimation. Numerical experiments demonstrate that the United Filter method surpasses the state-of-the-art Augmented Ensemble Kalman Filter, delivering more accurate state and parameter estimation for reduced fracture models. This framework also provides a robust and efficient solution for PDE-constrained inverse problems with uncertainties and sparse observations.}
}
@article{MARKOVITCH2024103847,
title = {Consumer reactions to chatbot versus human service: An investigation in the role of outcome valence and perceived empathy},
journal = {Journal of Retailing and Consumer Services},
volume = {79},
pages = {103847},
year = {2024},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2024.103847},
url = {https://www.sciencedirect.com/science/article/pii/S0969698924001437},
author = {Dmitri G. Markovitch and Rusty A. Stough and Dongling Huang},
keywords = {Chatbot, Empathy, Chatbot appearance, Anthropomorphic, Humanoid, Attribution theory},
abstract = {Service outcome valence is a prominent contextual factor that has been under-researched in studies of consumer response to automated service-givers. We investigate whether consumers respond differently to chatbot and human customer service when faced with positive versus negative service outcomes. We also explore the role of perceived empathy as a potential mediator in the focal relationship. 714 individuals participated in three studies based on the vignette method. Study participants reported significantly lower satisfaction, repatronage intentions, recommendation acceptance, and recommending the provider to others following interactions with a chatbot compared with a human agent in both positive and negative service outcome conditions. The effect was fully mediated by the service-giver's perceived empathy. Increasing a chatbot's perceived empathy via more empathetic communication (but not human-like appearance) improved consumer evaluations of chatbot service relative to a less empathetic chatbot configuration and matched evaluations of the human agent. A fourth study involved a quasi-experiment in which 100 individuals interacted with ChatGPT to obtain medical advice. This study corroborated our conclusions about the impact of perceived empathy on consumers' service experience and provider ratings.}
}
@article{LI2026743092,
title = {A comparative analysis of immune memory in bivalve and gastropod Mollusks: From mechanistic insights to practical applications},
journal = {Aquaculture},
volume = {612},
pages = {743092},
year = {2026},
issn = {0044-8486},
doi = {https://doi.org/10.1016/j.aquaculture.2025.743092},
url = {https://www.sciencedirect.com/science/article/pii/S0044848625009780},
author = {Hongyu Li and Hairun Li and Ling Zhao and Jialu Xu and Xianwei Li and Qingzhi Zhao and Yijie Zhang and Yuqing Shao and Ruke Wang and Jiyuan Wang and Lijun Lin and Xiaodong Yao and Xiaofen Zhang and Keda Chen},
keywords = {Bivalve, Gastropod, Immune, Immune memory, Innate immunity},
abstract = {Mollusks play essential ecological roles in marine and freshwater ecosystems, with their diversity reflected not only in morphological structures but also in immune strategies. Although traditionally considered to possess only innate immunity due to the absence of a typical adaptive immune system, recent studies have revealed that certain mollusks, such as oysters, exhibit “trained immunity”-an enhanced response upon secondary exposure to pathogens. This review summarizes the latest research advances on the immune systems of bivalve and gastropod mollusks, covering both humoral and cellular immunity, with a focus on systematically comparing their commonalities and differences in immune memory mechanisms. Core mechanisms include immune gene expression reprogramming, epigenetic modifications, metabolic reprogramming, and functional differentiation of immune cells. Bivalves primarily rely on complement and lectin pathways, while gastropods are characterized by the involvement of fibrinogen-related proteins (FREPs) and specific lectins. Transgenerational immune priming (TGIP) has been confirmed in bivalves, whereas relevant studies in gastropods remain limited. Furthermore, this review highlights the potential applications of immune memory in aquaculture disease management, such as developing immunostimulatory strategies to combat pathogens like Ostreid herpesvirus 1 (OsHV-1). A deeper understanding of the underlying mechanisms is expected to advance the development of immune-enhancing approaches.}
}
@article{BAO2023,
title = {A Preliminary Study on Graduate Student Instructors’ Exploration, Perception, and Use of ChatGPT},
journal = {International Journal of Computer-Assisted Language Learning and Teaching},
volume = {13},
number = {1},
year = {2023},
issn = {2155-7098},
doi = {https://doi.org/10.4018/IJCALLT.332873},
url = {https://www.sciencedirect.com/science/article/pii/S2155709823000099},
author = {Yingling Bao and Belle Li},
keywords = {ChatGPT, Exploration, Foreign Language, Novice Instructors, Perception, TPACK},
abstract = {ABSTRACT
Research on teachers’ technological pedagogical content knowledge (TPACK) has been burgeoning recently. Yet, little is known about how teachers integrate AI tools such as ChatGPT in language teaching. This preliminary qualitative study investigates the exploration and incorporation of ChatGPT in language teaching by graduate student instructors (GSIs). By analyzing data from questionnaires, focus group interviews, screenshots of interactions with ChatGPT, and participants' lesson plans, this study shows how instructors develop their knowledge about ChatGPT and mobilize content and pedagogy knowledge to enact technology integration. Findings reveal that GSIs adopted various strategies when exploring the affordances of ChatGPT. Furthermore, while GSIs form positive perceptions of ChatGPT affordances, negative perceptions pertain to its limited capacity to process the Chinese language. Lastly, GSIs drew on various aspects of TPACK to design lessons, among which content knowledge and its interplay with technology seem to be prominent.}
}
@article{MA202452,
title = {Eye tracking measures of bicyclists’ behavior and perception: A systematic review},
journal = {Transportation Research Part F: Traffic Psychology and Behaviour},
volume = {107},
pages = {52-68},
year = {2024},
issn = {1369-8478},
doi = {https://doi.org/10.1016/j.trf.2024.08.026},
url = {https://www.sciencedirect.com/science/article/pii/S136984782400233X},
author = {Shiyu Ma and Wenwen Zhang and Robert B. Noland and Clinton J. Andrews},
keywords = {Eye-tracking, Cycling experiments, Gaze metric, Safety, Stress},
abstract = {With improved portability and affordability, eye tracking devices have facilitated an expanding range of cycling experiments aimed at understanding cycling behavior and potential risks. Given the complexity of cyclists’ visual behavior and gaze measurements, we provide a comprehensive review with three key focuses: 1) the adoption and interpretation of various gaze metrics derived from cycling experiments, 2) a summary of the findings of those experiments, and 3) identifying areas for future research. A systematic review of three databases yielded thirty-five articles that met our inclusion criteria. Our review results show that cycling experiments with eye tracking allow analysis of the viewpoint of the cyclist and reactions to the built environment, road conditions, navigation behavior, and mental workload and/or stress levels. Our review suggests substantial variation in research objectives and the consequent selection of eye-tracking devices, experimental design, and which gaze metrics are used and interpreted. A variety of general gaze metrics and gaze measurements related to Areas of Interest (AOI) are applied to infer cyclists’ mental workload/stress levels and attention allocation respectively. The diversity of gaze metrics reported in the literature makes cross-study comparisons difficult. Areas for future research, especially potential integration with computer vision are also discussed.}
}
@article{JACKSON2024740786,
title = {A high-density genetic linkage map and QTL identification for growth traits in dusky kob (Argyrosomus japonicus)},
journal = {Aquaculture},
volume = {586},
pages = {740786},
year = {2024},
issn = {0044-8486},
doi = {https://doi.org/10.1016/j.aquaculture.2024.740786},
url = {https://www.sciencedirect.com/science/article/pii/S0044848624002473},
author = {Tassin Kim Jackson and Clint Rhode},
keywords = {Aquaculture, Genetic architecture, Candidate genes, Marker-assisted selection, Selective breeding},
abstract = {High-density genetic linkage maps provide a foundational genomic resource for quantitative trait locus (QTL) mapping, candidate gene localisation, and comparative genomic analysis. Data from such studies, in turn, can be incorporated into marker or genomics assisted selective breeding strategies for increased efficiency of aquaculture production. This study aimed to construct the first high-density genetic linkage map for dusky kob (Argyrosomus japonicus) a commercially important marine finfish in Asia, Australia, and South Africa. Using 2b-restriction site-associated DNA (2b-RAD) sequencing for genome-wide single nucleotide polymorphism (SNP) genotyping, in three full-sib F1 families (Family 1, n = 69 offspring; Family 2, n = 73 offspring; and Family 3, n = 70 offspring), led to the discovery and genotyping of 22,789 SNPs. Among these, 3992 quality filtered and informative SNPs were mapped to 24 linkage groups (LGs), aligning with the species' proposed haploid chromosome number. The total integrated genetic map spanned a length of 2550 cM with an average marker spacing of 0.68 cM, achieving a genome coverage of 98.61%. Male and female specific maps highlighted differential map lengths and recombination rates between the sexes, with the female map slightly longer and a lower recombination frequency than for the male. QTL analysis for growth-related traits, weight (W), standard length (sL), and Fulton's condition factor (K), identified a total of 25 QTLs of which five QTLs were found to be consistently shared across the traits. Collectively, these shared QTLs explained a substantial proportion of the phenotypic variance, accounting for between 9.30 and 19.30% of the observed variation, suggesting potential major genes for growth. These QTL regions led to the discovery of 65 potential candidate genes, including 11 genes that were specifically located within the shared QTLs. These genes were linked to essential biological processes, including metabolism, immunity, stress response, development, and vascular function. The establishment of this high-density genetic linkage map represents an important genomic resource for comprehending the genetic determinants of economically important traits in A. japonicus, with implications for advancing and optimising ongoing marker-assisted selection (MAS) initiatives in the species.}
}
@article{CUBILLOSPINILLA2025106354,
title = {Neural foundations of creativity: A voxel-based meta-analysis of the activations and deactivations underlying creativity across linguistic, musical, and visual domains},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {178},
pages = {106354},
year = {2025},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2025.106354},
url = {https://www.sciencedirect.com/science/article/pii/S0149763425003550},
author = {Leidy Cubillos-Pinilla and Allegre L. Hadida and Sandra Baez and Hernan Hernandez and Mert Kizilyamac},
keywords = {Creativity, FMRI deactivations, Alternative uses task, Seed-based d mapping},
abstract = {The neuroscience of creativity has proposed that shared and domain-specific brain mechanisms underlie creative thinking. However, greater nuance is needed in characterizing these mechanisms, and limited neuroimaging analyses, especially regarding the relationship between the Alternative Uses Task (AUT) and other linguistic tasks, have so far prevented a comprehensive understanding of the neural basis of creativity. This paper offers to fill these gaps with a closer examination of the contributions of the specific domains and the deactivations associated with creativity. We conduct a voxel-based meta-analysis of 43 neuroimaging studies involving 1118 participants. Using Seed-Based d Mapping, we investigate the spatial activity maps in the brain associated with overall creativity and with specific domains. Our findings reveal various domain-general mechanisms related to creativity, including working memory, the ability to connect distantly related concepts, the inhibition of conventional thought, interoception, internal goal orientation, mind wandering, and mental motor simulations. We also identify domain-specific mechanisms of creativity that differ by modality. Linguistic creativity requires inhibiting typical semantic associations, musical creativity involves auditory-motor integration and spontaneous expression, and visual creativity depends on inhibiting habitual visuospatial associations. Additionally, AUT is more effective at capturing novel tool manipulation and ideation rather than elaborative creative processes, which limits its scope. This meta-analysis underscores that creativity depends on multi-component neural circuits and highlights the need for future research to report deactivations, investigate neurofeedback applications, and analyze long-term and collaborative creative processes.}
}
@article{WANG2025108658,
title = {Recent advances in engineering microbial lipases for industrial applications},
journal = {Biotechnology Advances},
volume = {83},
pages = {108658},
year = {2025},
issn = {0734-9750},
doi = {https://doi.org/10.1016/j.biotechadv.2025.108658},
url = {https://www.sciencedirect.com/science/article/pii/S0734975025001442},
author = {Geng Wang and Asma Abdella and Mohamadali Fakhari and Jie Dong and Kevin K. Yang and Shang-Tian Yang},
keywords = {Lipase, Enzyme, Genetic engineering, Immobilization, Protein engineering},
abstract = {Lipases, a green biocatalyst found in animals, plants, and microorganisms, are widely used in the agricultural, biofuel, cosmetics, chemical, food, pharmaceutical, and textile industries due to their versatility, exceptional specificity, and ease of production and use. However, the presence of multiple isoforms of microbial lipases often limits their applications and requires costly purification. There are also growing demands for improved lipase stability, activity, and specificity in industrial applications. One emerging research direction in this field is integrating synthetic biology and engineering tools to design novel lipases for diverse industrial applications. Recent progress in protein engineering, immobilization technologies, and artificial intelligence (AI) tools have significantly improved lipase catalytic performance. This paper provides a comprehensive review of the classification, general characteristics, industrial production and applications of lipases and recent advances in engineering lipases and lipase-producing microbial cells to develop novel lipase-based bioprocesses and bioproducts.}
}
@article{MIRINDI2025100275,
title = {Prediction of flexural and split tensile strength of waste glass-concrete composite using machine learning algorithms},
journal = {Green Technologies and Sustainability},
pages = {100275},
year = {2025},
issn = {2949-7361},
doi = {https://doi.org/10.1016/j.grets.2025.100275},
url = {https://www.sciencedirect.com/science/article/pii/S2949736125001095},
author = {Derrick Mirindi and David Sinkhonde and Tajebe Bezabih and Frederic Mirindi and Oluwakemi Oshineye and Patrice Mirindi},
keywords = {Waste glass concrete, Machine learning, AdaBoost, XGBoost, LightGBM, Gaussian process},
abstract = {Waste material, including glass, presents significant environmental challenges due to its non-biodegradable nature and low global recycling rates. Incorporating waste glass into concrete offers a sustainable solution, but predicting its effects on mechanical properties, particularly flexural (fb) and split tensile (ft) strengths, remains complex. This study utilizes machine learning (ML) algorithms (decision tree (DT), extreme gradient boosting (XGBoost), adaptive boosting (AdaBoost), light gradient boosting machine (LightGBM), support vector regression (SVR), and gaussian process (GP)) to predict fb and ft strengths based on compressive strength (fc), concrete age, and glass replacement percentage of glass-concrete composites. Thirteen experimental studies were utilized using secondary data. Results demonstrate that Pearson correlation analysis reveals strong interdependence among mechanical properties (fc-fb: 0.809-0.876, fc-ft: 0.927-0.948, fb-ft: 0.943-0.970), with negligible influence of glass type and moderate positive impact of replacement percentage. The ML algorithms each offer unique predictive strengths—most notably, XGBoost training model achieves near-perfect accuracy (with R2 equal to 0.9991). However, k-fold cross-validation revealed overfitting concerns limiting applicability to conventional concrete compositions. Non-parametric analyses reveal moderate fc-fb correlations (Spearman’s ρ=0.5879, p=0.0739) and statistically significant fc-ft relationships (ρ=0.6364, p=0.0479), while ML models achieve high predictive accuracy by exploiting multi-feature interactions beyond simple pairwise correlations. These ML models enable optimized mix designs, advancing sustainable construction through efficient waste glass utilization as a partial aggregate replacement.}
}
@article{ROSCOE2023103059,
title = {Automated strategy feedback can improve the readability of physicians’ electronic communications to simulated patients},
journal = {International Journal of Human-Computer Studies},
volume = {176},
pages = {103059},
year = {2023},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2023.103059},
url = {https://www.sciencedirect.com/science/article/pii/S107158192300068X},
author = {Rod D. Roscoe and Renu Balyan and Danielle S. McNamara and Michelle Banawan and Dean Schillinger},
keywords = {Automated feedback, Natural language processing, Patient-physician communication, Readability, Electronic health records, Health literacy},
abstract = {Modern communication between health care professionals and patients increasingly relies upon secure messages (SMs) exchanged through an electronic patient portal. Despite the convenience of secure messaging, challenges include gaps between physician and patient expertise along with the asynchronous nature of such communication. Importantly, less readable SMs from physicians (e.g., too complicated) may result in patient confusion, non-adherence, and ultimately poorer health outcomes. The current simulation trial synthesizes work on patient-physician electronic communication, message readability assessments, and feedback to explore the potential for automated strategy feedback to improve the readability of physicians’ SMs to patients. Within a simulated secure messaging portal featuring multiple simulated patient scenarios, computational algorithms assessed the complexity of SMs written by 67 participating physicians to patients. The messaging portal provided strategy feedback for how physician responses might be improved (e.g., adding details and information to reduce complexity). Analyses of changes in SM complexity revealed that automated strategy feedback indeed helped physicians compose and refine more readable messages. Although the effects for any individual SM were slight, the cumulative effects within and across patient scenarios showed trends of decreasing complexity. Physicians appeared to learn how to craft more readable SMs via interactions with the feedback system. Implications for secure messaging systems and physician training are discussed, along with considerations for further investigation of broader physician populations and effects on patient experience.}
}
@article{WANG2024102809,
title = {Exploring product rendering generation design catering to multi-emotional needs through the Superiority Chart-Entropy Weight method and Stable Diffusion model},
journal = {Advanced Engineering Informatics},
volume = {62},
pages = {102809},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102809},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624004579},
author = {Zeng Wang and Hui-ru Pan and Jiang-shan Li and Shi-fan Niu},
keywords = {Superiority Chart-Entropy Weight method, Stable Diffusion model, Product rendering, Multi-emotional needs, Tunable weight allocation mechanism, Data driven},
abstract = {The experience economy has shifted user demands towards emotionalization, emphasizing multi-emotional considerations as pivotal in design. This study addresses challenges in accurately determining emotional needs and the inadequacy of current intelligent design approaches. It proposes a method for designing multi-emotional product renderings by integrating the Superiority Chart-Entropy Weight method with the Stable Diffusion model within a big data framework. Initially, online user comments, hand-drawn sketches, and renderings of target products are collected. The Superiority Chart-Entropy Weight is then adopted to establish weights for multi-emotional needs, creating an allocation mechanism of these weights. Incorporating these multi-emotional weights, a Stable Diffusion model embedded with LoRa is trained to generate diverse rendering schemes. Finally, the Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS) method is employed to select the optimal rendering scheme for 3D display. An experimental case study focusing on new energy vehicle renderings demonstrates the efficiency of this approach in precisely meeting users’ multi-emotional needs, thereby enhancing design efficiency and quality. Comparative experiments indicate that the method proposed in this study offers advantages in creating multi-emotional renderings. This study innovatively introduces a finer-grained multi-emotional needs confirmation method for users, overcoming the ambiguity and uncertainty of traditional recognition approaches, and develops a Stable Diffusion generation method tailored for product renderings, providing practical value in streamlining the conventional product design representation cycle and enhancing design efficiency, quality and user satisfaction.}
}
@article{SAURA2024100597,
title = {Is AI-based digital marketing ethical? Assessing a new data privacy paradox},
journal = {Journal of Innovation & Knowledge},
volume = {9},
number = {4},
pages = {100597},
year = {2024},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2024.100597},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X24001367},
author = {Jose Ramon Saura and Vatroslav Škare and Durdana Ozretic Dosen},
keywords = {Artificial intelligence, Digital marketing, Ethics, Privacy, Multiple correspondence analysis, R},
abstract = {The rapid development of artificial intelligence (AI) has significantly transformed digital marketing enhancing its effectiveness and raising new ethical and privacy concerns. This study investigates the ethical implications of AI-based digital marketing, particularly focusing on user privacy. In terms of methodology, a systematic literature review (SLR) was conducted to identify relevant variables, followed by Multiple Correspondence Analysis (MCA) using R within the framework of homogeneity analysis of variance using alternating least squares (HOMALS). The MCA analysis identified 3 multivariate groupings, and 21 individual variables extracted from 28 studies. The MCA identified a total of 4 clusters in the eigenvalues/variances analysis, and 5 clusters in the biplot analysis. The findings emphasize the need for a balanced approach that respects user privacy and ethical use of data when developing actions using AI-based digital marketing. However, no significant relationship is evident between the study of variables such as cross-device tracking or data-driven technologies and, the ethics of AI-based digital marketing, despite these being the most profitable actions in this environment. There is no evidence of developing personalized social media content or ads linked to privacy standards. However, a strong connection between behavioral analytics, smart content and metaverse is identified, highlighting the risks of this emerging technology in this research field, as it is not linked to privacy or ethics. Among the results, the strong proximity of real-time tracking, IoT, and surveillance variables underscores the critical need to ethically understand how user behavior in real-time is being monitored, as they do not offer a strong link to privacy or ethics. Additionally, this study provides 21 future research questions that address whether these practices are being ethically implemented, following standards like “privacy-by-default” or “privacy-by-design,” and complying with privacy laws in AI-based digital marketing. To ensure these practices align with ethical standards, it is essential to adopt frameworks prioritizing data dignity, which calls for treating user data as an extension of personal identity, requiring responsible and ethical handling throughout the data collection and processing lifecycle.}
}
@article{BRAHMACHARY2025129272,
title = {Large language model-based evolutionary optimizer: Reasoning with elitism},
journal = {Neurocomputing},
volume = {622},
pages = {129272},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.129272},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224020435},
author = {Shuvayan Brahmachary and Subodh M. Joshi and Aniruddha Panda and Kaushik Koneripalli and Arun Kumar Sagotra and Harshil Patel and Ankush Sharma and Ameya D. Jagtap and Kaushic Kalyanaraman},
keywords = {Large language models, Evolutionary Optimizers, Multi-objective optimization, Aerodynamic Design},
abstract = {Large Language Models (LLMs) have demonstrated remarkable reasoning abilities, prompting interest in their application as black-box optimizers. This paper asserts that LLMs possess the capability for zero-shot optimization across diverse scenarios, including multi-objective and high-dimensional problems. We introduce a novel population-based method for numerical optimization using LLMs called Large Language-Model-Based Evolutionary Optimizer (LEO). Our hypothesis is supported through numerical examples, spanning benchmark and industrial engineering problems such as supersonic nozzle shape optimization, heat transfer, and windfarm layout optimization. We compare our method to several gradient-based and gradient-free optimization approaches. While LLMs yield comparable results to state-of-the-art methods, their imaginative nature and propensity to hallucinate demand careful handling. We provide practical guidelines for obtaining reliable answers from LLMs and discuss method limitations and potential research directions.}
}
@article{LIU2024103191,
title = {Does modality matter? A meta-analysis of the effect of video input in L2 listening assessment},
journal = {System},
volume = {120},
pages = {103191},
year = {2024},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2023.103191},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X23002130},
author = {Tingting Liu and Vahid Aryadoust},
keywords = {Audio-based listening assessment, Meta-Analysis, Meta-regression, Target language use (TLU) domain, Video-based listening assessment, Visual cues},
abstract = {Over the past two decades, there has been a growing research interest in examining the effects of video-based second language (L2) listening tests. However, these studies have shown inconsistency in their findings, prompting the need for a comprehensive analysis. This study aims to address this issue by conducting a meta-analysis to synthesize the quantitative research in this field. Our primary objective is to determine the pooled effect of video-based L2 listening assessment on test-takers’ listening comprehension and identify moderators that could potentially influence this effect. These potential moderators encompassed participants' characteristics, research method, video input features, and outcome measures. Through an extensive search process, we identified a total of 28 primary studies (years 1984–2022) that contributed data from 43 independent samples. We found that video input had a small overall positive effect on test-takers’ performance (g = 0.297). Additionally, we observed patterns in the effect of video input across different levels of moderators such as test-takers’ language proficiency, research design, reporting of reliability, speaker presentation, video length, question accessibility, note-taking availability, and item format. We discuss the implications of these findings and conclude with the limitations and several perspectives for future research.}
}
@article{SHAHIN2024102462,
title = {Harnessing customized AI to create voice of customer via GPT3.5},
journal = {Advanced Engineering Informatics},
volume = {61},
pages = {102462},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102462},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624001101},
author = {Mohammad Shahin and F. Frank Chen and Ali Hosseinzadeh},
keywords = {ChatGPT, VoC, Lean Six Sigma, Industry 5.0, Artificial General Intelligence},
abstract = {The integration of customer feedback is universally acknowledged as crucial in the product development process. Yet, traditional feedback collection methods employed by companies, such as interviews and surveys, have remained mainly unchanged and come with limitations. Interviews often fail to accurately capture customers' needs due to communication barriers, while surveys prompt only incremental changes instead of inspiring innovation. This challenge is compounded in the service industry, where feedback is intangible and more difficult to quantify. Text analysis presents a promising solution to delve into customer preferences more deeply, providing insights that can guide the development of new products and services. Our research advances the use of generative AI, specifically the GPT engine, beyond its conventional role as a chatbot. We innovate by adapting it to extract actionable insights from customer-service interactions, offering real-time, valuable data for decision-making and representing a significant leap forward in Voice of the Customer (VoC) analysis.}
}
@article{DONG2024116666,
title = {Ship pipe route design based on NSGA-III and multi-population parallel evolution},
journal = {Ocean Engineering},
volume = {293},
pages = {116666},
year = {2024},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2024.116666},
url = {https://www.sciencedirect.com/science/article/pii/S0029801824000039},
author = {Zong-ran Dong and Wan-wan Luo},
keywords = {Ship pipe route design, Multi-objective optimization, NSGA-III, Heuristic pathfinding, OpenMP, Parallel evolution},
abstract = {Ship pipe route design (SPRD) aims to generate pipe layouts while considering various objectives and constraints in a confined 3D space, leading to extremely high complexity. To solve the problem of SPRD, traditional methods often adopt weighted summation of sub-objectives, introduce penalty functions to convert it to a single-objective optimization problem. However, these methods tend to yield a single optimal pipe route design pattern, and some existing multi-objective pipe routing algorithms do not have high search performance or sufficient treatment of constraints. Based on the grid-space decomposition model, this paper establishes a multi-objective pipe routing optimization model with several sub-objectives including path length, bends number, path energy, number of air-pockets, and number of violated bending distance, which also considers pipe routing for different diameters and interface direction requirements. A ship pipe route design framework based on the NSGA-III (Non-dominated Sorting Genetic algorithm III) is proposed, and its embedded pathfinding algorithm can explore pipe route using heuristic information and failure retry strategy, which greatly reduces the algorithm complexity compared to the classical algorithms such as A* and LEE and also facilitates parallel implementation. By employing OpenMP technology to achieve parallel evolution of multiple populations, more Pareto optimal solutions can be obtained in approximately the same timeframe as single population evolution. Finally, through comparative experiments using simulated cases, the feasibility and advancement of the proposed method are verified.}
}
@article{MELO2025322,
title = {An overview of randomized phase III clinical trials of cancer nanomedicines},
journal = {Cancer Pathogenesis and Therapy},
volume = {3},
number = {4},
pages = {322-336},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2024.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S2949713224000867},
author = {Micael N. Melo and Ricardo G. Amaral and Lucas R. {Melo de Andrade} and Patricia Severino and Cristina Blanco-Llamero and Luciana N. Andrade and Eliana B. Souto},
keywords = {Antineoplastic drugs, Chemotherapy, Nanomedicine, Drug delivery systems, Personalized medicine, Clinical trials},
abstract = {Background
Cancer therapy has undergone significant advances in recent decades attributed to personalized medicine and targeted drug delivery. Among the promising approaches, the use of nano-based delivery systems has become a relevant approach capable of improving treatment by releasing antineoplastic drugs at the target site, improving therapeutic efficacy, minimizing cytotoxicity in healthy tissues, and ultimately, reducing the intensity of adverse effects of chemotherapy. This study prospectively evaluated the impact of formulating anti-neoplastic drugs as nanomedicines on clinical response, overall survival, safety, and quality of life of cancer patients, based on the outcomes of randomized clinical trials.
Methods
A literature review was carried out by systematically searching the PubMed/MEDical Literature Analysis and Retrieval System Online (MEDLINE), Excerpta Medica Database (EMBASE), and Latin American and Caribbean Health Sciences Literature (LILACS) databases for phase III clinical trials, comparing nanomedicines with conventional therapies for the treatment of various cancer types.
Results
The nanomedicines analyzed were those that are approved and used in Brazil, considering the country's emerging market for advanced cancer treatments. From a total of 303 articles found, 26 articles were selected for systematic review. Studies showed that PEGylated l-asparaginase achieved a similar therapeutic effect to that of l-asparaginase, with fewer applications due to its longer half-life. Paclitaxel bound to albumin improved therapeutic efficacy as well as reduced infusion time and solvent-related toxicity of the conventional paclitaxel formulation. PEGylated liposomal doxorubicin showed better pharmacokinetics, reduced cardiotoxicity, and improved quality of life in cancer patients compared to that of free doxorubicin.
Conclusions
This study reinforces the scientific evidence of the added value of nanomedicines to improve therapeutic efficacy and reduce toxicity in patients under chemotherapy.}
}
@article{BIE2025101002,
title = {Can news predict firm bankruptcy?},
journal = {Journal of Financial Markets},
pages = {101002},
year = {2025},
issn = {1386-4181},
doi = {https://doi.org/10.1016/j.finmar.2025.101002},
url = {https://www.sciencedirect.com/science/article/pii/S1386418125000424},
author = {Siyu Bie and Guanhao Feng and Naixin Guo and Jingyu He},
keywords = {Bankruptcy prediction, ChatGPT, Generative AI, News data, Sentiment},
abstract = {We examine whether real-time business news predicts firm bankruptcy. Using full-text daily articles from the Dow Jones Newswires database, we generate firm-level predictors with ChatGPT and benchmark against FinBERT and dictionary-based models. ChatGPT-based variables outperform alternatives, with sentiment scores showing predictive power across horizons. Full-text news significantly enhance predictive accuracy over headlines. News-based measures add explanatory power beyond financial variables. Finally, we show that news captures timely information on macroeconomic conditions relevant to bankruptcy prediction, such as VIX, real GDP growth, and recession probability.}
}
@article{2024A11,
title = {Guide for Authors},
journal = {Journal of the American Society of Echocardiography},
volume = {37},
number = {1},
pages = {A11-A19},
year = {2024},
issn = {0894-7317},
doi = {https://doi.org/10.1016/S0894-7317(23)00603-X},
url = {https://www.sciencedirect.com/science/article/pii/S089473172300603X}
}
@article{ALIYEV2025101006,
title = {Business simulation games integrated with emerging technologies in business education: A review},
journal = {Entertainment Computing},
volume = {55},
pages = {101006},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2025.101006},
url = {https://www.sciencedirect.com/science/article/pii/S1875952125000862},
author = {Murad Aliyev and Vagif Fatullayev and Sadagat Aliyeva},
keywords = {Business simulation games, BSGs, Emerging technologies, Simulation-based learning, Business education, Review},
abstract = {Business simulation games (BSGs) have gained popularity in higher education, offering students hands-on experiences. Recent advancements in emerging technologies have further fuelled their growth, contributing to the global expansion of BSG market. This review aims to examine the integration of AI, generative AI chatbots, extended reality (XR), virtual reality (VR) (semi-immersive – 3D animated; fully immersive – business training simulators; mobile VR – 360-degree videos), blockchain, mobile and web-based technologies into BSGs and their potential to enhance learning outcomes. This literature review was conducted following the PRISMA framework. Through thematic synthesis analysis of 46 empirical studies, this study identified three major themes: (1) the pedagogical benefits of integrating emerging technologies in BSGs; (2) the factors that shape active student participation, including contextual relevance, instructional design, and intrinsic motivation; and (3) the persistent challenges related to technology integration, cultural adaptability, and inclusive access. The review highlights the dominance of quantitative and mixed-methods approaches, a lack of research in non-Western contexts, and the underrepresentation of long-term impact studies. It also emphasizes the need for pedagogically grounded, culturally responsive, and inclusive BSG designs supported by well-prepared instructors.}
}
@article{QUINTANILLA2025801,
title = {Artificial intelligence and robotics in the hydrogen lifecycle: A systematic review},
journal = {International Journal of Hydrogen Energy},
volume = {113},
pages = {801-817},
year = {2025},
issn = {0360-3199},
doi = {https://doi.org/10.1016/j.ijhydene.2025.03.016},
url = {https://www.sciencedirect.com/science/article/pii/S0360319925010973},
author = {Paulina Quintanilla and Ayman Elhalwagy and Lijia Duan and Salman {Masoudi Soltani} and Chun Sing Lai and Pantea Foroudi and Md Nazmul Huda and Monomita Nandy},
abstract = {Hydrogen lifecycle, encompassing production, storage, and transportation, is crucial in the global transition to clean energy. Integrating artificial intelligence (AI) and robotics into hydrogen lifecycle offers promising solutions to enhance efficiency, safety, and scalability. This paper presents a comprehensive review of the current advancements published over the past two decades (2005–2025), analyzing AI and robotics applications across hydrogen production, storage, and transportation. We systematically examine the role of AI in optimizing hydrogen production processes, improving the safety and efficiency of storage systems, and enhancing transportation logistics through real-time monitoring and route optimization. Additionally, the paper explores the use of robotics to handle complex tasks in hazardous environments within the hydrogen lifecycle. We identify key challenges and gaps in the literature and propose future research directions to fully leverage AI and robotics across hydrogen technologies. This review serves as a foundation for researchers and practitioners seeking to advance the integration of AI and robotics in the hydrogen economy.}
}
@article{RENAUD2024103877,
title = {VISTA: An inclusive insider threat taxonomy, with mitigation strategies},
journal = {Information & Management},
volume = {61},
number = {1},
pages = {103877},
year = {2024},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2023.103877},
url = {https://www.sciencedirect.com/science/article/pii/S0378720623001258},
author = {Karen Renaud and Merrill Warkentin and Ganna Pogrebna and Karl {van der Schyff}},
keywords = {Insider threats, Taxonomy, Mitigations, Cybersecurity},
abstract = {Insiders have the potential to do a great deal of damage, given their legitimate access to organisational assets and the trust they enjoy. Organisations can only mitigate insider threats if they understand what the different kinds of insider threats are, and what tailored measures can be used to mitigate the threat posed by each of them. Here, we derive VISTA (inclusiVe InSider Threat tAxonomy) based on an extensive literature review and a survey with C-suite executives to ensure that the VISTA taxonomy is not only scientifically grounded, but also meets the needs of organisations and their executives. To this end, we map each VISTA category of insider threat to tailored mitigations that can be deployed to reduce the threat.}
}
@article{DAI2023108129,
title = {ITF-WPI: Image and text based cross-modal feature fusion model for wolfberry pest recognition},
journal = {Computers and Electronics in Agriculture},
volume = {212},
pages = {108129},
year = {2023},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2023.108129},
url = {https://www.sciencedirect.com/science/article/pii/S0168169923005173},
author = {Guowei Dai and Jingchao Fan and Christine Dewi},
keywords = {Cross-modal fusion, Contextual transformer, Pyramid squeeze attention mechanism, Convolutional neural network and bi-directional long short-term memory, Pest recognition},
abstract = {As one of the necessary cash crops in China and many other countries, wolfberry is parasitized by multiple pests, and its yield is highly susceptible to being affected. On the other hand, agricultural pest backgrounds are complex. When identifying them, single-modal models cannot utilize diverse data types across modalities, resulting in low identification accuracy and data utilization. Traditional unimodal identification models can no longer meet the needs of multimodal data development in agriculture. To overcome these challenges, the ITF-WPI cross-modal feature fusion model is proposed, which consists of CoTN and ODLS for parallel processing of images and text, respectively. We incorporate the Transformer structure (CoT), which focuses on contextual feature extraction, into CoTN to make full use of the rich static and dynamic linear fusion contexts between adjacent keys and improve the 4-stage network of CoTN using Pyramid Squeezed Attention (PSA) to improve the extraction of multi-scale feature structure information and effectively promote the interaction of in-depth features with multi-scale spatial information. The ODLS network constructed by introducing 1D convolutional and bidirectional LSTM stacking has been shown to have more robust text feature acquisition than other advanced convolutional neural network-long short-term memory (CNN-LSTM) models from experimental results, with a 30% reduction in MACCs compared to the optimal model. The results showed that ITF-WPI performed well in accuracy, F1 score, model size, and MACCs with 97.98%, 93.19%, 52.20 MB, and 7.828 G compared to the classical state-of-the-art (SOTA) model, lightweight SOTA model and advanced Transformer neural network synthesis, respectively. The model has critical practical applications for promoting the development of cross-modal models in agriculture and research on wolfberry pest control and improving wolfberry yields. The code and dataset for this study will be posted on GitHub (https://github.com/wemindful/Cross-modal-pest-Identifying) as soon as the study is released, and new data will be updated in the future.}
}
@article{SAHUT2024114572,
title = {Antecedents and consequences of fake reviews in a marketing approach: An overview and synthesis},
journal = {Journal of Business Research},
volume = {175},
pages = {114572},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.114572},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324000766},
author = {Jean Michel Sahut and Michel Laroche and Eric Braune},
keywords = {Fake reviews, Technology, Behavior, Regulation, Strategy, Artificial intelligence},
abstract = {Fake reviews, characterized as misleading, can be positive, negative, or neutral, varying greatly across sectors and products. Their detrimental effects include reducing the informativeness and credibility of genuine reviews, leading to a distorted perception of products and affecting the development of online product reviews. This literature synthesis proposes a multidisciplinary approach to understand and combat fake reviews, emphasizing the need to differentiate them from genuine feedback through psychological and technological tactics. It outlines the importance of exploring the credibility routes influencing consumer behavior, the dynamics of fake review production, and the consequential effects on businesses and consumers. It also highlights the emergence of artificial intelligence as a powerful tool in identifying and combating fake reviews, advocating for continued exploration of detection strategies to preserve integrity and trust in online marketplaces. Lastly, it suggests avenues of research to deepen our knowledge of the antecedents and consequences of fake reviews, as well as of the various means available to prevent them, including technological, behavioral, and regulatory strategies.}
}
@article{ARDIMENTO2025112569,
title = {A novel LLM-based classifier for predicting bug-fixing time in Bug Tracking Systems},
journal = {Journal of Systems and Software},
volume = {230},
pages = {112569},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2025.112569},
url = {https://www.sciencedirect.com/science/article/pii/S0164121225002389},
author = {Pasquale Ardimento and Michele Capuzzimati and Gabriella Casalino and Daniele Schicchi and Davide Taibi},
keywords = {Bug fixing time, Software maintenance and evolution, Large language models, Zero-shot learning},
abstract = {Predicting whether a newly submitted bug will be resolved quickly or slowly is a crucial aspect of the bug triage process, as it enables project managers to estimate software maintenance efforts and manage development workflows more effectively. This paper proposes a deep learning approach for classifying bug reports into two categories—FAST or SLOW—based on their expected fixing time. The method leverages a feature set composed of the bug description and reporter comments and adopts a transfer learning strategy using pre-trained Large Language Models (LLMs). The problem is framed as a supervised text classification task, where LLMs exploit their ability to learn rich contextual representations of language. We introduce a novel classification workflow that guides the LLM through a structured prompt, combining two design patterns: the persona pattern to contextualize the task and the input semantic pattern to organize textual information. The workflow relies on zero-shot learning to assess whether the intrinsic knowledge embedded in the LLMs is sufficient for this prediction task. We conducted a comprehensive evaluation of three state-of-the-art LLMs across multiple real-world datasets sourced from Bugzilla, encompassing a diverse range of software projects. The experimental results demonstrate that the proposed method is effective in accurately identifying fast-resolving bugs. Among the evaluated models, LLaMA3-8B consistently delivered superior performance. Additionally, the absence of statistically significant performance variations across datasets highlights the generalizability of the approach. Notably, the LLMs maintained strong performance even on small and imbalanced datasets, underscoring their robustness and practical applicability in real-world, data-scarce scenarios.}
}
@article{KENNEDY2025106116,
title = {Asia-Pacific Developments},
journal = {Computer Law & Security Review},
volume = {56},
pages = {106116},
year = {2025},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2025.106116},
url = {https://www.sciencedirect.com/science/article/pii/S0267364925000111},
author = {Gabriela Kennedy and Joanna Wong and Justin Lai and James North and Philip Catania and Michael do Rozario and Jack Matthews and Arun Babu and Gayathri Poti and Ishita Vats and Kiyoko Nakaoka and Lam Chung Nian and Emma Choe},
abstract = {This column provides a country by country analysis of the latest legal developments, cases and issues relevant to the IT, media and telecommunications' industries in key jurisdictions across the Asia Pacific region. The articles appearing in this column are intended to serve as ‘alerts’ and are not submitted as detailed analyses of cases or legal developments.}
}
@article{VINTHERDAUGAARD2024101386,
title = {Blockchain solutions with consensus algorithms and immediate finality: Toward Panopticon-style monitoring to enhance anti-money laundering},
journal = {Electronic Commerce Research and Applications},
volume = {65},
pages = {101386},
year = {2024},
issn = {1567-4223},
doi = {https://doi.org/10.1016/j.elerap.2024.101386},
url = {https://www.sciencedirect.com/science/article/pii/S1567422324000310},
author = {Thomas {Vinther Daugaard} and Jakob {Bisgaard Jensen} and Robert J. Kauffman and Kwansoo Kim},
keywords = {Anti-money laundering (AML), Blockchain, Compliance, Distributed ledger technology (DLT), Exploratory research, Know-your-customer (KYC), Transaction cost theory (TCE), Transaction monitoring},
abstract = {Banks can reduce resources spent on anti-money laundering (AML) compliance with blockchain-based transaction infrastructure. We consider AML compliance as a superset of know-your-customer (KYC) and transaction monitoring capabilities. We carried out this research with Danske Bank and Concordium, using internal documents and interviews that served as empirical data. We show how storing digital representations of verified IDs with a blockchain can automate tasks and reduce redundant verification in KYC onboarding. Blockchain transparency also improves identifying counterparties, determining funds sources, and creating alerts in transaction monitoring. These reduce time and labor costs for AML compliance, which may lead to smaller banks. When more banks commit to layer-1 blockchain technology, the benefits of blockchain-based AML will increase. We carried out this theory-based qualitative research and encourage ECRA readers to recognize that the emerging technology innovations we study in this article have not yet been widely adopted and implemented by financial services firms. We also include a theoretical model with study hypotheses to make the main constructs that we investigate easily understood by non-technical ECRA readers. The findings we have developed are consistent with early-stage exploration in our research context and are intended to encourage more well-developed empirical results as the passage of time permits such work to be undertaken.}
}
@article{WILKHO2024102293,
title = {FF-BERT: A BERT-based ensemble for automated classification of web-based text on flash flood events},
journal = {Advanced Engineering Informatics},
volume = {59},
pages = {102293},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2023.102293},
url = {https://www.sciencedirect.com/science/article/pii/S1474034623004214},
author = {Rohan Singh Wilkho and Shi Chang and Nasir G. Gharaibeh},
keywords = {Flash flood, Text classification, Multi-label text classification, BERT},
abstract = {The web is a rich information repository that can be mined to uncover additional data about past flash flood (FF) events, currently missing from existing structured databases. However, this information originates from multiple sources (news articles, government records, and weather records among others) and may cover several topics. Furthermore, these topics may be disproportionately covered on the web. The large size and heterogenous nature of web information render manual review difficult. To address this challenge, we have developed a multi-label text classification model, FF-BERT. FF-BERT is designed to classify FF-related web paragraphs into one or more of seven categories: (1) Damage and Economic Impact (DI), (2) Fatalities, Injuries, and Rescue (FIR), (3) Hydrometeorology (HM), (4) Warning and Emergency (WE), (5) Response and Recovery (RR), (6) Public Health (PH), and (7) Mitigation (MG). To develop FF-BERT, we labeled 21,180 paragraphs from FF-related webpages and performed experiments with multiple model architectures based on the widely used language model Bidirectional Encoder Representation from Transformers (BERT). Our final model outperforms the baseline by 11.83%, as measured by the micro-F1 score. In addition, FF-BERT significantly improves the prediction of minority labels (RR-32.1%, PH-260.4%, and MG-138.6%). We demonstrate using real world examples that FF-BERT can be used to uncover new information about flash flood events. This information can be used to enhance existing databases, such as NOAA’s Storm Events Database.}
}
@article{SHEN2025118374,
title = {Advanced deep learning algorithms in food quality and authenticity},
journal = {TrAC Trends in Analytical Chemistry},
volume = {191},
pages = {118374},
year = {2025},
issn = {0165-9936},
doi = {https://doi.org/10.1016/j.trac.2025.118374},
url = {https://www.sciencedirect.com/science/article/pii/S0165993625002420},
author = {Che Shen and Qi Jin and Ganghua Zhou and Ran Wang and Zhenwei Wang and Di Liu and Kezhou Cai and Baocai Xu},
keywords = {Advanced deep learning, Algorithms, Food authentication, Food quality, Artificial intelligence, Food safety},
abstract = {Ensuring food quality and authenticity is critical to the food industry and consumers. With the advancements in Industry 4.0 and Artificial Intelligence (AI) technologies, deep learning (DL) offers unparalleled opportunities to extract information and make decisions on complex or large datasets. However, conventional convolutional neural networks (CNN) and recurrent neural networks (RNN) have limitations. The development of advanced DL algorithms can accommodate the growing demand for complex tasks and herald revolutionary breakthroughs in the field of food quality and authenticity identification, which will continue to be driven by the ongoing development of advanced DL. This review provides a comprehensive overview of various advanced DL algorithms for food quality identification and food authenticity analysis, including advanced variants of CNN, lightweight DL, sequential neural networks, graph neural networks (GNN), deep generative models (DGM), and target detection algorithms. It also surveys recent applications of advanced DL algorithms for Food quality inspection and authenticity analysis. This review discusses the challenges associated with advanced DL and the future trends, offering new insights into the development of advanced DL algorithms in food quality and authenticity. Challenges such as overfitting, scalability, interpretability, accessibility, data privacy, algorithmic bias, and the creation of large databases must be addressed in the application of advanced DL algorithms to drive their further iterations.}
}
@incollection{HARTSON2025411,
title = {Chapter 22 - Empirical UX Evaluation:: Data Collection},
editor = {Rex Hartson and Pardha S. Pyla},
booktitle = {The UX Book (Third Edition)},
publisher = {Morgan Kaufmann},
edition = {Third Edition},
pages = {411-441},
year = {2025},
isbn = {978-0-443-13443-2},
doi = {https://doi.org/10.1016/B978-0-443-13443-2.00022-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443134432000224},
author = {Rex Hartson and Pardha S. Pyla},
keywords = {empirical UX evaluation data collection, critical incident identification, user think-aloud technique, co-discovery, task perform metrics, questionnaires, emotional impact and meaningfulness evaluation data collection, evaluation session protocol, specialized UX evaluation methods},
abstract = {Empirical UX evaluation data collection techniques yield data directly observed and/or measured. They depend on actual experience rather than, say, theory or analysis. In practice, collection of objective quantitative empirical data usually means involving usage by real user participants performing representative or real tasks. Collection of subjective quantitative empirical data usually depends on questionnaires, often featuring semantic differential scales. Qualitative empirical data are used to identify UX problems in a design. Useful techniques include user think-aloud sessions and the identification of critical incidents, usage events that reveal something significant about the quality of the user experience, observed during task performance.}
}
@article{MANCHEL2024111322,
title = {From sampling to simulating: Single-cell multiomics in systems pathophysiological modeling},
journal = {iScience},
volume = {27},
number = {12},
pages = {111322},
year = {2024},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2024.111322},
url = {https://www.sciencedirect.com/science/article/pii/S2589004224025471},
author = {Alexandra Manchel and Michelle Gee and Rajanikanth Vadigepalli},
keywords = {Systems biology, Data processing in systems biology, In silico biology, Biological constraints, Omics},
abstract = {Summary
As single-cell omics data sampling and acquisition methods have accumulated at an unprecedented rate, various data analysis pipelines have been developed for the inference of cell types, cell states and their distribution, state transitions, state trajectories, and state interactions. This presents a new opportunity in which single-cell omics data can be utilized to generate high-resolution, high-fidelity computational models. In this review, we discuss how single-cell omics data can be used to build computational models to simulate biological systems at various scales. We propose that single-cell data can be integrated with physiological information to generate organ-specific models, which can then be assembled to generate multi-organ systems pathophysiological models. Finally, we discuss how generic multi-organ models can be brought to the patient-specific level thus permitting their use in the clinical setting.}
}
@article{CANANAU2025104816,
title = {Critical thinking in preparation for student teachers’ professional practice: A case study of critical thinking conceptions in policy documents framing teaching placement at a Swedish university},
journal = {Teaching and Teacher Education},
volume = {153},
pages = {104816},
year = {2025},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2024.104816},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X24003494},
author = {Iulian Cananau and Silvia Edling and Björn Haglund},
keywords = {Critical thinking, Teacher education, Placement, Teacher profession, Concept, Policy documents},
abstract = {This paper explores the conceptions of critical thinking in national and local policy documents for teaching placement, using the case of teacher education programs at a Swedish university. The concept under scrutiny is based on three contemporary theoretical models of critical thinking in education: critical thinking movement, critical pedagogy, and “criticality” movement. In Sweden, the teacher profession is framed with a broader socio-ethical scope than the focus on individual cognitive skills of the critical thinking movement. Critical reflection and self-reflection, two conceptions identified with the criticality ideal of education for critical being, prevail in the analyzed documents.}
}
@article{CANIGLIA2025107605,
title = {FOBICS: Assessing project security level through a metrics framework that evaluates DevSecOps performance},
journal = {Information and Software Technology},
volume = {178},
pages = {107605},
year = {2025},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2024.107605},
url = {https://www.sciencedirect.com/science/article/pii/S0950584924002106},
author = {Alessandro Caniglia and Vincenzo Dentamaro and Stefano Galantucci and Donato Impedovo},
keywords = {DevSecOps, Metrics framework, Project security, Software engineering, Evaluating security, DevOps, Security assessment, Software metrics, Secure software development, Business metrics},
abstract = {Context:
In today’s software development landscape, the DevSecOps approach has gained traction due to its focus on the software development process and bolstering security measures in projects, a task in light of the ever-evolving cybersecurity threats.
Objective:
This study aims to address the lack of metrics for quantitatively assessing its efficacy from both security and business logic perspectives.
Methods:
To tackle this issue, the research introduces the Framework of Business Index Concerning Security (FOBICS), a set of metrics designed to enable transparent evaluations of project security. FOBICS considers various perspectives relevant to DevSecOps practices. It includes factors such as project duration and financial outcomes, making it appealing for implementation in business settings.
Results:
The effectiveness of FOBICS is validated theoretically and empirically via its application in two real-world projects: the results from these implementations show a correlation between FOBICS metrics and the security strategies employed as the development methodologies adopted by diverse teams throughout the projects.
Conclusion:
Hence, FOBICS emerges as a tool for assessing and continuously monitoring project security, offering insights into areas of strength and areas that may require enhancement. FOBICS is shown to be effective in assessing the level of DevSecOps implementation. The ease of calculating FOBICS metrics makes them easily interpretable and continuously verifiable. Moreover, FOBICS summarizes most of the other quantitative and qualitative metrics in the literature.}
}
@article{POLAKOVA20242332,
title = {Examining the Reliability of ChatGPT as an Assessment Tool Compared to Human Evaluators},
journal = {Procedia Computer Science},
volume = {246},
pages = {2332-2341},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.543},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924025882},
author = {Petra Poláková and Petra Ivenz and Blanka Klímová},
keywords = {ChatGPT, assessment tool, comparative study, artificial intelligence, foreign language learning},
abstract = {With the increasing development of artificial intelligence (AI), educators are exploring various AI-driven tools to enhance language teaching and learning processes. This study investigates the reliability of ChatGPT as an AI-powered assessment tool in the context of foreign language (FL) education. Using a mixed-methods approach, the research examines ChatGPT’s evaluative abilities compared to human evaluators, focusing on its assessment of students’ writing skills. The study employed a total of two research samples: one comprising eight students and another consisting of eight teachers of English language at the university where the research took place. The findings reveal that while ChatGPT demonstrates potential in providing feedback, its limitations, particularly in accurate assessment of grammatical nuances, emphasize the need for supplementation with human evaluation. The method section provides detailed information on the data collection process, including the procedures followed for evaluating student summaries and conducting interviews with teachers. The study highlights the importance of acknowledging AI’s limitations and adopting a complementary approach to its integration in language education.}
}
@article{SUH2024,
title = {Toward Tailoring Just-in-Time Adaptive Intervention Systems for Workplace Stress Reduction: Exploratory Analysis of Intervention Implementation},
journal = {JMIR Mental Health},
volume = {11},
year = {2024},
issn = {2368-7959},
doi = {https://doi.org/10.2196/48974},
url = {https://www.sciencedirect.com/science/article/pii/S2368795924000982},
author = {Jina Suh and Esther Howe and Robert Lewis and Javier Hernandez and Koustuv Saha and Tim Althoff and Mary Czerwinski},
keywords = {workplace stress, just-in-time, just-in-time adaptive intervention, JITAI, engagement, microintervention, stress reduction, psychotherapy},
abstract = {Background
Integrating stress-reduction interventions into the workplace may improve the health and well-being of employees, and there is an opportunity to leverage ubiquitous everyday work technologies to understand dynamic work contexts and facilitate stress reduction wherever work happens. Sensing-powered just-in-time adaptive intervention (JITAI) systems have the potential to adapt and deliver tailored interventions, but such adaptation requires a comprehensive analysis of contextual and individual-level variables that may influence intervention outcomes and be leveraged to drive the system’s decision-making.
Objective
This study aims to identify key tailoring variables that influence momentary engagement in digital stress reduction microinterventions to inform the design of similar JITAI systems.
Methods
To inform the design of such dynamic adaptation, we analyzed data from the implementation and deployment of a system that incorporates passively sensed data across everyday work devices to send just-in-time stress reduction microinterventions in the workplace to 43 participants during a 4-week deployment. We evaluated 27 trait-based factors (ie, individual characteristics), state-based factors (ie, workplace contextual and behavioral signals and momentary stress), and intervention-related factors (ie, location and function) across 1585 system-initiated interventions. We built logistical regression models to identify the factors contributing to momentary engagement, the choice of interventions, the engagement given an intervention choice, the user rating of interventions engaged, and the stress reduction from the engagement.
Results
We found that women (odds ratio [OR] 0.41, 95% CI 0.21-0.77; P=.03), those with higher neuroticism (OR 0.57, 95% CI 0.39-0.81; P=.01), those with higher cognitive reappraisal skills (OR 0.69, 95% CI 0.52-0.91; P=.04), and those that chose calm interventions (OR 0.43, 95% CI 0.23-0.78; P=.03) were significantly less likely to experience stress reduction, while those with higher agreeableness (OR 1.73, 95% CI 1.10-2.76; P=.06) and those that chose prompt-based (OR 6.65, 95% CI 1.53-36.45; P=.06) or video-based (OR 5.62, 95% CI 1.12-34.10; P=.12) interventions were substantially more likely to experience stress reduction. We also found that work-related contextual signals such as higher meeting counts (OR 0.62, 95% CI 0.49-0.78; P<.001) and higher engagement skewness (OR 0.64, 95% CI 0.51-0.79; P<.001) were associated with a lower likelihood of engagement, indicating that state-based contextual factors such as being in a meeting or the time of the day may matter more for engagement than efficacy. In addition, a just-in-time intervention that was explicitly rescheduled to a later time was more likely to be engaged with (OR 1.77, 95% CI 1.32-2.38; P<.001).
Conclusions
JITAI systems have the potential to integrate timely support into the workplace. On the basis of our findings, we recommend that individual, contextual, and content-based factors be incorporated into the system for tailoring as well as for monitoring ineffective engagements across subgroups and contexts.}
}
@article{WANG2024,
title = {Applications and Concerns of ChatGPT and Other Conversational Large Language Models in Health Care: Systematic Review},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/22769},
url = {https://www.sciencedirect.com/science/article/pii/S143888712400757X},
author = {Leyao Wang and Zhiyu Wan and Congning Ni and Qingyuan Song and Yang Li and Ellen Clayton and Bradley Malin and Zhijun Yin},
keywords = {large language model, ChatGPT, artificial intelligence, natural language processing, health care, summarization, medical knowledge inquiry, reliability, bias, privacy},
abstract = {Background
The launch of ChatGPT (OpenAI) in November 2022 attracted public attention and academic interest to large language models (LLMs), facilitating the emergence of many other innovative LLMs. These LLMs have been applied in various fields, including health care. Numerous studies have since been conducted regarding how to use state-of-the-art LLMs in health-related scenarios.
Objective
This review aims to summarize applications of and concerns regarding conversational LLMs in health care and provide an agenda for future research in this field.
Methods
We used PubMed, ACM, and the IEEE digital libraries as primary sources for this review. We followed the guidance of PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) to screen and select peer-reviewed research articles that (1) were related to health care applications and conversational LLMs and (2) were published before September 1, 2023, the date when we started paper collection. We investigated these papers and classified them according to their applications and concerns.
Results
Our search initially identified 820 papers according to targeted keywords, out of which 65 (7.9%) papers met our criteria and were included in the review. The most popular conversational LLM was ChatGPT (60/65, 92% of papers), followed by Bard (Google LLC; 1/65, 2% of papers), LLaMA (Meta; 1/65, 2% of papers), and other LLMs (6/65, 9% papers). These papers were classified into four categories of applications: (1) summarization, (2) medical knowledge inquiry, (3) prediction (eg, diagnosis, treatment recommendation, and drug synergy), and (4) administration (eg, documentation and information collection), and four categories of concerns: (1) reliability (eg, training data quality, accuracy, interpretability, and consistency in responses), (2) bias, (3) privacy, and (4) public acceptability. There were 49 (75%) papers using LLMs for either summarization or medical knowledge inquiry, or both, and there are 58 (89%) papers expressing concerns about either reliability or bias, or both. We found that conversational LLMs exhibited promising results in summarization and providing general medical knowledge to patients with a relatively high accuracy. However, conversational LLMs such as ChatGPT are not always able to provide reliable answers to complex health-related tasks (eg, diagnosis) that require specialized domain expertise. While bias or privacy issues are often noted as concerns, no experiments in our reviewed papers thoughtfully examined how conversational LLMs lead to these issues in health care research.
Conclusions
Future studies should focus on improving the reliability of LLM applications in complex health-related tasks, as well as investigating the mechanisms of how LLM applications bring bias and privacy issues. Considering the vast accessibility of LLMs, legal, social, and technical efforts are all needed to address concerns about LLMs to promote, improve, and regularize the application of LLMs in health care.}
}
@article{DHAIGUDE2025100640,
title = {Mapping responsible artificial intelligence in business and management: Trends, influence, and emerging research directions},
journal = {Journal of Open Innovation: Technology, Market, and Complexity},
volume = {11},
number = {4},
pages = {100640},
year = {2025},
issn = {2199-8531},
doi = {https://doi.org/10.1016/j.joitmc.2025.100640},
url = {https://www.sciencedirect.com/science/article/pii/S2199853125001751},
author = {Amol S. Dhaigude and Giridhar B. Kamath},
keywords = {Responsible Artificial Intelligence, Innovation management, Responsible innovation, Business and management, Bibliometric analysis, Bibliographic coupling, VOSviewer, Biblioshiny, Research clusters},
abstract = {The rapid integration of AI into business and management demands ethical and responsible technology design and deployment. While various policies and frameworks exist, there is limited understanding of operationalizing responsible artificial intelligence (RAI). The literature remains fragmented, lacking cohesion and clarity. This bibliometric analysis quantitatively evaluates RAI literature’s research trends, key authors, collaborations, and thematic evolution in the business and management domain. A carefully designed search protocol based on an extensive literature review was used to retrieve 1942 research papers from the Scopus database (1981–2025), reflecting a 13.12 % annual growth rate and an average of 25.79 citations per paper. The study applied bibliographic coupling, keyword co-occurrence, and thematic mapping techniques using VOSviewer and Biblioshiny to identify intellectual structures and conceptual linkages. The results reveal four key clusters: "Ethics and Social Impacts of AI", "AI Adoption and Human-AI Interaction", "Auditing, Explainability, and Accountability in AI", and "Corporate Governance and Data Responsibility in AI". Future research directions for each cluster are proposed, providing valuable insights for practitioners and academicians. The paper highlights critical implications for developing responsible AI strategies in business and offers guidance for advancing scholarly work in this growing field.}
}
@article{DEVILLA2024102316,
title = {Doing process research in international business},
journal = {International Business Review},
volume = {33},
number = {5},
pages = {102316},
year = {2024},
issn = {0969-5931},
doi = {https://doi.org/10.1016/j.ibusrev.2024.102316},
url = {https://www.sciencedirect.com/science/article/pii/S0969593124000635},
author = {Maria Andrea {De Villa} and Ann Langley},
keywords = {Process research, International business, Time, Process data, Process theory},
abstract = {Process research develops our understanding of the emergence, flow, and evolution of phenomena over time through ongoing activities and events. The field of international business has long been concerned with developing an understanding of various kinds of processes over time. Yet, several international business scholars have called for more studies that recognize the process-based nature of international business phenomena. This paper therefore discusses the challenges of process research in international business and offers insight into how they may be addressed. We draw on the broader methodological literature and on exemplar process studies in international business to explore and illustrate a repertoire of methodological tools that may be useful in assembling the three critical ingredients of high-quality process research: rich process data, insightful process theory, and credible but creative coupling between the two.}
}
@article{SHENG2024123550,
title = {A review of mechanistic insights into CO2 reduction to higher alcohols for rational catalyst design},
journal = {Applied Catalysis B: Environmental},
volume = {343},
pages = {123550},
year = {2024},
issn = {0926-3373},
doi = {https://doi.org/10.1016/j.apcatb.2023.123550},
url = {https://www.sciencedirect.com/science/article/pii/S0926337323011931},
author = {Yao Sheng and Mikhail V. Polynski and Mathan K. Eswaran and Bikun Zhang and Alvin M.H. Lim and Lili Zhang and Jianwen Jiang and Wen Liu and Sergey M. Kozlov},
keywords = {CO reduction, Catalysis, Alcohols, Oxygenates, Reaction mechanism},
abstract = {The utilization of captured CO2 for chemical synthesis could play an important role in reducing CO2 emissions. Higher alcohols stand out among various products of CO2 reduction due to high market prices and diverse applications, e.g., as fuel additives. However, developing catalysts for this reaction requires a profound understanding of the reaction mechanisms and catalyst design principles, which are discussed in the present review. Depending on the catalytic sites, higher alcohol synthesis could proceed via vastly different pathways. Herein, we outline how various proposed reaction mechanisms lead to different catalyst design strategies for optimizing the rate of CO2 conversion into reactive C1 intermediates (CO, CHx, CHxO, and HCOO) and their coupling into C2+ intermediates that are eventually converted into higher alcohols. Lastly, we discuss knowledge gaps in achieving rational catalyst design for higher alcohol synthesis and the breakthrough potential of machine-learning techniques for catalyst discovery.}
}
@article{OLIVEIRA2025527,
title = {Unveiling the potential of digital human avatars in modern marketing strategies},
journal = {International Marketing Review},
volume = {42},
number = {4},
pages = {527-555},
year = {2025},
issn = {0265-1335},
doi = {https://doi.org/10.1108/IMR-12-2023-0339},
url = {https://www.sciencedirect.com/science/article/pii/S0265133525000267},
author = {Fabio Goncalves de Oliveira and Maksim Belitski and Nada Kakabadse and Nicholas Theodorakopoulos},
keywords = {Digital human avatars, Global digital marketing strategy, International dynamic marketing capabilities, Digital transformation, Generative AI, Absorptive capacity},
abstract = {Purpose
This study aims to develop a theoretical framework that marketing practitioners and scholars can adopt to enhance their understanding of how firms can effectively deploy and use digital human avatars as part of their global digital marketing strategy. By doing so, we inform investors of ongoing digital transformations of marketing practices that will equip marketeers to provide scalable, tailored, reliable and relevant digital self-service interactions to users, consequently improving the user/customer experience.
Design/methodology/approach
Thematic analysis was used to discover factors to enable the successful implementation of digital human avatars, drawing on in-depth interviews with fourteen executives of digital human avatars developer companies worldwide and analysis of ten podcasts and webinars with artificial intelligence (AI) experts.
Findings
Digital human avatars revitalise the international dynamic marketing capabilities (IDMCs) of firms by integrating advanced technologies that transform user interactions, improve engagement and facilitate knowledge acquisition, dissemination and usage across various sectors and business units globally. This integration promotes a dynamic approach to international brands, customer relationships and marketing knowledge management capabilities, offering profound value to users and firms.
Research limitations/implications
Our first limitation is a lack of diversity in data sources. As digital human avatars are an emerging field, we had to limit our study to 14 experts in AI and 10 podcasts. While this method provides deep insights into the perspectives of those directly involved in the development and implementation of digital human avatars, it may not capture the views of end-users or consumers who interact with these avatars, which can be an avenue for further research. Our second limitation is the potential bias in the interpretation of our interview data and podcasts. This study’s approach to data analysis, where themes are derived from the data itself, carries a risk of subjective interpretation by the researchers. Future studies are encouraged to investigate the impact of digital human avatars across different organisational contexts and ecosystems, especially focusing on how these technologies are integrated and perceived in various international markets.
Practical implications
The novel framework has direct implications for innovators and marketing practitioners who aim to adopt digital human avatars in their marketing practices to enhance the effectiveness of international marketing strategies.
Social implications
The adoption of digital human avatars can alleviate loneliest elderly and vulnerable people by being a companion. The human-like characteristics can impact sense of presence and attachment.
Originality/value
The novelty of our study lies in exploring the characteristics of technologies and practical factors that maximise the successful adoption of digital human avatars. We advance and contribute to the emerging theory of avatar marketing, IDMCs and absorptive capacity by demonstrating how digital human avatars could be adopted as part of a firm’s global digital marketing strategy. We focus specifically on six dimensions: outcomes and benefits, enhancements and capabilities, applications and domains, future implications, foundational elements and challenges and considerations. This framework has direct implications for innovators and marketing practitioners who aim to adopt digital human avatars in their marketing practices to enhance the effectiveness of international marketing strategies.}
}
@article{KHATUA2024100812,
title = {FedGen: Federated learning-based green edge computing for optimal route selection using genetic algorithm in Internet of Vehicular Things},
journal = {Vehicular Communications},
volume = {49},
pages = {100812},
year = {2024},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2024.100812},
url = {https://www.sciencedirect.com/science/article/pii/S2214209624000871},
author = {Sushovan Khatua and Anwesha Mukherjee and Debashis De},
keywords = {Internet of Vehicular Things, Federated learning, Vehicular networks, Optimal route, Time consumption, Power consumption},
abstract = {Time-efficient route planning is a significant research area of Internet of Vehicular Things. Optimal route selection is important to reach the destination in minimal time. Further, energy efficiency is vital for route planning in a sustainable environment. To address these issues, this paper proposes a federated learning and genetic algorithm-based green edge computing framework for optimal route planning in Internet of Vehicular Things. The vehicles are connected to the road side unit. The road side unit processes the image and video of the road, and predicts the number of vehicles on the road. For video processing Region-based Convolutional Neural Network is used. The road side units send the result and the local model parameters to the regional server. The regional server determines the optimal route using modified genetic algorithm, and sends it to the vehicles and the cloud. Also, the regional server updates its model and sends the updated model parameters to the road side units. The road side units update their local models accordingly. The regional server also sends the model parameters to the cloud, and the cloud updates the global model. The cloud sends the updated model parameters to the regional servers. The regional servers update their models accordingly. The results present that above 90% accuracy is achieved by the proposed model. The results also present that using modified GA the proposed approach reduces time and power consumption to find the optimal route by ∼62% and ∼66% than the cloud-only model.}
}
@incollection{FREITASDEARAUJOFILHO2025111,
title = {Chapter 5 - Safeguarding IoT networks with generative adversarial networks},
editor = {Dinh Thai Hoang and Nguyen Quang Hieu and Diep N. Nguyen and Ekram Hossain},
booktitle = {Advanced Machine Learning for Cyber-Attack Detection in IoT Networks},
publisher = {Academic Press},
pages = {111-142},
year = {2025},
isbn = {978-0-443-29032-9},
doi = {https://doi.org/10.1016/B978-0-44-329032-9.00010-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443290329000105},
author = {Paulo {Freitas de Araujo-Filho} and Georges Kaddoum and Divanilson R. Campelo and Cleber Zanchettin},
keywords = {Generative adversarial networks, Cybersecurity, Internet of things},
abstract = {Although generative adversarial networks (GANs) were initially developed to generate images, they have proven to be extremely useful in various other domains, including IoT security. By simultaneously training two competing neural networks, namely the generator and the discriminator, GANs successfully estimate generative models by capturing data distributions. Additionally, they provide a discriminative model that estimates the probability of a sample being real rather than produced by the generator. These capabilities are particularly valuable in the unsupervised detection of attacks, where labeled attack data is not available. Hence, GANs have an important role in securing IoT devices. Furthermore, GANs have shown promising results in other IoT security tasks, such as defending against adversarial attacks and evaluating authentication systems. In this chapter, we present different formulations and variations of GANs, discuss their applications in IoT security, showcase state-of-the-art GAN-based security solutions, and explore the challenges and future research opportunities in the field of IoT security.}
}
@article{KAPPEL2024106303,
title = {Measuring affect-related attention bias to emotionally valenced visual stimuli in horses},
journal = {Applied Animal Behaviour Science},
volume = {275},
pages = {106303},
year = {2024},
issn = {0168-1591},
doi = {https://doi.org/10.1016/j.applanim.2024.106303},
url = {https://www.sciencedirect.com/science/article/pii/S0168159124001515},
author = {Sarah Kappel and Marco A.Ramirez Montes De Oca and Sarah Collins and Katherine Herborn and Michael Mendl and Carole Fureix},
keywords = {Emotional state, Affective measures, Visual attention, Horse behaviour, Animal welfare},
abstract = {Negative affect appears to mediate animals’ attention to competing emotional stimuli (e.g., threatening vs. non-threatening conspecific face images), similarly to anxiety-related enhanced attention to social threat reported in humans. To investigate this ‘attention bias’ (AB, i.e., the differential attention allocation to certain types of information over others) in horses, we developed a visual AB test assessing horses’ attention towards image pairs showing unfamiliar conspecifics’ facial expressions indicating, a) negative (social threat), b) more neutral (at rest), and c) positive (food anticipation) situations. We predicted that horses exhibit greater attention to negative compared to neutral or positive face images (as a normal adaptive response), and that horses in negative affective states (inferred from validated welfare indices comprising direct (health, behaviour) and indirect (housing, management) measures summarised as individual welfare scores and subscores reflecting health, social and environmental aspects) show greater AB to negative face stimuli and all images overall. Comparing AB to positive versus neutral social stimuli is rarely considered in AB studies, we therefore explored horses’ AB responses without a priori predictions. Over six trials, 44 horses from three facilities were shown stimulus pairs (negative/neutral, negative/positive, positive/neutral) presented simultaneously on two projector screens. Attention was assessed as absolute attention duration to each image, the proportion of time the negative/positive stimulus was attended to relative to the other stimulus, and overall attention (i.e., duration of head turns towards both stimuli combined). AB to stimulus type, side, effects of facility and individual characteristics (welfare and subscores, age) was analysed using linear and generalised mixed-effect models. Against our predictions, horses attended to the images within the three stimulus pairs for similar lengths of time (negative-neutral: W=1870.5, p=0.2572; negative-positive: W=2542.5, p=0.9296; positive-neutral: W=1762.5, p=0.1019). Due to Covid-19 interruptions, our sample size was lower than our estimated required number (N=113). Still, lower welfare (X21=4.71, p=0.03) and health scores (X21=4.13, p=0.04) significantly predicted shorter attention to the negative face stimuli, possibly reflecting threat avoidance previously reported in other animals. We found significant facility effects on overall attention to the stimuli (X22=77.42, p<0.001), likely due to varying yard-specific conditions (e.g., lighting, noise). This highlights that external influences on visual attention require consideration when conducting cognitive tests at different testing sites. Further methodological investigation (e.g., test cue suitability, perceptual processing of computer-generated images; test stimuli familiarity; individual differences) is needed to evaluate the potential of AB as an indicator of affective valence in horses.}
}
@article{ZHAO2024109964,
title = {Domain generalization for cross-domain fault diagnosis: An application-oriented perspective and a benchmark study},
journal = {Reliability Engineering & System Safety},
volume = {245},
pages = {109964},
year = {2024},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2024.109964},
url = {https://www.sciencedirect.com/science/article/pii/S0951832024000395},
author = {Chao Zhao and Enrico Zio and Weiming Shen},
keywords = {Fault diagnosis, Domain shift, Domain generalization, Deep learning},
abstract = {Most data-driven methods for fault diagnostics rely on the assumption of independently and identically distributed data of training and testing. However, domain shift between the phases of training and testing is common in practice. Recently, domain generalization-based fault diagnosis (DGFD) has gained widespread attention for learning fault diagnosis knowledge from multiple source domains and applying it to unseen target domains. This paper summarizes the developments in DGFD from an application-oriented perspective. Firstly, basic definitions of DGFD and its variant applications are formulated. Then, motivations, goals, challenges and state-of-the-art solutions for different applications are discussed. The limitations of existing technologies are highlighted. A comprehensive benchmark study is carried out on eight open-source and two self-collected datasets to provide an understanding of the existing methods and a unified framework for researchers. Finally, several future directions are given. Our code is available at https://github.com/CHAOZHAO-1/DG-PHM.}
}
@incollection{OZCAN2025111,
title = {Chapter 5 - Dynamic relationalities across (stacked) strata},
editor = {Kerimcan Ozcan and Venkat Ramaswamy},
booktitle = {Dynamic Relationality Theory of Creative Transformation},
publisher = {Elsevier},
pages = {111-136},
year = {2025},
isbn = {978-0-443-30159-9},
doi = {https://doi.org/10.1016/B978-0-443-30159-9.00005-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780443301599000050},
author = {Kerimcan Ozcan and Venkat Ramaswamy},
keywords = {Becoming, Experiencial computing, Machinic generalized intelligence, Natural transformation, Reterritorialization, Technological singularity, Transcendence},
abstract = {In this chapter, explores the synergy between human intelligence (HI) and artificial intelligence (AI), emphasizing the transformative power of AI in digital ecosystems. It articulates the shift toward Machinic Generalized Intelligence (MGI), highlighting AI's role in creating immersive, personalized experiences. Through the lens of Dynamic Relationality Theory (DRT), it delves into “becoming” via lines of flight, marking departures from established structures toward new formations, with AI fostering technological singularity and healthcare evolution. It examines reterritorialization, where foundational cognitive processes evolve into complex systems, and the enrichment of the Experience-verse, blending organic and artificial elements for enhanced digital ecosystems. The chapter concludes by addressing identity and structure transformations within digital realms, underpinning the fluidity and continuous change integral to DRT's framework. This comprehensive analysis underscores the interdependent evolution of HI and AI, reinforcing their collective impact on advancing digital ecosystems.}
}
@article{AGUSTI2024117377,
title = {Christensenella minuta mitigates behavioral and cardiometabolic hallmarks of social defeat stress},
journal = {Biomedicine & Pharmacotherapy},
volume = {180},
pages = {117377},
year = {2024},
issn = {0753-3322},
doi = {https://doi.org/10.1016/j.biopha.2024.117377},
url = {https://www.sciencedirect.com/science/article/pii/S0753332224012629},
author = {A. Agusti and GV. Molina-Mendoza and M. Tamayo and V. Rossini and MC. Cenit and C. Frances-Cuesta and V. Tolosa-Enguis and EM. {Gómez Del Pulgar} and A. Flor-Duro and Y. Sanz},
keywords = {Microbiota, Gut-brain axis, Behavior, Dopamine, Social defeat, Depression},
abstract = {Psychological stress during early development and adolescence may increase the risk of psychiatric and cardiometabolic comorbidities in adulthood. The gut microbiota has been associated with mental health problems such as depression and anxiety and with cardiometabolic disease, but the potential role of the gut microbiota in their comorbidity is not well understood. We investigated the effects and mode of action of the intestinal bacterium Christensenella minuta DSM 32891 on stress-induced mental health and cardiometabolic disturbances in a mouse model of social defeat stress. We demonstrate that administered C. minuta alleviates chronic stress-induced depressive, anxiogenic and antisocial behavior. These effects are attributed to the bacterium’s ability to modulate the hypothalamic-pituitary-adrenal axis, which mediates the stress response. This included the oversecretion of corticosterone and the overexpression of its receptors, as well as the metabolism of dopamine (DA) and the expression of its receptors (D1, D2L and D2S). Additionally, C. minuta administration reduced chronically induced inflammation in plasma, spleen and some brain areas, which likely contribute to the recovery of physical and behavioral function. Furthermore, C. minuta administration prevented chronic stress-induced cardiovascular damage by regulating key enzymes mediating liver fibrosis and oxidative stress. Finally, C. minuta increased the abundance of bacteria associated with mental health. Overall, our study highlights the potential of microbiota-directed interventions to alleviate both the physical and mental effects of chronic stress.}
}
@incollection{STANCIU2025443,
title = {Chapter 28 - Artificial intelligence for cancer care 4.0/5.0},
editor = {Tuan Anh Nguyen},
booktitle = {IoT-WSN-DT Based Medical Systems and Nanotechnology for Smart Cancer Care},
publisher = {Academic Press},
pages = {443-460},
year = {2025},
isbn = {978-0-443-33984-4},
doi = {https://doi.org/10.1016/B978-0-443-33984-4.00007-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443339844000079},
author = {Alexandru Stanciu and Elena Paraschiv},
keywords = {Artificial intelligence, Digital twins, Explainable AI, Generative AI, Machine learning, Oncology},
abstract = {The integration of artificial intelligence (AI) in healthcare has revolutionized cancer care, enabling earlier detection, more accurate prognoses, and tailored treatment strategies. This chapter explores the transition from Healthcare 4.0 to Healthcare 5.0, highlighting the shift from a technology-centric approach to one that is deeply personalized and patient-centered. In Healthcare 5.0, we envision the focus will be on leveraging AI to empower patients and create a truly patient-centric experience. This includes using predictive modeling to anticipate treatment outcomes, employing explainable AI (XAI) to ensure transparency and trust, and utilizing cutting-edge technologies such as generative AI and digital twins to simulate patient-specific disease progressions and treatment responses. The chapter delves into the foundational machine-learning techniques used in cancer diagnosis, such as supervised learning, unsupervised learning, deep learning, and reinforcement learning. It then explores more advanced AI technologies, including generative AI, XAI, and digital twins, and discusses their applications in cancer care. Additionally, the chapter emphasizes the importance of data curation and augmentation in ensuring the availability of high-quality, diverse datasets for AI systems. It also examines computational pathology, which combines traditional pathology with AI to analyze pathology data in unprecedented ways. This chapter provides a comprehensive overview of the current and future applications of AI in cancer care, highlighting its potential to transform the way cancer is diagnosed and treated.}
}
@article{KORKMAZ2024104954,
title = {From GitHub to GDP: A framework for measuring open source software innovation},
journal = {Research Policy},
volume = {53},
number = {3},
pages = {104954},
year = {2024},
issn = {0048-7333},
doi = {https://doi.org/10.1016/j.respol.2024.104954},
url = {https://www.sciencedirect.com/science/article/pii/S0048733324000039},
author = {Gizem Korkmaz and J. Bayoán {Santiago Calderón} and Brandon L. Kramer and Ledia Guci and Carol A. Robbins},
keywords = {Open source software, Cost measurement, GitHub, Innovation, Gross domestic product, Software investment, National accounts},
abstract = {Open source software (OSS) is software that anyone can review, modify, and distribute freely, usually with only minor restrictions such as giving credit to the creator of the work. The use of OSS is growing rapidly, due to its value in increasing firm and economy-wide productivity. Despite its widespread use, there is no standardized methodology for measuring the scope and impact of this fundamental intangible asset. This study presents a framework to measure the value of OSS using data collected from GitHub, the largest platform in the world with over 100 million developers. The data include over 7.6 million repositories where software is developed, stored, and managed. We collect information about contributors and development activity such as code changes and license detail. By adopting a cost estimation model from software engineering, we develop a methodology to generate estimates of investment in OSS that are consistent with the U.S. national accounting methods used for measuring software investment. We generate annual estimates of current and inflation-adjusted investment as well as the net stock of OSS for the 2009–2019 period. Our estimates show that the U.S. investment in 2019 was $37.8 billion with a current-cost net stock of $74.3 billion.}
}
@article{ALADINI2025100566,
title = {Self-directed writing development across computer/AI-based tasks: Unraveling the traces on L2 writing outcomes, growth mindfulness, and grammatical knowledge},
journal = {Computers in Human Behavior Reports},
volume = {17},
pages = {100566},
year = {2025},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2024.100566},
url = {https://www.sciencedirect.com/science/article/pii/S2451958824001994},
author = {Alaa Aladini and Sayed M. Ismail and Mohamad {Ahmad Saleem Khasawneh} and Goodarz Shakibaei},
keywords = {AI-based tasks, Grammatical knowledge, Growth mindfulness, L2 writing outcomes, Self-directed writing},
abstract = {As technology continues to reshape the educational landscape, understanding how autonomous engagement with AI-driven platforms influences second language (L2) acquisition is increasingly important. This study examined the impact of self-directed writing development through computer- and AI-based tasks on L2 writing outcomes, growth mindfulness, and grammatical knowledge. The research was conducted in three private English institutes in Ahvaz, Iran, involving 561 intermediate-level EFL learners that were selected using a convenience sampling method. Using a quasi-experimental design, participants were divided into two groups: an experimental group (EG) of 276 students, which engaged in self-directed AI-based writing tasks, and a control group (CG) of 285 students, which followed traditional writing instruction. Quantitative data were gathered through pre- and post-tests measuring writing proficiency, growth mindfulness, and grammatical accuracy. Additionally, qualitative data were collected through interviews and questionnaires administered to the EG to assess their attitudes toward AI-based learning. The results indicated that the EG significantly outperformed the CG in writing outcomes and grammatical accuracy. Moreover, the EG demonstrated greater growth in mindfulness, with participants showing increased awareness of their writing processes and enhanced self-regulation strategies. Interviews and questionnaires revealed that participants in the EG held positive attitudes toward AI-based tasks, emphasizing increased engagement, autonomy, enjoyment, motivation, personalized learning, critical thinking, self-efficacy, time management, and collaboration in their English learning development. These findings underscore the potential of AI-based tasks in fostering both linguistic competence and metacognitive skills in L2 learners. The study provides valuable insights into the role of AI technologies in promoting independent learning and calls for further exploration of AI-based interventions in writing education.}
}
@article{BERKOWITZ2024102890,
title = {Filling successive technologically-induced governance gaps: Meta-organizations as regulatory innovation intermediaries},
journal = {Technovation},
volume = {129},
pages = {102890},
year = {2024},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2023.102890},
url = {https://www.sciencedirect.com/science/article/pii/S0166497223002018},
author = {Heloise Berkowitz and Antoine Souchaud},
keywords = {Meta-Organization, Technologically-induced governance gap, Sectoral governance, Regulation, Innovation intermediaries, Digital innovation, Organizationality, Meta-organizational filiation},
abstract = {Successive digital innovations create technologically-induced governance gaps that make public regulation quickly obsolete and that might be filled by sectoral governance. The literature has shown that most sectoral governance happens at the level of meta-organizations, organizations whose members are themselves organizations, although we lack a temporal understanding of this phenomenon. Further, while regulation is generally understood as a salient function of innovation intermediaries, the literature on innovation intermediaries has focused mostly on other functions such as idea sourcing, knowledge sharing, or capacity building. We know relatively little about regulatory innovation intermediaries, especially how they might evolve in response to the emergence of technologically-induced governance gaps. In this paper, we conduct an in-depth case study of the evolutions of the FinTech sector in France over almost 30 years, using more than 3000 min of interviews, 4500 pages of archives, and non-participant observations. We study three successive (non)digital financial innovations: business angels, crowdfunding platforms for SMEs, and blockchain technologies. We develop a meta-organizational analysis to investigate meta-organizations as regulatory innovation intermediaries. We describe the evolutions and interrelations of new technologies and meta-organizations, and unpack mechanisms of meta-organizational capacity building for multiple contributors, effects of innovation on organizationality and trajectories of meta-organizational filiation.}
}
@incollection{EGHBAL202591,
title = {Chapter Five - Modernizing distribution networks for an electrified future: case study of Queensland, Australia},
editor = {Fereidoon Sioshansi},
booktitle = {Electrification and the Future of Decentralized Electricity Supply},
publisher = {Elsevier},
pages = {91-120},
year = {2025},
isbn = {978-0-443-34268-4},
doi = {https://doi.org/10.1016/B978-0-443-34268-4.00015-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443342684000159},
author = {Daniel Eghbal and Glenn Springall},
keywords = {Distributed Energy Resources (DER), distribution system operator (DSO), dynamic connections, grid modernization, Queensland, rooftop solar},
abstract = {This chapter summarizes key strategies that enabled Energex and Ergon Energy Network to achieve one of the highest per-capita uptakes of rooftop solar globally. The chapter outlines key foundational distribution system operator capabilities such as dynamic connections, distributed energy resource orchestration, and optimal operation of local renewable energy zones. The chapter concludes with recommendations for modernizing distribution networks, drawing on the case study of Queensland that collectively pave the way for a resilient, efficient, and customer-centric energy system.}
}
@article{MOHAMMADI2025118632,
title = {An interpretable machine learning-based model for shear resistance prediction of CFRP-strengthened RC beams using experimental and synthetic dataset},
journal = {Composite Structures},
volume = {351},
pages = {118632},
year = {2025},
issn = {0263-8223},
doi = {https://doi.org/10.1016/j.compstruct.2024.118632},
url = {https://www.sciencedirect.com/science/article/pii/S0263822324007608},
author = {Amirhossein Mohammadi and Joaquim A.O. Barros and José Sena-Cruz},
keywords = {Machine learning (ML), RC beams, Shear strengthening, Externally Bonded Reinforcement (EBR), Carbon Fibre Reinforced Polymer (CFRP), Synthetic dataset},
abstract = {Existing analytical models for predicting the shear resistance of RC beams strengthened with externally bonded CFRP reinforcements exhibit deficient performance due to their inability to accurately capture the complex resisting mechanisms. Combined with significant statistical uncertainties in shear failure, driven by its brittle nature, this further undermines the reliability of these models. To address these limitations, this study leverages Machine Learning (ML) to develop more robust and reliable predictive tool. A rigorous feature-selection process identified eight predictors as the most influential. Subsequently, nine ML-algorithms were trained on a refined experimental dataset comprising 239 beams, with XGBoost emerging as the top performer. This model also outperformed established models likefib Bulletin-90 and ACI 2023 models. However, the limited scope of the experimental dataset constrained the model’s predictive performance especially when separately evaluated on beams strengthened with U-wraps, full wraps or side-bonded FRP configurations. Therefore, to achieve a more reliable model a synthetic dataset was generated using Tabular Variational Auto-Encoder. The XGBoost model trained with the synthetic dataset significantly improved the performance of the former model and exhibited better predictions for all strengthening configurations. Finally, to ensure the physical consistency of predictions, values obtained from the SHapley Additive exPlanations method were analysed.}
}
@article{KHALIL2025115456,
title = {Unlocking the AI-Productivity paradox in HR: Qualitative insights across organizational levels},
journal = {Journal of Business Research},
volume = {199},
pages = {115456},
year = {2025},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2025.115456},
url = {https://www.sciencedirect.com/science/article/pii/S0148296325002796},
author = {Ashraf Khalil and Reeti Agarwal and Muhammad Zafar Yaqub and Armando Papa},
keywords = {Artificial Intelligence, Productivity Paradox, Productivity, General Purpose Technology},
abstract = {Artificial Intelligence (AI) is widely expected to boost productivity and economic growth. As with other technological innovations, a productivity paradox emerges, stating that productivity falls upon its introduction. Therefore, while organizations consistently augment their investments in AI, they might fall short of significant productivity improvements. This study delves into this productivity paradox using a longitudinal qualitative research design with two waves of data collection. We explored four critical themes: AI’s evolving role in organizations, its tangible effects on HR productivity, the underlying reasons behind the productivity paradox, and its multifaceted impact on the employee, team, and organizational levels. Our findings reveal compelling insights into why increased AI investments may not always translate into immediate productivity gains. In addition to providing a framework outlining the relationship between AI and the productivity paradox in HR operations, the findings offer insightful information that can be extremely helpful to industry practitioners.}
}
@article{SCHIFANO2025107591,
title = {High throughput edit distance computation on FPGA-based accelerators using HLS},
journal = {Future Generation Computer Systems},
volume = {164},
pages = {107591},
year = {2025},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.107591},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X24005557},
author = {Sebastiano Fabio Schifano and Marco Reggiani and Enrico Calore and Rino Micheloni and Alessia Marelli and Cristian Zambelli},
keywords = {DNA-based storage, Bioinformatics, Edit distance, HLS programming, FPGA, Performance analysis},
abstract = {Edit distance is a computational grand challenge problem to quantify the minimum number of editing operations required to modify one string of characters to the other, finding many applications of natural language processing. In recent years, relevant and increasing interest has also emerged from deoxyribonucleic acid (DNA) applications, like Next Generation Sequencing and DNA storage technologies. Both applications share two crucial features: i) the information is coded into the four bases of DNA and ii) the level of operational noise is still high causing errors in the data, requiring inclusion in the workflow of the computation of algorithms such as the edit distance for finding similarities between sequences. To boost this computation many solutions are available in the literature. Among them, the FPGAs are largely used since the data domain of those applications is strings of 4 characters represented as two-bit values, inconveniently fitting the basic data types of ordinary CPUs and GPUs, with additional benefits of providing a high level of parallelism and low processing latency. This contribution presents a computing- and energy-efficient design implementing the edit distance algorithm combining metaprogramming and High-Level Synthesis. We also assess the performance of our design targeting recent FPGA-based accelerators. Our solution uses nearly 90% of FPGA basic-block hardware resources achieving about 90% of computing efficiency delivering a maximum throughput of 16.8 TCUPS and an energy efficiency of 46 Mpair/Joule, enabling the use of FPGAs as a new class of accelerators for High Performance Computing in DNA applications.}
}
@article{MENG2026104496,
title = {Can ChatGPT relate to you? Exploring consumer satisfaction with AI-generated product advice through the lens of consumption values},
journal = {Journal of Retailing and Consumer Services},
volume = {88},
pages = {104496},
year = {2026},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2025.104496},
url = {https://www.sciencedirect.com/science/article/pii/S0969698925002759},
author = {Kexin Meng and Jing Jian Xiao},
keywords = {Generative AI (GAI), Consumption values, Consumer satisfaction, Trust, Product attribute, Task type},
abstract = {As generative AI (GAI) tools increasingly assist consumers in making purchasing decisions, understanding how users evaluate such recommendations has become a timely and essential research question. This study applies the Theory of Consumption Values to examine how consumers develop satisfaction with ChatGPT's product recommendations, while also critically assessing the relevance of each value dimension in the context of AI-mediated interactions. Drawing on a randomized online experiment with U.S. participants, we investigate the relationships between customer satisfaction with ChatGPT's responses and five perceived consumption values: functional, emotional, epistemic, social, and conditional. We also investigate if trust plays a mediating role in these connections and whether they differ depending on the task type (requiring mostly human or machine skills) and product attribute (functional, experiential, hybrid). The findings indicate that, except for social value, all value dimensions are strongly linked to greater levels of satisfaction; the most significant correlation is found for functional value. Trust significantly mediates the value–satisfaction relationship, with conditional value exhibiting the most substantial indirect effect through trust. Interestingly, functional value plays a more prominent role in associating with satisfaction for experiential and hybrid products, as well as in human-skill-intensive tasks, rather than in functional products or machine-skill-oriented tasks. Conditional value consistently shows both direct and mediated associations with satisfaction across functional and hybrid products, as well as both task types. Epistemic value demonstrates both direct and mediated associations with satisfaction in functional and experiential product contexts, as well as in tasks requiring primarily machine-based skills. These findings advance theoretical understanding of value perception in GAI interactions and offer practical insights for designing context-sensitive and trust-oriented recommendation systems.}
}
@article{JIANG2024105113,
title = {They believe students can fly: A scoping review on the utilization of drones in educational settings},
journal = {Computers & Education},
volume = {220},
pages = {105113},
year = {2024},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2024.105113},
url = {https://www.sciencedirect.com/science/article/pii/S0360131524001271},
author = {Michael Yi-Chao Jiang and Morris Siu-Yung Jong and Ching Sing Chai and Biyun Huang and Gaowei Chen and Chung-Kwan Lo and Frankie Kwan-Kit Wong},
keywords = {Drones, Unmanned aerial vehicles (UAVs), Scoping review, SAMR, Technology integration},
abstract = {In the past decade, drones have become another cutting-edge technology for educators, especially those in STEM-related domains. Accordingly, there is a significant need to thoroughly examine how drones are integrated into current pedagogical practices. This study scopes the domain of drone-based learning based on a collection of forty-eight articles identified via systematic searches across the Web of Science (WoS) databases. The analytical framework for coding is underpinned by the Substitution-Augmentation-Modification-Redefinition (SAMR) model. The review explored trends, domains and pedagogical activities, research approaches, learners and learning objectives, variables and aspects of interest, and most importantly, the integration levels of drones into current pedagogical practices. The findings highlight that drones are predominantly utilized in short-term, intermittent, and collaborative learning activities, particularly within STEM-related fields. Notably, the analysis reveals a prevalent use of drones to transform learning, mainly at the Modification and Redefinition levels of the SAMR framework. Regarding drone types, off-the-shelf drones are primarily used for applying-oriented learning and are evenly distributed across the Augmentation, Modification, and Redefinition levels. Conversely, custom-built drones are typically utilized for creating-oriented tasks and are most often associated with the highest SAMR level, i.e., Redefinition. Building upon these findings, the present work underscores the importance of addressing the novelty effect associated with drone-based learning, exploring strategies for sustaining student engagement over time, and investigating the cognitive benefits of intermittent drone use in educational settings. The collaborative nature of drone-based activities is also emphasized, calling for more process-oriented research to understand how drones influence collaborative learning.}
}
@article{2025iii,
title = {Contents},
journal = {Procedia Computer Science},
volume = {253},
pages = {iii-xxii},
year = {2025},
note = {6th International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/S1877-0509(25)00405-3},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925004053}
}
@article{KAUR2025113606,
title = {3D printed biomaterials: From fabrication techniques to clinical applications: A systematic review},
journal = {European Polymer Journal},
volume = {227},
pages = {113606},
year = {2025},
issn = {0014-3057},
doi = {https://doi.org/10.1016/j.eurpolymj.2024.113606},
url = {https://www.sciencedirect.com/science/article/pii/S001430572400867X},
author = {Amandeep Kaur and Sandeep Singh and Niraj Bala and Sushil {Kumar Kansal}},
keywords = {3D printing, 3D printing techniques Biomaterials, Medical applications},
abstract = {The type of biomaterial employed in the manufacturing of an implant determines its success. The material for implants should be easily adaptable, inert biocompatible, and mechanically robust. But the ideal properties may vary depending on the specific application and patient needs. In the pharmaceutical and medical industries, 3D printing technology has revolutionised the capacity to create customised implants for patients that are integrated with bioactive medications, cells, and proteins. Currently, a wide range of biomaterials such as ceramics, polymers, metals, hydrogels and composites are employed in medical 3D printing. Various applications of 3D printing such as manufacture of personalised implants, prostheses, drug delivery systems and 3D scaffolds for biological tissue engineering and regenerative medicine have grown quickly as a result of ongoing research and advancements in the biomaterials used in 3D printing. In this study, novel biomaterials utilised in medical 3D printing techniques are the main subject of interest. Furthermore, the present review sheds light on the most widely used medical 3D printing technologies, including fused deposition modelling, extrusion-based bioprinting, polyjet printing, and inkjet methods, as well as their clinical applications, different biomaterials that are presently under investigation by researchers, and important challenges.}
}
@article{LI2025100894,
title = {A concise review of intelligent game agent},
journal = {Entertainment Computing},
volume = {52},
pages = {100894},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100894},
url = {https://www.sciencedirect.com/science/article/pii/S1875952124002623},
author = {Hui Li and Xinyi Pang and Bixia Sun and Kexin Liu},
keywords = {Intelligent agent, Artificial intelligence, Monte Carlo tree, Reinforcement learning, Large language models},
abstract = {Intelligent game agents are crafted using AI technologies to mimic player behavior and make decisions autonomously. Over the past decades, the scope of intelligent agents has broadened from chess to encompass content generation, player modeling, and result prediction, reflecting the field’s evolving and multifaceted nature. In this paper, we conduct a systematic review of recent literature on intelligent methods and applications of game agents, along with general game agent frameworks. Our findings suggest that creating general intelligent agents remains a significant challenge, yet it is worthwhile to explore methods that better integrate the strengths of different techniques to build more robust and adaptable intelligent game agents.}
}
@article{ZHU2025103412,
title = {Fostering children's dispositional autonomy and AI understanding through co-designing AI systems: A learning science perspective},
journal = {International Journal of Human-Computer Studies},
volume = {196},
pages = {103412},
year = {2025},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2024.103412},
url = {https://www.sciencedirect.com/science/article/pii/S1071581924001952},
author = {Yumeng Zhu and Samantha-Kaye Johnston and Caifeng Zhu and Yan Li},
keywords = {AI education, Co-design, Learning science, K-12, Child-centered AI, Design methods, Autonomy},
abstract = {Co-designing AI systems with children to foster their autonomy has gained traction in the child-computer interaction community. However, the prerequisites for co-designing with a focus on children's dispositional autonomy, their intentional inclination to determine their own actions, and their understanding of AI, have not been thoroughly examined. This study contributes to child-centered co-design research methodologies from the perspective of learning science, aiming to enhance children's dispositional autonomy and AI understanding through co-design activities. A 14-week curriculum based on the Learning by Design (LBD) framework was developed, incorporating activities that require co-designing AI systems with students. 116 middle school students, organized into 24 groups, engaged with the curriculum. Through the analysis of pre-and post-questionnaires, storytelling drawings, and co-design worksheets, we assessed how the LBD curriculum influenced students’ dispositional autonomy and how students’ understandings (perceptions and demands) of AI systems changed during this process. Our findings indicate that the LBD curriculum significantly impacted students’ dispositional autonomy in two of the three dimensions that were assessed (authorship/congruence and interest-taking), and students transitioned from passive users to active engagers of AI. Based on students’ designs, we further propose designing AI systems with children-in-the-loop approaches. We provide a conceptual framework for categorizing the types of digital nudges provided by AI systems. This framework aims to foster children's dispositional autonomy and enhance their understanding of AI by facilitating self-regulation in their interactions with these systems.}
}
@article{BOUCHER2024104041,
title = {Smart PSS modelling language for value offer prototyping: A design case study in the field of heating appliance offers},
journal = {Computers in Industry},
volume = {155},
pages = {104041},
year = {2024},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2023.104041},
url = {https://www.sciencedirect.com/science/article/pii/S0166361523001914},
author = {Xavier Boucher and Camilo Murillo Coba and Damien Lamy},
keywords = {Smart PSS, Design prototypes, Value offer design, Conceptual models},
abstract = {The recent convergence between two industrial transitions towards digitalization on the one side and servitization on the other side led to the new business strategies of digital servitization and smart PSS delivery. While inheriting from the previous scientific literature on PSS, because of the multiple impacts of digitalization in the overall system, the processes of ensuring the design and engineering of smart PSS solutions poses new challenges. This research addresses the specific needs to develop conceptual prototypes of smart PSS value offers, at early stages of the design process. The paper presents the development and experimentation of a modelling language and its associated modelling toolkit (sPS²Modeller). The application case study addresses the design of a smart PSS in the field of heating appliances, developed in collaboration with the company elm.leblanc, Bosch Group – France.}
}
@article{KEEGAN2023228,
title = {Examining the dark force consequences of AI as a new actor in B2B relationships},
journal = {Industrial Marketing Management},
volume = {115},
pages = {228-239},
year = {2023},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2023.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0019850123001918},
author = {Brendan James Keegan and Sophie Iredale and Peter Naudé},
keywords = {Artificial intelligence, B2B relationships, Dark forces, Tensions, Dehumanization},
abstract = {Artificial intelligence (AI) in industrial marketing has seen significant research attention through various theoretical lenses with an emerging thread examining the dark side effects of AI. Thirty-four semi-structured interviews were conducted with buyers and suppliers of AI marketing solutions to investigate the consequences of AI ‘dark forces’ on B2B relationships. We posit AI as a new actor that has blurred the lines of the actors-resources-activities model. Findings show AI is now considered a new actor within B2B networks wielding dark force consequences such as algorithmic gatekeeping, which initiates dehumanization effects. In addition, AI is reliant on access to datasets which drives up resource costs. A lack of accountability of AI marketing solutions leads to opportunistic behaviours compromising actor relationships. Our conceptual model maps our understanding of the dark force consequences underpinning theoretical and managerial implications and recommendations for increased awareness and mitigation of dark forces.}
}
@article{GWAGWA2024101078,
title = {How could the United Nations Global Digital Compact prevent cultural imposition and hermeneutical injustice?},
journal = {Patterns},
volume = {5},
number = {11},
pages = {101078},
year = {2024},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2024.101078},
url = {https://www.sciencedirect.com/science/article/pii/S266638992400237X},
author = {Arthur Gwagwa and Warmhold Jan Thomas Mollema},
keywords = {AI governance, AI regulation, Global Digital Compact, United Nations, cultural imposition, hermeneutical injustice, domination, artificial intelligence, AI ethics, AI colonialism},
abstract = {Summary
As the geopolitical superpowers race to regulate the digital realm, their divergent rights-centered, market-driven, and social-control-based approaches require a global compact on digital regulation. If diverse regulatory jurisdictions remain, forms of domination entailed by cultural imposition and hermeneutical injustice related to AI legislation and AI systems will follow. We argue for consensual regulation on shared substantive issues, accompanied by proper standardization and coordination. Failure to attain consensus will fragment global digital regulation, enable regulatory capture by authoritarian powers or bad corporate actors, and deepen the historical geopolitical power asymmetries between the global South and the global North. To prevent an unjust regulatory landscape where the global South’s cultural and hermeneutic resources are absent, two principles for the Global Digital Compact to counter these prospective harms are proposed and discussed: (1) “recognitive consensus on key substantive benefits and harms” and (2) “procedural consensus on global coordination and essential standards.”}
}
@article{SARKER2025123956,
title = {Examining consumer adoption of social commerce: An extended META-UTAUT model},
journal = {Technological Forecasting and Social Change},
volume = {212},
pages = {123956},
year = {2025},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2024.123956},
url = {https://www.sciencedirect.com/science/article/pii/S0040162524007546},
author = {Prianka Sarker and Laurie Hughes and Tegwen Malik and Yogesh K. Dwivedi},
keywords = {Adoption, Consumer, Information systems, Marketing, Social commerce, Social media, Use behavior},
abstract = {Social commerce has evolved into a mainstream channel for marketers and businesses for selling products online. However, consumers in many developing economies have yet to fully adopt social commerce technology. This research, therefore, aims to develop and empirically validate a conceptual model for understanding the factors influencing consumer adoption of social commerce in Bangladesh using an adapted and extended version of the Meta-UTAUT model. Analysis was undertaken to determine the appropriateness of external constructs such as trust, social support, anxiety, grievance redressal, innovativeness, and continuous participation intention. This research collected data from 402 social commerce users from Bangladesh to test and validate the proposed research model. The results suggest that performance expectancy, effort expectancy, innovativeness and trust have a direct influence on consumer attitude, whilst social influence, grievance redressal, facilitating conditions, social support, anxiety, and attitude, significantly influence usage behavior. The results also found that usage behavior is a strong predictor of continuous participation intention. This research contributes to existing knowledge by conceptualizing and validating a technology adoption model, which emphasizes the role of anxiety and grievance redressal in consumer acceptance of social commerce.}
}
@article{YAO2024e33531,
title = {The evolution of the ambidextrous innovation synergy strategy of new entrants from the perspective of key core technology monopoly},
journal = {Heliyon},
volume = {10},
number = {13},
pages = {e33531},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e33531},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024095628},
author = {Shuang Yao and Leke Wu and Donghua Yu},
keywords = {Key core technology, New entrants, Ambidextrous innovation synergy, Original innovation search, Network embedding},
abstract = {Ambidextrous innovation synergy is an effective way for new entrants and R&D entities to break the blockade of key core technologies. This paper constructs a tripartite evolutionary game model of new entrants, the R&D entity, and monopoly enterprises under the monopoly situation of key core technologies, discusses the dynamic equilibrium process of how new entrants cooperate with the R&D entity to carry out the ambidextrous innovation synergy strategy, and extends the model to the policy subsidy situations of different development stages of key core technology. The results show that the monopoly of key core technologies enhances the original innovation search ability of new entrants and promotes the evolution of enterprise imitation innovation to the exploratory innovation strategy. In the basic research stage of key core technology, the exploratory innovation strategy of new entrants is more sensitive to the cost of network embedding and the original innovation knowledge search. New entrants prefer the imitation innovation strategy, and policy subsidies have no significant effect on exploratory innovation. In the promotion stage of the key core technology market, fiscal and tax subsidies can more easily promote the evolution of new entrants from the imitative innovation strategy to the exploratory innovation strategy than R&D subsidies, and network embeddedness can induce enterprises to carry out exploratory innovation only when a certain threshold is reached. In addition, this paper discusses the influence mechanism of monopoly enterprises' suppression intensities and key core technology breakthrough probabilities on the evolution equilibrium of new entrants' ambidextrous innovation synergy strategies.}
}
@article{LENG2024111373,
title = {ArchiDiffusion: A novel diffusion model connecting architectural layout generation from sketches to Shear Wall Design},
journal = {Journal of Building Engineering},
volume = {98},
pages = {111373},
year = {2024},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2024.111373},
url = {https://www.sciencedirect.com/science/article/pii/S2352710224029413},
author = {Hao Leng and Yuqing Gao and Ying Zhou},
keywords = {Shear wall structures, Intelligent design framework, Layout generation, Deep learning, Diffusion model, Automation in building design},
abstract = {Shear wall structures are widely used in residential and office buildings, but the overall design process is complex and inefficient. This study introduces a novel diffusion-based model, named ArchiDiffusion, designed to revolutionize the generation of architectural floor plans from user-drawn sketches. ArchiDiffusion employs a two-stage process that ensures both creativity and practicality, setting a new standard in automated design. Embedded within the End-to-End Shear Wall Design (EESD) framework, ArchiDiffusion seamlessly integrates with existing structural design processes, including the previously developed StructDiffusion model, to streamline the traditionally complex and inefficient design workflow. Experimental results demonstrate that ArchiDiffusion significantly outperforms existing models in layout generation, reducing design time and enhancing project quality. A case study reveals that the EESD framework, powered by ArchiDiffusion, increases the design efficiency by 50 times compared to traditional workflows. Notably, ArchiDiffusion achieves a 9.6%–15.2% improvement in layout generation accuracy over traditional GAN-based models, while the EESD framework demonstrates an approximate 20% enhancement in overall building performance, as measured by energy efficiency and spatial optimization metrics. This research highlights the significant potential of ArchiDiffusion in intelligent design processes for shear wall residential buildings, offering a promising solution to the challenges faced in integrating architectural and structural design.}
}
@article{SHORE2024103063,
title = {Building entrepreneurial resilience during crisis using generative AI: An empirical study on SMEs},
journal = {Technovation},
volume = {135},
pages = {103063},
year = {2024},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2024.103063},
url = {https://www.sciencedirect.com/science/article/pii/S0166497224001135},
author = {Adam Shore and Manisha Tiwari and Priyanka Tandon and Cyril Foropon},
keywords = {Generative AI, Entrepreneurial orientation, Entrepreneurial resilience, Market turbulence, Dynamic capability view},
abstract = {Recently, Gen AI has garnered significant attention across various sectors of society, particularly capturing the interest of small business due to its capacity to allow them to reassess their business models with minimal investment. To understand how small and medium-sized firms have utilised Gen AI-based tools to cope with the market's high level of turbulence caused by the COVID-19 pandemic, geopolitical crises, and economic slowdown, researchers have conducted an empirical study. Although Gen AI is receiving more attention, there remains a dearth of empirical studies that investigate how it influences the entrepreneurial orientation of firms and their ability to cultivate entrepreneurial resilience amidst market turbulence. Most of the literature offers anecdotal evidence. To address this research gap, the authors have grounded their theoretical model and research hypotheses in the contingent view of dynamic capability. They tested the research hypotheses using cross-sectional data from a pre-tested survey instrument, which yielded 87 useable responses from small and medium enterprises in France. The authors used variance-based structural equation modelling with the commercial WarpPLS 7.0 software to test the theoretical model. The study's findings suggest that Gen AI and EO have a significant influence on building entrepreneurial resilience as higher-order and lower-order dynamic capabilities. However, market turbulence has a negative moderating effect on the path that joins entrepreneurial orientation and entrepreneurial resilience. The results suggest that the assumption that high market turbulence will have positive effects on dynamic capabilities and competitive advantage is not always true, and the linear assumption does not hold, which is consistent with some scholars' assumptions. The study's results offer significant contributions to the contingent view of dynamic capabilities and open new research avenues that require further investigation into the non-linear relationship of market turbulence.}
}
@article{WU2025105119,
title = {How well can ChatGPT forecast tourism demand?},
journal = {Tourism Management},
volume = {108},
pages = {105119},
year = {2025},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2024.105119},
url = {https://www.sciencedirect.com/science/article/pii/S0261517724002383},
author = {Doris Chenguang Wu and Wenjia Li and Ji Wu and Mingming Hu and Shujie Shen},
keywords = {tourism demand forecasting, ChatGPT, Zero-shot, Chain-of-Thought, artificial intelligence},
abstract = {ChatGPT has demonstrated remarkable capabilities across various natural language processing (NLP) tasks. However, its potential for forecasting tourism demand from temporal data, specifically historical tourism arrivals data, remains an unexplored frontier. This research presents the first attempt to conduct an extensive Zero-shot and Chain-of-Thought analysis of ChatGPT's capabilities in tourism demand forecasting, under various temporal scenarios. Based on the Macau inbound tourism arrivals dataset, our empirical findings indicate that the predictive capability of ChatGPT-4 is noteworthy compared to the three benchmark time series models (Naïve, Exponential Smoothing, SARIMA) and the three benchmark machine learning models (Random Forest, Multi-Layer Perceptron, Long Short-Term Memory), especially when the forecast horizon is relatively short. Furthermore, compared to Zero-shot prompts, engaging in continuous dialogue can enhance the forecast accuracy of ChatGPT-4. This performance of ChatGPT highlights its potential for quantitative data prediction as a new user-friendly and cost-effective management tool.}
}
@article{ALMOGREN2024e31887,
title = {Exploring factors influencing the acceptance of ChatGPT in higher education: A smart education perspective},
journal = {Heliyon},
volume = {10},
number = {11},
pages = {e31887},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e31887},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024079180},
author = {Abeer S. Almogren and Waleed Mugahed Al-Rahmi and Nisar Ahmed Dahri},
keywords = {Smart education, ChatGPT, Higher education, Acceptance factors, Technology adoption},
abstract = {AI-powered chatbots hold great promise for enhancing learning experiences and outcomes in today's rapidly evolving education system. However, despite the increasing demand for such technologies, there remains a significant research gap regarding the factors influencing users' acceptance and adoption of AI-powered chatbots in educational contexts. This study aims to address this gap by investigating the factors that shape users' attitudes, intentions, and behaviors towards adopting ChatGPT for smart education systems. This research employed a quantitative research approach, data were collected from 458 of participants through a structured questionnaire designed to measure various constructs related to technology acceptance, including perceived ease of use, perceived usefulness, feedback quality, assessment quality, subject norms, attitude towards use, and behavioral intention to use ChatGPT. Structural model analysis (SEM) Statistical techniques were then utilized to examine the relationships between these constructs. The findings of the study revealed that Perceived ease of use and perceived usefulness emerged as significant predictors of users' attitudes towards ChatGPT for smart education. Additionally, feedback quality, assessment quality, and subject norms were found to positively influence users' behavioral intentions to use ChatGPT for smart educational purposes. Moreover, users' attitudes towards use and behavioral intentions were significantly proved for the actual adoption of ChatGPT. However, a few hypotheses, such as the relationship between trust in ChatGPT and perceived usefulness, were not supported by the data. This study contributes to the existing body information systems applications for the determining factor of technology acceptance in smart education context.}
}
@article{ELJAOUHARI2025123658,
title = {Turning trash into treasure: Exploring the potential of AI in municipal waste management - An in-depth review and future prospects},
journal = {Journal of Environmental Management},
volume = {373},
pages = {123658},
year = {2025},
issn = {0301-4797},
doi = {https://doi.org/10.1016/j.jenvman.2024.123658},
url = {https://www.sciencedirect.com/science/article/pii/S0301479724036442},
author = {Asmae {El jaouhari} and Ashutosh Samadhiya and Anil Kumar and Eyob Mulat-weldemeskel and Sunil Luthra and Rajesh Kumar},
keywords = {Artificial intelligence, Conceptual framework, Municipal waste, Optimization, Performance metrics, Systematic literature review},
abstract = {Rapid urbanization, economic expansion, and population growth have increased waste generation in many nations worldwide. Research on municipal waste management (MWM) is moving towards new frontiers in efficiency and applicability due to the growing amount of data being collected in these systems and the convergence of various technological applications; artificial intelligence (AI) techniques present novel and creative alternatives for MWM. Even though much research has been conducted in this field, relatively few review studies assess how advancements in AI techniques can contribute to the sustainable advancement of MWM systems. Furthermore, there are discrepancies and a dearth of knowledge regarding the operation of AI-based techniques in MWM. To close this gap, this study conducts a thorough review of the relevant literature with an application of preferred reporting items for systematic reviews and meta-analyses-based methods, examining 229 peer-reviewed publications to explore the role of AI in different MWM areas, such as waste characteristics forecasting, waste bin level monitoring, process parameter prediction, vehicle routing, and MWM planning. The main AI techniques and models used in MWM optimization, as well as the application areas and stated performance metrics, are all thoroughly analyzed in this review. A conceptual framework is proposed to guide research and practice to take a holistic approach to MWM, along with areas of future study that need to be explored. Researchers, policymakers, municipalities, governments, and other waste management organizations will benefit from this study to minimize costs, maximize efficiency, eliminate the need for manual labor, and change the approach to MWM.}
}
@article{LIPNICKAS2025101017,
title = {Adaptive online course design: Analysis of changes in student behaviour throughout the degree lifecycle},
journal = {The Internet and Higher Education},
volume = {66},
pages = {101017},
year = {2025},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2025.101017},
url = {https://www.sciencedirect.com/science/article/pii/S1096751625000260},
author = {Gediminas Lipnickas and Joanne Harris and Bora Qesja and Svetlana {De Vos}},
keywords = {Learning analytics, Learning design, Engagement patterns, Academic performance, Online learning environments, Course design},
abstract = {With the growth of the online higher education sector, educational institutions are increasingly creating asynchronous online courses resembling Massive Open Online Courses (MOOCs), characterised by reduced interpersonal interactions. While these courses offer higher flexibility for students, much remains unknown about how the design of these courses impacts student behaviour and performance. This study combines learning analytics and learning design (via Open University Learning Design Initiative (OULDI) taxonomy) to examine effective online course design elements in a 100 % online environment. Effectiveness is evaluated based on the impact of design elements on student engagement and performance. Student engagement patterns throughout the degree are also explored. Results show that while assimilative activities are those most frequently undertaken by students, they rank as fourth in impact on performance. Experiential, interactive/adaptive, and productive activities, though more impactful, are less common and constitute only a fraction of online course design activities. Students were also more likely to engage with videos as opposed to readings, indicating a preference for this type of content in the online learning environment. Furthermore, an inverse correlation was found between students attempting a range of activities, and the need to communicate with staff (i.e., asking for clarification/guidance). Results also identified six types of student engagement patterns, revealing a transition over time towards an assessment focus, where students self-optimise and prioritise assessment completion (over other content/activities). In an online environment, where introducing sequential/scaffolding activities may prove difficult, findings indicate that activities should be clearly linked to assessments to cater for student engagement patterns.}
}
@article{TAN2025107715,
title = {EC5: Edge–cloud collaborative computing framework with compressive communication},
journal = {Future Generation Computer Systems},
volume = {166},
pages = {107715},
year = {2025},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2025.107715},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X2500010X},
author = {Jingwei Tan and Fagui Liu and Bin Wang and Qingbo Wu and C.L. Philip Chen},
keywords = {Edge computing, Edge–cloud collaborative computing, Collaborative inference, DNN partition, Feature compression},
abstract = {With an increasing number of deep neural network (DNN)-based applications being deployed at the edges, edge–cloud collaborative computing has emerged as a promising solution to alleviate the burden on resource-constrained edges by collaborative inference. However, simply offloading part of DNN to the cloud introduces significant communication overhead during inference. In this paper, we propose EC5, an Edge–Cloud Collaborative Computing framework with Compressive Communication. The compression of the intermediate feature is formulated using information theory and jointly optimized with the DNN through end-to-end multi-task learning. By decomposing DNN parameters into a new space, EC5 enables efficient storage and update of models across various compression levels. An Adaptive Exit scheme is designed to retain high-confidence inputs on the edge for fast inference, reducing reliance on the cloud. Experimental comparisons with baseline methods prove that EC5 significantly conserves network bandwidth and reduces communication instances, with low latency and acceptable accuracy loss, showing flexibility across different communication scenarios.}
}
@article{BIANCHINI2025124303,
title = {Drivers and barriers of AI adoption and use in scientific research},
journal = {Technological Forecasting and Social Change},
volume = {220},
pages = {124303},
year = {2025},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2025.124303},
url = {https://www.sciencedirect.com/science/article/pii/S0040162525003348},
author = {Stefano Bianchini and Moritz Müller and Pierre Pelletier},
keywords = {Artificial intelligence, Technology adoption, Scientific discovery, Economics of science},
abstract = {We study the early adoption and use of artificial intelligence (AI) in scientific research. Using a large dataset of publications from OpenAlex (all fields, up to 2024) and building on theories of scientific and technical human capital, we identify key factors that influence AI adoption. We find that early adopters were domain scientists embedded in AI-rich collaboration networks and affiliated with institutions with strong AI credentials. Access to high-performance computing (HPC) mattered only in a few scientific disciplines, such as biology and medical sciences. More recently, as tools like Large Language Models (LLMs) have diffused, AI has become more accessible, and institutional advantages appear to matter less. However, social capital—especially ties to AI-experienced collaborators and early-career researchers—remains a persistent driver of adoption. We discuss the implications for science policy and the organization of research in the age of AI.}
}
@article{KULAL2024100329,
title = {Enhancing public service delivery efficiency: Exploring the impact of AI},
journal = {Journal of Open Innovation: Technology, Market, and Complexity},
volume = {10},
number = {3},
pages = {100329},
year = {2024},
issn = {2199-8531},
doi = {https://doi.org/10.1016/j.joitmc.2024.100329},
url = {https://www.sciencedirect.com/science/article/pii/S2199853124001239},
author = {Abhinandan Kulal and Habeeb Ur Rahiman and Harinakshi Suvarna and N. Abhishek and Sahana Dinesh},
keywords = {Artificial Intelligence (AI), Public Service Delivery, Maturity Level, Efficiency Impact},
abstract = {This study aims to investigate the impact of Artificial Intelligence (AI) adoption on public service delivery efficiency in India. It addresses a significant gap in existing literature by investigating the impact of AI adoption on public service delivery efficiency in India, a context that has not been extensively explored. Through a comparative analysis approach, the study assesses the effectiveness of AI applications in enhancing public service delivery. The quantitative research design employed in the study draws on previous literature on AI integration in governance and focuses on Chief Information Officers (CIOs) as primary respondents. The findings reveal significant improvements in citizen-centric services and municipal processes due to AI adoption. However, the impact on human-centric aspects is found to be moderate. The study also underscores the importance of infrastructure readiness for successful AI implementation. Notably, only 25 % of organizations were found to be possessing advanced technological infrastructure. This research is original in its focus on Chief Information Officers (CIOs) as primary respondents and its comparative analysis approach to assess the effectiveness of AI applications in enhancing public service delivery. This study offers valuable insights for policymakers and practitioners. Emphasizing the need for effective policies and infrastructure development, it highlights the potential of AI to eliminate corruption risks and enhance overall efficiency and transparency in public service delivery mechanisms.}
}
@article{KARIOTIS2025,
title = {Patient-Accessible Electronic Health Records and Information Practices in Mental Health Care Contexts: Scoping Review},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/54973},
url = {https://www.sciencedirect.com/science/article/pii/S143888712500189X},
author = {Timothy Kariotis and Megan Prictor and Kathleen Gray and Shanton Chang},
keywords = {patient-accessible electronic health records, patient portals, psychiatry, mental health, health informatics, mental illness, scoping review},
abstract = {Background
Patients are increasingly being provided with access to their electronic health records. However, in mental health care contexts, concerns have been raised due to a perception that such access would pose risks to patients, third parties, and the therapeutic relationship. These perceived risks may affect the information practices of health care professionals (HCPs) and patients, such as how they document, share, and use information in mental health care services with a patient-accessible electronic health record (PAEHR). Although there is growing research interest in PAEHRs, no study has specifically examined how they impact information practices. Understanding the impacts on information practices may help explain other outcomes of implementing PAEHRs and inform their design.
Objective
This scoping review aimed to explore the research on PAEHRs in mental health care contexts and how PAEHRs affect information practices of HCPs and patients in this context.
Methods
A scoping review was considered the most appropriate method due to the relatively recent adoption of PAEHRs in mental health care contexts and the heterogeneous nature of the evidence base. A comprehensive search of electronic databases was conducted for original empirical studies that described the use of PAEHRs or associated systems in mental health care contexts. One author reviewed all full texts, with 3 other authors reviewing a subset of studies. The study characteristics and findings were documented, and a thematic synthesis and textual narrative analysis were used to develop descriptive and analytical themes that addressed the research questions.
Results
A total of 66 studies were considered eligible and included in the analysis. The impact of PAEHRs on information practices in mental health care contexts included the following: (1) they may change how HCPs document patient information, including a reduction in detail and a focus on information perceived by HCPs as objective rather than subjective; (2) they may negatively impact workflows due to changes in documentation practices and limited guidance for HCPs on how to use PAEHRs; and (3) they may contribute to improved communication between HCPs and patients, including constructive disagreements regarding what is documented in the health record. The changes to HCP information practices were influenced by a concern for the therapeutic relationship and patient safety. Furthermore, PAEHRs supported new information practices for patients, such as using their PAEHR to prepare for clinical encounters.
Conclusions
We have identified several ways in which PAEHRs shape the information practices of HCPs and patients in the mental health context. These findings can inform the design of PAEHRs to promote information practices that contribute to improving the quality of mental health care. Further research is necessary to understand how changes in information practices due to the implementation of PAEHRs impact clinical outcomes and patient experiences of care.}
}
@article{LIPPENS2024100054,
title = {Computer says ‘no’: Exploring systemic bias in ChatGPT using an audit approach},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {2},
number = {1},
pages = {100054},
year = {2024},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2024.100054},
url = {https://www.sciencedirect.com/science/article/pii/S2949882124000148},
author = {Louis Lippens},
keywords = {Large language models, ChatGPT, Systemic bias, Hiring discrimination, Correspondence audit},
abstract = {Large language models offer significant potential for increasing labour productivity, such as streamlining personnel selection, but raise concerns about perpetuating systemic biases embedded into their pre-training data. This study explores the potential ethnic and gender bias of ChatGPT—a chatbot producing human-like responses to language tasks—in assessing job applicants. Using the correspondence audit approach from the social sciences, I simulated a CV screening task with 34,560 vacancy–CV combinations where the chatbot had to rate fictitious applicant profiles. Comparing ChatGPT's ratings of Arab, Asian, Black American, Central African, Dutch, Eastern European, Hispanic, Turkish, and White American male and female applicants, I show that ethnic and gender identity influence the chatbot's evaluations. Ethnic discrimination is more pronounced than gender discrimination and mainly occurs in jobs with favourable labour conditions or requiring greater language proficiency. In contrast, gender bias emerges in gender-atypical roles. These findings suggest that ChatGPT's discriminatory output reflects a statistical mechanism echoing societal stereotypes. Policymakers and developers should address systemic bias in language model-driven applications to ensure equitable treatment across demographic groups. Practitioners should practice caution, given the adverse impact these tools can (re)produce, especially in selection decisions involving humans.}
}
@article{HOSSEINI2024142594,
title = {Mutual impacts of changing climate and flexible pavement performance considering resilience and sustainable aspects},
journal = {Journal of Cleaner Production},
volume = {460},
pages = {142594},
year = {2024},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2024.142594},
url = {https://www.sciencedirect.com/science/article/pii/S0959652624020420},
author = {Fatemeh Hosseini and Mahdi Nasimifar and Nadarajah Sivaneswaran and Amir Golalipour},
keywords = {Changing climate, Pavement performance, Life-cycle assessment, Sustainability, Resilience},
abstract = {Roads play a vital role in transportation systems, and their construction and maintenance expenses are high. Those reasons make crucial the examination of factors that accelerate road deterioration and those factors' negative impacts on societies. Climatic-related elements, especially temperature and precipitation, significantly affect the quality and lifespans of roads. The Intergovernmental Panel on Climate Change has reported that increasing greenhouse gas (GHG) emissions is causing changes in climate and that the rate of change has accelerated during the past several decades. To assess the impacts of changing climatic parameters on flexible-pavement performance, this study used 32 climate models to evaluate the performance of interstate, primary, and secondary roads across 11 diverse locations with varying traffic and climatic conditions. The study's findings reveal that changing climate exacerbates pavement distresses, leading to reduced pavement lifespans and increased numbers of reconstruction projects, which in turn raise demands for materials and equipment and contribute to higher GHG emissions. The effects of changing climate and changing climate's associated economic and environmental costs make the application of various engineering solutions to enhance pavement resilience essential, as described in this paper, in the absence of comprehensive emissions reduction strategies.}
}