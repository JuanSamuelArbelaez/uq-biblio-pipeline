@article{BASARAN2025111145,
title = {XAInomaly: Explainable and interpretable Deep Contractive Autoencoder for O-RAN traffic anomaly detection},
journal = {Computer Networks},
volume = {261},
pages = {111145},
year = {2025},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2025.111145},
url = {https://www.sciencedirect.com/science/article/pii/S1389128625001136},
author = {Osman Tugay Basaran and Falko Dressler},
keywords = {Explainable and trustworthy AI, Generative AI, O-RAN, Autoencoder, Anomaly detection, Network management},
abstract = {Generative Artificial Intelligence (AI) techniques have become integral part in advancing next generation wireless communication systems by enabling sophisticated data modeling and feature extraction for enhanced network performance. In the realm of open radio access networks (O-RAN), characterized by their disaggregated architecture and heterogeneous components from multiple vendors, the deployment of generative models offers significant advantages for network management such as traffic analysis, traffic forecasting and anomaly detection. However, the complex and dynamic nature of O-RAN introduces challenges that necessitate not only accurate detection mechanisms but also reduced complexity, scalability, and most importantly interpretability to facilitate effective network management. In this study, we introduce the XAInomaly framework, an explainable and interpretable Semi-supervised (SS) Deep Contractive Autoencoder (DeepCAE) design for anomaly detection in O-RAN. Our approach leverages the generative modeling capabilities of our SS-DeepCAE model to learn compressed, robust representations of normal network behavior, which captures essential features, enabling the identification of deviations indicative of anomalies. To address the black-box nature of deep learning models, we propose reactive Explainable AI (XAI) technique called fastshap-C, which is providing transparency into the model’s decision-making process and highlighting the features contributing to anomaly detection.}
}
@article{LI20241581,
title = {Sentiment Analysis Using E-Commerce Review Keyword-Generated Image with a Hybrid Machine Learning-Based Model},
journal = {Computers, Materials and Continua},
volume = {80},
number = {1},
pages = {1581-1599},
year = {2024},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2024.052666},
url = {https://www.sciencedirect.com/science/article/pii/S1546221824005113},
author = {Jiawen Li and Yuesheng Huang and Yayi Lu and Leijun Wang and Yongqi Ren and Rongjun Chen},
keywords = {Sentiment analysis, keyword-generated image, machine learning, Word2Vec-TextRank, CNN-SVM},
abstract = {In the context of the accelerated pace of daily life and the development of e-commerce, online shopping is a mainstream way for consumers to access products and services. To understand their emotional expressions in facing different shopping experience scenarios, this paper presents a sentiment analysis method that combines the e-commerce review keyword-generated image with a hybrid machine learning-based model, in which the Word2Vec-TextRank is used to extract keywords that act as the inputs for generating the related images by generative Artificial Intelligence (AI). Subsequently, a hybrid Convolutional Neural Network and Support Vector Machine (CNN-SVM) model is applied for sentiment classification of those keyword-generated images. For method validation, the data randomly comprised of 5000 reviews from Amazon have been analyzed. With superior keyword extraction capability, the proposed method achieves impressive results on sentiment classification with a remarkable accuracy of up to 97.13%. Such performance demonstrates its advantages by using the text-to-image approach, providing a unique perspective for sentiment analysis in the e-commerce review data compared to the existing works. Thus, the proposed method enhances the reliability and insights of customer feedback surveys, which would also establish a novel direction in similar cases, such as social media monitoring and market trend research.}
}
@article{GROZA2025100057,
title = {Realising the potential impact of artificial intelligence for rare diseases – A framework},
journal = {Rare},
volume = {3},
pages = {100057},
year = {2025},
issn = {2950-0087},
doi = {https://doi.org/10.1016/j.rare.2024.100057},
url = {https://www.sciencedirect.com/science/article/pii/S2950008724000401},
author = {Tudor Groza and Chun-Hung Chan and David A. Pearce and Gareth Baynam},
keywords = {Rare diseases, Patient journey, Generative artificial intelligence, Diagnosis, Care coordination},
abstract = {Rare diseases (RD) are conditions affecting fewer than 1 in 2000 persons, with over 7000 largely genetic RDs affecting 3.5 %-5.9 % of the global population, or approximately 262.9–446.2 million people. The substantial healthcare burden and costs, such as the $1 trillion annual expense in the USA, highlight the urgent need for improved RD management. The International Rare Diseases Research Consortium (IRDiRC) addresses this need through global collaboration, aiming for timely and accurate diagnosis, development of 1000 new therapies, and methodologies to measure impact by 2027. IRDiRC's initiatives include biannual meetings and workshops, like the AI-focused workshop in October 2023. This identified AI as crucial for advancing RD research and proposed a Framework for AI to enhance the RD patient journey by addressing efficiency and quality of life through modular solutions mapped to critical stages. The Framework integrates diverse data sources to improve diagnosis, treatment, and impact assessment, reflecting a holistic, cross-sector approach. By guiding multi-stakeholder efforts, the Framework aims to harness AI’s potential to significantly improve rare disease care.}
}
@article{AGUINIS2024101029,
title = {How to use generative AI as a human resource management assistant},
journal = {Organizational Dynamics},
volume = {53},
number = {1},
pages = {101029},
year = {2024},
issn = {0090-2616},
doi = {https://doi.org/10.1016/j.orgdyn.2024.101029},
url = {https://www.sciencedirect.com/science/article/pii/S0090261624000020},
author = {Herman Aguinis and Jose R. Beltran and Amando Cope},
keywords = {Artificial intelligence, Human resource management, Leadership, The future of work, Technology, Talent management},
abstract = {Human resource management (HRM) professionals are often overworked, and their jobs are increasingly complex. Therefore, many suffer from job burnout, and only some can allocate the necessary time to strategic issues. We show how generative artificial intelligence (AI), particularly ChatGPT, can be a helpful HRM assistant for both strategic and operational tasks. But, for this to happen, we demonstrate the need to create valuable prompts that result in specific, helpful, and actionable HRM recommendations. Accordingly, we provide eight guidelines for creating high-quality and effective prompts and illustrate their usefulness in general across eight critical HRM domains and in more depth in the particular areas of workforce diversity and strategic HRM. We also provide recommendations and demonstrate how to implement a critical verification process to check on ChatGPT’s suggestions. We conclude with a list of “dos and don’ts” and that when used by sufficiently trained HRM professionals, it is a very useful tool because it helps complete tasks faster, hopefully reducing their job burnout and allowing them to allocate more time to strategic and long-term issues. In turn, these benefits will likely result in helping achieve the as-of-yet-unrealized aspiration of “having a seat at the table.”}
}
@article{PANAGIOTOU2025106287,
title = {Generative AI-augmented offshore jacket design: Integrated approach for mixed tabular data generation under scarcity and imbalance},
journal = {Automation in Construction},
volume = {177},
pages = {106287},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2025.106287},
url = {https://www.sciencedirect.com/science/article/pii/S0926580525003279},
author = {Emmanouil Panagiotou and Han Qian and Steffen Marx and Eirini Ntoutsi},
keywords = {Artificial intelligence, Generative AI, Machine learning, Multi-objective optimization, Mixed tabular data, Data scarcity, Data imbalance, Offshore wind turbines, Industrial design, Offshore jacket substructure},
abstract = {Generative Artificial Intelligence (AI) has found various applications in domains like computer vision and natural language processing. However, limited research exists in the engineering domain, where prevailing challenges involve mixed tabular data, data scarcity, and imbalances. This paper focuses on generating synthetic offshore jacket designs to improve the data quality of a scarce and imbalanced existing dataset. Data quality is quantified by evaluating the machine-learning efficiency of the synthetic data on a domain-specific downstream task. An integrated method is proposed for generating jacket designs, combining modern data-driven techniques with traditional multi-objective-driven approaches. The method addresses challenges related to mixed attributes, data scarcity, and class imbalances. Experimental results demonstrate improved predictive performance on the downstream task when models are trained on synthetic data compared to using only real data. These findings contribute to the advancement of generative AI in offshore engineering and related fields, offering valuable insights and potential applications.}
}
@article{MUMUNI2025113,
title = {Automated data processing and feature engineering for deep learning and big data applications: A survey},
journal = {Journal of Information and Intelligence},
volume = {3},
number = {2},
pages = {113-153},
year = {2025},
issn = {2949-7159},
doi = {https://doi.org/10.1016/j.jiixd.2024.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S2949715924000027},
author = {Alhassan Mumuni and Fuseini Mumuni},
keywords = {AutoML, Automated data preprocessing, Data processing, Automated feature engineering, Generative artificial intelligence, Big data},
abstract = {Modern approach to artificial intelligence (AI) aims to design algorithms that learn directly from data. This approach has achieved impressive results and has contributed significantly to the progress of AI, particularly in the sphere of supervised deep learning. It has also simplified the design of machine learning systems as the learning process is highly automated. However, not all data processing tasks in conventional deep learning pipelines have been automated. In most cases data has to be manually collected, preprocessed and further extended through data augmentation before they can be effective for training. Recently, special techniques for automating these tasks have emerged. The automation of data processing tasks is driven by the need to utilize large volumes of complex, heterogeneous data for machine learning and big data applications. Today, end-to-end automated data processing systems based on automated machine learning (AutoML) techniques are capable of taking raw data and transforming them into useful features for big data tasks by automating all intermediate processing stages. In this work, we present a thorough review of approaches for automating data processing tasks in deep learning pipelines, including automated data preprocessing – e.g., data cleaning, labeling, missing data imputation, and categorical data encoding – as well as data augmentation (including synthetic data generation using generative AI methods) and feature engineering – specifically, automated feature extraction, feature construction and feature selection. In addition to automating specific data processing tasks, we discuss the use of AutoML methods and tools to simultaneously optimize all stages of the machine learning pipeline.}
}
@article{HAYAWI2024101533,
title = {Generative AI and large language models: A new frontier in reverse vaccinology},
journal = {Informatics in Medicine Unlocked},
volume = {48},
pages = {101533},
year = {2024},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2024.101533},
url = {https://www.sciencedirect.com/science/article/pii/S2352914824000893},
author = {Kadhim Hayawi and Sakib Shahriar and Hany Alashwal and Mohamed Adel Serhani},
keywords = {Reverse vaccinology, Large language models (LLMs), AI, Generative AI, Vaccine candidate identification, AI ethics, Vaccines},
abstract = {Reverse vaccinology is an emerging concept in the field of vaccine development as it facilitates the identification of potential vaccine candidates. Biomedical research has been revolutionized with the recent innovations in Generative Artificial Intelligence (AI) and Large Language Models (LLMs). The intersection of these two technologies is explored in this study. In this study, the impact of Generative AI and LLMs in the field of vaccinology is explored. Through a comprehensive analysis of existing research, prospective use cases, and an experimental case study, this research highlights that LLMs and Generative AI have the potential to enhance the efficiency and accuracy of vaccine candidate identification. This work also discusses the ethical and privacy challenges, such as data consent and potential biases, raised by such applications that require careful consideration. This study paves the way for experts, researchers, and policymakers to further investigate the role and impact of Generative AI and LLM in vaccinology and medicine.}
}
@article{CHOWDHURY2025129906,
title = {Handling language prior and compositional reasoning issues in Visual Question Answering system},
journal = {Neurocomputing},
volume = {635},
pages = {129906},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129906},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225005788},
author = {Souvik Chowdhury and Badal Soni},
keywords = {Visual Question Answering, Large language model, In-context learning, Computer vision, Natural language processing, Generative artificial intelligence},
abstract = {Visual Question Answering (VQA) models often suffer from language bias, favoring common but incorrect answers, and struggle with compositional reasoning in complex queries. This paper proposes a unified approach using a multimodal large language model enhanced with adaptive prompts designed for specific tasks. Our method directly addresses these issues by reducing language bias and improving compositional reasoning. Extensive evaluations on benchmark datasets, including VQA v2.0, VQACP, TDIUC, GQA, Visual7 W, TextVQA, and STVQA show that our approach outperforms state-of-the-art models, achieving accuracy improvements of 8% to 9%. These results demonstrate the effectiveness of our method in enhancing VQA accuracy, making it a significant advancement for more reliable and robust applications in real-world scenarios.}
}
@article{SHAYEGAN2025100722,
title = {A hybrid approach to content generation based on user experience using generative AI elements},
journal = {Machine Learning with Applications},
volume = {21},
pages = {100722},
year = {2025},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2025.100722},
url = {https://www.sciencedirect.com/science/article/pii/S2666827025001057},
author = {Mohammad Javad Shayegan and Hossein Hosseinpour},
keywords = {User experience (UX), User-centric, Content generation, Large language models (LLMS), Generative AI, GAI},
abstract = {Understanding and analyzing User Experience (UX) is a critical challenge in e-commerce. This study addresses the integration of UX analysis and Generative Artificial Intelligence (GAI) for content creation, presenting a two-phase approach. In the first phase, UX elements were extracted from user reviews of Amazon digital products and analyzed using clustering algorithms, including K-means, enhanced K-means, and Self-Organizing Maps (SOM). In the second phase, the top UX elements identified were used to generate promotional content with GPT-3.5 Turbo and Claude 3.5 Sonnet language models. The content was evaluated using the Perplexity metric, with three AI models—BERT, GPT-2, and DistilBERT. Results show that the enhanced K-means algorithm paired with GPT-3.5 Turbo achieved the best performance, yielding a Perplexity score of 3.476. This approach demonstrates the potential for leveraging real user data to create targeted and engaging content, providing businesses with actionable insights for improving audience engagement.}
}
@article{CLARKE2025106131,
title = {Principles for the responsible application of Generative AI},
journal = {Computer Law & Security Review},
volume = {57},
pages = {106131},
year = {2025},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2025.106131},
url = {https://www.sciencedirect.com/science/article/pii/S2212473X25000045},
author = {Roger Clarke},
keywords = {Risk assessment, Large language models, GenAI artefact, ChatGPT, Regulation},
abstract = {The quest for Artificial Intelligence (AI) has comprised successive waves of excessive enthusiasm followed by long, dispirited lulls. Most recently, during the first 3–4 years of public access to Generative Artificial Intelligence (GenAI), many authors have bought into the bullish atmosphere, replaying consultancies' predictions about gold mines of process efficiency and innovation. A more balanced approach to the technology is needed. Instances of apparently positive results need calm analysis, firstly to distinguish mirages from genuine contributions; secondly, to identify ways to effectively exploit the new capabilities; and thirdly, to formulate guidance for the avoidance and mitigation of negative consequences. This article's first contribution is to ground the evaluation of GenAI's pathway, applications, impacts, implications and risks in a sufficiently deep appreciation of the technology's nature and key features. A wide range of sources is drawn on, in order to present descriptions of the processes involved in text-based GenAI. From those processes, 20 key characteristics are abstracted that together give rise to the promise and the threats GenAI embodies. The effects of GenAI derive not from the technological features alone, but also from the patterns within which it is put to use. By mapping usage patterns across to domains of application, the phenomenon's impacts and implications can be more reliably delineated. The analysis provides a platform whereby the article's final contribution can be made. Previously-formulated principles for the responsible application of AI of all kinds are applied in the particular context of GenAI.}
}
@article{XIAO2025102835,
title = {Can ChatGPT replace humans in crisis communication? The effects of AI-mediated crisis communication on stakeholder satisfaction and responsibility attribution},
journal = {International Journal of Information Management},
volume = {80},
pages = {102835},
year = {2025},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2024.102835},
url = {https://www.sciencedirect.com/science/article/pii/S0268401224000835},
author = {Yi Xiao and Shubin Yu},
keywords = {Chatbot, AI, Crisis communication, Instructing information, Adjusting information},
abstract = {Imagine a world where chatbots are the first responders to crises, efficiently addressing concerns and providing crucial information. ChatGPT has demonstrated the capability of GenAI (Generative Artificial Intelligence)-powered chatbots when deployed to answer crisis-related questions in a timely and cost-efficient manner, thus replacing humans in crisis communication. However, public reactions to such messages remain unknown. To address this problem, this study recruited participants (N1 = 399, N2 = 189, and N3 = 121) and conducted two online vignette experiments and a qualitative survey. The results suggest that, when organizations fail to handle crisis-related requests, stakeholders exhibit higher satisfaction and lower responsibility attribution to chatbots providing instructing (vs. adjusting) information, as they are perceived to be more competent. However, when organizations satisfy requests, chatbots that provide adjusting (vs. instructing information) lead to higher satisfaction and lower responsibility attribution due to higher perceived competence. The second experiment involving a public emergency crisis scenario reveals that, regardless of the information provided (instructing or adjusting), stakeholders exhibit greater satisfaction and positive attitudes toward high-competence (vs. low-competence) chatbots. The qualitative study further confirms the experimental findings and offers insights to improve crisis chatbots. These findings contribute to the literature by extending situational crisis communication theory to nonhuman touchpoints and providing a deeper understanding of using chatbots in crisis communication through the lens of machine heuristics. The study also offers practical guidance for organizations to strategically integrate chatbots and human agents in crisis management based on context.}
}
@article{WANG2024100181,
title = {Comparing ChatGPT and clinical nurses’ performances on tracheostomy care: A cross-sectional study},
journal = {International Journal of Nursing Studies Advances},
volume = {6},
pages = {100181},
year = {2024},
issn = {2666-142X},
doi = {https://doi.org/10.1016/j.ijnsa.2024.100181},
url = {https://www.sciencedirect.com/science/article/pii/S2666142X24000080},
author = {Tongyao Wang and Juan Mu and Jialing Chen and Chia-Chin Lin},
keywords = {Generative artificial intelligence, ChatGPT, Education, Tracheostomy, Nursing},
abstract = {Background
The release of ChatGPT for general use in 2023 by OpenAI has significantly expanded the possible applications of generative artificial intelligence in the healthcare sector, particularly in terms of information retrieval by patients, medical and nursing students, and healthcare personnel.
Objective
To compare the performance of ChatGPT-3.5 and ChatGPT-4.0 to clinical nurses on answering questions about tracheostomy care, as well as to determine whether using different prompts to pre-define the scope of the ChatGPT affects the accuracy of their responses.
Design
Cross-sectional study.
Setting
The data collected from the ChatGPT was collected using the ChatGPT-3.5 and 4.0 using access provided by the University of Hong Kong. The data from the clinical nurses working in mainland China was collected using the Qualtrics survey program.
Participants
No participants were needed for collecting the ChatGPT responses. A total of 272 clinical nurses, with 98.5 % of them working in tertiary care hospitals in mainland China, were recruited using a snowball sampling approach.
Method
We used 43 tracheostomy care-related questions in a multiple-choice format to evaluate the performance of ChatGPT-3.5, ChatGPT-4.0, and clinical nurses. ChatGPT-3.5 and GPT-4.0 were both queried three times with the same questions by different prompts: no prompt, patient-friendly prompt, and act-as-nurse prompt. All responses were independently graded by two qualified otorhinolaryngology nurses on a 3-point accuracy scale (correct, partially correct, and incorrect). The Chi-squared test and Fisher exact test with post-hoc Bonferroni adjustment were used to assess the differences in performance between the three groups, as well as the differences in accuracy between different prompts.
Results
ChatGPT-4.0 showed significantly higher accuracy, with 64.3 % of responses rated as ‘correct’, compared to 60.5 % in ChatGPT-3.5 and 36.7 % in clinical nurses (X 2 = 74.192, p < .001). Except for the ‘care for the tracheostomy stoma and surrounding skin’ domain (X2 = 6.227, p = .156), scores from ChatGPT-3.5 and -4.0 were significantly better than nurses’ on domains related to airway humidification, cuff management, tracheostomy tube care, suction techniques, and management of complications. Overall, ChatGPT-4.0 consistently performed well in all domains, achieving over 50 % accuracy in each domain. Alterations to the prompt had no impact on the performance of ChatGPT-3.5 or -4.0.
Conclusion
ChatGPT may serve as a complementary medical information tool for patients and physicians to improve knowledge in tracheostomy care.
Tweetable abstract
ChatGPT-4.0 can answer tracheostomy care questions better than most clinical nurses. There is no reason nurses should not be using it.}
}
@article{YAU2025130847,
title = {Combinations of generative adversarial network and reinforcement learning: A survey},
journal = {Neurocomputing},
volume = {650},
pages = {130847},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.130847},
url = {https://www.sciencedirect.com/science/article/pii/S092523122501519X},
author = {Kok-Lim Alvin Yau and Yung-Wey Chong and Xiumei Fan and Faranak Nejati and Mohammad Kazem Chamran and Shalini Darmaraju},
keywords = {Generative artificial intelligence, Generative adversarial network, GAN, Reinforcement learning, RL, Artificial intelligence},
abstract = {A generative adversarial network (GAN) consists of a generator and a discriminator, which extract features and compete through min–max optimization in a zero-sum two-player game. Reinforcement learning (RL) enables a decision maker (agent) to observe, learn, and select optimal actions within a dynamic environment over time. The combination of these two artificial intelligence approaches, referred to as GAN-RL, presents a powerful synergy that leverages their strengths while addressing their respective limitations. This paper provides the first comprehensive review that systematically examines GAN-RL, offering an in-depth analysis of its theoretical foundations, key methodologies, and diverse applications. Specifically, we categorize GAN-RL approaches based on five primary objectives: (a) generating comprehensive synthetic datasets for training; (b) minimizing the discrepancies between value (or cumulative reward) distributions, where the cumulative reward is defined as the total sum of rewards an agent accumulates over the course of its interactions with the environment; (c) predicting the next scenario; (d) predicting the gradient of the generator in discrete tasks; and (e) learning from demonstrations. Our analysis highlights how GAN-RL enhances system performance, including improvements in cumulative reward, convergence rate, and prediction accuracy. By identifying open challenges and future research directions, this review fills a critical gap in the literature and serves as a valuable resource for researchers exploring the intersection of GANs and RL.}
}
@article{SHIN202340,
title = {Bridging the gap of bibliometric analysis: The evolution, current state, and future directions of tourism research using ChatGPT},
journal = {Journal of Hospitality and Tourism Management},
volume = {57},
pages = {40-47},
year = {2023},
issn = {1447-6770},
doi = {https://doi.org/10.1016/j.jhtm.2023.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S1447677023001596},
author = {Hakseung Shin and Juhyun Kang},
keywords = {Generative artificial intelligence (GAI), ChatGPT, Bibliometric analysis, Tourism research, Knowledge structure, Research agenda},
abstract = {ChatGPT can generate coherent text with unprecedented fluency by processing massive amounts of text data. Given the chatbot's remarkable accuracy in responses to a wide range of topics, this research aims to examine the evolution, present status, and future directions of tourism research using ChatGPT. A total of 15 interview questions were developed and semi-structured interviews were conducted with ChatGPT. The responses were qualitatively analyzed to identify the main themes associated with the issues of tourism research, such as key topics of previous research, forces to influence the evolution, achievement and limitations of research, and under examined areas of research. The use of ChatGPT provided valuable insights into the latest progressions within tourism research. For example, unlike the widely held view adopted by most tourism studies, ChatGPT indicates that the interdisciplinary nature of tourism research strongly contributes to the development of other academic fields, suggesting the maturity of tourism research.}
}
@article{ZHOU2025102508,
title = {Modern energy resilience studies with artificial intelligence for energy transitions},
journal = {Cell Reports Physical Science},
volume = {6},
number = {4},
pages = {102508},
year = {2025},
issn = {2666-3864},
doi = {https://doi.org/10.1016/j.xcrp.2025.102508},
url = {https://www.sciencedirect.com/science/article/pii/S2666386425001079},
author = {Yuekuan Zhou and Zhaohui Dan},
keywords = {climate change, energy resilience, carbon neutrality, sustainability development goals, machine learning, generative artificial intelligence, AI},
abstract = {Summary
Climate change and multifaceted energy crises necessitate resilient power systems for sustainable and smart energy transitions. However, correlations among energy efficiency, energy reliability, robustness, flexibility, and energy resilience remain unclear. This review employs bibliometric analysis to evaluate AI-driven solutions, particularly generative AI, in enhancing urban energy resilience. We quantify energy resilience metrics, as well as highlight the synergy among energy efficiency, energy reliability, robustness, flexibility, energy resilience with carbon neutrality, and multi-sector strategies across supply, demand, storage, and grid systems. The analysis demonstrates the capacity of AI to improve climate change adaptation during extreme events, illustrated as bio-inspired frameworks that emulate human self-regulation and self-healing. The integration of end-user participation and techno-economic-social benefits are emphasized. Big data technology facilitates information communications and inter-component interactions, while generative AI enables automatic city-scale information modeling and real-time decision-making. To conclude, we highlight challenges in smart energy transitions and suggest pathways to harmonize resilience with energy efficiency and reliability under climate challenges.}
}
@article{CHOI2024,
title = {Optimizing ChatGPT’s Interpretation and Reporting of Delirium Assessment Outcomes: Exploratory Study},
journal = {JMIR Formative Research},
volume = {8},
year = {2024},
issn = {2561-326X},
doi = {https://doi.org/10.2196/51383},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X24005225},
author = {Yong K Choi and Shih-Yin Lin and Donna Marie Fick and Richard W Shulman and Sangil Lee and Priyanka Shrestha and Kate Santoso},
keywords = {generative artificial intelligence, generative AI, large language models, ChatGPT, delirium detection, Sour Seven Questionnaire, prompt engineering, clinical vignettes, medical education, caregiver education},
abstract = {Background
Generative artificial intelligence (AI) and large language models, such as OpenAI’s ChatGPT, have shown promising potential in supporting medical education and clinical decision-making, given their vast knowledge base and natural language processing capabilities. As a general purpose AI system, ChatGPT can complete a wide range of tasks, including differential diagnosis without additional training. However, the specific application of ChatGPT in learning and applying a series of specialized, context-specific tasks mimicking the workflow of a human assessor, such as administering a standardized assessment questionnaire, followed by inputting assessment results in a standardized form, and interpretating assessment results strictly following credible, published scoring criteria, have not been thoroughly studied.
Objective
This exploratory study aims to evaluate and optimize ChatGPT’s capabilities in administering and interpreting the Sour Seven Questionnaire, an informant-based delirium assessment tool. Specifically, the objectives were to train ChatGPT-3.5 and ChatGPT-4 to understand and correctly apply the Sour Seven Questionnaire to clinical vignettes using prompt engineering, assess the performance of these AI models in identifying and scoring delirium symptoms against scores from human experts, and refine and enhance the models’ interpretation and reporting accuracy through iterative prompt optimization.
Methods
We used prompt engineering to train ChatGPT-3.5 and ChatGPT-4 models on the Sour Seven Questionnaire, a tool for assessing delirium through caregiver input. Prompt engineering is a methodology used to enhance the AI’s processing of inputs by meticulously structuring the prompts to improve accuracy and consistency in outputs. In this study, prompt engineering involved creating specific, structured commands that guided the AI models in understanding and applying the assessment tool’s criteria accurately to clinical vignettes. This approach also included designing prompts to explicitly instruct the AI on how to format its responses, ensuring they were consistent with clinical documentation standards.
Results
Both ChatGPT models demonstrated promising proficiency in applying the Sour Seven Questionnaire to the vignettes, despite initial inconsistencies and errors. Performance notably improved through iterative prompt engineering, enhancing the models’ capacity to detect delirium symptoms and assign scores. Prompt optimizations included adjusting the scoring methodology to accept only definitive “Yes” or “No” responses, revising the evaluation prompt to mandate responses in a tabular format, and guiding the models to adhere to the 2 recommended actions specified in the Sour Seven Questionnaire.
Conclusions
Our findings provide preliminary evidence supporting the potential utility of AI models such as ChatGPT in administering standardized clinical assessment tools. The results highlight the significance of context-specific training and prompt engineering in harnessing the full potential of these AI models for health care applications. Despite the encouraging results, broader generalizability and further validation in real-world settings warrant additional research.}
}
@article{LIN202485,
title = {Towards an AI policy framework in scholarly publishing},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {2},
pages = {85-88},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2023.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S1364661323002887},
author = {Zhicheng Lin},
keywords = {generative artificial intelligence, large language models, science, policy, publishing},
abstract = {The rapid adoption of artificial intelligence (AI) tools in academic research raises pressing ethical concerns. I examine major publishing policies in science and medicine, uncovering inconsistencies and limitations in guiding AI usage. To encourage responsible AI integration while upholding transparency, I propose an enabling framework with author and reviewer policy templates.}
}
@article{LOMURNO202552,
title = {Synthetic image learning: Preserving performance and preventing Membership Inference Attacks},
journal = {Pattern Recognition Letters},
volume = {190},
pages = {52-58},
year = {2025},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2025.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167865525000388},
author = {Eugenio Lomurno and Matteo Matteucci},
keywords = {Generative deep learning, Dataset generation, Classification Accuracy Score, Privacy, Membership Inference Attack, Generative Knowledge Distillation, Knowledge Recycling},
abstract = {Generative artificial intelligence has transformed the generation of synthetic data, providing innovative solutions to challenges like data scarcity and privacy, which are particularly critical in fields such as medicine. However, the effective use of this synthetic data to train high-performance models remains a significant challenge. This paper addresses this issue by introducing Knowledge Recycling (KR), a pipeline designed to optimise the generation and use of synthetic data for training downstream classifiers. At the heart of this pipeline is Generative Knowledge Distillation, the proposed technique that significantly improves the quality and usefulness of the information provided to classifiers through a synthetic dataset regeneration and soft labelling mechanism. The KR pipeline has been tested on a variety of datasets, with a focus on six highly heterogeneous medical image datasets, ranging from retinal images to organ scans. The results show a significant reduction in the performance gap between models trained on real and synthetic data, with models based on synthetic data outperforming those trained on real data in some cases. Furthermore, the resulting models show almost complete immunity to Membership Inference Attacks, manifesting privacy properties missing in models trained with conventional techniques.}
}
@article{NTOUMANIS2025102879,
title = {Self-determination theory informed research for promoting physical activity: Contributions, debates, and future directions},
journal = {Psychology of Sport and Exercise},
volume = {80},
pages = {102879},
year = {2025},
issn = {1469-0292},
doi = {https://doi.org/10.1016/j.psychsport.2025.102879},
url = {https://www.sciencedirect.com/science/article/pii/S1469029225000780},
author = {Nikos Ntoumanis and Arlen C. Moller},
keywords = {Narrative review, Tripartite model, Behavioral science, Motivation, Financial incentives, Competition},
abstract = {In this review we evaluate the applications of self-determination theory (SDT) research to promote motivation for physical activity (PA) and exercise. The evidence suggests that SDT-informed interventions are often effective at changing health behaviors, including PA/exercise, and associated health outcomes. The effect sizes are small to moderate and are often mediated by increases in autonomous motivation (primarily), interpersonal support for basic psychological needs, and competence need satisfaction. We also identify conceptual debates within the SDT literature and between SDT and other literatures, and discuss their relevance with respect to PA. We particularly focus on tripartite conceptualizations of interpersonal styles and psychological needs, whether there are more than three basic psychological needs, and the use of financial incentives and competition to promote PA. Our review also provides future conceptual and methodological directions for SDT-based research, building on advances in technology (e.g., generative Artificial Intelligence and Large Language Models) and the broader field of behavioral science (e.g., optimization designs, system-level interventions, behavior change intervention ontologies).}
}
@article{FASANO20251,
title = {The dilemma of accuracy in bankruptcy prediction: a new approach using explainable AI techniques to predict corporate crises},
journal = {European Journal of Innovation Management},
volume = {28},
number = {11},
pages = {1-22},
year = {2025},
issn = {1460-1060},
doi = {https://doi.org/10.1108/EJIM-06-2024-0633},
url = {https://www.sciencedirect.com/science/article/pii/S1460106024000075},
author = {Francesco Fasano and Carlo Adornetto and Iliess Zahid and Maurizio {La Rocca} and Luigi Montaleone and Gianluigi Greco and Alfio Cariola},
keywords = {Bankruptcy prediction, Corporate failure, Generative Artificial Intelligence, Business crisis management, Digital transformation},
abstract = {Purpose
Our aim is to develop a highly precise corporate crisis prediction model that surpasses previous versions, rooted in the forefront of technological advancements.
Design/methodology/approach
Artificial Intelligence (AI) for corporate default prediction with a novel approach based on a mix of techniques, enabling it to achieve a higher accuracy. We investigated models with sequence lengths that were both fixed and variable, and we chose the best variable sequence length model.
Findings
Our findings demonstrate that the artificial techniques implemented lead to very high accuracy in predicting business crises compared to previous research efforts, even those utilising long-time sequences or a high volume of observations.
Research limitations/implications
We highlight the key variables with a higher predictive power that need monitoring to prevent business crises. We also aim to open a new avenue of research that, starting from the use of these techniques and our results, can implement models incorporating non-accounting variables to prevent business crises.
Practical implications
We provide a model/tool that assesses a possible business crisis in advance through a monitoring and alert system. Policymakers can use our research’s output as a tool to combine with current credit-scoring systems and to assess the effectiveness of the new corporate crisis reforms that are upcoming in many European countries. The results of our research can be useful also to banks, public entities, and consulting firms that interact with companies and are interested in the evaluation of a firm’s financial health and stability.
Originality/value
Our innovative work leverages cutting-edge methodologies such as deep Recurrent Neural Networks and explainable AI. This choice is driven by the rapid evolution of AI techniques in practical application.}
}
@article{LAI2025,
title = {Roles of AI-Based Synthetic Data in Health Economics and Outcomes Research},
journal = {Value in Health},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.04.2157},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525023125},
author = {Tim C. Lai and Surachat Ngorsuraches},
keywords = {data privacy, generative artificial intelligence, privacy enhancing technology, synthetic data},
abstract = {Objectives
We aim to raise awareness of potential applications of synthetic data within the health economics and outcomes research (HEOR) community.
Methods
We provide a concise overview of synthetic data, including data generation and types. We then discuss 3 major data-associated challenges and how synthetic data may be used to address them. Finally, we discuss data utility, privacy protection, potential concerns of its applicability, and future research direction.
Results
The use of synthetic data is an alternative privacy protection technique to enhance data availability, strengthen the robustness of findings for underrepresented populations, and alleviate data insufficiency issues in rare disease research. More studies are needed to explore synthetic data use and address data challenges in HEOR studies. Furthermore, the development of an evaluation framework is encouraged to better support the integration of synthetic data into the HEOR field.
Conclusions
Synthetic data provide a unique opportunity to overcome data-related challenges in HEOR.}
}
@article{YANG2025116061,
title = {A systematic review of building energy performance forecasting approaches},
journal = {Renewable and Sustainable Energy Reviews},
volume = {223},
pages = {116061},
year = {2025},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2025.116061},
url = {https://www.sciencedirect.com/science/article/pii/S1364032125007348},
author = {Yizhou Yang and Qiuhua Duan and Forooza Samadi},
keywords = {Building energy performance forecasting (BEPF), Physics-based modeling, Black-box modeling, Hybrid-driven, Thermal properties of materials, Weather impact, Occupant behavior, Real-time adaptability, Artificial intelligence (AI) technique},
abstract = {Building energy performance forecasting (BEPF) is an active area of research with the potential to improve the efficiency of building energy management systems, support global sustainability goals, and mitigate climate change impacts. This systematic review examines three main prediction methods: model-driven, data-driven, and hybrid-driven, each with different principles, basics, advantages, disadvantages, practical applications, challenges, and limitations in addressing the complexities of building energy performance. The review focuses on key influencing factors, including building features, climatic conditions, and occupant behavior, while identifying critical research gaps in current methodologies. Through a bibliometric analysis of 95 relevant publications from 2019 to 2024, this review provides a quantitative overview of research progress and emerging trends. Findings indicate that although BEPF techniques have evolved rapidly, most studies continue to overlook the variability and complexity of occupant behavior, a factor with significantly affects forecast accuracy. To address this, we propose a modular AI-integrated forecasting framework that leverages the strengths of existing approaches, integrates real-time IoT data, and incorporate advanced artificial intelligence techniques, such as generative Artificial Intelligence, reinforcement learning, and Large Language Models (LLMs). A decision-making framework is also introduced to guide method selection based on specific building characteristics, data availability, desired accuracy, and operational goals, offering practical guidance for engineering and policy applications. Additionally, future research should extend beyond individual building dynamics to include a wider range of community-level determinants, such as policy frameworks, economic factors, and social determinants of health considerations (SDOH), aiming for a more comprehensive understanding of building energy consumption patterns. This review not only synthesizes current knowledge but also lays the foundation for future innovations in BEPF. We advocate for moving towards an AI-enhanced, adaptive forecasting model that can integrate different driven methods, capture the variability and unpredictability of occupant behavior, and improve the accuracy and reliability of energy forecasts.}
}
@article{ESPOSITO2025112607,
title = {Generative AI for software architecture. Applications, challenges, and future directions},
journal = {Journal of Systems and Software},
pages = {112607},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2025.112607},
url = {https://www.sciencedirect.com/science/article/pii/S0164121225002766},
author = {Matteo Esposito and Xiaozhou Li and Sergio Moreschini and Noman Ahmad and Tomas Cerny and Karthik Vaidhyanathan and Valentina Lenarduzzi and Davide Taibi},
keywords = {Generative AI, Software architecture, Multivocal literature review, Large language model, Prompt engineering, Model human interaction, XAI},
abstract = {Context:
Generative Artificial Intelligence (GenAI) is transforming much of software development, yet its application in software architecture is still in its infancy.
Aim:
Systematically synthesize the use, rationale, contexts, usability, and challenges of GenAI in software architecture.
Method:
Multivocal literature review (MLR), analyzing peer-reviewed and gray literature, identifying current practices, models, adoption contexts, reported challenges, and extracting themes via open coding.
Results:
This review identifies a significant adoption of GenAI for architectural decision support and architectural reconstruction. OpenAI GPT models are predominantly applied, and there is consistent use of techniques such as few-shot prompting and retrieval-augmented generation (RAG). GenAI has been applied mostly to the initial stages of the Software Architecture Life Cycle (SALC), such as Requirements-to-Architecture and Architecture-to-Code. Monolithic and microservice architectures were the main targets. However, rigorous testing of GenAI outputs was typically missing from the studies. Among the most frequent challenges are model precision, hallucinations, ethical aspects, privacy issues, lack of architecture-specific datasets, and the absence of sound evaluation frameworks.
Conclusions:
GenAI shows significant potential in software design, but there are several challenges on its way toward greater adoption. Research efforts should target designing general evaluation methodologies, handling ethics and precision, increasing transparency and explainability, and promoting architecture-specific datasets and benchmarks to overcome the gap between theoretical possibility and practical use. Editor’s note: Open Science material was validated by the Journal of Systems and Software Open Science Board.}
}
@article{ABIRAFEH202587,
title = {Can ChatGPT provide parent education for oral immunotherapy?},
journal = {Annals of Allergy, Asthma & Immunology},
volume = {135},
number = {1},
pages = {87-90},
year = {2025},
issn = {1081-1206},
doi = {https://doi.org/10.1016/j.anai.2025.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S1081120625002042},
author = {Jana Abi-Rafeh and Diana Toscano-Rivero and Bruce D. Mazer},
abstract = {Background
Oral Immunotherapy (OIT) has exhibited great potential in the treatment of food allergy. However, there is no global consensus on best practices of OIT. Parents of allergic children often struggle with concerns regarding OIT methodology, safety, and lack of accessible educational resources. ChatGPT is a generative artificial intelligence chatbot from OpenAI recognized for its ability to formulate human-like conversations. Although applications of artificial intelligence in medical settings continue to be explored, the effectiveness of ChatGPT as an educational resource remains unknown for OIT.
Objective
To assess the accuracy of ChatGPT as a self-guided educational resource for parents with children undergoing OIT.
Methods
A total of 14 common questions from parents regarding OIT were entered into ChatGPT version 3.5 and answers were copied verbatim. These responses were then categorized into basic, advanced, or medical, and evaluated by Allergy-Immunology health care practitioners from North America and the United Kingdom using a 10-point Likert scale. Response readability, understandability, and reproducibility were assessed using the Flesch Reading Ease and Flesch-Kincaid Grade level scores, the Patient Education Materials Assessment Tool, and natural language processing tools, respectively.
Results
The average median rankings by the practitioners per category were 8.6, 8.4, and 7.8 for basic, advanced, and medical, respectively. ChatGPT responses exhibited low readability scores, corresponding with a high-grade reading level. Understandability was between 73% to 84%, with scores decreased owing to response complexity. When assessing reproducibility, ChatGPT responses achieved rates between 83% and 93%.
Conclusion
Our results revealed that ChatGPT provides intelligible and comprehensive responses to patient questions. Health care practitioners polled were generally positive but identified important limitations.}
}
@article{JIN2025100107,
title = {Deep learning for three-dimensional (3D) plant phenomics},
journal = {Plant Phenomics},
pages = {100107},
year = {2025},
issn = {2643-6515},
doi = {https://doi.org/10.1016/j.plaphe.2025.100107},
url = {https://www.sciencedirect.com/science/article/pii/S264365152500113X},
author = {Shichao Jin and Dawei Li and Ting Yun and Jianling Tang and Ke Wang and Shaochen Li and Hongyi Yang and Si Yang and Shan Xu and Lin Cao and Haifeng Xia and Qinghua Guo and Yu Zhang and Dong Jiang and Yanfeng Ding},
keywords = {3D phenomics, deep learning, dataset, sampling, annotation},
abstract = {Abstract:
Plant phenomics, the comprehensive study of plant phenotypes, has gained prominence as a vital tool for understanding the intricate relationships between genotypes and the environment. Image-based plant phenomics has progressed rapidly, and three-dimensional (3D) phenotyping is a valuable extension of traditional 2D phenomics. However, the increased data dimensionality poses challenges to feature extraction and phenotyping. In recent decades, deep learning has led to remarkable progress in revolutionizing 3D phenotyping. Therefore, this review highlights the importance of using deep learning in 3D plant phenomics. It systematically overviews the capabilities of deep learning for 3D computer vision, covering 3D representation, classification, detection and tracking, semantic segmentation, instance segmentation, and generation. Additionally, deep learning techniques for 3D point preprocessing (e.g., annotation, downsampling, and dataset organization) and various plant phenotyping tasks are discussed. Finally, the challenges and perspectives associated with deep learning in 3D plant phenomics are summarized, including (1) benchmark dataset construction by using synthetic datasets and methods such as generative artificial intelligence and unsupervised or weakly supervised learning; (2) accurate and efficient 3D point cloud analysis by leveraging multitask learning, lightweight models, and self-supervised learning; and (3) deep learning for 3D plant phenomics by exploring interpretability, extensibility, and multimodal data utilization. The exploration of deep learning in 3D plant phenomics is poised to spur breakthroughs in a new dimension of plant science.}
}
@article{BISWAS2025450,
title = {Applying the stimulus-organism-behavior-consequence framework to examine the relationship between intention, usage and recommendation of ChatGPT in higher education},
journal = {International Journal of Educational Management},
volume = {39},
number = {2},
pages = {450-468},
year = {2025},
issn = {0951-354X},
doi = {https://doi.org/10.1108/IJEM-09-2023-0463},
url = {https://www.sciencedirect.com/science/article/pii/S0951354X25000109},
author = {Mohammad Islam Biswas and Md. Shamim Talukder and Yasheng Chen},
keywords = {Artificial intelligence, Technology adoption, ChatGPT, SOBC framework, Likelihood of recommending, Higher education},
abstract = {Purpose
The adoption and usage of generative artificial intelligence tools like Chat Generative Pre-Trained Transformer (ChatGPT) in academia is the subject of increasing research interest. This study investigates the factors influencing the intention, usage and recommendation of ChatGPT among university students by employing the stimulus-organism-behavior-consequence (SOBC) framework.
Design/methodology/approach
The proposed research model was validated by employing the partial least squares structural equation modeling (PLS-SEM) approach using 249 university students.
Findings
The study revealed that intention to use and usage behavior of ChatGPT among university students are highly influenced by perceived usefulness, initial trust, personal innovativeness and availability of information and support. Similarly, the study found a sequence of significant positive relationships among intention to use, actual use and likelihood of recommending the technology to others. However, the results showed that the impact of perceived ease of use and social influence on behavioral intention was not found to be significant predictors of intention to use ChatGPT in academic settings.
Practical implications
The research findings offer a number of benefits for educational institutions and technology developers regarding students’ perceptions of ChatGPT and its academic applications. Eventually, the findings will encourage AI technology developers to enhance the quality and design of their solutions. Additionally, it helps educators in designing the AI governance framework to promote the ethical and transparent use of AI in academic environments.
Originality/value
This study contributes to the expanding body of technology adoption research and offers an integrated theoretical framework for comprehending the adoption and usage of ChatGPT in academic settings.}
}
@article{MENG2025109974,
title = {A robust unified spoofing audio detection scheme},
journal = {Computers and Electrical Engineering},
volume = {122},
pages = {109974},
year = {2025},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2024.109974},
url = {https://www.sciencedirect.com/science/article/pii/S0045790624008991},
author = {Hao Meng and Wei Ou and Ju Huang and Haozhe Liang and Wenbao Han and Qionglu Zhang},
keywords = {Spoofing audio detection, Deepfakes, Self-supervised learning, Multi-task learning},
abstract = {The rapid development of generative artificial intelligence and deepfakes techniques makes it increasingly tough to identify different kinds of spoofing audio, which on one hand weakens the safety of Automatic Speaker Verification (ASV) systems, and on the other hand, negatively affects national security and societal stability. In the face of the emergence of constantly evolving forgery techniques, we need a detection model with strong generalization and high robustness to deal with them. In this work, we propose a Robust and Unified Spoofing Audio Detection (RUSAD) scheme, which is capable of dealing with multiple attacks such as logic attacks, replay attacks and adversarial attacks. We propose an innovative scheme from the perspectives of upstream feature extraction and downstream spoofing classification: the self-supervised upstream learning model based on the Conformer network extracts speech representations, establishes probabilistic spectrum-augmentation events to improve model robustness against adversarial attacks, and formulate multiple decoding tasks for classification and regression; downstream classification of audio spoofing based on inference of the SE-ResNeXt network, supplemented by self-attention pooling and the OC-Softmax angular loss function in order to improve classification performance. We perform detailed experimental evaluations on both the ASVspoof2021 and ADD2023 datasets. The results show that the scheme has improved performance, generalization, and robustness in comparison to the baseline system as well as to most forensic countermeasures, which are capable of achieving the goal of dealing with multiple attacks.}
}
@incollection{MACEDO202583,
title = {Chapter 3 - Automating drug discovery},
editor = {Alberto Pais and Carla Vitorino and Sandra Nunes and Tânia Cova},
booktitle = {Artificial Intelligence for Drug Product Lifecycle Applications},
publisher = {Academic Press},
pages = {83-97},
year = {2025},
isbn = {978-0-323-91819-0},
doi = {https://doi.org/10.1016/B978-0-323-91819-0.00003-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323918190000038},
author = {Bruno Macedo and Tiago Taveira-Gomes},
keywords = {Drug design, Drug discovery, Drug repurposing, Generative artificial intelligence, Graph-based models, Machine learning, Neural networks, Predictive toxicology},
abstract = {The development of new effective medicines has become an urgency. Multiple drug resistant bacteria, tumor heterogeneity, autoimmune disorders or viral mutations emphasizes the urgency for new treatments. Generative Artificial Intelligence is a promising approach to identify new patterns in molecular optimization by effectively exploring the vast chemical space. Graph-based models have emerged as powerful deep learning techniques. These models are capable of processing large datasets and mapping complex correlations more efficiently than traditional methods. This paper explores the technical foundations from graph-based Artificial Intelligence models on training optimization to ensure accuracy and reliable predictions for their purpose in drug discovery, including molecule screening, drug optimization, and understanding molecular interactions.}
}
@article{HUNG2025100151,
title = {The efficacy of incorporating Artificial Intelligence (AI) chatbots in brief gratitude and self-affirmation interventions: Evidence from two exploratory experiments},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {4},
pages = {100151},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100151},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000350},
author = {Jing Wen Hung and Andree Hartanto and Adalia Y.H. Goh and Zoey K.Y. Eun and K.T.A. Sandeeshwara Kasturiratna and Zhi Xuan Lee and Nadyanna M. Majeed},
keywords = {Positive psychology intervention, Gratitude, Self-affirmation, Artificial intelligence, AI chatbots, Well-being},
abstract = {Numerous studies have demonstrated that positive psychology interventions, including brief interventions, can significantly improve well-being outcomes. These findings are particularly important given that many of these interventions are brief and self-administered, making them both accessible and scalable for large populations. However, the efficacy of positive psychology interventions is often constrained by small effect sizes. In light of advancements in generative Artificial Intelligence (AI), this study explored whether integrating AI chatbots into positive psychology interventions could enhance their efficacy compared to traditional self-administered approaches. Study 1 examined the efficacy of a gratitude intervention delivered through Snapchat's My AI, while Study 2 evaluated a self-affirmation intervention integrated with a customized ChatGPT. Both studies employed within-subject experimental designs. Contrary to our hypotheses, the integration of AI did not yield incremental improvements in gratitude outcomes (Study 1), or self-view outcomes (Study 2) compared to existing non-AI interventions. However, exploratory analyses revealed that the AI-integrated self-affirmation intervention significantly enhanced life satisfaction and medium-arousal positive affect, suggesting potential benefits for selected well-being outcomes. These findings indicate that while AI integration in brief, self-administered positive psychology interventions may enhance certain outcomes, its suitability varies across intervention types. Further research is needed to better understand the contexts in which AI can effectively augment positive psychology interventions.}
}
@article{FENG2024537,
title = {From HAL to GenAI: Optimizing chatbot impacts with CARE},
journal = {Business Horizons},
volume = {67},
number = {5},
pages = {537-548},
year = {2024},
note = {SPECIAL ISSUE: WRITTEN BY CHATGPT},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2024.04.012},
url = {https://www.sciencedirect.com/science/article/pii/S0007681324000570},
author = {Cai (Mitsu) Feng and Elsamari Botha and Leyland Pitt},
keywords = {Generative AI, Chatbots, AI adoption, AI risks, AI ethics, Large language models},
abstract = {This article explores the evolution and prospects of conversational chatbots, specifically the latest generation referred to as generative artificial intelligence (GenAI) chatbots. This article comprehensively examines GenAI chatbots’ business applications and impact across macro, meso, and micro levels of organizations. At the macro level, this article explores how GenAI chatbots reshape industry dynamics. The meso perspective delves into organizational changes, while the micro lens focuses on enhancing individual productivity, learning, and creativity. GenAI chatbots’ immense potential is accompanied by risks in four areas: matching, ethics, technology, and adaptability (META). In response to these challenges, the article introduces a human-centric CARE framework—standing for collaboration, accountability, responsiveness, and empowerment—to mitigate the risks and to optimize the effects of GenAI chatbots. This work provides practical guidelines for navigating the complex landscape of GenAI implementation.}
}
@article{HIROSAWA2024,
title = {Comparative Analysis of Diagnostic Performance: Differential Diagnosis Lists by LLaMA3 Versus LLaMA2 for Case Reports},
journal = {JMIR Formative Research},
volume = {8},
year = {2024},
issn = {2561-326X},
doi = {https://doi.org/10.2196/64844},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X24006528},
author = {Takanobu Hirosawa and Yukinori Harada and Kazuki Tokumasu and Tatsuya Shiraishi and Tomoharu Suzuki and Taro Shimizu},
keywords = {artificial intelligence, clinical decision support system, generative artificial intelligence, large language models, natural language processing, NLP, AI, clinical decision making, decision support, decision making, LLM: diagnostic, case report, diagnosis, generative AI, LLaMA},
abstract = {Background
Generative artificial intelligence (AI), particularly in the form of large language models, has rapidly developed. The LLaMA series are popular and recently updated from LLaMA2 to LLaMA3. However, the impacts of the update on diagnostic performance have not been well documented.
Objective
We conducted a comparative evaluation of the diagnostic performance in differential diagnosis lists generated by LLaMA3 and LLaMA2 for case reports.
Methods
We analyzed case reports published in the American Journal of Case Reports from 2022 to 2023. After excluding nondiagnostic and pediatric cases, we input the remaining cases into LLaMA3 and LLaMA2 using the same prompt and the same adjustable parameters. Diagnostic performance was defined by whether the differential diagnosis lists included the final diagnosis. Multiple physicians independently evaluated whether the final diagnosis was included in the top 10 differentials generated by LLaMA3 and LLaMA2.
Results
In our comparative evaluation of the diagnostic performance between LLaMA3 and LLaMA2, we analyzed differential diagnosis lists for 392 case reports. The final diagnosis was included in the top 10 differentials generated by LLaMA3 in 79.6% (312/392) of the cases, compared to 49.7% (195/392) for LLaMA2, indicating a statistically significant improvement (P<.001). Additionally, LLaMA3 showed higher performance in including the final diagnosis in the top 5 differentials, observed in 63% (247/392) of cases, compared to LLaMA2’s 38% (149/392, P<.001). Furthermore, the top diagnosis was accurately identified by LLaMA3 in 33.9% (133/392) of cases, significantly higher than the 22.7% (89/392) achieved by LLaMA2 (P<.001). The analysis across various medical specialties revealed variations in diagnostic performance with LLaMA3 consistently outperforming LLaMA2.
Conclusions
The results reveal that the LLaMA3 model significantly outperforms LLaMA2 per diagnostic performance, with a higher percentage of case reports having the final diagnosis listed within the top 10, top 5, and as the top diagnosis. Overall diagnostic performance improved almost 1.5 times from LLaMA2 to LLaMA3. These findings support the rapid development and continuous refinement of generative AI systems to enhance diagnostic processes in medicine. However, these findings should be carefully interpreted for clinical application, as generative AI, including the LLaMA series, has not been approved for medical applications such as AI-enhanced diagnostics.}
}
@article{WU2025691,
title = {Unleashing the power of text for credit default prediction: Comparing human-written and generative AI-refined texts},
journal = {European Journal of Operational Research},
volume = {326},
number = {3},
pages = {691-706},
year = {2025},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2025.04.032},
url = {https://www.sciencedirect.com/science/article/pii/S0377221725003170},
author = {Zongxiao Wu and Yizhe Dong and Yaoyiran Li and Baofeng Shi},
keywords = {OR in banking, Generative AI, Large language model, Credit risk, Text mining},
abstract = {This study explores the integration of a representative large language model, ChatGPT, into lending decision-making with a focus on credit default prediction. Specifically, we use ChatGPT to analyse and interpret loan assessments written by loan officers and generate refined versions of these texts. Our comparative analysis reveals significant differences between generative artificial intelligence (AI)-refined and human-written texts in terms of text length, semantic similarity, and linguistic representations. Using deep learning techniques, we show that incorporating unstructured text data, particularly ChatGPT-refined texts, alongside conventional structured data significantly enhances credit default predictions. Furthermore, we demonstrate how the contents of both human-written and ChatGPT-refined assessments contribute to the models’ prediction and show that the effect of essential words is highly context-dependent. Moreover, we find that ChatGPT’s analysis of borrower delinquency contributes the most to improving predictive accuracy. We also evaluate the business impact of the models based on human-written and ChatGPT-refined texts, and find that, in most cases, the latter yields higher profitability than the former. This study provides valuable insights into the transformative potential of generative AI in financial services.}
}
@article{ZOU2025103940,
title = {Bringing Attention to CAD: Boundary Representation Learning via Transformer},
journal = {Computer-Aided Design},
volume = {189},
pages = {103940},
year = {2025},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2025.103940},
url = {https://www.sciencedirect.com/science/article/pii/S0010448525001010},
author = {Qiang Zou and Lizhen Zhu},
keywords = {Computer-aided design, Boundary representation models, Deep learning, Transformer, B-rep learning},
abstract = {The recent rise of generative artificial intelligence (AI), powered by Transformer networks, has achieved remarkable success in natural language processing, computer vision, and graphics. However, the application of Transformers in computer-aided design (CAD), particularly for processing boundary representation (B-rep) models, remains largely unexplored. To bridge this gap, we propose a novel approach for adapting Transformers to B-rep learning, called the Boundary Representation Transformer (BRT). B-rep models pose unique challenges due to their irregular topology and continuous geometric definitions, which are fundamentally different from the structured and discrete data Transformers are designed for. To address this, BRT proposes a continuous geometric embedding method that encodes B-rep surfaces (trimmed and untrimmed) into Bézier triangles, preserving their shape and continuity without discretization. Additionally, BRT employs a topology-aware embedding method that organizes these geometric embeddings into a sequence of discrete tokens suitable for Transformers, capturing both geometric and topological characteristics within B-rep models. This enables the Transformer’s attention mechanism to effectively learn shape patterns and contextual semantics of boundary elements in a B-rep model. Extensive experiments demonstrate that BRT achieves state-of-the-art performance in part classification and feature recognition tasks.}
}
@article{ISMAILFAWAZ2025104337,
title = {Establishing a unified evaluation framework for human motion generation: A comparative analysis of metrics},
journal = {Computer Vision and Image Understanding},
volume = {254},
pages = {104337},
year = {2025},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2025.104337},
url = {https://www.sciencedirect.com/science/article/pii/S1077314225000608},
author = {Ali Ismail-Fawaz and Maxime Devanne and Stefano Berretti and Jonathan Weber and Germain Forestier},
keywords = {Human motion generation, Evaluation of generative models, Generative models metrics, Human motion data},
abstract = {The development of generative artificial intelligence for human motion generation has expanded rapidly, necessitating a unified evaluation framework. This paper presents a detailed review of eight evaluation metrics for human motion generation, highlighting their unique features and shortcomings. We propose standardized practices through a unified evaluation setup to facilitate consistent model comparisons. Additionally, we introduce a novel metric that assesses diversity in temporal distortion by analyzing warping diversity, thereby enhancing the evaluation of temporal data. We also conduct experimental analyses of three generative models using two publicly available datasets, offering insights into the interpretation of each metric in specific case scenarios. Our goal is to offer a clear, user-friendly evaluation framework for newcomers, complemented by publicly accessible code: https://github.com/MSD-IRIMAS/Evaluating-HMG.}
}
@article{SALAH2025101698,
title = {Can generative AI craft scale items? A mixed-method study on AI's capability to adapt and create new scales with recommendations for best practices},
journal = {Social Sciences & Humanities Open},
volume = {12},
pages = {101698},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101698},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125004267},
author = {Mohammed Salah and Fadi Abdelfattah and Hussam {Al Halbusi} and Suaad Jassem and Muna Mohammed and Maria Mohd Ismail and Amira {Al Balghouni}},
keywords = {Generative AI, Scale development, ChatGPT, Trust in AI, AI self-efficacy, AI risk perception},
abstract = {This study explored the potential of generative artificial intelligence (AI), specifically Generative Pre-trained Transformer 4 (GPT-4), in revolutionizing the development and adaptation of research scales, a process traditionally characterized by its time-intensive nature and susceptibility to human bias. This study employed a mixed-method approach and assessed GPT-4's ability to generate reliable and valid scales and compared them with conventional methods. GPT-4 was chosen for its accessibility and accuracy in producing contextually appropriate items. Quantitative analysis confirmed the reliability and validity of the AI-generated scales, while expert evaluations highlighted the model's ability to enhance methodological efficiency and reduce bias. However, this study underscores the importance of combining AI's computational strengths with human expertise to ensure optimal outcomes. This research integrates generative AI into scale development and introduces innovative practices that streamline the process without compromising quality. These findings pave the way for future explorations of AI's role in research methodologies, and offer recommendations for best practices in using AI for scale development. This study contributes to the broader discourse on AI's transformative potential in research, and emphasizes its capacity to enhance the precision and efficiency of data collection tools.}
}
@article{SHAW2025102495,
title = {Physical artificial intelligence in nursing: Robotics},
journal = {Nursing Outlook},
volume = {73},
number = {5},
pages = {102495},
year = {2025},
issn = {0029-6554},
doi = {https://doi.org/10.1016/j.outlook.2025.102495},
url = {https://www.sciencedirect.com/science/article/pii/S0029655425001484},
author = {Ryan J. Shaw and Boyuan Chen},
keywords = {Nursing, Robotics, Generative artificial intelligence},
abstract = {Background
Robotics, driven by advancements in physical artificial intelligence (AI), offers potential solutions–yet many challenges– to creating innovative care models to meet the needs of the future.
Purpose
To present an overview of robotics across various industries and explain how physical AI is aiding the development and integration of robots into skilled nursing. We discuss the opportunities and challenges of incorporating robots into nursing and offer recommendations for nurses on designing equitable, human-centered care models that include robotics.
Methods
This paper discusses robotics across industries, with a focus on healthcare and nursing. It examines technological capabilities, nursing education needs, and ethical, regulatory, and workforce implications.
Discussion
Robots are increasingly used for logistics, cleaning, and limited direct care tasks. Advancement in physical AI will enable robots to perceive, reason, and act in dynamic environments, supporting human-robot teaming and patient care. Challenges include technical limitations, ethical concerns, disparities in access, and regulatory gaps. Nursing education must evolve to prepare professionals for collaborative practice with robotic systems.
Conclusion
Robotics must be designed to augment care delivery, such as through virtual care models and remote operation. Nurses must lead in designing, implementing, and regulating robotic technologies to ensure they enhance patient outcomes and promote health equity.}
}
@article{ZHANG2024,
title = {Examining the Role of Large Language Models in Orthopedics: Systematic Review},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/59607},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124007970},
author = {Cheng Zhang and Shanshan Liu and Xingyu Zhou and Siyu Zhou and Yinglun Tian and Shenglin Wang and Nanfang Xu and Weishi Li},
keywords = {large language model, LLM, orthopedics, generative pretrained transformer, GPT, ChatGPT, digital health, clinical practice, artificial intelligence, AI, generative AI, Bard},
abstract = {Background
Large language models (LLMs) can understand natural language and generate corresponding text, images, and even videos based on prompts, which holds great potential in medical scenarios. Orthopedics is a significant branch of medicine, and orthopedic diseases contribute to a significant socioeconomic burden, which could be alleviated by the application of LLMs. Several pioneers in orthopedics have conducted research on LLMs across various subspecialties to explore their performance in addressing different issues. However, there are currently few reviews and summaries of these studies, and a systematic summary of existing research is absent.
Objective
The objective of this review was to comprehensively summarize research findings on the application of LLMs in the field of orthopedics and explore the potential opportunities and challenges.
Methods
PubMed, Embase, and Cochrane Library databases were searched from January 1, 2014, to February 22, 2024, with the language limited to English. The terms, which included variants of “large language model,” “generative artificial intelligence,” “ChatGPT,” and “orthopaedics,” were divided into 2 categories: large language model and orthopedics. After completing the search, the study selection process was conducted according to the inclusion and exclusion criteria. The quality of the included studies was assessed using the revised Cochrane risk-of-bias tool for randomized trials and CONSORT-AI (Consolidated Standards of Reporting Trials–Artificial Intelligence) guidance. Data extraction and synthesis were conducted after the quality assessment.
Results
A total of 68 studies were selected. The application of LLMs in orthopedics involved the fields of clinical practice, education, research, and management. Of these 68 studies, 47 (69%) focused on clinical practice, 12 (18%) addressed orthopedic education, 8 (12%) were related to scientific research, and 1 (1%) pertained to the field of management. Of the 68 studies, only 8 (12%) recruited patients, and only 1 (1%) was a high-quality randomized controlled trial. ChatGPT was the most commonly mentioned LLM tool. There was considerable heterogeneity in the definition, measurement, and evaluation of the LLMs’ performance across the different studies. For diagnostic tasks alone, the accuracy ranged from 55% to 93%. When performing disease classification tasks, ChatGPT with GPT-4’s accuracy ranged from 2% to 100%. With regard to answering questions in orthopedic examinations, the scores ranged from 45% to 73.6% due to differences in models and test selections.
Conclusions
LLMs cannot replace orthopedic professionals in the short term. However, using LLMs as copilots could be a potential approach to effectively enhance work efficiency at present. More high-quality clinical trials are needed in the future, aiming to identify optimal applications of LLMs and advance orthopedics toward higher efficiency and precision.}
}
@article{COPPOLINO2025129406,
title = {The good, the bad, and the algorithm: The impact of generative AI on cybersecurity},
journal = {Neurocomputing},
volume = {623},
pages = {129406},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129406},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225000785},
author = {Luigi Coppolino and Salvatore D’Antonio and Giovanni Mazzeo and Federica Uccello},
keywords = {AI, Artificial intelligence, Generative adversarial network, Web security, Network security, Attack obfuscation, Intrusion detection system},
abstract = {Generative Adversarial Networks (GANs) are emerging as a transformative technology in cybersecurity, presenting both opportunities and challenges in enhancing defensive and offensive strategies. This paper explores the impact that Generative Artificial Intelligence (AI) has on cybersecurity, focusing on its application in the field of network and web security. Current research reveals robust defensive approaches; however, there remains a significant gap in the application of Generative AI to develop advanced attack scenarios capable of bypassing existing defense mechanisms. Our work attempts to fill this gap and spreads awareness regarding a potential exposure of Neural Network (NN)-based Intrusion Detection Systems (IDSs) against AI-enhanced attacks. Unlike conventional approaches that focus on Input Perturbation, Data Poisoning, or Spoofing, we propose a novel offensive strategy called Attack Obfuscation. This strategy leverages Conditional GANs (CGANs) to conceal genuine attacks by injecting synthetic traffic designed to deceive NN-based IDS. The experimental investigation validates the proposed approach against three distinct datasets and different typologies of attacks, managing to successfully deceive the IDS.}
}
@article{MOORHOUSE2024103399,
title = {Developing language teachers’ professional generative AI competence: An intervention study in an initial language teacher education course},
journal = {System},
volume = {125},
pages = {103399},
year = {2024},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2024.103399},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X24001817},
author = {Benjamin Luke Moorhouse and Yuwei Wan and Chenze Wu and Lucas Kohnke and Tsz Ying Ho and Theresa Kwong},
abstract = {Generative Artificial Intelligence (GenAI) tools have been argued to have transformative potential in education; yet existing literature suggests that language teachers generally lack the abilities to leverage these tools effectively and critically. Conducted in an initial language teacher education programme at a Hong Kong university, this mixed-method intervention study aims to explore the effects of explicit training for using GenAI tools for language teaching in rising pre-service language teachers’ professional GenAI competence (P-GenAI-C). 54 M.Ed students took part in an 11-week course intervention aiming to enhance the five aspects in the P-GenAI-C framework. Analysis of pre- and post-intervention questionnaires, which encompassed a mix of open and closed items to gather participants’ knowledge and perceptions of utilising GenAI tools, as well as the follow-up interviews, revealed that the intervention was effective in stretching all aspects of pre-service teachers’ P-GenAI-C. While there was greater evidence of improvement in participants’ pedagogical competence and critical awareness of GenAI tools deployment, there was less evidence of development in other aspects, such as teachers’ capacity to guide their students to use GenAI tools effectively and responsibly. This discrepancy might be attributed to the lack of such content in the course intervention. Implications for incorporating elements of P-GenAI-C into teacher preparation courses and programmes are discussed.}
}
@article{LEE2024103690,
title = {Human vs. AI: The battle for authenticity in fashion design and consumer response},
journal = {Journal of Retailing and Consumer Services},
volume = {77},
pages = {103690},
year = {2024},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2023.103690},
url = {https://www.sciencedirect.com/science/article/pii/S0969698923004411},
author = {Garim Lee and Hye-Young Kim},
keywords = {Generative AI, AI-Assisted design, Schema theory, Authenticity, AI customization},
abstract = {Generative Artificial Intelligence (AI) empowers the AI design process. Then, how do consumers respond to AI-designed fashion products? Building on schema theory, this research investigated the extent to which AI-designed clothing is perceived as authentic through three online experiments. Study 1 (n = 121) and Study 2 (n = 161) showed consumers generally respond more favorably to human-designed (vs. AI-designed) clothing, which is driven by perceived authenticity and expected product quality. Study 3 (n = 156) confirmed that negative responses toward AI-designed clothing can be mitigated when consumers have the option to provide input to customize the design because it enhances perceived authenticity. Study findings offer a theoretical understanding of how and why consumers respond to AI-designed products and practical guidelines for retailers.}
}
@incollection{SALDANHADAGAMA2024,
title = {Facility location problems in supply chain operations},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2024},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-443-28993-4.00050-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780443289934000500},
author = {Francisco Saldanha-da-Gama},
keywords = {Effectiveness, Efficiency, Facility location, Logistics, Optimization modeling, Risk, Supply chain operations, Time, Triple bottom line, Uncertainty},
abstract = {This chapter focuses on the role of facility location problems on planning and managing supply chain operations. Emphasis is put on strategic supply chain design. Different aspects are discussed, which include the multilayer, multicommodity, and multiobjective nature of the problems in the field. Time-dependent decisions and uncertainty in data are also aspects covered. The insights resulting from the discussion made are materialized in a general mathematical model that leverages the discrete capacitated facility location. This lays the ground for embedding logistics decisions like distribution, inventory, procurement, and production. Different mechanisms for hedging against uncertainty are then analyzed, which ultimately lead to show how a facility location model can be set at the core of supply chain risk analytics. Environmental and social concerns aligned with the triple bottom line concept are also covered. In particular, the role of facility location in reverse logistics and closed-loop supply chain design is analyzed. Different sectors are discussed, including agro-food, energy, commercial industry, healthcare, and humanitarian operations. Several modern trends are highlighted. These include blockchain technology, data-driven decision-making, and the role of Big Data and generative Artificial Intelligence.}
}
@article{RIZOS2025101969,
title = {The impact of LLMs on mathematics education and research at the university},
journal = {Social Sciences & Humanities Open},
volume = {12},
pages = {101969},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101969},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125006977},
author = {Ioannis Rizos and Nikolaos Gkrekas},
keywords = {LLMs, ChatGPT, Mathematics education, Tertiary education, AI},
abstract = {This study examines the impact of generative Artificial Intelligence and Large Language Models on the academic community, with a specific focus on the Greek math community during the spring semester of 2023–2024. The study involved 81 undergraduate students, 10 university teaching personnel, and 8 researchers. The study used questionnaires, interviews, and work samples to investigate the use and perceptions of Large Language Models in three academic domains: mathematics education, applied mathematics, and machine learning. The environment and the conditions in which the student interview data were collected were in the form of an original type of Mathematics workshop section, encouraging an experimental process that may be adopted in future seminars, conferences, or colloquia. The findings imply cautious usage of Large Language Models with moderate satisfaction among students, modest use by teaching staff, and limited use in research. While Large Language Models have potential in educational contexts, their existing limits in dealing with sophisticated mathematical issues, proofs/justification, and developing unique answers underscore the importance of cautious integration into academic processes. This study highlights the necessity for further exploration of Artificial Intelligence capabilities and their implications for future academic environments. Moreover, it underscores a novel trend in mathematics-focused academia that may bear resemblance to practices observed in other sciences. This area merits further investigation by future research.}
}
@article{STEELE2023100160,
title = {To GPT or not GPT? Empowering our students to learn with AI},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100160},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100160},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000395},
author = {Jennifer L. Steele},
keywords = {ChatGPT, Artificial intelligence, Pedagogy, Educational technology, Academic integrity},
abstract = {I argue that ChatGPT and other generative artificial intelligence tools pose three main threats to our current education systems, creating problems of measurement, information accuracy, and skill devaluation. But when we place these threats into historical context, we see that AI tools can also empower students and level the educational playing field. In classrooms from primary to tertiary and spanning all content areas, we can help our students become critical thinkers by using ChatGPT to comprehend texts, aggregate knowledge, and understand genre conventions in prose as well as programming. The aim is to help students leverage AI as a tool that they question and critique, advancing their own comprehension, research, and composition skills in the process.}
}
@article{ARFAIE2024110815,
title = {ChatGPT and neurosurgical education: A crossroads of innovation and opportunity},
journal = {Journal of Clinical Neuroscience},
volume = {129},
pages = {110815},
year = {2024},
issn = {0967-5868},
doi = {https://doi.org/10.1016/j.jocn.2024.110815},
url = {https://www.sciencedirect.com/science/article/pii/S0967586824003540},
author = {Saman Arfaie and Mohammad {Sadegh Mashayekhi} and Mohammad Mofatteh and Crystal Ma and Richard Ruan and Mark A. MacLean and Rena Far and Jasleen Saini and Irene E. Harmsen and Taylor Duda and Alwyn Gomez and Alexander D. Rebchuk and Alick {Pingbei Wang} and Neilen Rasiah and Eddie Guo and Ali M. Fazlollahi and Emma {Rose Swan} and Pouya Amin and Safraz Mohammed and Jeffrey D. Atkinson and Rolando F. {Del Maestro} and Fady Girgis and Ashish Kumar and Sunit Das},
keywords = {ChatGPT, Clinical neuroscience, Generative artificial intelligence, Large Language Model, Medical education, Neural networks, Open AI},
abstract = {Large language models (LLM) have been promising recently in the medical field, with numerous applications in clinical neuroscience. OpenAI’s launch of Generative Pre-trained Transformer 3.5 (GPT-3.5) in November 2022 and its successor, Generative Pre-trained Transformer 4 (GPT 4) in March 2023 have garnered widespread attention and debate surrounding natural language processing (NLP) and LLM advancements. Transformer models are trained on natural language datasets to predict and generate sequences of characters. Using internal weights from training, they produce tokens that align with their understanding of the initial input. This paper delves into ChatGPT’s potential as a learning tool in neurosurgery while contextualizing its abilities for passing medical licensing exams and neurosurgery written boards. Additionally, possibilities for creating personalized case presentations and study material are discussed alongside ChatGPT’s capacity to optimize the research workflow and perform a concise literature review. However, such tools need to be used with caution, given the possibility of artificial intelligence hallucinations and other concerns such as user overreliance, and complacency. Overall, this opinion paper raises key points surrounding ChatGPT’s role in neurosurgical education.}
}
@article{SILVA2025101680,
title = {Cloud removal with compact diffusion models: A residual block-based approach},
journal = {Remote Sensing Applications: Society and Environment},
volume = {39},
pages = {101680},
year = {2025},
issn = {2352-9385},
doi = {https://doi.org/10.1016/j.rsase.2025.101680},
url = {https://www.sciencedirect.com/science/article/pii/S2352938525002332},
author = {Leandro Henrique Furtado Pinto Silva and João Fernando Mari and Mauricio Cunha Escarpinati and André Ricardo Backes},
keywords = {Cloud removal, Remote sensing, Satellite images, Diffusion models},
abstract = {Satellites are powerful tools for remote sensing, as they enable the imaging of large areas with high quality. However, satellites can be prone to artifacts such as clouds, which can negatively influence the analysis of these images. Thus, researchers have widely investigated cloud removal techniques to mitigate these artifacts, leveraging the rise of generative artificial intelligence methods. These techniques, although powerful, require a high computational cost, which limits their use in real-time applications, embedded devices, and environmental monitoring systems, where computational resources are often limited. Therefore, this work presents an approach based on compact latent diffusion, where the denoising model uses attention channels and residual block operations. In addition, we evaluated different training loss functions, which help the model perform cloud removal across various land cover types. Considering a resource-constrained approach, we investigated different experimental configurations using Pareto Front to optimize the most promising experiments. Our results demonstrate a balance between reconstruction quality and computational cost compared to baseline. Our approaches have between 48% and 82% fewer parameters while presenting competitive results for similarity, noise, and perceptual metrics.}
}
@incollection{GAUR2026211,
title = {Chapter 12 - Lawfulness and generative AI},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {211-226},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00011-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443331244000114},
author = {Loveleen Gaur and Ajith Abraham},
keywords = {Data privacy, Ethical principles, Generative AI, Healthcare law, Medical regulations, Patient rights, Transparency},
abstract = {This chapter explores the legal landscape surrounding generative artificial intelligence (AI) in healthcare, emphasizing the need for a comprehensive legal and ethical framework to govern its use. Generative AI, which encompasses technologies that can create content, analyze data, and support clinical decision-making, has numerous applications in healthcare, including diagnostics, treatment planning, and patient management. However, the integration of AI technologies raises significant legal and ethical considerations that must be navigated to ensure patient rights and safety. The chapter begins by defining generative AI and examining its applications within the medical field. It discusses existing medical regulations that govern practice, including licensing, malpractice laws, and clinical guidelines, while exploring how the adoption of AI is reshaping these frameworks. Through case studies, it highlights the legal challenges and compliance issues encountered in AI-driven medical practice, focusing on liability and regulatory adherence. Patient rights and data privacy are crucial themes, with a review of the legal frameworks protecting patient autonomy and confidentiality. Key data privacy laws, such as General Data Protection Regulation (GDPR) and Health Insurance Portability and Accountability Act (HIPAA), are discussed in relation to generative AI, along with best practices for compliance. Transparency and fairness in AI systems are emphasized, detailing the legal and ethical imperatives for clear decision-making processes and the avoidance of biases in AI applications. The chapter outlines key ethical principles governing the use of AI in healthcare, such as autonomy, beneficence, and justice, and the importance of integrating these principles into AI development. The chapter concludes with case studies demonstrating successful legal and ethical practices in AI healthcare solutions and discusses future directions for evolving legal standards and ethical frameworks. Recommendations for building a robust legal and ethical framework are provided, ensuring that generative AI contributes positively to healthcare while addressing the challenges it presents.}
}
@article{JO2025124326,
title = {The fear of being replaced by generative AI: An examination of influential factors among office workers},
journal = {Technological Forecasting and Social Change},
volume = {220},
pages = {124326},
year = {2025},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2025.124326},
url = {https://www.sciencedirect.com/science/article/pii/S0040162525003579},
author = {Hyeon Jo and Do-Hyung Park},
keywords = {Artificial intelligence, Job replacement anxiety, Anthropomorphism, Personalization, Skepticism},
abstract = {As advancements in generative artificial intelligence (GAI) permeate the modern workplace, anxieties about job replacement become increasingly prevalent. This study utilized partial least squares structural equation modeling on a sample of Korean office workers from various industries to explore the correlations between various factors and job replacement anxiety in the context of GAI. Memorability and self-learning characteristics of GAI were found to not significantly influence job replacement concerns. On the other hand, personalization and anthropomorphism—AI's human-like characteristics and adaptability—were found to be significantly associated with increased job replacement anxiety. Additionally, skepticism was found to significantly moderate the relationships between these GAI characteristics and job replacement anxiety. This research pioneers a nuanced exploration of how personalization and anthropomorphism, as dimensions of GAI, directly contribute to job replacement anxiety, providing an informed perspective by integrating skepticism as a moderating factor in a culturally specific context. The findings from this study provide new insights into how perceptions of GAI characteristics and demographics influence job replacement concerns.}
}
@article{BUNDUCHI2025124095,
title = {A legitimacy-based explanation for user acceptance of controversial technologies: The case of Generative AI},
journal = {Technological Forecasting and Social Change},
volume = {215},
pages = {124095},
year = {2025},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2025.124095},
url = {https://www.sciencedirect.com/science/article/pii/S004016252500126X},
author = {Raluca Bunduchi and Dan-Andrei Sitar-Tăut and Daniel Mican},
keywords = {Technology acceptance, Legitimacy, Technology uncertainty, Technology variation},
abstract = {Controversial technologies are technologies where social concerns play a disproportionate role in shaping the public attitudes to their adoption. An example of such controversial technologies is Generative Artificial Intelligence (GenAI), whose rapid diffusion is fuelled by expectations for significant performance improvements, while also facing concerns at individual (trust in technology), technology (accuracy and quality), and institutional (cultural, ethical and regulatory) level. Individual and technology factors are well accounted for by rational choice-based models which underpin most technology acceptance research. Such models are less suited to explore the role of institutional factors in shaping technology acceptance. Drawing from legitimacy and technology lifecycle research, we develop a legitimacy-based model of GenAI adoption which accounts for the institutional context in which technology use happens, and for technology characteristics, namely its maturity, in shaping users' acceptance. Surveying 483 information systems students who are GenAI users, we find that users' perceptions of technology uncertainty and variation positively affect their technology legitimacy evaluations and that their pragmatic and cognitive legitimacy evaluations, but not moral, affect their intention to use. We answer recent calls to examine alternative theoretical predictors of technology acceptance, and to consider the role of context in examining the acceptance of controversial technologies.}
}
@incollection{JAGANATHAN2026241,
title = {Chapter 11 - Federated learning for predictive modeling of disease prevention in metaverse},
editor = {Shubham Mahajan and Jyotir Moy Chatterjee},
booktitle = {Federated Learning in Metaverse Healthcare},
publisher = {Academic Press},
pages = {241-264},
year = {2026},
isbn = {978-0-443-33789-5},
doi = {https://doi.org/10.1016/B978-0-443-33789-5.00013-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443337895000133},
author = {Dharani Jaganathan and A. Vadivel and S. {Jansi Rani} and Vaishnavi Thangamuthu},
keywords = {Data security, cardiovascular disease, metaverse, federated learning, healthcare},
abstract = {The Indian healthcare system, serving 1.4 billion people through a complicated public-private system, faces significant challenges such as a lack of proper infrastructure and healthcare providers, an imbalance of cities-villages and an increasing difficulty of noncommunicable diseases. The metaverse is a combined virtual space, developed by combining the virtual reality with augmented physical reality revolutionizing clinical care by improving patient care, decision making and health care operations. Virtual assistants and chatbots support clinicians in providing treatment advice and assisting patients with care-related queries. While generative artificial intelligence (AI) enables synthetic records for algorithms. Telemetry and observation of sick people can be done with IoT-powered virtual hospitals. Augmented Reality enhances clinical care by providing real-time digital information, promoting treatments for age-related diseases. Along with these advantages there is a possibility of security concerns such as Identity Theft and data privacy concerns since the metaverse collects a lot of user data, device vulnerabilities. Here, federated learning (FL) a new form of training the AI model for handling and storing private data in a decentralized model without sharing the confidential record. This chapter will explore metaverse in healthcare and the impact of FL in predictive modeling for disease prevention.}
}
@article{YANG2024100085,
title = {Understanding natural language: Potential application of large language models to ophthalmology},
journal = {Asia-Pacific Journal of Ophthalmology},
volume = {13},
number = {4},
pages = {100085},
year = {2024},
issn = {2162-0989},
doi = {https://doi.org/10.1016/j.apjo.2024.100085},
url = {https://www.sciencedirect.com/science/article/pii/S2162098924000860},
author = {Zefeng Yang and Deming Wang and Fengqi Zhou and Diping Song and Yinhang Zhang and Jiaxuan Jiang and Kangjie Kong and Xiaoyi Liu and Yu Qiao and Robert T. Chang and Ying Han and Fei Li and Clement C. Tham and Xiulan Zhang},
keywords = {Large language model, Ophthalmology, Artificial intelligence, ChatGPT},
abstract = {Large language models (LLMs), a natural language processing technology based on deep learning, are currently in the spotlight. These models closely mimic natural language comprehension and generation. Their evolution has undergone several waves of innovation similar to convolutional neural networks. The transformer architecture advancement in generative artificial intelligence marks a monumental leap beyond early-stage pattern recognition via supervised learning. With the expansion of parameters and training data (terabytes), LLMs unveil remarkable human interactivity, encompassing capabilities such as memory retention and comprehension. These advances make LLMs particularly well-suited for roles in healthcare communication between medical practitioners and patients. In this comprehensive review, we discuss the trajectory of LLMs and their potential implications for clinicians and patients. For clinicians, LLMs can be used for automated medical documentation, and given better inputs and extensive validation, LLMs may be able to autonomously diagnose and treat in the future. For patient care, LLMs can be used for triage suggestions, summarization of medical documents, explanation of a patient’s condition, and customizing patient education materials tailored to their comprehension level. The limitations of LLMs and possible solutions for real-world use are also presented. Given the rapid advancements in this area, this review attempts to briefly cover many roles that LLMs may play in the ophthalmic space, with a focus on improving the quality of healthcare delivery.}
}
@article{JANG2025106174,
title = {Generative AI in architectural design: Application, data, and evaluation methods},
journal = {Automation in Construction},
volume = {174},
pages = {106174},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2025.106174},
url = {https://www.sciencedirect.com/science/article/pii/S0926580525002146},
author = {Suhyung Jang and Hyunsung Roh and Ghang Lee},
keywords = {Artificial intelligence (AI), Architectural design, Design generation, Neural network (NN), Deep learning},
abstract = {This paper presents a systematic review of generative artificial intelligence (AI) use in architectural design from 2014 to 2024, focusing on 1) AI models and theory-application gaps, 2) design phases, tasks, and objectives, 3) data types and contents, and 4) evaluation methods. Based on 161 journal papers selected using preferred reporting items for systematic reviews and meta-analysis (PRISMA), the analysis reveals the theory-application gap has been reduced by 96.09 %, from 62 to 2.5 years, highlighting rapid AI adoption since 2021 with generative adversarial networks (GANs) leading, and transformers and diffusion models gaining traction. For its application, AI is employed in schematic design phases in 68.94 %, while later phases remain underexplored. Regarding types of data used, images dominate at both input (52.8 %) and output (68.32 %), with multimodal and graph data showing promise. For evaluation, comparative evaluation was most utilized (60.9 %) supported by subjective assessment by authors (34.2 %) and third parties (17.4 %).}
}
@article{VAUGHN2024101487,
title = {Enhancing Healthcare Education: Leveraging ChatGPT for Innovative Simulation Scenarios},
journal = {Clinical Simulation in Nursing},
volume = {87},
pages = {101487},
year = {2024},
issn = {1876-1399},
doi = {https://doi.org/10.1016/j.ecns.2023.101487},
url = {https://www.sciencedirect.com/science/article/pii/S1876139923001019},
author = {Jacqueline Vaughn and Shannon H. Ford and Melissa Scott and Carolyn Jones and Allison Lewinski},
keywords = {generative artificial intelligence, ChatGPT, simulation, Scenario Design},
abstract = {Background
Developing simulation scenarios for implementation in nursing programs is labor intensive and time consuming. The purpose of this study was to determine if ChatGPT could create accurate and realistic simulation scenarios efficiently to assist faculty in healthcare education.
Methods
ChatGPT was used to create five healthcare simulations. The scenarios were sent to 18 peer reviewers who evaluated them using a 25-question Likert scale survey, which also included opportunities to provide qualitative feedback.
Results
Data analysis revealed that scenarios varied in terms of realism regarding patient profile, history, present illness and the way the scenario unfolded. Also noted was that pertinent information was missing in all scenarios however, the information generated was accurate. Most of the reviewer comments were positive and many were surprised at the amount of overall information included in each scenario.
Conclusions
ChatGPT is a powerful AI tool that has the potential to help simulation educators develop simulation scenarios. However, at present, caution needs to be employed, considering its current limitations.}
}
@article{NEGRON2025194,
title = {OP0233-PARE UNDERSTANDING SEXUALITY IN RHEUMATIC AND MUSCULOSKELETAL DISEASES: EXPANDING THE REUMASUTRA PROJECT TO THE GENERAL POPULATION},
journal = {Annals of the Rheumatic Diseases},
volume = {84},
pages = {194-195},
year = {2025},
note = {EULAR 2025: European Congress of Rheumatology},
issn = {0003-4967},
doi = {https://doi.org/10.1016/j.ard.2025.05.244},
url = {https://www.sciencedirect.com/science/article/pii/S0003496725012774},
author = {J.B.J.B. Negrón and R. {(Lliga Reumatològica Catalana)}},
keywords = {Diversity, Equity, and Inclusion (DEI), Education, Quality of life},
abstract = {Background:
In EULAR 2020, the results of our ongoing project Reumasutra were presented. The aims were to (i) understand the complexities and the difficulties of sexuality in people with rheumatic and musculoskeletal diseases (RMDs), (ii) offer a solution to the problems previously identified, and (iii) (un)validate the proposed solution using feedback of people with RMDs [1]. However, we were forced to pause the last phase of the project due to diverse challenges been the most influential the development of generative artificial intelligence and its potential use for creating deepfakes. This technology brought with it ethical challenges. Therefore, we wanted to be sure how we could best protect the dignity of the individuals who trusted us by participating in the explicit audiovisual shorts, which involved recreating adapted sexual positions for people with RMDs. While considering the best options available, we decided that the topic of sexuality and sex in RMDs was too important to be put on hold for an extended period. Therefore, we chose to expand Reumasutra by creating a documentary for people of all ages, aimed at making the taboo topic of sexuality and sex in RMDs visible and accessible to the general population.
Objectives:
To create a documentary for the general population on sexuality and sex in RMDs in order to raise awareness of this taboo topic.
Methods:
For this work, our ontological and epistemological assumptions stand by the constructivist/interpretivist paradigm which establishes that there are multiple subjective realities, each of which is socially constructed by and between individuals. The creation of the documentary was approached using qualitative research methodology and methods. Narrative interviews were used as the method of data collection. Interviews were moderated by the same researcher which was assisted by an audiovisual team in charge of recording the interviews and subsequent audiovisual editing of the final piece. A total of 10 interviews (eight with women), conducted in Catalan, Spanish, and English, took place in February 2024 in Barcelona, Spain. Seven of the interviews were with individuals with RMDs (such as axial spondylarthritis, fibromyalgia, rheumatoid arthritis, and pulmonary sarcoidosis, among others), and the remaining interviews were with health professionals or patient advocates. It is important to note that some of the individuals interviewed held more than one role, being both people with RMDs and healthcare professionals or patient advocates. After data collection, a qualitative content analysis was performed.
Results:
Our main result is the documentary (approximate duration of 50 minutes) in which four main topics were generated and could be appreciated in more depth. Although sexuality and sex were the primary focus of our work, the narrative interviews revealed important issues that we were previously unaware of, which may also be invisible to the general population. The four main topics are: (i) structural violence and microaggressions against women, (ii) lack of education on diversity, equity, and inclusion (DEI) within the medical community, (iii) the formation of a new identity after diagnosis, and (iv) women's bodies as factories for producing life.
Conclusion:
There is an invisibility of women in medicine. Just as sexuality and sex in RMDs are not a local problem but a global one, we believe this invisibility is also a global issue. Sociocultural variables and dynamics (e.g., religious practices) play a role in the magnitude of this issue across different countries. Structural violence and various types of aggression were identified in the experiences of the women who participated, which was not the case for the men interviewed. DEI education is needed in medical training to counterbalance this violence. New meaning in the lives of the participants was found through collective activities that created bonds with different communities. However, there is a reproductive reductionism in rheumatology when the topic of sexuality and sex is addressed with women. Our results serve as an invitation for everyone involved in the diagnosis and treatment of RMDs to reflect on our practices, their origins, and ask ourselves: Are there better ways?
REFERENCES:
[1] Negrón JB, Ponce L, Galega LLR, Catalana LLR. OP0309-PARE REUMASUTRA: Rethinking Sexuality in Rheumatic and Musculoskeletal Diseases. BMJ Publishing Group Ltd; 2020.
Acknowledgements:
To all those who shared intimate aspects of their experience with the disease. Thank you for your vulnerability and for teaching us lessons that are not taught in textbooks or classrooms.
Disclosure of Interests:
None declared. © The Authors 2025. This abstract is an open access article published in Annals of Rheumatic Diseases under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). Neither EULAR nor the publisher make any representation as to the accuracy of the content. The authors are solely responsible for the content in their abstract including accuracy of the facts, statements, results, conclusion, citing resources etc.}
}
@article{DAS2025100213,
title = {Generative AI for drug discovery and protein design: the next frontier in AI-driven molecular science},
journal = {Medicine in Drug Discovery},
volume = {27},
pages = {100213},
year = {2025},
issn = {2590-0986},
doi = {https://doi.org/10.1016/j.medidd.2025.100213},
url = {https://www.sciencedirect.com/science/article/pii/S2590098625000107},
author = {Uddalak Das},
keywords = {Generative AI, Molecular design, Protein engineering, Diffusion models, Drug discovery},
abstract = {Generative artificial intelligence (AI) has emerged as a disruptive paradigm in molecular science, enabling algorithmic navigation and construction of chemical and proteomic spaces through data-driven modeling. This review systematically delineates the theoretical underpinnings, algorithmic architectures, and translational applications of deep generative models—including variational autoencoders (VAEs), generative adversarial networks (GANs), autoregressive transformers, and score-based denoising diffusion probabilistic models (DDPMs)—in the rational design of bioactive small molecules and functional proteins. We examine the role of latent space learning, probabilistic manifold exploration, and reinforcement learning in inverse molecular design, focusing on optimization of pharmacologically relevant objectives such as ADMET profiles, synthetic accessibility, and target affinity. Furthermore, we survey advancements in graph-based molecular generative frameworks, LLM-guided protein sequence modeling, and diffusion-based structural prediction pipelines (e.g., RFdiffusion, FrameDiff), which have demonstrated state-of-the-art performance in de novo protein engineering and conformational sampling. Generative AI is also catalyzing a paradigm shift in structure-based drug discovery via AI-augmented molecular docking (e.g., DiffDock), end-to-end binding affinity prediction, and quantum chemistry-informed neural potentials. We explore the convergence of generative models with Bayesian retrosynthesis planners, self-supervised pretraining on ultra-large chemical corpora, and multimodal integration of omics-derived features for precision therapeutics. Finally, we discuss translational milestones wherein AI-designed ligands and proteins have progressed to preclinical and clinical validation, and speculate on the synthesis of generative AI, closed-loop automation, and quantum computing in future autonomous molecular design ecosystems.}
}
@article{SZCZESNIEWSKI2024398,
title = {Quality of information about urologic pathology in English and Spanish from ChatGPT, BARD, and Copilot},
journal = {Actas Urológicas Españolas (English Edition)},
volume = {48},
number = {5},
pages = {398-403},
year = {2024},
issn = {2173-5786},
doi = {https://doi.org/10.1016/j.acuroe.2024.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S2173578624000167},
author = {J.J. Szczesniewski and A. {Ramos Alba} and P.M. {Rodríguez Castro} and M.F. {Lorenzo Gómez} and J. {Sainz González} and L. {Llanes González}},
keywords = {Artificial intelligence, Information quality, ChatGPT, Copilot, BARD, Urology, Inteligencia artificial, Calidad de información, ChatGPT, Copilot, BARD, Urología},
abstract = {Introduction and objective
Generative artificial intelligence makes it possible to ask about medical pathologies in dialog boxes. Our objective was to analyze the quality of information about the most common urological pathologies provided by ChatGPT (OpenIA), BARD (Google), and Copilot (Microsoft).
Methods
We analyzed information on the following pathologies and their treatments as provided by AI: prostate cancer, kidney cancer, bladder cancer, urinary lithiasis, and benign prostatic hypertrophy (BPH). Questions in English and Spanish were posed in dialog boxes; the answers were collected and analyzed with DISCERN questionnaires and the overall appropriateness of the response. Surgical procedures were performed with an informed consent questionnaire.
Results
The responses from the three chatbots explained the pathology, detailed risk factors, and described treatments. The difference is that BARD and Copilot provide external information citations, which ChatGPT does not. The highest DISCERN scores, in absolute numbers, were obtained in Copilot; however, on the appropriacy scale it was noted that their responses were not the most appropriate. The best surgical treatment scores were obtained by BARD, followed by ChatGPT, and finally Copilot.
Conclusions
The answers obtained from generative AI on urological diseases depended on the formulation of the question. The information provided had significant biases, depending on pathology, language, and above all, the dialog box consulted.
Resumen
Introducción y objetivo
La inteligencia artificial (IA) generativa permite preguntar, a través de los cuadros de diálogo, sobre patologías médicas. Nuestro objetivo fue analizar la calidad de la información acerca de las patologías urológicas más comunes en los chatbots ChatGPT de OpenIA, BARD de Google y Copilot de Microsoft.
Material y método
Se realizó un análisis de la información aportada por IA sobre las siguientes patologías y sus tratamientos: cáncer de próstata, cáncer renal, cáncer de vejiga, litiasis urinarias e hipertrofia benigna de próstata (HBP). A través de cuadros de diálogo se formularon preguntas estructuradas en inglés y en español, recopilando las respuestas para analizarlas posteriormente con cuestionarios DISCERN y sobre la idoneidad global de la respuesta. Los tratamientos quirúrgicos se realizaron con cuestionario de consentimiento informado.
Resultados
Las respuestas obtenidas a través de los tres chatbots explicaron la patología, detallaron los factores de riesgo y describieron los tratamientos. La diferencia radica en que BARD y Copilot aportan citas de información externa, algo que ChatGPT no realiza. Las puntuaciones DISCERN más altas, en números absolutos, se obtuvieron en Copilot; sin embargo, en la escala de idoneidad se objetivó que sus respuestas no fueron las más apropiadas. Las mejores puntuaciones de tratamientos quirúrgicos fueron obtenidas por BARD, seguido de ChatGPT y finalmente de Copilot.
Conclusiones
Las respuestas obtenidas de la IA generativa sobre enfermedades urológicas dependieron de la formulación de la pregunta. La información proporcionada presentó sesgos importantes, dependiendo de la patología, del idioma y, sobre todo, del cuadro de diálogo consultado.}
}
@article{XIA2025106024,
title = {Intelligent co-design of shear wall and beam layouts using a graph neural network},
journal = {Automation in Construction},
volume = {172},
pages = {106024},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2025.106024},
url = {https://www.sciencedirect.com/science/article/pii/S0926580525000640},
author = {Jikang Xia and Wenjie Liao and Bo Han and Shulu Zhang and Xinzheng Lu},
keywords = {Shear wall structure, Graph neural network, Graph co-representation of wall and beam, Intelligent co-design, Feature engineering},
abstract = {Generative artificial intelligence-driven design of shear wall structures is crucial for the intelligent design of buildings, but current methods arrange shear walls and then beams successively, overlooking their interdependence. This paper constructed a graph representation of the coupled potential positions for shear walls and beams and proposed a co-design method driven by a graph neural network (GNN). Feature engineering was used to represent shear wall and beam layouts as graph data enhanced through data augmentation to improve GNN model generalization. The GraphSAGE algorithm analyzed the graph to simultaneously generate the shear wall and beam layouts followed by postprocessing for extraction and optimization based on encoded design rules. A case study validated the method, showing that intersections over union for GNN-generated layouts were 14.9 % and 35.6 % higher than those from the conventional approach. This method offers a reference for the coupled design of multiple structural attributes.}
}
@article{MASROURI2024102230,
title = {Generative AI model trained by molecular dynamics for rapid mechanical design of architected graphene},
journal = {Extreme Mechanics Letters},
volume = {72},
pages = {102230},
year = {2024},
issn = {2352-4316},
doi = {https://doi.org/10.1016/j.eml.2024.102230},
url = {https://www.sciencedirect.com/science/article/pii/S235243162400110X},
author = {Milad Masrouri and Kamalendu Paul and Zhao Qin},
keywords = {Architected graphene, Molecular dynamics, Stable Diffusion, Low Rank Adaptation, Von Mises stress field},
abstract = {Generative artificial intelligence (AI) is shown to be a useful tool to automatically learn from existing information and generate new information based on their connections, but its usage for quantitative mechanical research is less understood. Here, we focus on the structure-mechanics relationship of architected graphene as graphene with void defects of specific patterns. We use Molecular Dynamics (MD) to simulate uniaxial tension on architected graphene, extract the von Mises stress field in mechanical loading, and use the results to train a fine-tuned generative AI model through a Low-Rank Adaptation method. This model enables the freely designed architected graphene structures and predicts its associated stress field in uniaxial tension loading through simple descriptive language. We demonstrate that the fine-tuned model can be established with a few training images and can quantitatively predict the stress field for graphene with various defect geometries and distributions not included in the training set. We validate the accuracy of the stress field with MD simulations. Moreover, we illustrate that our generative AI model can predict the stress field from a schematic drawing of the architected graphene through image-to-image generation. These features underscore the promising future for employing advanced generative AI models in end-to-end advanced nanomaterial design and characterization, enabling the creation of functional, structural materials without using complex numerical modeling and data processing.}
}
@article{DONG2024102397,
title = {Exploring the integration of IoT and Generative AI in English language education: Smart tools for personalized learning experiences},
journal = {Journal of Computational Science},
volume = {82},
pages = {102397},
year = {2024},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2024.102397},
url = {https://www.sciencedirect.com/science/article/pii/S187775032400190X},
author = {Wanjin Dong and Daohua Pan and Soonbae Kim},
keywords = {IoT, Generative AI, Smart tools, Adaptive learning environment},
abstract = {English language education is undergoing a transformative shift, propelled by advancements in technology. This research explores the integration of the Internet of Things (IoT) and Generative Artificial Intelligence (Generative AI) in the context of English language education, with a focus on developing a personalized oral assessment method. The proposed method leverages real-time data collection from IoT devices and Generative AI's language generation capabilities to create a dynamic and adaptive learning environment. The study addresses historical challenges in traditional teaching methodologies, emphasizing the need for AI approaches. The research objectives encompass a comprehensive exploration of the historical context, challenges, and existing technological interventions in English language education. A novel, technology-driven oral assessment method is designed, implemented, and rigorously evaluated using datasets such as Librispeech and L2Arctic. The ablation study investigates the impact of training dataset proportions and model learning rates on the method's performance. Results from the study highlight the importance of maintaining a balance in dataset proportions, selecting an optimal learning rate, and considering model depth in achieving optimal performance.}
}
@article{HELD2024,
title = {A Novel Cognitive Behavioral Therapy–Based Generative AI Tool (Socrates 2.0) to Facilitate Socratic Dialogue: Protocol for a Mixed Methods Feasibility Study},
journal = {JMIR Research Protocols},
volume = {13},
year = {2024},
issn = {1929-0748},
doi = {https://doi.org/10.2196/58195},
url = {https://www.sciencedirect.com/science/article/pii/S1929074824006164},
author = {Philip Held and Sarah A Pridgen and Yaozhong Chen and Zuhaib Akhtar and Darpan Amin and Sean Pohorence},
keywords = {generative artificial intelligence, mental health, feasibility, cognitive restructuring, Socratic dialogue, mobile phone},
abstract = {Background
Digital mental health tools, designed to augment traditional mental health treatments, are becoming increasingly important due to a wide range of barriers to accessing mental health care, including a growing shortage of clinicians. Most existing tools use rule-based algorithms, often leading to interactions that feel unnatural compared with human therapists. Large language models (LLMs) offer a solution for the development of more natural, engaging digital tools. In this paper, we detail the development of Socrates 2.0, which was designed to engage users in Socratic dialogue surrounding unrealistic or unhelpful beliefs, a core technique in cognitive behavioral therapies. The multiagent LLM-based tool features an artificial intelligence (AI) therapist, Socrates, which receives automated feedback from an AI supervisor and an AI rater. The combination of multiple agents appeared to help address common LLM issues such as looping, and it improved the overall dialogue experience. Initial user feedback from individuals with lived experiences of mental health problems as well as cognitive behavioral therapists has been positive. Moreover, tests in approximately 500 scenarios showed that Socrates 2.0 engaged in harmful responses in under 1% of cases, with the AI supervisor promptly correcting the dialogue each time. However, formal feasibility studies with potential end users are needed.
Objective
This mixed methods study examines the feasibility of Socrates 2.0.
Methods
On the basis of the initial data, we devised a formal feasibility study of Socrates 2.0 to gather qualitative and quantitative data about users’ and clinicians’ experience of interacting with the tool. Using a mixed method approach, the goal is to gather feasibility and acceptability data from 100 users and 50 clinicians to inform the eventual implementation of generative AI tools, such as Socrates 2.0, in mental health treatment. We designed this study to better understand how users and clinicians interact with the tool, including the frequency, length, and time of interactions, users’ satisfaction with the tool overall, quality of each dialogue and individual responses, as well as ways in which the tool should be improved before it is used in efficacy trials. Descriptive and inferential analyses will be performed on data from validated usability measures. Thematic analysis will be performed on the qualitative data.
Results
Recruitment will begin in February 2024 and is expected to conclude by February 2025. As of September 25, 2024, overall, 55 participants have been recruited.
Conclusions
The development of Socrates 2.0 and the outlined feasibility study are important first steps in applying generative AI to mental health treatment delivery and lay the foundation for formal feasibility studies.
International Registered Report Identifier (IRRID)
DERR1-10.2196/58195}
}
@article{WEN2025,
title = {EdgeAIGC: Model caching and resource allocation for Edge Artificial Intelligence Generated Content},
journal = {Digital Communications and Networks},
year = {2025},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2025.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S2352864825001142},
author = {Wu Wen and Yibin Huang and Xinxin Zhao and Peiying Zhang and Kai Liu and Guowei Shi},
keywords = {Generative AI, Edge Model Caching, Resource Allocation, Edge Intelligence},
abstract = {With the rapid development of Generative Artificial Intelligence technology, the traditional cloud-based centralized model training and inference face significant limitations due to high transmission latency and costs, which restrict user-side in-situ Artificial Intelligence Generated Content (AIGC) service requests. To this end, we propose the Edge Artificial Intelligence Generated Content (EdgeAIGC) framework, which can effectively solve the problems brought by cloud computing by implementing in-situ processing of services close to the data source through edge computing. However, AIGC models usually have a large parameter scale and complex computing requirements, which poses a huge challenge to the storage and computing resources of edge devices. This paper focuses on the edge intelligence model caching and resource allocation problems in the EdgeAIGC framework, aiming to improve the cache hit rate and resource utilization of edge devices for models by optimizing the model caching strategy and resource allocation scheme, and realize in-situ AIGC service processing. With the optimization objectives of minimizing service request response time and execution cost in resource-constrained environments, we employ the Twin Delayed Deep Deterministic Policy Gradient algorithm for optimization. Experimental results show that, compared with other methods, our model caching and resource allocation strategies can effectively improve the cache hit rate by at least 41.06% and reduce the response cost.}
}
@article{LIM2025,
title = {The art of medical synthesis: Where Chinese medical wisdom intersects with artificial intelligence},
journal = {Journal of Traditional Chinese Medical Sciences},
year = {2025},
issn = {2095-7548},
doi = {https://doi.org/10.1016/j.jtcms.2025.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S209575482500078X},
author = {Enoch Chi Ngai Lim and Nga Chong Lisa Cheng and Chi Eung Danforn Lim},
keywords = {Artificial intelligence, Chinese medicine, Western medicine, Regulation, Ethics},
abstract = {Generative artificial intelligence (AI), specifically large language models, such as DeepSeek, has accelerated the digital transformation of healthcare systems in both developing and developed countries. The use of AI in diagnostics, image processing and interpretation, treatment personalization, clinical documentation, and drug discovery is an example of the implementation of AI in Western medicine. The need for evidence-based studies and a standardized approach to scientific medicine aligns well with these applications. AI can leave a lasting impact on the Chinese medicine (CM) landscape by increasing expectations and presenting new challenges. The analogy between the CM-specific diagnostic methods and syndrome differentiation, which is holistic, pattern-oriented, patient-centered, and clinical data analysis, is significant at multiple levels. These qualities pose challenges for AI usage in CM, which heavily relies on structured data and pattern recognition. Despite these adversities, AI can still be used in CM through data standardization, prediction formulation, and treatment planning, provided that the integration of this tool considers the primary principles of CM and adheres to ethical and regulatory considerations. This review examines the dichotomous approach to health and medicine in the contexts of AI and CM, highlighting the evolving potential, inherent limitations, and ethical and regulatory issues associated with the application of AI to CM. It provides a foundation for developing technologically progressive yet culturally and philosophically sensitive strategies that are in harmony with traditional clinical values.}
}
@article{ZHOU2025110090,
title = {Forward and inverse adversarial model applying to well-logging},
journal = {Engineering Applications of Artificial Intelligence},
volume = {144},
pages = {110090},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.110090},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625000909},
author = {Jun Zhou and Juan Zhang and Rongbo Shao and Lizhi Xiao and Guangzhi Liao},
keywords = {Generative artificial intelligence, Well logging, Forward model, Inverse model, Machine learning},
abstract = {Geophysical logging is critical for reservoir characterization but is limited by the small sample problem in machine learning. To address this, we propose the Forward and Inverse Adversarial Model (FIAM), which borrows the training method from generative adversarial networks and applies to geophysical logging. The FIAM includes a forward model for generating synthetic logging data and an inverse model for predicting reservoir parameters. These models are trained using an adversarial process, enabling continuous improvement without large labeled datasets. In the case study with exploration logging data, the FIAM enhances reservoir parameter prediction effect and maps the relationship between logging curves and reservoir parameters by pure data-driven training. The inverse model is pre-trained by measured data and then guides the forward model to generate logging data based on virtual reservoir parameters. Both models are trained alternately until no further improvement is achieved. Experimental results on oilfield datasets show that the FIAM improves reservoir parameter predictions by more than 30% when facing the small sample problem. The FIAM demonstrates significant potential for improving reservoir parameters prediction with small sample dataset, advancing both artificial intelligence methodologies and practical engineering applications.}
}
@article{FAKFARE2025104070,
title = {Customer word-of-mouth for generative AI: Innovation and adoption in hospitality and tourism},
journal = {International Journal of Hospitality Management},
volume = {126},
pages = {104070},
year = {2025},
issn = {0278-4319},
doi = {https://doi.org/10.1016/j.ijhm.2024.104070},
url = {https://www.sciencedirect.com/science/article/pii/S0278431924003827},
author = {Pipatpong Fakfare and Noppadol Manosuthi and Jin-Soo Lee and Heesup Han and Minkyoung Jin},
keywords = {Generative AI, Word-of-mouth (WOM), Five-state customer adoption, Innovation, Hospitality and tourism},
abstract = {Generative artificial intelligence (AI), such as ChatGPT, is increasingly utilized to facilitate decision-making processes in various aspects of our lives, including travel activities. Despite its growing adoption in the travel service industry, a research gap focusing on the innovation characteristics of ChatGPT, customer adoption, and word-of-mouth (WOM) remains. By utilizing stringent methodologies through variable- and case-based approaches, this study explores the influence of ChatGPT innovation characteristics and customer adoption factors in inducing WOM. The formal set-theoretic approach further explores the intersections between the empirical model, theory, and outcome (WOM). The results provide novel insights into customer WOM for generative AI, examining whether innovation attributes, such as relative benefits, complexity and compatibility, and/or states of customer adoption factors -- particularly in terms of cognitive, affective, and behavioral response individually or in combination -- contribute to WOM, thereby leading to theoretical and practical implications in the hospitality and tourism industry.}
}
@article{LI2024,
title = {Impact of Artificial Intelligence–Generated Content Labels On Perceived Accuracy, Message Credibility, and Sharing Intentions for Misinformation: Web-Based, Randomized, Controlled Experiment},
journal = {JMIR Formative Research},
volume = {8},
year = {2024},
issn = {2561-326X},
doi = {https://doi.org/10.2196/60024},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X24007443},
author = {Fan Li and Ya Yang},
keywords = {generative AI, artificial intelligence, ChatGPT, AIGC label, misinformation, perceived accuracy, message credibility, sharing intention, social media, health information},
abstract = {Background
The proliferation of generative artificial intelligence (AI), such as ChatGPT, has added complexity and richness to the virtual environment by increasing the presence of AI-generated content (AIGC). Although social media platforms such as TikTok have begun labeling AIGC to facilitate the ability for users to distinguish it from human-generated content, little research has been performed to examine the effect of these AIGC labels.
Objective
This study investigated the impact of AIGC labels on perceived accuracy, message credibility, and sharing intention for misinformation through a web-based experimental design, aiming to refine the strategic application of AIGC labels.
Methods
The study conducted a 2×2×2 mixed experimental design, using the AIGC labels (presence vs absence) as the between-subjects factor and information type (accurate vs inaccurate) and content category (for-profit vs not-for-profit) as within-subjects factors. Participants, recruited via the Credamo platform, were randomly assigned to either an experimental group (with labels) or a control group (without labels). Each participant evaluated 4 sets of content, providing feedback on perceived accuracy, message credibility, and sharing intention for misinformation. Statistical analyses were performed using SPSS version 29 and included repeated-measures ANOVA and simple effects analysis, with significance set at P<.05.
Results
As of April 2024, this study recruited a total of 957 participants, and after screening, 400 participants each were allocated to the experimental and control groups. The main effects of AIGC labels were not significant for perceived accuracy, message credibility, or sharing intention. However, the main effects of information type were significant for all 3 dependent variables (P<.001), as were the effects of content category (P<.001). There were significant differences in interaction effects among the 3 variables. For perceived accuracy, the interaction between information type and content category was significant (P=.005). For message credibility, the interaction between information type and content category was significant (P<.001). Regarding sharing intention, both the interaction between information type and content category (P<.001) and the interaction between information type and AIGC labels (P=.008) were significant.
Conclusions
This study found that AIGC labels minimally affect perceived accuracy, message credibility, or sharing intention but help distinguish AIGC from human-generated content. The labels do not negatively impact users’ perceptions of platform content, indicating their potential for fact-checking and governance. However, AIGC labeling applications should vary by information type; they can slightly enhance sharing intention and perceived accuracy for misinformation. This highlights the need for more nuanced strategies for AIGC labels, necessitating further research.}
}
@article{MIZUMOTO2025100210,
title = {Large language models fall short in classifying learners’ open-ended responses},
journal = {Research Methods in Applied Linguistics},
volume = {4},
number = {2},
pages = {100210},
year = {2025},
issn = {2772-7661},
doi = {https://doi.org/10.1016/j.rmal.2025.100210},
url = {https://www.sciencedirect.com/science/article/pii/S277276612500031X},
author = {Atsushi Mizumoto and Mark Feng Teng},
keywords = {Research methods, Generative AI, Large language models (LLM), Qualitative analysis, Coding and classification},
abstract = {Generative Artificial Intelligence (GenAI), based on large language models (LLMs), excels in various language comprehension tasks and is increasingly utilized in applied linguistics research. This study examines the accuracy and methodological implications of using LLMs to classify open-ended responses from learners. We surveyed 143 Japanese university students studying English as a foreign language (EFL) about their essay-writing process. Two human evaluators independently classified the students’ responses based on self-regulated learning processes: planning, monitoring, and evaluation. At the same time, several LLMs performed the same classification task, and their results were compared with those of the human evaluators using Cohen’s kappa coefficient. We established κ ≥ 0.8 as the threshold for strong agreement based on rigorous methodological standards. Our findings revealed that even the best-performing model (DeepSeek-V3) achieved only moderate agreement (κ = 0.68), while other models demonstrated fair-to-moderate agreement (κ = 0.37–0.61). Surprisingly, open-source models outperformed several commercial counterparts. These results highlight the necessity of expert oversight when integrating GenAI as a support tool in qualitative data analysis. The paper concludes by discussing the methodological implications for using LLMs in qualitative research and proposing specific prompt engineering strategies to enhance their reliability in applied linguistics.}
}
@article{CAI2025103373,
title = {Differentially private synthetic data generation for robust information fusion},
journal = {Information Fusion},
volume = {124},
pages = {103373},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103373},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525004464},
author = {Xiaohong Cai and Yi Sun and Zhaowen Lin and Ripeng Li and Tianwei Cai},
keywords = {Generative artificial intelligence, Fusion, Differential privacy, Fine-tuning},
abstract = {Synthetic data is crucial in information fusion in term of enhancing data representation and improving system robustness. Among all synthesis methods, deep generative models exhibit excellent performance. However, recent studies have shown that the generation process faces privacy challenges due to the memorization of training instances by generative models. To maximize the benefits of synthesis data while ensuring data security, we propose a novel framework for the generation and utilization of private synthetic data in information fusion processes. Furthermore, we present differential private adaptive fine-tuning (DP-AdaFit), a method for private parameter efficient fine-tuning that applies differential privacy only to the singular values of the incremental updates. In details, DP-AdaFit adaptively adjusts the rank of the low-rank weight increment matrices according to their importance score, and allows us to achieve an equivalent privacy policy by only injecting noise into gradient of the corresponding singular values. Such a novel approach essentially reduces their parameter budget but avoids too much noise introduced by the singular value decomposition. We decrease the cost on memory and computation nearly half of the SOTA, and achieve the FID of 19.2 on CIFAR10. Our results demonstrate that trading off weights contained in the differential privacy fine-tuning parameters can improve model performance, even achieving generation quality competitive with differential privacy full fine-tuning diffusion model. Our code is available at DP-AdaFit.}
}
@article{CELIKTEN20243351,
title = {HybridGAD: Identification of AI-Generated Radiology Abstracts Based on a Novel Hybrid Model with Attention Mechanism},
journal = {Computers, Materials and Continua},
volume = {80},
number = {2},
pages = {3351-3377},
year = {2024},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2024.051574},
url = {https://www.sciencedirect.com/science/article/pii/S154622182400537X},
author = {Tuğba Çelikten and Aytuğ Onan},
keywords = {Generative artificial intelligence, AI-generated text detection, attention mechanism, hybrid model for text classification},
abstract = {The purpose of this study is to develop a reliable method for distinguishing between AI-generated, paraphrased, and human-written texts, which is crucial for maintaining the integrity of research and ensuring accurate information flow in critical fields such as healthcare. To achieve this, we propose HybridGAD, a novel hybrid model that combines Long Short-Term Memory (LSTM), Bidirectional LSTM (Bi-LSTM), and Bidirectional Gated Recurrent Unit (Bi-GRU) architectures with an attention mechanism. Our methodology involves training this hybrid model on a dataset of radiology abstracts, encompassing texts generated by AI, paraphrased by AI, and written by humans. The major findings of our analysis indicate that HybridGAD achieves a high accuracy of 98%, significantly outperforming existing state-of-the-art models. This high performance is attributed to the model’s ability to effectively capture the contextual nuances and structural differences between AI-generated and human-written texts. In conclusion, HybridGAD not only enhances the accuracy of text classification in the field of radiology but also paves the way for more advanced medical diagnostic processes by ensuring the authenticity of textual information. Future research will focus on integrating textual and visual data for comprehensive radiology assessments and improving model generalization with partially labeled data. This study underscores the potential of HybridGAD in transforming medical text classification and highlights its applicability in ensuring the integrity and reliability of research in healthcare and beyond.}
}
@article{ANTIA2025100243,
title = {Healthy Heart Assistant, a WhatsApp-Based Generative Pretrained Transformer Technology, for Self-Care in Hypertensive Patients},
journal = {Mayo Clinic Proceedings: Digital Health},
volume = {3},
number = {3},
pages = {100243},
year = {2025},
issn = {2949-7612},
doi = {https://doi.org/10.1016/j.mcpdig.2025.100243},
url = {https://www.sciencedirect.com/science/article/pii/S2949761225000501},
author = {Samuel E. Antia and Collins N. Ugwu and Vishal Ghodka and Babangida S. Chori and Muhammad S. Nazir and Chizoba A. Odili and Godsent C. Isiguzo and Sri Vasireddy and Augustine N. Odili},
abstract = {Objective
To evaluate the feasibility, usability, and efficacy of innovative generative pretrained transformer chatbot in improving self-care in hypertensive patients in a resource-limited setting.
Patients and Methods
A single-arm nonblinded clinical trial was deployed in a busy cardiology clinic in a low-resource setting. Artificial intelligence–enabled chatbot (Healthy Heart Assistant) was activated in smartphones of 50 adults on treatment for hypertension. Participants were trained on how to use the Healthy Heart Assistant including setting medication and appointment reminders. Baseline questionnaires were administered at enrollment and 30 days later to explore acceptability, feasibility and usability of the bot. We used chatbot usability questionnaire and self-made Healthy Heart Assistant satisfaction questionnaire to assess bot usability and patients’ satisfaction, respectively. The study began on April 5, 2024, through July 15, 2024.
Results
Of 200 hypertensive clinic attendees, 70 (35%) had internet-enabled bot-compatible cell phones, of which 50 hypertensive patients were recruited to participate in the study. Among 50 participants, 2 (4%) were lost to follow-up; 19 (39.6%) were women; and 40 (83.3%) had attained tertiary level of education. Mean time of training to use bot was 5.7 minutes, with 35 (70.8%) of participants being able to use the bot within 5 minutes. The median frequency of chats for participants within the timeframe was an average of 1.5 chats/day. Chatbot usability questionnaire score was 69.5%, whereas self-made Healthy Heart Assistant satisfaction questionnaire score was 90%.
Conclusion
This proof-of-concept study shows that generative artificial intelligence can be applied with reasonable success in hypertension self-care in low-resource settings and has potential for being effective.}
}
@article{THOMAS2024102619,
title = {ChatGPT appropriation: A catalyst for creative performance, innovation orientation, and agile leadership},
journal = {Technology in Society},
volume = {78},
pages = {102619},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102619},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24001672},
author = {Asha Thomas and Harshleen Kaur Duggal and Puja Khatri and Vincenzo Corvello},
keywords = {ChatGPT appropriation, Creative performance, Generative AI, Innovation orientation, Agile leadership},
abstract = {Appropriation of generative artificial intelligence is a burgeoning area in the realm of technological advancements and holds significant promise for organizational dynamics and creative performance. This study seeks to clarify its relationship with Individual Creative Performance, understand the influences of Innovation Orientation and Agile Leadership on Appropriation, with particular reference with ChatGPT and propose a framework for its comprehension. Drawing from a targeted sample of 671 responses across prominent industries in Poland, we uncover a marked empirical gap. Our results underscore the instrumental role of Innovation Orientation in molding both ChatGPT Appropriation and Individual Creative Performance, while also emphasizing the mediating roles of Innovation Orientation and ChatGPT Appropriation in the nexus between Agile Leadership and Individual Creative Performance.}
}
@article{GAO2025100472,
title = {Do AI chatbot-integrated writing tasks influence writing self-efficacy and critical thinking ability? An exploratory study},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100472},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100472},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25001122},
author = {Jie Gao and Jing Zhang and Yalin Li},
keywords = {AI chatbot-integrated writing tasks, Critical thinking ability, Writing self-efficacy, Vocational college students, Quasi-experimental design},
abstract = {Emerging discussions have boomed in relation to recent trends and applications of generative artificial intelligence in education, but few attention were paid to AI chatbots in terms of critical thinking ability and second language (L2) writing self-efficacy. To address such research gap, this study aims to delve into effectiveness of AI chatbot-integrated writing tasks on critical thinking ability and writing self-efficacy among vocational college students. Followed the quasi-experiment design, this study recruited 80 first-year vocational college students from two intact class. Throughout seven-week's instruction, quantitative data were collected with pre- and post-questionnaires of writing self-efficacy and critical thinking ability. The results revealed no statistical difference in terms of both critical thinking ability and writing self-efficacy even with greater increase among the experimental group than that of the control peers. Further analysis of each dimension demonstrated the statistical difference of language construction, indicating that vocational college students with limited language proficiency strive to promote language organization in their writings in terms of critical thinking ability development. The research contributes valuable empirical evidence of incorporating generative AI chatbots into L2 writing by extending the Cognitive Load Theory and Social Cognitive Theory. It also underscores the need to leveraging AI chatbots as tools for cognitive transformation rather than mere procedural assistance, and relevant training programs are essential to optimize the educational benefits of AI tools and cultivate digital literacy among vocational college learners.}
}
@article{PRINZ2025105515,
title = {Codes across (life)sciences},
journal = {BioSystems},
volume = {254},
pages = {105515},
year = {2025},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2025.105515},
url = {https://www.sciencedirect.com/science/article/pii/S030326472500125X},
author = {Robert Prinz and Philipp Bucher and Ádám Kun and Omar Paredes and Anna Aragno and Candice Shelby and Markus Gumbel and Elena Fimmel and Lutz Strüngmann},
keywords = {Code biology, Mathematics, Computer science, Synthetic biology, Ecological codes, Psychology, Psychoanalysis, Cultural codes, Cyborgism, Transhumanism},
abstract = {The concept of “code” connotes different meanings, intentions, and formalizations. From mathematics and computer sciences to psychology and culture, the term becomes less formal, more diverse, and sometimes appears ambiguous. In biology a growing number of codes ignite a debate about their role in evolution, biocomplexity, and agency, to name just a few. Here, a transdisciplinary group of code scientists attempts to capture the big picture of code research across their fields of interest. In this cross-sectional overview commonalities emerge that may pave the way towards a unified theory of life-based-on-codes. Codes underly cellular processes, perception, cognition, and communication. From ecosystems to human language, codes influence how individuals behave in groups, memorize, learn, and take part in cultural practices. Emotions like aggression, fear, anger, frustration, are important motivators of behaviour modulating mutual communication and sculpting individual experience. The inheritance of experience in form of innate release mechanisms, stereotyped behaviour, or archetypes may have phylogenetic and ontogenetic roots that rely on codes and impact our conscious decision making. Unconsciously, even our dreams draw on codes. In the future, conflation of different coding systems, e.g., from synthetic biology and generative artificial intelligence, will merge biological codes with machine logic and computer language to promote next-level transhumanism. Codes emerge as a currency converter between systems of life and between different scientific disciplines.}
}
@article{HUSSAIN2025100707,
title = {Humanizing generative AI Brands: How brand anthropomorphism converts customers into brand heroes},
journal = {Computers in Human Behavior Reports},
volume = {19},
pages = {100707},
year = {2025},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2025.100707},
url = {https://www.sciencedirect.com/science/article/pii/S2451958825001228},
author = {Khalid Hussain},
keywords = {Brand anthropomorphism, Brand respect, Brand hero, Generative AI, Branding},
abstract = {The recent surge in research on generative artificial intelligence (GenAI) can be attributed to the unparalleled success of ChatGPT. This success has fueled the development of new GenAI applications that are rapidly transforming the business landscape. Academic research largely focuses on exploring how GenAI can be utilized to enhance the effectiveness of business processes and everyday life of consumers. However, limited attention has been paid to understanding how GenAI brands can sustain their business in this highly dynamic and fiercely competitive GenAI market. To fill this gap, the present study investigated the role of brand anthropomorphism attributes in influencing brand respect and brand heroes. A sample of 315 consumers of GenAI applications was recruited from two countries: the United States of America (n = 167) and the United Kingdom (n = 148). Psychometric properties were validated via confirmatory factor analysis, and hypotheses were tested using PLS-SEM with SmartPLS 4.0. In addition, the present study conducted an importance-performance map analysis to complement the structural analysis. Findings revealed that moral virtue, cognitive experience and appearance attributes of brand anthropomorphism enhance brand respect. Whereas moral virtue, appearance and conscious emotionality attributes of brand anthropomorphism positively influence brand hero. Respondents’ age significantly moderates some of the proposed relationships while gender does not exhibit a significant influence. Theoretical contributions and managerial implications are also discussed.}
}
@article{DUAN2025103221,
title = {Inverse design of lattice structures with target mechanical performance via generative adversarial networks considering the effect of process parameters},
journal = {Advanced Engineering Informatics},
volume = {65},
pages = {103221},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103221},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625001144},
author = {Chenglong Duan and Dazhong Wu},
keywords = {Inverse design, Additive manufacturing, Lattice structures, Machine learning, Generative adversarial networks},
abstract = {While generative artificial intelligence has been used to design materials and structures for additive manufacturing, current techniques can only generate design parameters. However, not only design parameters but also additive manufacturing (AM) process parameters affect the mechanical properties of additively manufactured materials. To address this issue, we introduce an auxiliary classifier generative adversarial network (ACGAN)-based computational framework that generates both design and AM process parameters to fabricate lattice structures with target mechanical performance. The computational framework consists of two ACGAN models, including a generative model called InverseACGAN and a forward predictive model called ForwardACGAN. The generative model generates critical design parameters of the lattice structures, including line distance, layer height, and infill pattern, as well as AM process parameters, including print speed and print temperature, based on target mechanical properties (i.e., porosity and compressive modulus). The forward predictive model predicts the mechanical properties of the lattice structures generated by the generative model. The experimental results show that the porosity and compressive modulus of the lattice structures designed by ACGAN are in good agreement with the target porosity and compressive modulus. The average mean absolute percentage errors between target and actual porosity, and target and actual compressive modulus are 6.481% and 10.208%, respectively.}
}
@article{ZHAO2025102829,
title = {Generative AI: The transformative impact of ChatGPT on systemic financial risk in Chinese banks},
journal = {Pacific-Basin Finance Journal},
volume = {93},
pages = {102829},
year = {2025},
issn = {0927-538X},
doi = {https://doi.org/10.1016/j.pacfin.2025.102829},
url = {https://www.sciencedirect.com/science/article/pii/S0927538X25001660},
author = {Yikai Zhao and Runyu Dai and Jun Nagayasu},
keywords = {AI, ChatGPT, Systemic financial risk, Chinese banks},
abstract = {We investigate the impact of ChatGPT, a generative artificial intelligence (GenAI) application, on the systemic financial risk of Chinese banks. Using a sample of 42 publicly traded banks and employing regression discontinuity (RD) and regression discontinuity difference-in-differences (RD-DID) methodologies, we assess the immediate effects following the launch of ChatGPT on November 30, 2022. Our findings reveal an immediate and significant increase in systemic financial risk, measured by ΔCoVaR. Robustness checks, including placebo tests, alternative risk measures, and varying sample windows, confirm the reliability of these results. Mechanism analysis highlights that transitional challenges during GenAI adoption exacerbate systemic vulnerabilities. Smaller banks, rural commercial banks, and banks with higher nonperforming loan ratios (NPL) face heightened risks, while large state-owned banks remain relatively insulated. These findings underscore the double-edged nature of disruptive innovations such that GenAI integration poses short-term risks to financial stability even if GenAI has transformative potential.}
}
@article{FRAILENARVAEZ2025100466,
title = {Between machines and art: The impact of CNC technology on artistic creation},
journal = {Array},
volume = {27},
pages = {100466},
year = {2025},
issn = {2590-0056},
doi = {https://doi.org/10.1016/j.array.2025.100466},
url = {https://www.sciencedirect.com/science/article/pii/S2590005625000931},
author = {Marcelo Fraile-Narváez and Mihaela I. Chidean},
keywords = {Development of low-cost CNC machine, Generative artificial intelligence, Human–machine creative - collaboration, Digital art materialisation, Material variability in digital fabrication},
abstract = {This study shows how a hybrid workflow based on a Style-GAN-3 (with 256 × 256 pixel resolution) together with a €185 open-hardware plotter reframes authorship by uniting algorithmic invention with material execution. Specifically, it focuses on the development of a low-cost CNC machine, named ‘Gorosito’, which includes various customisation elements, such as the ability to interchange drawing tools to suit the operator/artist. Experimental validation of Gorosito is performed using images generated with generative AI and also including a comparison of the results with those produced by a commercial CNC machine. Results reveal precision of 0.045 mm and a 34% cost saving comparing with other commercial solutions. Our findings also show that each artwork, derived from the same digital file, acquires a unique expression, which leads to a redefinition of authenticity in digital art and provides a renewed perspective on the interplay between technology, artistic creation and cultural perception. The study thus positions Gorosito as an open and reproducible framework that any creative-code laboratory can adopt, bridging machine learning research with low-cost digital fabrication.}
}
@article{OMAR2024e595,
title = {ChatGPT for digital pathology research},
journal = {The Lancet Digital Health},
volume = {6},
number = {8},
pages = {e595-e600},
year = {2024},
issn = {2589-7500},
doi = {https://doi.org/10.1016/S2589-7500(24)00114-6},
url = {https://www.sciencedirect.com/science/article/pii/S2589750024001146},
author = {Mohamed Omar and Varun Ullanat and Massimo Loda and Luigi Marchionni and Renato Umeton},
abstract = {Summary
The rapid evolution of generative artificial intelligence (AI) models including OpenAI's ChatGPT signals a promising era for medical research. In this Viewpoint, we explore the integration and challenges of large language models (LLMs) in digital pathology, a rapidly evolving domain demanding intricate contextual understanding. The restricted domain-specific efficiency of LLMs necessitates the advent of tailored AI tools, as illustrated by advancements seen in the last few years including FrugalGPT and BioBERT. Our initiative in digital pathology emphasises the potential of domain-specific AI tools, where a curated literature database coupled with a user-interactive web application facilitates precise, referenced information retrieval. Motivated by the success of this initiative, we discuss how domain-specific approaches substantially minimise the risk of inaccurate responses, enhancing the reliability and accuracy of information extraction. We also highlight the broader implications of such tools, particularly in streamlining access to scientific research and democratising access to computational pathology techniques for scientists with little coding experience. This Viewpoint calls for an enhanced integration of domain-specific text-generation AI tools in academic settings to facilitate continuous learning and adaptation to the dynamically evolving landscape of medical research.}
}
@article{GIANNAKOPOULOS2023,
title = {Evaluation of the Performance of Generative AI Large Language Models ChatGPT, Google Bard, and Microsoft Bing Chat in Supporting Evidence-Based Dentistry: Comparative Mixed Methods Study},
journal = {Journal of Medical Internet Research},
volume = {25},
year = {2023},
issn = {1438-8871},
doi = {https://doi.org/10.2196/51580},
url = {https://www.sciencedirect.com/science/article/pii/S1438887123009949},
author = {Kostis Giannakopoulos and Argyro Kavadella and Anas {Aaqel Salim} and Vassilis Stamatopoulos and Eleftherios G Kaklamanos},
keywords = {artificial intelligence, AI, large language models, generative pretrained transformers, evidence-based dentistry, ChatGPT, Google Bard, Microsoft Bing, clinical practice, dental professional, dental practice, clinical decision-making, clinical practice guidelines},
abstract = {Background
The increasing application of generative artificial intelligence large language models (LLMs) in various fields, including dentistry, raises questions about their accuracy.
Objective
This study aims to comparatively evaluate the answers provided by 4 LLMs, namely Bard (Google LLC), ChatGPT-3.5 and ChatGPT-4 (OpenAI), and Bing Chat (Microsoft Corp), to clinically relevant questions from the field of dentistry.
Methods
The LLMs were queried with 20 open-type, clinical dentistry–related questions from different disciplines, developed by the respective faculty of the School of Dentistry, European University Cyprus. The LLMs’ answers were graded 0 (minimum) to 10 (maximum) points against strong, traditionally collected scientific evidence, such as guidelines and consensus statements, using a rubric, as if they were examination questions posed to students, by 2 experienced faculty members. The scores were statistically compared to identify the best-performing model using the Friedman and Wilcoxon tests. Moreover, the evaluators were asked to provide a qualitative evaluation of the comprehensiveness, scientific accuracy, clarity, and relevance of the LLMs’ answers.
Results
Overall, no statistically significant difference was detected between the scores given by the 2 evaluators; therefore, an average score was computed for every LLM. Although ChatGPT-4 statistically outperformed ChatGPT-3.5 (P=.008), Bing Chat (P=.049), and Bard (P=.045), all models occasionally exhibited inaccuracies, generality, outdated content, and a lack of source references. The evaluators noted instances where the LLMs delivered irrelevant information, vague answers, or information that was not fully accurate.
Conclusions
This study demonstrates that although LLMs hold promising potential as an aid in the implementation of evidence-based dentistry, their current limitations can lead to potentially harmful health care decisions if not used judiciously. Therefore, these tools should not replace the dentist’s critical thinking and in-depth understanding of the subject matter. Further research, clinical validation, and model improvements are necessary for these tools to be fully integrated into dental practice. Dental practitioners must be aware of the limitations of LLMs, as their imprudent use could potentially impact patient care. Regulatory measures should be established to oversee the use of these evolving technologies.}
}
@article{CENGIZ2025103837,
title = {Exploring second language writers’ engagement with ChatGPT feedback: Revision behaviors and perceptions},
journal = {System},
volume = {134},
pages = {103837},
year = {2025},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2025.103837},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X25002477},
author = {Behice Ceyda Cengiz and Zeynep Bilki and Amine Hatun Ataş and Berkan Celik},
keywords = {Second language (L2) writing, Writing feedback, Generative artificial intelligence (GenAI), ChatGPT feedback, Feedback prompt},
abstract = {While recent research underlines ChatGPT's potential as a second language (L2) writing feedback tool, its effectiveness and role in engaging L2 writers require further investigation. This study explores how English as a Foreign Language (EFL) writers engage with ChatGPT feedback by analyzing their revision behaviors and perceptions of its effectiveness in revising their opinion essays. Using a convergent parallel mixed methods design, the study involved 25 B1-level EFL students from a university in Türkiye. Data were collected through essay drafts, change tracker sheets, a questionnaire, and interviews. The descriptive and thematic analysis of essays, change tracker sheets, and interviews revealed that most content and language feedback was accepted, while organization feedback received mixed engagement of acceptance and rejection. Students were more likely to accept language use feedback than content or organization feedback, often incorporating ChatGPT's revisions directly. For content feedback, the most common revision operations were additions and substitutions while more than a third of the revisions in response to organization feedback involved no corrections. Correction was the most frequent revision operation for language use feedback. Questionnaire and interview analyses further revealed that while ChatGPT feedback was generally well-received and considered beneficial for writing improvement, students faced challenges related to feedback length, specificity, advanced language, and misunderstandings. This study provides valuable insights into how EFL students interact with ChatGPT-generated feedback, highlighting both its potential to support L2 writing development and the challenges that may limit its effectiveness.}
}
@article{HUETTEMANN2025102901,
title = {Designing ontology-based search systems for research articles},
journal = {International Journal of Information Management},
volume = {83},
pages = {102901},
year = {2025},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2025.102901},
url = {https://www.sciencedirect.com/science/article/pii/S0268401225000337},
author = {Sebastian Huettemann and Roland M. Mueller and Barbara Dinter},
keywords = {Search engines, Ontologies, Domain ontologies, Large language models, Knowledge extraction, Design science research, Literature review},
abstract = {The process of conducting scientific literature reviews is becoming increasingly complex and time-consuming due to the rapid expansion of available research. Popular academic search engines offer limited filtering capabilities and suffer from low precision. Machine learning-enhanced approaches tend to target rather specific areas, and novel approaches based on generative artificial intelligence suffer from hallucinations. Drawing on information foraging theory, this article presents a design science research project aimed at generating design knowledge for developing domain-specific search systems for research articles. Our contributions include: (1) integrating domain ontologies with large language models to design ontology-based search systems, (2) generating descriptive design knowledge by exploring the problem space, (3) generating prescriptive design knowledge for developing domain-specific search systems, and (4) presenting an ontology-based search engine prototype. Our results indicate that the proposed solution supports researchers in conducting literature reviews by increasing information gain while reducing interaction costs.}
}
@article{HERCKIS2025,
title = {AI-enabled fraud detection, prevention, and perpetration in nursing credential evaluation: A scoping study},
journal = {Journal of Nursing Regulation},
year = {2025},
issn = {2155-8256},
doi = {https://doi.org/10.1016/j.jnr.2025.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S2155825625000973},
author = {Lauren Herckis and Emily Tse},
keywords = {Scoping review, Fraud, Credential evaluation, Artificial intelligence},
abstract = {Background
Credential fraud among healthcare professionals is a global, significant, and ever-evolving challenge. Technological innovations, such as digital imaging and generative artificial intelligence (AI) that make it easier to fabricate documents, have changed the credential evaluation and verification landscape. A global health worker shortage compounds the critical need to maintain integrity, reliability, and rigor in credential verification of healthcare professionals.
Purpose
To identify evidence-based best practices for combatting nursing credential fraud in the context of AI.
Methods
This research effort entailed a scoping review following Arskey and O'Malley's methodological framework to identify scholarly research related to AI and nursing credential fraud. After the scoping review, an environmental scan of grey literature and professional guidance was performed. Integrated analysis of the findings was used to develop themes and recommendations to guide future work.
Results
Four articles, all published between 2020 and 2025, were subjected to full-text review. Of these four articles, none directly addressed AI in perpetrating or combatting nursing credential fraud. The environmental scan revealed practices documented by professional associations and regulatory bodies as well as emerging trends. Five areas of future research are recommended based on these findings: (1) translate existing research, (2) collaborate in cross-functional teams; (3) engage in experimental software development; (4) generate evidence-based guidance; and (5) participate in ongoing evaluation processes.
Conclusions
This study found emerging practices but no empirical research or evidence-based guidance on the use of AI in combatting or perpetuating nursing credential fraud. Literature addressing employment fraud, AI and nursing regulation, and AI in credential evaluation reveal that nursing credential fraud leveraging AI tools requires urgent attention from regulators, credential evaluators, employers, and researchers.}
}
@article{ANAND2025101069,
title = {Algorithms in the orchard: An embedding-based expert answering system for apple rust},
journal = {Smart Agricultural Technology},
volume = {12},
pages = {101069},
year = {2025},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2025.101069},
url = {https://www.sciencedirect.com/science/article/pii/S2772375525003028},
author = {Astha Anand and Jian Shen and Armin Bernd Cremers and Marc Jacobs},
keywords = {Embeddings, Retrieval-augmented generation, Knowledge graph, Apple rust, Large language model, Generative artificial intelligence, Agricultural pest control},
abstract = {As sustainable agricultural practices gain importance, the need for intelligent pest control decision-making has grown. This paper introduces SEEDS: Similarity-based Expert Embedding Decision System, a Retrieval-Augmented Generation (RAG) based agricultural question-answering (QA) system. It is built upon a domain-specific knowledge graph (KG), representing Cedar Apple Rust disease, its host and causative agents, plant defense molecules against apple rust infection, and various pesticides. Utilizing the OpenAI embedding model, the system generates embeddings for user queries and KG data, employing similarity metrics to rank KG entries, facilitating accurate and relevant pest control recommendations. SEEDS is a promising niche AI tool in plant protection, setting the stage for scalable, extensible QA frameworks in precision agriculture. The results signify not only a step forward in agricultural expert systems but also highlight the potential for expanding this approach to other crops and pests, marking a substantial advancement in the use of AI for agricultural pest control.}
}
@incollection{OZCAN2025137,
title = {Chapter 6 - Dynamic relationalities of relational dynamics},
editor = {Kerimcan Ozcan and Venkat Ramaswamy},
booktitle = {Dynamic Relationality Theory of Creative Transformation},
publisher = {Elsevier},
pages = {137-155},
year = {2025},
isbn = {978-0-443-30159-9},
doi = {https://doi.org/10.1016/B978-0-443-30159-9.00006-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443301599000062},
author = {Kerimcan Ozcan and Venkat Ramaswamy},
keywords = {Artificial general intelligence, Becoming, Differential forms, Differential transformation, Homotopy, Monad, Singularity},
abstract = {Chapter 6 delves into the continuous transformation of identities and structures within Dynamic Relationality Theory employing category theory and differential topology to explore the fluid concept of “becoming.” It highlights significant shifts in relational dynamics, particularly with the advent of generative artificial intelligence (AI), emphasizing the role of natural transformation in guiding the evolution of categories and their interrelationships amid profound changes. The chapter employs differential topological concepts like smooth manifolds, vector fields, Lie derivatives, differential forms, and de Rham cohomology to model transformations within and across categories, providing a holistic view of relational dynamics, especially relevant to Artificial General Intelligence (AGI). It introduces a new monadology to encapsulate category dynamics and applies homotopy theory to model gradual and controlled transformations. The discussion culminates in the exploration of singularity in AGI as a differential transformation, underlining the impact of emerging technologies on categorical transformations and their implications for immersive, AI-driven interaction.}
}
@incollection{GAUR2026227,
title = {Chapter 13 - Empathy and generative AI: Role and ethical challenges},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {227-242},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00001-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780443331244000011},
author = {Loveleen Gaur and Ajith Abraham},
keywords = {Emotional intelligence, Empathy, Ethical challenges, Generative AI, Human-AI interactions, Transparency, User autonomy},
abstract = {This chapter delves into the concept of empathy in the context of generative artificial intelligence (AI), examining its significance in enhancing human-AI interactions while addressing the ethical challenges that arise. Empathy, defined as the ability to understand and share the feelings of another, is crucial for creating AI systems that foster meaningful and socially intelligent interactions. By embedding empathetic responses into AI design, developers can improve user experiences and engagement, making technology more relatable and effective. The chapter discusses various strategies for incorporating empathy into AI systems, such as leveraging natural language processing, affective computing, and emotional intelligence models. Through illustrative case studies, it highlights successful applications of empathetic AI, showcasing how they enhance user satisfaction. However, designing empathetic AI is fraught with challenges, including technical limitations and the complexity of accurately understanding emotional nuances. Ethical considerations surrounding empathetic AI are a major focus. The potential for emotional manipulation poses significant risks, necessitating discussions about authenticity and transparency. The chapter explores how empathetic interactions can respect user autonomy, ensuring that AI does not undermine decision-making abilities. Through case studies, the ethical dilemmas faced by emotional AI assistants and health-related AI systems are examined, illustrating the complexities of managing empathy in practice. Developing ethical guidelines for empathetic AI is essential, and the chapter advocates for the involvement of diverse stakeholders in the design process to address ethical concerns effectively. Looking to the future, the chapter discusses innovations in empathetic AI technologies and the need to anticipate emerging ethical challenges. It concludes with recommendations for building a robust framework that supports ethical empathy in AI, aiming to create systems that are both effective and aligned with ethical principles.}
}
@article{DENG2025118467,
title = {Becoming a cognitive miser? Antecedents and consequences of addictive ChatGPT use},
journal = {Social Science & Medicine},
volume = {383},
pages = {118467},
year = {2025},
issn = {0277-9536},
doi = {https://doi.org/10.1016/j.socscimed.2025.118467},
url = {https://www.sciencedirect.com/science/article/pii/S0277953625007981},
author = {Zihao Deng and Zhaohua Deng},
keywords = {Addictive use, Dual-system theory, Self-construal, Cognitive miserliness},
abstract = {Generative Artificial Intelligence (GenAI) has significantly enhanced productivity across diverse domains, however, growing concerns persist regarding its addictive use and potential cognitive ramifications. This study employed dual-system theory to examine the cognitive-behavioral mechanisms underpinning addictive ChatGPT use, positioning self-construal as a key antecedent and cognitive miserliness as a critical consequence. We adopted a mixed-methods approach for both exploratory and confirmatory analysis. Three cross-sectional surveys revealed that heightened activity in the impulsive cognitive system was a significant predictor of addictive ChatGPT use. Moreover, a dysregulation between the impulsive and reflective cognitive systems exacerbated compulsive tendencies and facilitated cognitive miserliness. Self-construal also affected these effects: individuals with an independent orientation were more likely to rely on the impulsive cognitive system, while those with an interdependent orientation engaged the reflective cognitive system more frequently. Notably, the reflective cognitive system often failed to adequately inhibit addictive ChatGPT use. Qualitative insights supported these findings and offered a deeper understanding of users’ behavioral patterns. This study contributes to theoretical discourse on the adverse cognitive impact of GenAI use, and informs managers seeking to design interventions that promote healthier digital engagement.}
}
@article{HE2025103020,
title = {Beyond simple interaction: Uncovering the perception-interaction intrinsic mechanism of generative AI agents—A multi-modal big data analysis with PLS-SEM and fsQCA},
journal = {Technology in Society},
volume = {83},
pages = {103020},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.103020},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25002106},
author = {Hao He and Shizhen Bai and Chunjia Han and Mu Yang and Weijia Fan and Brij B. Gupta},
keywords = {Human-AI interaction, Generative AI agent, Interactive willingness, Perceived characteristics, Empathy, Multi-modal big data analysis},
abstract = {Generative Artificial Intelligence (GenAI) is increasingly being adopted across industries, yet existing literature has not fully explored the unique traits and the complex mechanism it introduces. To address this gap, this study investigates the unique characteristics of GenAI agents and their impact on user interaction behaviors. By analyzing user-generated text and AI-generated images from the Character.AI platform, we examine three key perceptual characteristics: social personalization, functional customization, and emotional affordance. Through multi-modal machine learning approaches combining Structural Topic Modeling (STM) and Facial Action Coding System (FACS), we propose the “perceived characteristics of GenAI agent-empathy-interactive willingness” (PCoGenAI-E-IW) theoretical model to explore how user perceptions transform into interactive behaviors. Furthermore, the PLS-SEM analysis and configurational approach identify 10 distinct variable combinations that influence users’ interaction willingness. The findings validate our multi-modal analytical framework while providing valuable empirical evidence for marketing strategy formulation, service experience optimization, and theoretical advancement in human-AI interaction research.}
}
@article{YAU2024,
title = {Accuracy of Prospective Assessments of 4 Large Language Model Chatbot Responses to Patient Questions About Emergency Care: Experimental Comparative Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/60291},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124007404},
author = {Jonathan Yi-Shin Yau and Soheil Saadat and Edmund Hsu and Linda Suk-Ling Murphy and Jennifer S Roh and Jeffrey Suchard and Antonio Tapia and Warren Wiechmann and Mark I Langdorf},
keywords = {artificial intelligence, AI, chatbots, generative AI, natural language processing, consumer health information, patient education, literacy, emergency care information, chatbot, misinformation, health care, medical consultation},
abstract = {Background
Recent surveys indicate that 48% of consumers actively use generative artificial intelligence (AI) for health-related inquiries. Despite widespread adoption and the potential to improve health care access, scant research examines the performance of AI chatbot responses regarding emergency care advice.
Objective
We assessed the quality of AI chatbot responses to common emergency care questions. We sought to determine qualitative differences in responses from 4 free-access AI chatbots, for 10 different serious and benign emergency conditions.
Methods
We created 10 emergency care questions that we fed into the free-access versions of ChatGPT 3.5 (OpenAI), Google Bard, Bing AI Chat (Microsoft), and Claude AI (Anthropic) on November 26, 2023. Each response was graded by 5 board-certified emergency medicine (EM) faculty for 8 domains of percentage accuracy, presence of dangerous information, factual accuracy, clarity, completeness, understandability, source reliability, and source relevancy. We determined the correct, complete response to the 10 questions from reputable and scholarly emergency medical references. These were compiled by an EM resident physician. For the readability of the chatbot responses, we used the Flesch-Kincaid Grade Level of each response from readability statistics embedded in Microsoft Word. Differences between chatbots were determined by the chi-square test.
Results
Each of the 4 chatbots’ responses to the 10 clinical questions were scored across 8 domains by 5 EM faculty, for 400 assessments for each chatbot. Together, the 4 chatbots had the best performance in clarity and understandability (both 85%), intermediate performance in accuracy and completeness (both 50%), and poor performance (10%) for source relevance and reliability (mostly unreported). Chatbots contained dangerous information in 5% to 35% of responses, with no statistical difference between chatbots on this metric (P=.24). ChatGPT, Google Bard, and Claud AI had similar performances across 6 out of 8 domains. Only Bing AI performed better with more identified or relevant sources (40%; the others had 0%-10%). Flesch-Kincaid Reading level was 7.7-8.9 grade for all chatbots, except ChatGPT at 10.8, which were all too advanced for average emergency patients. Responses included both dangerous (eg, starting cardiopulmonary resuscitation with no pulse check) and generally inappropriate advice (eg, loosening the collar to improve breathing without evidence of airway compromise).
Conclusions
AI chatbots, though ubiquitous, have significant deficiencies in EM patient advice, despite relatively consistent performance. Information for when to seek urgent or emergent care is frequently incomplete and inaccurate, and patients may be unaware of misinformation. Sources are not generally provided. Patients who use AI to guide health care decisions assume potential risks. AI chatbots for health should be subject to further research, refinement, and regulation. We strongly recommend proper medical consultation to prevent potential adverse outcomes.}
}
@article{SHI2025124328,
title = {Toward open-source foundation model ecosystem: Impact evaluation framework and promotion mechanism},
journal = {Technological Forecasting and Social Change},
volume = {221},
pages = {124328},
year = {2025},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2025.124328},
url = {https://www.sciencedirect.com/science/article/pii/S0040162525003592},
author = {Jincheng Shi and Shan Jiang},
keywords = {Artificial intelligence, Open source, Foundation model, Generative artificial intelligence, Impact evaluation},
abstract = {Open-source foundation models cultivate complex innovation ecosystems that render traditional, project-centric evaluation frameworks inadequate. To address this gap, our study develops and validates a three-level framework for assessing ecosystem-level impact and identifying its enhancement mechanisms. Grounded in technology diffusion theory, we conduct a mixed-methods analysis of 14 leading models, using data from Hugging Face, GitHub, and X (formerly Twitter). Our findings reveal that while the initial impact of these models is balanced, significant gaps emerge at the secondary (derivative innovation) and tertiary (global influence) levels. We term this challenge the “climbing effect”—the difficulty of transitioning impact across these levels—and identify specific technical and strategic control points that facilitate this progression. Theoretically, this study shifts the unit of analysis from individual projects to broader ecosystems, challenges the assumption of “smooth diffusion,” and introduces control point theory to the open-source context. Practically, our findings offer actionable strategies for developers and an evidence-based framework for policymakers to foster a more prosperous open-source AI landscape.}
}
@article{DONG2025102582,
title = {Revisiting PR professionalism and ethics in the generative AI era through PR practitioners’ insights},
journal = {Public Relations Review},
volume = {51},
number = {3},
pages = {102582},
year = {2025},
issn = {0363-8111},
doi = {https://doi.org/10.1016/j.pubrev.2025.102582},
url = {https://www.sciencedirect.com/science/article/pii/S036381112500044X},
author = {Chuqing Dong and Morgan {van den Berg}},
keywords = {Ethics, Generative artificial intelligence (GAI), Professional code of ethics, PR practitioners},
abstract = {Recent breakthroughs in artificial intelligence (AI) continue to redefine strategic communication practices, provoking serious consideration for ethical implications, guidelines, and contextualizing areas of integration. Based on interviews with 21 PR professionals, this study examined perspectives on AI, particularly Generative AI (GAI), in PR practices and related ethical implications. Results highlight key benefits and commonly shared challenges of GAI use in PR practices. Additionally, the study reveals various ethical concerns identified by professionals in GAI use and the moral values held by professionals in guiding their ethical GAI use. This study contributes to an ongoing discussion on developing PR ethics theories pertinent to professionals that address PR practitioners’ timely ethical concerns around GAI. Practically, this study helps PR scholars and educators understand how professionals navigate rapidly advancing GAI technologies while maintaining high ethical standards and social responsibility.}
}
@incollection{GAUR2026197,
title = {Chapter 11 - Health equity and generative AI: Role, impact, and challenges},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {197-210},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00006-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780443331244000060},
author = {Loveleen Gaur and Ajith Abraham},
keywords = {Algorithm bias, Ethical issues, Fairness, Generative AI, Health disparities, Health equity, Inclusive healthcare, Public health},
abstract = {This chapter explores the intersection of health equity and generative artificial intelligence (AI), emphasizing the role of AI in addressing health disparities while recognizing the challenges it presents. Health equity refers to the principle of fairness in healthcare, ensuring that all individuals have access to necessary resources and opportunities for optimal health. Generative AI has emerged as a transformative tool in healthcare, aiding in diagnosis, treatment planning, and patient management. However, algorithmic bias poses significant risks, exacerbating existing disparities and potentially leading to inequitable healthcare outcomes. The chapter examines how biases in AI algorithms can contribute to health disparities, illustrated through case studies showcasing real-world implications. Ethical concerns surrounding distributive justice, patient autonomy, and resource allocation are also addressed, highlighting the importance of equitable AI integration in healthcare systems. Strategies for developing fair algorithms, implementing ethical guidelines, and engaging with affected communities are discussed as essential components for promoting health equity. Additionally, the chapter presents case studies that demonstrate successful initiatives aimed at mitigating bias and enhancing equity through AI applications. Looking ahead, it identifies future directions for fair AI development, the need for policy and regulatory measures, and the vision for an inclusive healthcare system where generative AI serves to bridge health equity gaps.}
}
@article{XIAO2024105874,
title = {Automated daily report generation from construction videos using ChatGPT and computer vision},
journal = {Automation in Construction},
volume = {168},
pages = {105874},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105874},
url = {https://www.sciencedirect.com/science/article/pii/S0926580524006101},
author = {Bo Xiao and Yifan Wang and Yongpan Zhang and Chen Chen and Amos Darko},
keywords = {Construction daily report generation, Computer vision, ChatGPT, Construction management, Project documentation},
abstract = {Daily reports are important in construction management, informing project teams about status, enabling timely resolutions of delays and budget issues, and serving as official records for disputes and litigation. However, current practices are manual and time-consuming, requiring engineers to physically visit sites for observations. To fill this gap, this paper proposes an automated framework to generate daily construction reports from on-site videos by integrating ChatGPT and computer vision (CV)-based methods. The framework utilizes CV methods to analyze video footage and extract relevant productivity and activity information, which is then fed into ChatGPT using proper prompts to generate daily reports. A web application is developed to implement and validate the framework on a real construction site in Hong Kong, generating daily reports over a month. This research enhances construction management by significantly reducing documentation efforts through generative artificial intelligence, with potential applications in jobsite safety management, quality reporting, and stakeholder communication.}
}
@article{GUTIERREZMAQUILON2024,
title = {Integrating GPT-Based AI into Virtual Patients to Facilitate Communication Training Among Medical First Responders: Usability Study of Mixed Reality Simulation},
journal = {JMIR Formative Research},
volume = {8},
year = {2024},
issn = {2561-326X},
doi = {https://doi.org/10.2196/58623},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X24007133},
author = {Rodrigo {Gutiérrez Maquilón} and Jakob Uhl and Helmut Schrom-Feiertag and Manfred Tscheligi},
keywords = {medical first responders, verbal communication skills, training, virtual patient, generative artificial intelligence, GPT, large language models, prompt engineering, mixed reality},
abstract = {Background
Training in social-verbal interactions is crucial for medical first responders (MFRs) to assess a patient’s condition and perform urgent treatment during emergency medical service administration. Integrating conversational agents (CAs) in virtual patients (VPs), that is, digital simulations, is a cost-effective alternative to resource-intensive human role-playing. There is moderate evidence that CAs improve communication skills more effectively when used with instructional interventions. However, more recent GPT-based artificial intelligence (AI) produces richer, more diverse, and more natural responses than previous CAs and has control of prosodic voice qualities like pitch and duration. These functionalities have the potential to better match the interaction expectations of MFRs regarding habitability.
Objective
We aimed to study how the integration of GPT-based AI in a mixed reality (MR)–VP could support communication training of MFRs.
Methods
We developed an MR simulation of a traffic accident with a VP. ChatGPT (OpenAI) was integrated into the VP and prompted with verified characteristics of accident victims. MFRs (N=24) were instructed on how to interact with the MR scenario. After assessing and treating the VP, the MFRs were administered the Mean Opinion Scale-Expanded, version 2, and the Subjective Assessment of Speech System Interfaces questionnaires to study their perception of the voice quality and the usability of the voice interactions, respectively. Open-ended questions were asked after completing the questionnaires. The observed and logged interactions with the VP, descriptive statistics of the questionnaires, and the output of the open-ended questions are reported.
Results
The usability assessment of the VP resulted in moderate positive ratings, especially in habitability (median 4.25, IQR 4-4.81) and likeability (median 4.50, IQR 3.97-5.91). Interactions were negatively affected by the approximately 3-second latency of the responses. MFRs acknowledged the naturalness of determining the physiological states of the VP through verbal communication, for example, with questions such as “Where does it hurt?” However, the question-answer dynamic in the verbal exchange with the VP and the lack of the VP’s ability to start the verbal exchange were noticed. Noteworthy insights highlighted the potential of domain-knowledge prompt engineering to steer the actions of MFRs for effective training.
Conclusions
Generative AI in VPs facilitates MFRs’ training but continues to rely on instructions for effective verbal interactions. Therefore, the capabilities of the GPT-VP and a training protocol need to be communicated to trainees. Future interactions should implement triggers based on keyword recognition, the VP pointing to the hurting area, conversational turn-taking techniques, and add the ability for the VP to start a verbal exchange. Furthermore, a local AI server, chunk processing, and lowering the audio resolution of the VP’s voice could ameliorate the delay in response and allay privacy concerns. Prompting could be used in future studies to create a virtual MFR capable of assisting trainees.}
}
@article{AGARWAL2025100214,
title = {Beyond boundaries: Charting the frontier of healthcare with big data and ai advancements in pharmacovigilance},
journal = {Health Sciences Review},
volume = {14},
pages = {100214},
year = {2025},
issn = {2772-6320},
doi = {https://doi.org/10.1016/j.hsr.2025.100214},
url = {https://www.sciencedirect.com/science/article/pii/S2772632025000066},
author = {Arohi Agarwal and Gagan Singh and Samyak Jain and Piyush Mittal},
keywords = {Big data, Big data analytics, Genomics, Structured data, Unstructured data, Semi-structured data, Descriptive analytics, Exploratory or discovery analytics, Predictive analytics, Pharmacovigilance (Pv), Artificial intelligence (AI), Generative adversarial networks, Variational autoencoders, Transformer-based models},
abstract = {The healthcare sector is intricate, generating vast amounts of data from various sources at an accelerated pace. The contemporary trend of Big Data Analytics is pivotal, impacting not only the pharmaceutical industry but also transforming healthcare, contributing to personalized treatment, aiding in preventive healthcare, managing electronic health records, facilitating adverse drug reporting, and incorporating consumer reviews. This article provides an overview of the inevitable influence of big data and the utilization of artificial intelligence in revolutionizing both healthcare and the pharmaceutical sector. It delves into the notable benefits and challenges encountered in advancing data analytics of the early 21st century.In many countries, Post-marketing surveillance of drug safety relinquishes on a systematic analysis of spontaneous using Generative artificial intelligence (AI) to overcome gaps in the present PV ecosystem is critical to maintaining an uninterrupted record of security and effectiveness within healthcare analytics, data mining techniques, predictive analytics, and the emergence of scientific fields like bioinformatics and health informatics are empowered by Big Data. Nevertheless, the integration of AI in healthcare, especially in pharmacovigilance, aligns with the evolving landscape of electronic health information technology. In conclusion, review highlights the transformative impact of Big Data and AI in healthcare, emphasizing their applications in pharmacovigilance and pharmacoepidemiology. The continuous evolution of these technologies holds promise for improving patient safety, personalized medicine, and overall healthcare outcomes.}
}
@article{DALVIESFAHANI2025124291,
title = {Stimulus-organism-response framework of decision-makers intention to adopt generative AI to replace entry-level jobs: The moderating impact of personality traits},
journal = {Technological Forecasting and Social Change},
volume = {219},
pages = {124291},
year = {2025},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2025.124291},
url = {https://www.sciencedirect.com/science/article/pii/S0040162525003221},
author = {Mohammad Dalvi-Esfahani and Hajar Barati-Ahmadabadi and T. Ramayah and Jason J. Turner and Noorminshah {A. Iahad} and Nasrin Azar},
keywords = {Generative AI, Entry-level jobs, Stimulus-Organism-Response (S-O-R), Theory of Effective Use (TEU)},
abstract = {This study was motivated by the limited research on the adoption of Generative Artificial Intelligence (GenAI) in the workplace. Based on the Stimulus-Organism-Response (S-O-R) framework, we developed a model to assess the factors influencing decision-makers' intention to adopt GenAI as a substitute for entry-level jobs in financial institutions. To test the hypotheses, we collected survey data from 335 respondents in Malaysian financial institutions and analyzed it using partial least squares structural equation modeling. The findings indicate that trust in GenAI significantly affects decision-makers' intention to adopt it as an alternative solution to human positions. Trust, in turn, was found to be positively influenced by constructs from the Theory of Effective Use (transparent interaction, informed action, and representational fidelity) as well as AI literacy, which reflects users' ability to evaluate and interact with AI. The results also show that personality traits, particularly conscientiousness, moderate the relationship between trust and adoption intention, highlighting the importance of individual differences in GenAI usage. Collectively, our findings extend the S-O-R framework by revealing how both cognitive and affective factors shape GenAI adoption behavior. The study also offers practical implications for GenAI stakeholders, especially about the vital role of trust-building strategies in fostering AI adoption.}
}
@article{KUNZE2025547,
title = {Large Language Models Applied to Health Care Tasks May Improve Clinical Efficiency, Value of Care Rendered, Research, and Medical Education},
journal = {Arthroscopy: The Journal of Arthroscopic & Related Surgery},
volume = {41},
number = {3},
pages = {547-556},
year = {2025},
issn = {0749-8063},
doi = {https://doi.org/10.1016/j.arthro.2024.12.010},
url = {https://www.sciencedirect.com/science/article/pii/S0749806324010478},
author = {Kyle N. Kunze and Benedict U. Nwachukwu and Mark P. Cote and Prem N. Ramkumar},
abstract = {Large language models (LLMs) are generative artificial intelligence models that create content on the basis of the data on which it was trained. Processing capabilities have evolved from text only to being multimodal including text, images, audio, and video features. In health care settings, LLMs are being applied to several clinically important areas, including patient care and workflow efficiency, communications, hospital operations and data management, medical education, practice management, and health care research. Under the umbrella of patient care, several core use cases of LLMs include simplifying documentation tasks, enhancing patient communication (interactive language and written), conveying medical knowledge, and performing medical triage and diagnosis. However, LLMs warrant scrutiny when applied to health care tasks, as errors may have negative implications for health care outcomes, specifically in the context of perpetuating bias, ethical considerations, and cost-effectiveness. Customized LLMs developed for more narrow purposes may help overcome certain performance limitations, transparency challenges, and biases present in contemporary generalized LLMs by curating training data. Methods of customizing LLMs broadly fall under 4 categories: prompt engineering, retrieval augmented generation, fine-tuning, and agentic augmentation, with each approach conferring different information-retrieval properties for the LLM.
Level of Evidence
Level V, expert opinion.}
}
@article{LI2025103015,
title = {The psychological mechanism of value co-creation with human-centred generative AI robot assistants},
journal = {Technology in Society},
volume = {83},
pages = {103015},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.103015},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25002052},
author = {Zhaotong Li and Kum Fai Yuen and Chee-Chong Teo},
keywords = {Human-centred generative AI, Robot assistant, Value co-creation, Autonomy competence relatedness model, Mind perception theory},
abstract = {Human-Generative Artificial Intelligence (GAI) interactions are receiving increasing attention in both society and academia, and GAI integration makes robot assistants more human-centred to better serve consumers. Understanding the value co-creation process between human consumers and GAI robot assistants is critical for the broader adoption of such technologies. This study seeks to investigate the psychological mechanisms and antecedent factors that underlie the human–AI value co-creation process, which has received limited attention in the literature. Accordingly, a theoretical model based on the Autonomy Competence Relatedness (ACR) model and Mind Perception Theory (MPT) is developed to examine the technological features and psychological factors that promote value co-creation. A survey was conducted in Singapore and collected 607 responses, which were analysed through covariance-based structural equation modelling. Survey results reveal that GAI robot assistant features (i.e., sensing autonomy, thought autonomy, action autonomy, personalisation, anthropomorphism, and interactivity) positively impact value co-creation through the mediation of consumers' psychological motivations, including perceived autonomy, competence, warmth, and relatedness satisfactions. By extending the ACR model with MPT, this study enhances the literature on human-GAI interactions, offering a novel understanding of the psychological factors driving value co-creation in human-centred GAI applications.}
}
@article{CANOORTIZ2024102745,
title = {Enhancing pavement crack segmentation via semantic diffusion synthesis model for strategic road assessment},
journal = {Results in Engineering},
volume = {23},
pages = {102745},
year = {2024},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2024.102745},
url = {https://www.sciencedirect.com/science/article/pii/S2590123024010004},
author = {Saúl Cano-Ortiz and Eugenio Sainz-Ortiz and Lara {Lloret Iglesias} and Pablo {Martínez Ruiz del Árbol} and Daniel Castro-Fresno},
keywords = {Pavement crack segmentation, Generative artificial intelligence, Semantic diffusion synthesis, Road maintenance, Deep learning},
abstract = {Computer-aided deep learning has significantly advanced road crack segmentation. However, supervised models face challenges due to limited annotated images. There is also a lack of emphasis on deriving pavement condition indices from predicted masks. This article introduces a novel semantic diffusion synthesis model that creates synthetic crack images from segmentation masks. The model is optimized in terms of architectural complexity, noise schedules, and condition scaling. The optimal architecture outperforms state-of-the-art semantic synthesis models across multiple benchmark datasets, demonstrating superior image quality assessment metrics. The synthetic frames augment these datasets, resulting in segmentation models with significantly improved efficiency. This approach enhances results without extensive data collection or annotation, addressing a key challenge in engineering. Finally, a refined pavement condition index has been developed for automated end-to-end defect detection systems, promoting more effective maintenance planning.}
}
@article{AMIN2025147,
title = {Release of complex imaging reports to patients, do radiologists trust AI to help?},
journal = {Current Problems in Diagnostic Radiology},
volume = {54},
number = {2},
pages = {147-150},
year = {2025},
issn = {0363-0188},
doi = {https://doi.org/10.1067/j.cpradiol.2024.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S0363018824002354},
author = {Kanhai S. Amin and Melissa A. Davis and Amir Naderi and Howard P. Forman},
keywords = {Radiology Report, Imaging Report, Artificial Intelligence, 21st Century Cures Act, ChatGPT, Health Communication, Large Language Models},
abstract = {Background
As a result of the 21st Century Cures Act, radiology reports are immediately released to patients. However, these reports are often too complex for the lay patient, potentially leading to stress and anxiety. While solutions such as patient portals or providing radiologist contact information have been proposed in the past, new generative artificial intelligence technologies like ChatGPT and Google Gemini may provide the most accessible and scalable method of simplifying radiology reports for patients. Here, we gather the opinions of radiologists regarding this possibility.
Methods
An eight-question survey was sent out to all diagnostic/interventional radiology attendings and clinical fellows at our large academic medical center.
Results
From our survey (N = 52), 52.8 % of respondents agreed/strongly agreed that patients should have immediate access to their radiology reports. Only 9.61 % agreed that radiology reports are understandable by the lay patient. Regarding potential avenues to improve patient comprehension of their radiology reports, using artificial intelligence to simplify reports with a manual check by radiologists garnered the most support/strong support (46.2 %). Support of artificial intelligence generated simplifications dropped to (23.1 %) without a manual check.
Conclusion
Patients are increasingly gaining access to their radiology reports, but reports may be too complex for the lay patient. Eventually, artificial intelligence systems may help simplify radiology reports for patients, but there is currently limited support from radiologists.}
}
@article{MOROSKY20254,
title = {Practical applications of artificial intelligence chatbots in obstetrics and gynecology medical education},
journal = {American Journal of Obstetrics and Gynecology},
volume = {233},
number = {1},
pages = {4-11},
year = {2025},
issn = {0002-9378},
doi = {https://doi.org/10.1016/j.ajog.2025.04.021},
url = {https://www.sciencedirect.com/science/article/pii/S0002937825002285},
author = {Christopher M. Morosky and Laura Baecher-Lind and Katherine T. Chen and Angela Fleming and Shireen Madani Sims and Helen Kang Morgan and Celeste S. Royce and Tammy Sonn and Alyssa Stephenson-Famy and Jill Sutton and Jonathan Schaffir and Rashmi Bhargava},
keywords = {artificial intelligence, biases, chatbot, ChatGPT, data privacy, faculty development, feedback, hallucinations, informed approach, integration, large language models, learning objectives, medical education, mentorship, responsible use, teaching},
abstract = {Generative artificial intelligence chatbots are sophisticated conversational artificial intelligence tools that have the capability to interpret natural language inputs and produce responses that closely resemble human speech. Artificial intelligence chatbots hold significant promise in revolutionizing medical education by offering invaluable support across various educational domains, including teaching, learning, and assessment. Their practical applications span a wide spectrum, from aligning learning objectives and simplifying administrative tasks to facilitating feedback, aiding faculty development, and supporting mentorship initiatives. However, alongside their potential benefits, concerns exist regarding data privacy, inherent biases, and occasional errors termed “hallucinations,” underscoring the imperative for a cautious and informed approach to their integration within educational settings. It therefore becomes essential for medical educators and academic institutions to proactively engage with artificial intelligence technologies like chatbots, not only to leverage their benefits but also to critically assess and address associated challenges such as bias, privacy, and misinformation. By thoughtfully integrating artificial intelligence tools, medical educators can determine where these technologies are most beneficial, implement safeguards against potential harms, and explore innovative applications to enhance medical education.}
}
@article{WANG2024104133,
title = {Audio–visual deepfake detection using articulatory representation learning},
journal = {Computer Vision and Image Understanding},
volume = {248},
pages = {104133},
year = {2024},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2024.104133},
url = {https://www.sciencedirect.com/science/article/pii/S1077314224002145},
author = {Yujia Wang and Hua Huang},
keywords = {Deepfake detection, Audio–visual, Articulatory representation},
abstract = {Advancements in generative artificial intelligence have made it easier to manipulate auditory and visual elements, highlighting the critical need for robust audio–visual deepfake detection methods. In this paper, we propose an articulatory representation-based audio–visual deepfake detection approach, ART-AVDF. First, we devise an audio encoder to extract articulatory features that capture the physical significance of articulation movement, integrating with a lip encoder to explore audio–visual articulatory correspondences in a self-supervised learning manner. Then, we design a multimodal joint fusion module to further explore inherent audio–visual consistency using the articulatory embeddings. Extensive experiments on the DFDC, FakeAVCeleb, and DefakeAVMiT datasets demonstrate that ART-AVDF obtains a significant performance improvement compared to many deepfake detection models.}
}
@article{SINGH2024103021,
title = {Applications of generative AI and future organizational performance: The mediating role of explorative and exploitative innovation and the moderating role of ethical dilemmas and environmental dynamism},
journal = {Technovation},
volume = {133},
pages = {103021},
year = {2024},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2024.103021},
url = {https://www.sciencedirect.com/science/article/pii/S0166497224000713},
author = {Kuldeep Singh and Sheshadri Chatterjee and Marcello Mariani},
keywords = {Generative AI, Organization future performance, Exploratory and exploitative innovation, Environmental dynamism, Ethics},
abstract = {Generative Artificial Intelligence (GenAI) is one of the popular AI technologies which can produce multiple kinds of contents including music, text, image, as well as synthetic data. As GenAI technology can produce various forms of contents, organizations must face ethical dilemmas as to where this technology is likely to be used. Organizations do not want to compromise their ethical standards and compliance policies. Against this backdrop, the aim of this study is to examine if GenAI technology could improve the future performance of the organizations. This study deployed ethical dilemmas and environmental dynamism as two moderators acting on different linkages between adoption of GenAI and organizational future performance. With the help of literature review and theories, a theoretical model has been developed conceptually which was validated using PLS-SEM technique with the feedback of 326 responses from different types of organizations. This study found that the adoption of GenAI could improve exploratory and exploitative innovation under the moderating effects of environmental dynamism and ethical dilemmas. Moreover, it highlighted that the application of GenAI could improve organizational performance.}
}