@article{ZHANG2025100687,
title = {Structure and oxygen saturation recovery of sparse photoacoustic microscopy images by deep learning},
journal = {Photoacoustics},
volume = {42},
pages = {100687},
year = {2025},
issn = {2213-5979},
doi = {https://doi.org/10.1016/j.pacs.2025.100687},
url = {https://www.sciencedirect.com/science/article/pii/S2213597925000060},
author = {Shuyan Zhang and Jingtan Li and Lin Shen and Zhonghao Zhao and Minjun Lee and Kun Qian and Naidi Sun and Bin Hu},
keywords = {Deep learning, Photoacoustic microscopy, Sparse data, High-speed imaging, Image reconstruction},
abstract = {Photoacoustic microscopy (PAM) leverages the photoacoustic effect to provide high-resolution structural and functional imaging. However, achieving high-speed imaging with high spatial resolution remains challenging. To address this, undersampling and deep learning have emerged as common techniques to enhance imaging speed. Yet, existing methods rarely achieve effective recovery of functional images. In this study, we propose Mask-enhanced U-net (MeU-net) for recovering sparsely sampled PAM structural and functional images. The model utilizes dual-channel input, processing photoacoustic data from 532 nm and 558 nm wavelengths. Additionally, we introduce an adaptive vascular attention mask module that focuses on vascular information recovery and design a vessel-specific loss function to enhance restoration accuracy. We simulate data from mouse brain and ear imaging under various levels of sparsity (4 ×, 8 ×, 12 ×) and conduct extensive experiments. The results demonstrate that MeU-net significantly outperforms traditional interpolation methods and other representative models in structural information and oxygen saturation recovery.}
}
@article{ASHRAF2024100363,
title = {Data Information integrated Neural Network (DINN) algorithm for modelling and interpretation performance analysis for energy systems},
journal = {Energy and AI},
volume = {16},
pages = {100363},
year = {2024},
issn = {2666-5468},
doi = {https://doi.org/10.1016/j.egyai.2024.100363},
url = {https://www.sciencedirect.com/science/article/pii/S2666546824000296},
author = {Waqar Muhammad Ashraf and Vivek Dua},
keywords = {Explainable AI, Model interpretation, Scientific machine learning, Artificial neural network, Loss function},
abstract = {Developing a well-predictive machine learning model that also offers improved interpretability is a key challenge to widen the application of artificial intelligence in various application domains. In this work, we present a Data Information integrated Neural Network (DINN) algorithm that incorporates the correlation information present in the dataset for the model development. The predictive performance of DINN is also compared with a standard artificial neural network (ANN) model. The DINN algorithm is applied on two case studies of energy systems namely energy efficiency cooling (ENC) & energy efficiency heating (ENH) of the buildings, and power generation from a 365 MW capacity industrial gas turbine. For ENC, DINN presents lower mean RMSE for testing datasets (RMSE_test = 1.23 %) in comparison with the ANN model (RMSE_test = 1.41 %). Similarly, DINN models have presented better predictive performance to model the output variables of the two case studies. The input perturbation analysis following the Gaussian distribution for noise generation reveals the order of significance of the variables, as made by DINN, can be better explained by the domain knowledge of the power generation operation of the gas turbine. This research work demonstrates the potential advantage to integrate the information present in the data for the well-predictive model development complemented with improved interpretation performance thereby opening avenues for industry-wide inclusion and other potential applications of machine learning.}
}
@article{VAERNESBRANDEN202423,
title = {Placental human papillomavirus infections and adverse pregnancy outcomes},
journal = {Placenta},
volume = {152},
pages = {23-30},
year = {2024},
issn = {0143-4004},
doi = {https://doi.org/10.1016/j.placenta.2024.05.126},
url = {https://www.sciencedirect.com/science/article/pii/S0143400424002406},
author = {Magdalena R. Værnesbranden and Anne Cathrine Staff and Johanna Wiik and Katrine Sjøborg and Corina S. Rueegg and Meryam Sugulle and Karin C. {Lødrup Carlsen} and Berit Granum and Guttorm Haugen and Gunilla Hedlin and Camilla G. Johannessen and Björn Nordlund and Camilla F. Nystrand and Anbjørg Rangberg and Eva M. Rehbinder and Knut Rudi and Yvonne Sandberg and Håvard O. Skjerven and Cilla Söderhäll and Riyas Vettukattil and Christine M. Jonassen},
keywords = {Placental biopsies, Genital HPV infection, Human papillomavirus, PreventADALL, Placental dysfunction syndromes},
abstract = {Introduction
Knowledge on prevalence and association of human papillomavirus (HPV) in third trimester placentae and adverse pregnancy outcomes is limited. We investigated the prevalence of placental HPV at delivery, explored urine HPV characteristics associated with placental HPV and whether placental HPV increased the risk adverse pregnancy outcomes.
Methods
Pregnant women were enrolled in the Scandinavian PreventADALL mother-child cohort study at midgestation. Human papillomavirus genotyping was performed on placental biopsies collected at delivery (n = 587) and first-void urine at midgestation and delivery (n = 556). Maternal characteristics were collected by questionnaires at gestational week 18 and 34. Adverse pregnancy outcomes were registered from chart data including hypertensive disorders of pregnancy, gestational diabetes mellitus and newborns small for gestational age. Uni- and multivariable regression models were used to investigate associations.
Results
Placental HPV was detected in 18/587 (3 %). Twenty-eight genotypes were identified among the 214/556 (38 %) with midgestational urine HPV. Seventeen of the 18 women with placental HPV were midgestational HPV positive with 89 % genotype concordance. Midgestational high-risk-(HR)-HPV and high viral loads of Any- or HR-HPV were associated with placental HPV. Persisting HPV infection from midgestation to delivery was not associated with placental HPV. Adverse pregnancy outcomes were seen in 2/556 (0.4 %) of women with placental HPV.
Discussion
In this general cohort of pregnant women, the prevalence of placental HPV was 3 %, and midgestational urinary HPV 38 %. High HPV viral load increased the risk for placental HPV infections. We observed no increased risk for adverse pregnancy outcomes in women with placental HPV.}
}
@article{QI2026103178,
title = {T2VEval: Benchmark dataset and objective evaluation method for T2V-generated videos},
journal = {Displays},
volume = {91},
pages = {103178},
year = {2026},
issn = {0141-9382},
doi = {https://doi.org/10.1016/j.displa.2025.103178},
url = {https://www.sciencedirect.com/science/article/pii/S014193822500215X},
author = {Zelu Qi and Ping Shi and Shuqi Wang and Chaoyang Zhang and Fei Zhao and Zefeng Ying and Da Pan and Xi Yang and Zheqi He and Teng Dai},
keywords = {Text-to-video, Quality assessment, Evaluation benchmark, Objective evaluation},
abstract = {Recent advances in text-to-video (T2V) technology, as demonstrated by models such as Runway Gen-3, Pika, Sora, and Kling, have significantly broadened the applicability and popularity of the technology. This progress has created a growing demand for accurate quality assessment metrics to evaluate the perceptual quality of T2V-generated videos and optimize video generation models. However, assessing the quality of text-to-video outputs remain challenging due to the presence of highly complex distortions, such as unnatural actions and phenomena that defy human cognition. To address these challenges, we constructed T2VEval-Bench, a multi-dimensional benchmark dataset for text-to-video quality evaluation, which contains 148 textual prompts and 1,783 videos generated by 13 T2V models. To ensure a comprehensive evaluation, we scored each video on four dimensions in the subjective experiment, which are overall impression, text–video consistency, realness, and technical quality. Based on T2VEval-Bench, we developed T2VEval, a multi-branch fusion scheme for T2V quality evaluation. T2VEval assesses videos across three branches: text–video consistency, realness, and technical quality. Using an attention-based fusion module, T2VEval effectively integrates features from each branch and predicts scores with the aid of a large language model. Additionally, we implemented a divide-and-conquer training strategy, enabling each branch to learn targeted knowledge while maintaining synergy with the others. Experimental results demonstrate that T2VEval achieves state-of-the-art performance across multiple metrics.}
}
@article{SHAFQAT2024928,
title = {Big data analytics capabilities and leadership: catalysts of firm performance in telecommunications},
journal = {Business Process Management Journal},
volume = {31},
number = {3},
pages = {928-947},
year = {2024},
issn = {1463-7154},
doi = {https://doi.org/10.1108/BPMJ-06-2024-0458},
url = {https://www.sciencedirect.com/science/article/pii/S1463715424000062},
author = {Hira Shafqat and Baojian Zhang and Muhammad Ahmed and Muhammad Rizwan Ullah and Muhammad Zulfiqar},
keywords = {Dynamic capabilities, Talent capabilities, Top management attitude, Big data analytics, Firm performance},
abstract = {Purpose
The proliferation of big data analytics (BDA)-enabled tools and technologies has endowed organizations with the capacity to augment decision-making processes, optimize operational endeavors and foster innovation across diverse business domains. Consequently, BDA has been posited as a catalyst for enhanced customer relationship management, improved risk mitigation strategies and heightened operational efficiencies, all of which converge to augment overall firm performance. Thus, the purpose of this research is to introduce a conceptual framework aimed at explaining the influence of BDA capabilities on the performance of telecommunications firms in Pakistan. Additionally, it examines the potential mediating effect of talent capabilities and moderating effect of top management attitude on firm performance.
Design/methodology/approach
Data from a sample comprising 520 participants were collected via survey questionnaires. The study employed Partial Least Squares-Structural Equation Modeling to empirically evaluate the proposed model.
Findings
Results reveal a positive association between BDA technology and information capabilities with both BDA talent capabilities and firm performance. Furthermore, the analysis suggests that BDA talent capabilities mediate the relationship between BDA dynamic capabilities and firm performance, while top management attitude acts as a moderator, enhancing the relationship between BDA talent capabilities and firm performance.
Originality/value
There is a scarcity of research that has examined the relationship of BDA capabilities, top management attitude and firm performance. This study attempts to examine their interrelationships. First, it enhances the extant literature by elucidating the mediating role of BDA talent capabilities in the relationship between BDA technology and information capabilities and firm performance. Second, the study introduces a novel dimension by incorporating top management attitude as a moderator variable. This augmentation adds layers of complexity to comprehending BDA implementation dynamics, emphasizing leadership’s role in fostering an enabling environment for effective utilization of BDA capabilities.}
}
@article{QUTTAINAH2024,
title = {Cost, Usability, Credibility, Fairness, Accountability, Transparency, and Explainability Framework for Safe and Effective Large Language Models in Medical Education: Narrative Review and Qualitative Study},
journal = {JMIR AI},
volume = {3},
year = {2024},
issn = {2817-1705},
doi = {https://doi.org/10.2196/51834},
url = {https://www.sciencedirect.com/science/article/pii/S281717052400022X},
author = {Majdi Quttainah and Vinaytosh Mishra and Somayya Madakam and Yotam Lurie and Shlomo Mark},
keywords = {large language model, LLM, ChatGPT, CUC-FATE framework, cost, usability, credibility, fairness, accountability, transparency, and explainability, analytical hierarchy process, AHP, total interpretive structural modeling, TISM, medical education, adoption, guideline, development, health care, chat generative pretrained transformer, generative language model tool, user, innovation, data generation, narrative review, health care professional},
abstract = {Background
The world has witnessed increased adoption of large language models (LLMs) in the last year. Although the products developed using LLMs have the potential to solve accessibility and efficiency problems in health care, there is a lack of available guidelines for developing LLMs for health care, especially for medical education.
Objective
The aim of this study was to identify and prioritize the enablers for developing successful LLMs for medical education. We further evaluated the relationships among these identified enablers.
Methods
A narrative review of the extant literature was first performed to identify the key enablers for LLM development. We additionally gathered the opinions of LLM users to determine the relative importance of these enablers using an analytical hierarchy process (AHP), which is a multicriteria decision-making method. Further, total interpretive structural modeling (TISM) was used to analyze the perspectives of product developers and ascertain the relationships and hierarchy among these enablers. Finally, the cross-impact matrix-based multiplication applied to a classification (MICMAC) approach was used to determine the relative driving and dependence powers of these enablers. A nonprobabilistic purposive sampling approach was used for recruitment of focus groups.
Results
The AHP demonstrated that the most important enabler for LLMs was credibility, with a priority weight of 0.37, followed by accountability (0.27642) and fairness (0.10572). In contrast, usability, with a priority weight of 0.04, showed negligible importance. The results of TISM concurred with the findings of the AHP. The only striking difference between expert perspectives and user preference evaluation was that the product developers indicated that cost has the least importance as a potential enabler. The MICMAC analysis suggested that cost has a strong influence on other enablers. The inputs of the focus group were found to be reliable, with a consistency ratio less than 0.1 (0.084).
Conclusions
This study is the first to identify, prioritize, and analyze the relationships of enablers of effective LLMs for medical education. Based on the results of this study, we developed a comprehendible prescriptive framework, named CUC-FATE (Cost, Usability, Credibility, Fairness, Accountability, Transparency, and Explainability), for evaluating the enablers of LLMs in medical education. The study findings are useful for health care professionals, health technology experts, medical technology regulators, and policy makers.}
}
@article{WANG2025157118,
title = {Unlocking the gut-lung axis: Feixin decoction as a novel modulator in hypoxic pulmonary hypertension},
journal = {Phytomedicine},
volume = {146},
pages = {157118},
year = {2025},
issn = {0944-7113},
doi = {https://doi.org/10.1016/j.phymed.2025.157118},
url = {https://www.sciencedirect.com/science/article/pii/S0944711325007573},
author = {Fei-ying Wang and Jian Yi and Ling-ling Zhou and Jun-lan Tan and Xian-ya Cao and Chao Zhang and Jia-jing Wan and Lan Song and Ai-guo Dai},
keywords = {Hypoxic pulmonary hypertension, Gut microbiota, Gut-lung axis, Herbal medicine, Feixin decoction},
abstract = {Background
Feixin decoction (FXD) is an effective traditional Chinese medicine prescription for treating chronic pulmonary heart disease and hypoxic pulmonary hypertension (HPH), However, the pharmacological mechanism of FXD in preventing HPH remains unclear.
Purpose
This study aimed to evaluate the preventive and therapeutic effect of FXD on HPH and confirm the association between HPH, gut microbiota, and FXD.
Methods
Multiple in vivo animal models were used, including HPH rat models, microbiota depletion models, and fecal microbiota transplantation (FMT) models. The HPH phenotype was evaluated through: right heart catheterization for hemodynamic parameters, doppler echocardiography for cardiac function assessment, hematoxylin-eosin staining for histopathological examination, and immunofluorescence labeling for specific protein expression analysis. Concurrently, transmission electron microscopy was utilized to observe the ultrastructure of the intestinal barrier, combined with immunofluorescence to examine the distribution characteristics of tight junction proteins. To elucidate the mechanism by which HPH ameliorates gut microbiota dysbiosis and associated metabolites, the study integrated 16S rRNA sequencing for microbiota composition analysis, dual-platform untargeted metabolomics for differential metabolite screening, and targeted metabolomics for quantitative validation.
Results
FXD exhibited significant therapeutic effects in HPH rats, ameliorating pulmonary vascular remodeling, attenuating right ventricular hypertrophy, reducing systemic inflammation, and restoring intestinal barrier function. Additionally, FXD partially restored intestinal ecological balance by enriching beneficial species (Lactobacillus and Lactobacillus johnsonii) while reducing pathogenic genera (Escherichia-Shigella and Helicobacter rodentium). Concurrently, FXD treatment induced favorable metabolic alterations, characterized by elevated levels of beneficial metabolites including eicosapentaenoic acid (EPA) and docosahexaenoic acid (DHA), along with reduced concentrations of pro-inflammatory 5-hydroxytryptamine (5-HT). Gut microbiota depletion and fecal microbiota transplantation (FMT) studies established that FXD's therapeutic effects on HPH are mediated through gut microbiota modulation. Mechanistic investigations revealed that this protection likely involves inhibition of the TLR4/MyD88/NF-κB signaling pathway. In vitro studies further corroborated these findings, showing that FXD-enriched metabolites potently suppressed abnormal proliferation, migration and apoptosis in human pulmonary arterial smooth muscle cells (HPASMCs). Notably, EPA, the most significantly increased metabolite, specifically attenuates hypoxia-induced HPASMCs proliferation by interfering with the TLR4/MyD88/NF-κB signaling axis.
Conclusions
Our study confirms that FXD alleviates HPH by regulating gut microbiota and its associated metabolites and validates the potential of FXD as a gut microbiota modulator and an HPH treatment, thereby providing a new therapeutic strategy to improve treatment efficacy.}
}
@article{ZOU2025102158,
title = {Enhancing EFL writing with visualised GenAI feedback: A cognitive affective theory of learning perspective on revision quality, emotional response, and human-computer interaction},
journal = {Learning and Motivation},
volume = {91},
pages = {102158},
year = {2025},
issn = {0023-9690},
doi = {https://doi.org/10.1016/j.lmot.2025.102158},
url = {https://www.sciencedirect.com/science/article/pii/S0023969025000657},
author = {Bin Zou and Chenghao Wang and Huimin He and Congxin Li and Erick Purwanto and Ping Wang},
keywords = {Generative AI visualised feedback, EFL writing, Revision quality, Human-computer interaction, Emotional response, Willingness to write, CATLM},
abstract = {With the rapid development of large language models and natural language processing technologies, Generative AI (GenAI) chatbots have offered new opportunities for supporting EFL learners in writing and revision. However, existing GenAI chatbots’ output is predominantly presented in plain, text-only formats, which may impose a high cognitive load and trigger negative emotional responses. Despite growing interest in GenAI-assisted writing instruction, limited research has examined how visual enhancements to GenAI chatbot output might improve revision outcomes and learners’ emotional experiences. Grounded in the Cognitive-Affective Theory of Learning with Media, this study employed a self-developed GenAI-powered writing chatbot to investigate the effects of visualised feedback on EFL learners’ writing performance and emotional responses during revision. A 2 (time: pre-test and post-test) × 2 (feedback mode: visualised vs. non-visualised) quasi-experimental design was employed. Group A (N = 30) received standard text-only feedback, while Group B (N = 30) received visualised feedback incorporating colour variation, tabular formatting, and bolded text. Results from pre-and post-tests and questionnaires indicated that visualised feedback significantly improved coherence and cohesion in learners’ writing, reduced negative emotions, and resulted in lower cognitive load. These findings offer practical implications for language educators, learners, and developers, highlighting the critical role of how AI-generated content is presented in building emotionally supportive and cognitively effective GenAI-assisted learning environments.}
}
@article{JUEL2025106137,
title = {Visualising future, sustainable cities: Insights from participatory workshops at the COP28 climate conference},
journal = {Cities},
volume = {165},
pages = {106137},
year = {2025},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2025.106137},
url = {https://www.sciencedirect.com/science/article/pii/S026427512500438X},
author = {Rachel Juel and Constance Bwire and Hajar Chams Eddine and Deena Mariyam and Harshita Umesh and Roaa Alobeid and Gabrielle Bonnet and James Milner and Shunmay Yeung and Robert Hughes},
keywords = {Youth, Climate, Sustainability, Urban, AI, Health},
abstract = {Climate change significantly impacts urban youth, yet they are rarely invited to contribute to sustainable urban-planning. To address this, four workshops were held during the 28th session of the United Nations Framework Convention on Climate Change Conference of Parties (COP28) in Dubai. These workshops gathered insights into the experiences of urban children and youth in cities affected by climate change through discussions with youth and other stakeholders present at COP28. Opportunities for creating healthier and more sustainable youth-focused cities were identified using a participatory approach. Youth facilitators led discussions between participants and an expert panel, and participants shared their experiences and perspectives of growing up in cities and their hopes for future youth-focused cities amidst a changing climate. Narrative was collected through an online collaboration tool, which was fed into an artificial intelligence tool to generate images, which served as triggers for further discussion. The thematic analysis of the narratives was conducted by a team of early-career researchers. Three themes were identified: the effects of climate change on urban youth, visions for healthier and more sustainable cities prioritising youth, and principles guiding action. The findings emphasize the importance of involving young people and representing children's needs in research and decision-making.}
}
@article{WANG2024107231,
title = {The structure, self-assembly and dynamics of lipid nanodiscs revealed by computational approaches},
journal = {Biophysical Chemistry},
volume = {309},
pages = {107231},
year = {2024},
issn = {0301-4622},
doi = {https://doi.org/10.1016/j.bpc.2024.107231},
url = {https://www.sciencedirect.com/science/article/pii/S0301462224000607},
author = {Beibei Wang and D. Peter Tieleman},
keywords = {Molecular modeling, Molecular dyncamics simulations, Nanodiscs, Membrane mimetics, Membrane proteins},
abstract = {Nanodisc technology is increasingly being used in structural, biochemical and biophysical studies of membrane proteins. The computational approaches have revealed many important features of nanodisc assembly, structures and dynamics. Therefore, we reviewed the application of computational approaches, especially molecular modeling and molecular dyncamics (MD) simulations, to characterize nanodiscs, including the structural models, assembly and disassembly, protocols for modeling, structural properties and dynamics, and protein-lipid interactions in nanodiscs. More amazing computational studies about nanodiscs are looked forward to in the future.}
}
@article{JU2024112542,
title = {Three-stage binarization of color document images based on discrete wavelet transform and generative adversarial networks},
journal = {Knowledge-Based Systems},
volume = {304},
pages = {112542},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112542},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124011766},
author = {Rui-Yang Ju and Yu-Shian Lin and Yanlin Jin and Chih-Chia Chen and Chun-Tse Chien and Jen-Shiun Chiang},
keywords = {Deep learning, Computer vision, Discrete wavelet transform, Generative adversarial networks, Document image processing, Document image enhancement, Document image binarization},
abstract = {The efficient extraction of text information from the background in degraded color document images is an important challenge in the preservation of ancient manuscripts. The imperfect preservation of ancient manuscripts has led to different types of degradation over time, such as page yellowing, staining, and ink bleeding, seriously affecting the results of document image binarization. This work proposes an effective three-stage network method to image enhancement and binarization of degraded documents using generative adversarial networks (GANs). Specifically, in Stage-1, we first split the input images into multiple patches, and then split these patches into four single-channel patch images (gray, red, green, and blue). Then, three single-channel patch images (red, green, and blue) are processed by the discrete wavelet transform (DWT) with normalization. In Stage-2, we use four independent generators to separately train GAN models based on the four channels on the processed patch images to extract color foreground information. Finally, in Stage-3, we train two independent GAN models on the outputs of Stage-2 and the resized original input images (512 × 512) as the local and global predictions to obtain the final outputs. The experimental results show that the Avg-Score metrics of the proposed method are 77.64, 77.95, 79.05, 76.38, 75.34, and 77.00 on the (H)-DIBCO 2011, 2013, 2014, 2016, 2017, and 2018 datasets, which are at the state-of-the-art level. The implementation code for this work is available at https://github.com/abcpp12383/ThreeStageBinarization.}
}
@article{LIU2025,
title = {Knowledge Enhanced Industrial Question-Answering Using Large Language Models},
journal = {Engineering},
year = {2025},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2025.07.035},
url = {https://www.sciencedirect.com/science/article/pii/S2095809925004527},
author = {Ronghui Liu and Hao Ren and Haojie Ren and Wu Rui and Wei Cui and Xiaojun Liang and Chunhua Yang and Weihua Gui},
keywords = {Retrieval augmented generation, Knowledge enhancement, Question answering, Large language models, Industrial knowledge automation},
abstract = {Modern industrial systems have grown increasingly extensive, complex, and hierarchical, with operations relying on numerous knowledge-based queries. These queries necessitate considerable human resources while also requiring high levels of accuracy, subjectivity, and consistency, all of which critically influence operational efficiency. To overcome these challenges, this study proposes an industrial retrieval-augmented generation (RAG) method designed to enhance large language models (LLMs) using domain-specific knowledge, thereby improving the precision of question answering. A comprehensive industrial knowledge base was constructed from diverse sources, including journal articles, theses, books, and patents. A Text classification model based on bidirectional encoder representations from transformers (BERTs) was trained to accurately classify incoming queries. Furthermore, the general text embedding–dense passage retrieval (GTE–DPR) model was employed to perform word embedding and vector similarity retrieval, facilitating the alignment of query vectors with relevant entries in the knowledge base to obtain initial responses. These initial results were subsequently refined by LLMs to produce accurate final answers. Experimental evaluations confirm the effectiveness of the proposed approach. In particular, when applied to ChatGLM2-6B, the RAG method increased the ROUGE-L score from 32.52% to 55.04% and improved accuracy from 50.52% to 73.92%. Comparable improvements were also observed with LLaMA2-7B, underscoring the RAG framework’s capability to significantly enhance the accuracy and relevance of industrial question-answering (QA) systems.}
}
@article{ZHANG2025102312,
title = {Algorithm to emotion: a three-stage model of user acceptance for AI-generated news platforms},
journal = {Telematics and Informatics},
volume = {101},
pages = {102312},
year = {2025},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2025.102312},
url = {https://www.sciencedirect.com/science/article/pii/S0736585325000747},
author = {Ke Zhang and Yuchen Xie and Wangjing Han and Dandan Zhang and Yan Quan},
keywords = {AI news recommendation, AIDUA model, User acceptance, Algorithmic transparency, Emotion mediation},
abstract = {With the rapid development of AI, Users’ acceptance of intelligent recommendation technology on news platforms directly affects the effectiveness and sustainability of using intelligent recommendation AI news. This study investigates user acceptance of AI-driven news recommendation platforms by applying the Artificial Intelligent Device Use Acceptance (AIDUA) model. Through a survey of 1,100 users, we examine how six AI-specific factors—social influence, perceived novelty, intelligence, accuracy, transparency, and fairness—shape performance expectancy and effort expectancy, ultimately influencing acceptance decisions. Results reveal that all six factors positively impact performance expectancy, while social influence, accuracy, transparency, and fairness reduce effort expectancy. Notably, perceived accuracy (β = 0.200) exerts the strongest effect, underscoring content quality as a critical driver of trust. Emotion mediates between cognitive evaluations and behavioral outcomes, with positive emotions enhancing acceptance and negative emotions amplifying resistance. The study advances theoretical understanding by extending the AIDUA model to AI journalism, highlighting the dual-path role of cognitive and affective evaluations.}
}
@article{SHUM2024100091,
title = {Perils, power and promises: Latent profile analysis on the attitudes towards artificial intelligence (AI) among middle-aged and older adults in Hong Kong},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {2},
number = {2},
pages = {100091},
year = {2024},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2024.100091},
url = {https://www.sciencedirect.com/science/article/pii/S2949882124000513},
author = {Ngai-Yin Eric Shum and Hi-Po Bobo Lau},
keywords = {Artificial intelligence, Attitudes, Middle-aged, Older adults, Latent profile analysis, ChatGPT, Hong Kong},
abstract = {With the increasing influence of artificial intelligence (AI) on various aspects of society, understanding public attitudes towards AI becomes crucial. This study investigated attitudes towards AI among Hong Kong middle-aged and older adults. In June 2023, an online survey was conducted among a sample of 740 smartphone users aged 45 years or older (Max = 78) in Hong Kong. Using exploratory factor analysis, we found three factors from the General Attitude to Artificial Intelligence Scale (GAAIS) - Perils, Power, and Promises. Subsequently, with latent profile analysis we revealed three latent profiles: (i) Enthusiasts (18.4%; high on Promises and Power but low on Perils); (ii) Skeptics (12.3%; high on Perils but low on Promises and Power), and (iii) Indecisive (69.3%; moderate on all three factors). The Enthusiasts were more likely to be male, with higher socio-economic status, better self-rated health, and greater mobile device proficiency, optimism, innovativeness, but also less insecurity with technology, compared to the Indecisive, and then to the Skeptics. Our findings suggest that most middle-aged and older adults in Hong Kong hold an ambivalent view towards AI, appreciating its power and potentials while also cognizant of the perils it may entail. Our findings are timely considering the recent debates on ethical use of AI evoked by smart phone applications such as ChatGPT and will be valuable for practitioners and scholars for developing inclusive AI-facilitated services and applications.}
}
@article{CHERVENAK2023575,
title = {The promise and peril of using a large language model to obtain clinical information: ChatGPT performs strongly as a fertility counseling tool with limitations},
journal = {Fertility and Sterility},
volume = {120},
number = {3, Part 2},
pages = {575-583},
year = {2023},
issn = {0015-0282},
doi = {https://doi.org/10.1016/j.fertnstert.2023.05.151},
url = {https://www.sciencedirect.com/science/article/pii/S0015028223005228},
author = {Joseph Chervenak and Harry Lieman and Miranda Blanco-Breindel and Sangita Jindal},
keywords = {Artificial intelligence, natural language processing, fertility knowledge, counseling, online},
abstract = {Objective
To compare the responses of the large language model-based “ChatGPT” to reputable sources when given fertility-related clinical prompts.
Design
The “Feb 13” version of ChatGPT by OpenAI was tested against established sources relating to patient-oriented clinical information: 17 “frequently asked questions (FAQs)” about infertility on the Centers for Disease Control (CDC) Website, 2 validated fertility knowledge surveys, the Cardiff Fertility Knowledge Scale and the Fertility and Infertility Treatment Knowledge Score, as well as the American Society for Reproductive Medicine committee opinion “optimizing natural fertility.”
Setting
Academic medical center.
Patient(s)
Online AI Chatbot.
Intervention(s)
Frequently asked questions, survey questions and rephrased summary statements were entered as prompts in the chatbot over a 1-week period in February 2023.
Main Outcome Measure(s)
For FAQs from CDC: words/response, sentiment analysis polarity and objectivity, total factual statements, rate of statements that were incorrect, referenced a source, or noted the value of consulting providers.
For fertility knowledge surveys
Percentile according to published population data.
For Committee Opinion
Whether response to conclusions rephrased as questions identified missing facts.
Result(s)
When administered the CDC’s 17 infertility FAQ’s, ChatGPT produced responses of similar length (207.8 ChatGPT vs. 181.0 CDC words/response), factual content (8.65 factual statements/response vs. 10.41), sentiment polarity (mean 0.11 vs. 0.11 on a scale of -1 (negative) to 1 (positive)), and subjectivity (mean 0.42 vs. 0.35 on a scale of 0 (objective) to 1 (subjective)). In total, 9 (6.12%) of 147 ChatGPT factual statements were categorized as incorrect, and only 1 (0.68%) statement cited a reference. ChatGPT would have been at the 87th percentile of Bunting’s 2013 international cohort for the Cardiff Fertility Knowledge Scale and at the 95th percentile on the basis of Kudesia’s 2017 cohort for the Fertility and Infertility Treatment Knowledge Score. ChatGPT reproduced the missing facts for all 7 summary statements from “optimizing natural fertility.”
Conclusion(s)
A February 2023 version of “ChatGPT” demonstrates the ability of generative artificial intelligence to produce relevant, meaningful responses to fertility-related clinical queries comparable to established sources. Although performance may improve with medical domain-specific training, limitations such as the inability to reliably cite sources and the unpredictable possibility of fabricated information may limit its clinical use.
La promesa y el peligro de usar un modelo de lenguaje amplio para obtener información clínica: ChatGPT funciona fuertemente como una herramienta de asesoramiento de fertilidad con limitaciones
Objetivo
Comparar las respuestas del "ChatGPT" basado en modelos de lenguaje amplio con fuentes acreditadas cuando se les dan indicaciones clínicas relacionadas con la fertilidad.
Diseño
La versión del "13 de febrero" de ChatGPT de OpenAI se probó contra fuentes establecidas relacionadas con la información clínica orientada al paciente: 17 "preguntas frecuentes (FAQ)" sobre la infertilidad en el sitio web de los Centros para el Control de Enfermedades (CDC), 2 encuestas validadas de conocimiento de fertilidad, la Escala de Conocimiento de Fertilidad de Cardiff y la Puntuación de Conocimiento de Tratamiento de Fertilidad e Infertilidad, así como la opinión del comité de la Sociedad Americana de Medicina Reproductiva "optimizando la fertilidad natural".
Entorno
Centro médico académico.
Paciente(s)
AI Chatbot en línea.
Intervención(es)
Las preguntas frecuentes, las preguntas de la encuesta y las declaraciones resumidas reformuladas se ingresaron como indicaciones en el chatbot durante un período de 1 semana en febrero de 2023.
Principales medidas de resultado
Para preguntas frecuentes de los CDC: palabras/respuestas, polaridad y objetividad del análisis de sentimientos, declaraciones fácticas totales, tasa de declaraciones incorrectas, referencias a una fuente o el valor de los proveedores de consultoría.
Para encuestas de conocimiento de fertilidad
percentil según datos de población publicados.
Para la opinión del Comité
si la respuesta a las conclusiones reformulada como preguntas identificó hechos faltantes.
Resultado(s)
Cuando se administraron las 17 preguntas frecuentes sobre infertilidad de los CDC, ChatGPT produjo respuestas de longitud similar (207.8 ChatGPT vs. 181.0 palabras/respuesta de los CDC), contenido fáctico (8.65 declaraciones / respuestas fácticas vs. 10.41), polaridad de sentimiento (media 0.11 vs. 0.11 en una escala de -1 (negativo) a 1 (positivo)) y subjetividad (media 0.42 vs. 0.35 en una escala de 0 (objetivo) a 1 (subjetivo)). En total, 9 (6.12%) de las 147 declaraciones fácticas de ChatGPT se clasificaron como incorrectas, y solo 1 (0.68%) declaración citó una referencia. ChatGPT habría estado en el percentil 87 de la cohorte internacional de Bunting en 2013 para la Escala de Conocimiento de Fertilidad de Cardiff y en el percentil 95 sobre la base de la cohorte 2017 de Kudesia para la Puntuación de Conocimiento de Tratamiento de Fertilidad e Infertilidad. ChatGPT reprodujo los hechos faltantes para las 7 declaraciones resumidas de "optimización de la fertilidad natural".
Conclusión(es)
Una versión de febrero de 2023 de ''ChatGPT'' demuestra la capacidad de la inteligencia artificial generativa para producir respuestas relevantes y significativas a consultas clínicas relacionadas con la fertilidad comparables a las fuentes establecidas. Aunque el rendimiento puede mejorar con la capacitación específica del dominio médico, las limitaciones como la incapacidad de citar fuentes de manera confiable y la posibilidad impredecible de información fabricada pueden limitar su uso clínico.}
}
@article{SCHUMANN2025108646,
title = {Identifying distinct types of internet use that predict the likelihood of planning or committing a terrorist attack: Findings from an analysis of individuals convicted on terrorism(-related) charges in England and Wales},
journal = {Computers in Human Behavior},
volume = {168},
pages = {108646},
year = {2025},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2025.108646},
url = {https://www.sciencedirect.com/science/article/pii/S0747563225000937},
author = {Sandy Schumann and Jonathan Kenyon and Jens Binder},
keywords = {Internet use, Terrorism, Radicalisation, Mobilisation, Risk assessment},
abstract = {Previous research has documented that the internet plays an increasingly important role in facilitating involvement in terrorism. However, the level of specificity of this literature is low. Advancing current insights, we examined how three concrete examples of active (i.e., generate/disseminate terrorist propaganda; interact with co-ideologues) and two examples of passive (i.e., learn about terrorist ideologies/actors; learn tactical information) internet use are related to distinct distal and proximal dynamics of radicalisation. Additionally, we assessed associations between the different types of internet use and the likelihood of having planned/committed a terrorist attack. We analysed a unique dataset based on closed-source risk assessment reports of individuals convicted of terrorism(-related) offences in England and Wales (N = 377). Results of this secondary data analysis pointed to three internet use repertoires: (1) learning about tactical information and terrorist ideologies/actors; (2) only learning about terrorist ideologies/actors; (3) active internet use and learning about terrorist ideologies/actors. Learning about tactical information and terrorist ideologies/actors was (compared to the other two repertoires) associated with a higher likelihood of having planned/committed an act of terrorism. Additionally, levels of capability were higher if individuals learnt both tactical and ideological information online compared to using the internet actively and browsing content about terrorist ideologies/actors. Individuals characterised by either internet use repertoire did, however, not vary significantly regarding their levels of engagement with extremist ideas and actors and the degree to which they had developed an extremist mindset. The results can inform terrorist/violent extremist risk assessment.}
}
@article{CHEN2024128837,
title = {Recombinant bacteriophage T4 displaying key epitopes of the foot-and-mouth disease virus as a novel nanoparticle vaccine},
journal = {International Journal of Biological Macromolecules},
volume = {258},
pages = {128837},
year = {2024},
issn = {0141-8130},
doi = {https://doi.org/10.1016/j.ijbiomac.2023.128837},
url = {https://www.sciencedirect.com/science/article/pii/S0141813023057367},
author = {Cen Chen and Nan Zhang and Mengling Li and Aili Guo and Yifei Zheng and Farwa Humak and Ping Qian and Pan Tao},
keywords = {Foot-and-mouth disease virus, Bacteriophage T4, Virus-like particle vaccines, B- and T- cell epitopes},
abstract = {Foot-and-mouth disease virus (FMDV) is a highly contagious pathogen that has caused significant economic losses in the livestock industry. Peptide vaccines engineered with the protective epitopes of FMDV have provided a safer alternative for disease prevention than the traditional inactivated vaccines. However, the immunogenicity of the peptide is usually poor and therefore an adjuvant is required. Here, we showed that recombinant T4 phages displaying the B-cell epitope of the FMDV VP1 protein (VP1130–158), without additional adjuvants, induced similar levels of antigen-specific IgG1 but higher levels of IgG2a compared to the peptide vaccine. Incorporation of a CD4+ T cell epitope, either 3A21–35 of FMDV 3A protein or P2830–844 of tetanus toxoid, further enhanced the immunogenicity of VP1-T4 phage nanoparticles. Interestingly, the extrinsic adjuvant cannot enhance the immunogenicity of the nanoparticles, indicating the intrinsic adjuvant activities of T4 phage. Furthermore, the recombinant T4 phage can be produced on a large scale within a short period of time at a relatively low-cost using Escherichia coli, heralding its potential in the development of a safe and effective FMDV vaccine.}
}
@article{TIBAU2024101331,
title = {ChatGPT for chatting and searching: Repurposing search behavior},
journal = {Library & Information Science Research},
volume = {46},
number = {4},
pages = {101331},
year = {2024},
issn = {0740-8188},
doi = {https://doi.org/10.1016/j.lisr.2024.101331},
url = {https://www.sciencedirect.com/science/article/pii/S0740818824000525},
author = {Marcelo Tibau and Sean Wolfgand Matsui Siqueira and Bernardo Pereira Nunes},
keywords = {ChatGPT, Large language models (LLMs), Searching as learning (SaL), Search tactics, Search strategy adaptation, Conversational information systems},
abstract = {Generative AI tools, exemplified by ChatGPT, are transforming the way users interact with information by enabling dialogue-based querying instead of traditional keyword searches. While this conversational approach can simplify user interactions, it also presents challenges in structuring effective searches, refining prompts, and verifying AI-generated content. This study addresses these complexities by repurposing traditional search tactics for use in conversational AI environments, specifically to support the Searching as Learning (SaL) paradigm. Forty-five adapted tactics are introduced to aid users in defining information needs, refining queries, and evaluating ChatGPT's responses for relevance, utility, and reliability. Using the Efficient Search Tactic Identification (ESTI) method and constant comparison analysis, these tactics were mapped into a stratified model with seven categories. The framework provides a structured approach for users to leverage conversational agents more effectively, promoting critical thinking and iterative learning. This research underscores the importance of developing robust search strategies tailored to conversational AI environments, facilitating deeper learning and reflective information engagement. Additionally, it highlights the need for ongoing research into the design and evaluation of future chat-and-search systems.}
}
@article{SHAO2025113309,
title = {An accurate reconstruction method for indoor bioaerosol concentration field from asynchronous and sparse LiDAR measurements based on latent diffusion models},
journal = {Building and Environment},
volume = {282},
pages = {113309},
year = {2025},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2025.113309},
url = {https://www.sciencedirect.com/science/article/pii/S0360132325007899},
author = {Xuqiang Shao and Mingyu Li and Lei Wang and Hao Han and Zhijian Liu and Jiancai Huang and Zaishan Qi},
keywords = {Latent diffusion models (LDM), Field reconstruction, Bioaerosols dispersion, Indoor air pollution, Computational fluid dynamics (CFD)},
abstract = {Bioaerosols are the primary route for pathogen transmission, and have a serious negative impact on human health. Accurately measuring the distribution of bioaerosol concentrations in the indoor environment holds significant importance. Current methodologies are constrained by limitations in measurement resolution and speed, and unable to obtain the global 3D concentration fields directly. We propose a Sparse Reconstruction Latent Diffusion Model (SR-LDM) that reconstructs the 3D global concentration field from the asynchronous sparse bioaerosol concentration data measured by LiDAR. The concentration field reconstruction is formulated as a conditional generation task, leveraging the powerful generative capabilities of the Latent Diffusion Models (LDM) to infer global distributions from sparse observational data. We employ a contrastive learning strategy to train a dedicated condition encoder, which extracts information from spatiotemporal sparse data measured at different locations and times to guide the generation of the global concentration field. We use a validated Computational Fluid Dynamics (CFD) solver to construct a dataset of aerosol concentration fields in an empty channel. The results indicate that our SR-LDM model effectively reconstructs the global concentration field formed by a single release source, using historical sparse measurement data that accounts for 1 %–3.2 % of the total number of units. In most cases, high-quality results are obtained after 6–16 iterations, and the similarity with CFD data reaches 80 %.}
}
@article{VAZQUEZCANO2023101380,
title = {ChatGPT: The brightest student in the class},
journal = {Thinking Skills and Creativity},
volume = {49},
pages = {101380},
year = {2023},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2023.101380},
url = {https://www.sciencedirect.com/science/article/pii/S1871187123001487},
author = {Esteban Vázquez-Cano and José M. Ramírez-Hurtado and José M. Sáez-López and Eloy López-Meneses},
keywords = {ChatGPT, Summarizing, Assessment, Content, Style},
abstract = {This paper presents a research study that evaluated the score ChatGPT would get when summarizing a reading comprehension text from the PISA international tests with a prompt that made it simulate doing this as if it were a 15-year-old student. For this purpose, the text was camouflaged among 30 other summaries made by real 15-year-old students and was evaluated by 30 Spanish language teachers with different profiles in terms of age, professional experience, and gender who were unaware that one of the texts was made by artificial intelligence (AI). The evaluation of the summary, for which a homogeneous rubric is used, is based on two fundamental criteria: content and style. For the data analysis descriptive and inferential statistical techniques were used. The results show that the ChatGPT summary obtained the best marks in terms of content and style, with its respective marks being 3 and 2.5 points higher than those of the students. Therefore, we can deduce that the style and content of the ChatGPT summary greatly exceeded those presented by the students. These results are independent of the ages, levels of professional experience, and genders of the teachers who corrected the summary. The integration of AI tools such as ChatGPT must be based on solid methodological proposals that integrate their use from a creative and critical perspective that allows learning with the support of these tools and not using them as substitutes for the development of basic student competencies.}
}
@article{PRIY2025103909,
title = {Suppression of flow boiling instabilities in microchannel heat sinks using a passive vapor venting technique},
journal = {Thermal Science and Engineering Progress},
volume = {65},
pages = {103909},
year = {2025},
issn = {2451-9049},
doi = {https://doi.org/10.1016/j.tsep.2025.103909},
url = {https://www.sciencedirect.com/science/article/pii/S2451904925007000},
author = {Akash Priy and Md. Danish Eqbal and Manabendra Pathak and Mohd.Kaleem Khan},
keywords = {Microchannel heat sink, Flow boiling instabilities, Vapor venting, Augmented manifold design, Bubble clogging},
abstract = {Flow boiling in microchannels involving phase-change heat transfer is a promising technique for high heat dissipation from electronic devices. However, two-phase heat transfer in microchannels is adversely affected by flow boiling instabilities. The present work explores a passive vapor venting technique featuring a superhydrophobic stainless steel mesh screen and a fluidic dampener to suppress flow boiling instabilities in microchannels. Experimental investigations have been made to study the flow and heat transfer characteristics in conventional microchannels, i.e., non-venting (NV) and microchannels with passive vapor venting (VV) configuration. Microchannels have been fabricated on a copper block, chosen for its high thermal conductivity, and enclosed within a Teflon housing to enhance thermal insulation. A superhydrophobic coating of Cytonix Fluropel is applied on the stainless steel mesh to make it superhydrophobic. Flow boiling experiments have been performed using deionized water, with mass fluxes ranging from 255-535 kg/m2s and heat fluxes from 10 to 220 W/cm2. An early evacuation of large vapor slugs in the VV configuration eliminates the vapor clogging and backflow, thus promoting frequent rewetting of the hotspots in the microchannels. The high amplitude and low frequency flow fluctuations in NV configurations are converted into low amplitude and high frequency fluctuations in the VV configuration. The temperature and pressure fluctuations are drastically reduced in the VV configuration, resulting in a 95 % higher heat transfer coefficient (HTC) than in the NV configuration. It also produces a 47 % reduction in pressure drop compared to the NV configuration.}
}
@article{ZALAN2023100059,
title = {Making the metaverse real},
journal = {Digital Business},
volume = {3},
number = {2},
pages = {100059},
year = {2023},
issn = {2666-9544},
doi = {https://doi.org/10.1016/j.digbus.2023.100059},
url = {https://www.sciencedirect.com/science/article/pii/S2666954423000078},
author = {Tatiana Zalan and Paolo Barbesino},
keywords = {Augmented reality, Digital ID, Internet, IT infrastructure, Metaverse, Virtual reality, Virtual worlds, web3},
abstract = {Key stakeholders across different industries with competing visions, motivations and technology bets are investing significant financial resources in developing the building blocks of the metaverse. The purpose of this opinion piece aimed primarily at practitioners is to explore the key question: What is needed to make the metaverse real? What are the key uncertainties that must be resolved? We are motivated by shedding light on whether the metaverse is just a new marketing buzzword or a new transformative trend. We have identified six areas with key uncertainties, which require agreement and solutions from industry players – the space, the interface, the IT infrastructure, the monetary infrastructure, the digital ID and the energy. These uncertainties will be resolved in a series of cooperative and competitive games among the key stakeholders who will need to work on being aligned on a set of standards. The practical implication is that the metaverse cannot be ignored, but there are non-trivial challenges that need to be resolved first. Our paper provides a framework for practitioners to think through these issues in a more systematic fashion.}
}
@article{LI2024124,
title = {Public data and corporate employment: Evidence from the launch of Chinese public data platform},
journal = {Economic Analysis and Policy},
volume = {84},
pages = {124-144},
year = {2024},
issn = {0313-5926},
doi = {https://doi.org/10.1016/j.eap.2024.08.023},
url = {https://www.sciencedirect.com/science/article/pii/S0313592624002121},
author = {Xin Li and Zhaoda Liu and Yongwei Ye},
keywords = {Public data, Digital infrastructure, Employment, Expansion effect},
abstract = {We investigate whether public data influences corporate employment. Our identification scheme treats the launch of Chinese public data platforms as a quasi-natural experiment and then conducts a difference-in-differences estimation. The results show that firms have hired more employees after opening public data platforms in the provinces where their offices are located, especially for companies in the mature stage, service industry companies, and companies located in regions with more advanced digital infrastructure and more developed financial system. Mechanism tests show that public data platform openness plays a role in corporate employment through the production scale expansion effect, the business scope expansion effect, and the digital asset investment effect. In addition, examining the two dimensions of data quality and platform construction quality, we find that the quality of public data openness has a significant effect on corporate employment. Our findings provide evidence for Chinese government to promote the openness of public data.}
}
@article{MA2024,
title = {A Machine Learning and Large Language Model-Integrated Approach to Research Project Evaluation},
journal = {Journal of Database Management},
volume = {35},
number = {1},
year = {2024},
issn = {1063-8016},
doi = {https://doi.org/10.4018/JDM.345400},
url = {https://www.sciencedirect.com/science/article/pii/S1063801624000142},
author = {Jian Ma and Zhimin Zheng and Peihu Zhu and Zhaobin Liu},
keywords = {Large Language Models, Machine Learning Algorithms, Peer Review Assessment, Research Project Evaluation},
abstract = {ABSTRACT
Research project evaluation upon completion is one of the important tasks for research management in government funding agencies and research institutions. Due to the increased number of funded projects, it is hard to find qualified reviewers in the same research disciplines. This paper proposes a machine learning and large language model integrated approach to provide decision support for research project evaluation. Machine learning algorithms are proposed to compute the weights of key performance indicators (KPIs) and scores of KPIs based on the evaluation results of completed projects, large language models are used to summarize research contributions or findings on project reports. Then domain experts are invited to consolidate the weights and scores for the KPIs and assess the novelty and impact of research contribution or findings. Experiments have been conducted in practical settings and the results have shown that the proposed method can greatly improve research management efficiency and provide more consistent evaluation results on funded research projects.}
}
@article{MORTATI2025101327,
title = {Data thickening: A new frontier in design cognition},
journal = {Design Studies},
volume = {100},
pages = {101327},
year = {2025},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2025.101327},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X25000390},
author = {Marzia Mortati and Cabirio Cautela},
keywords = {design cognition, design process(es), big data, thick data},
abstract = {The literature extensively discusses how designers utilize their cognitive abilities in the creative process, primarily leveraging context-specific, observational data. The vast availability of big data introduces new challenges to this, related to the integration of large datasets into the design process. Despite the rich body of research on design cognition, there has been a noticeable lack of studies addressing how different types of data influence design cognitive mechanisms. This article investigates how designers navigate heterogeneous data types (big/thin and small/thick) within the creative process, introducing the concept of “data thickening,” a cognitive mechanism through which designers delve into problems to uncover their essence and bridge the problem-space with the solution-space.}
}
@article{YANG2025112996,
title = {Damage imaging in structural health monitoring with fine-tuned conditional diffusion model},
journal = {Mechanical Systems and Signal Processing},
volume = {236},
pages = {112996},
year = {2025},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2025.112996},
url = {https://www.sciencedirect.com/science/article/pii/S0888327025006971},
author = {Xin Yang and Sergio Cantero-Chinchilla and Morteza Moradi and Panagiotis Komninos and Chen Fang and Yunlai Liao and Pradeep Kundu and Dimitrios Zarouchas and Dimitrios Chronopoulos},
keywords = {Structural health monitoring, Damage imaging, Conditional diffusion models, Fine-tuning technique, Delay-and-sum beamforming, Ultrasonic sparse array imaging},
abstract = {Damage imaging plays a crucial role in structural health monitoring (SHM) systems for fast and efficient damage assessment. Delay-and-sum (DAS) beamforming is a widely used algorithm in non-destructive testing for damage imaging, but its effectiveness is often compromised by the use of sparse ultrasonic transducer arrays and the difficulty in detecting progressive delamination larger than the wavelength using guided wave-based methods under fatigue loading. Although X-ray imaging offers detailed assessments of progressive delamination, its application is still limited due to the need to interrupt fatigue loading cycles and its high operational cost. To this end, we propose a novel Damage Imaging framework that uses the fine-tuned Conditional Diffusion Model for SHM systems (DI-CDM). Leveraging the powerful image generation capabilities of diffusion models, the framework was fine-tuned by combining DAS beamforming images derived from ultrasonic sparse array data with X-ray images captured during fatigue loading cycles of the composite structures. The proposed approach can generate damage images that reveal the progression of delamination size in the fatigue loading process. The framework was validated through numerical simulations and experimental data from NASA datasets for composite structures, demonstrating its potential and effectiveness by applying diffusion models in SHM applications to enable fast, high-resolution damage imaging.}
}
@article{2023100434,
title = {Table of Contents},
journal = {Ophthalmology Science},
volume = {3},
number = {4},
pages = {100434},
year = {2023},
issn = {2666-9145},
doi = {https://doi.org/10.1016/S2666-9145(23)00166-5},
url = {https://www.sciencedirect.com/science/article/pii/S2666914523001665}
}
@article{PARMANTO2024,
title = {A Reliable and Accessible Caregiving Language Model (CaLM) to Support Tools for Caregivers: Development and Evaluation Study},
journal = {JMIR Formative Research},
volume = {8},
year = {2024},
issn = {2561-326X},
doi = {https://doi.org/10.2196/54633},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X24004189},
author = {Bambang Parmanto and Bayu Aryoyudanta and Timothius Wilbert Soekinto and I Made Agus Setiawan and Yuhan Wang and Haomin Hu and Andi Saptono and Yong Kyung Choi},
keywords = {large language model, caregiving, caregiver, informal care, carer, GPT, language model, LLM, elderly, aging, ChatGPT, machine learning, natural language processing, NLP},
abstract = {Background
In the United States, 1 in 5 adults currently serves as a family caregiver for an individual with a serious illness or disability. Unlike professional caregivers, family caregivers often assume this role without formal preparation or training. Thus, there is an urgent need to enhance the capacity of family caregivers to provide quality care. Leveraging technology as an educational tool or an adjunct to care is a promising approach that has the potential to enhance the learning and caregiving capabilities of family caregivers. Large language models (LLMs) can potentially be used as a foundation technology for supporting caregivers. An LLM can be categorized as a foundation model (FM), which is a large-scale model trained on a broad data set that can be adapted to a range of different domain tasks. Despite their potential, FMs have the critical weakness of “hallucination,” where the models generate information that can be misleading or inaccurate. Information reliability is essential when language models are deployed as front-line help tools for caregivers.
Objective
This study aimed to (1) develop a reliable caregiving language model (CaLM) by using FMs and a caregiving knowledge base, (2) develop an accessible CaLM using a small FM that requires fewer computing resources, and (3) evaluate the model’s performance compared with a large FM.
Methods
We developed a CaLM using the retrieval augmented generation (RAG) framework combined with FM fine-tuning for improving the quality of FM answers by grounding the model on a caregiving knowledge base. The key components of the CaLM are the caregiving knowledge base, a fine-tuned FM, and a retriever module. We used 2 small FMs as candidates for the foundation of the CaLM (LLaMA [large language model Meta AI] 2 and Falcon with 7 billion parameters) and adopted a large FM (GPT-3.5 with an estimated 175 billion parameters) as a benchmark. We developed the caregiving knowledge base by gathering various types of documents from the internet. We focused on caregivers of individuals with Alzheimer disease and related dementias. We evaluated the models’ performances using the benchmark metrics commonly used in evaluating language models and their reliability for providing accurate references with their answers.
Results
The RAG framework improved the performance of all FMs used in this study across all measures. As expected, the large FM performed better than the small FMs across all metrics. Interestingly, the small fine-tuned FMs with RAG performed significantly better than GPT 3.5 across all metrics. The fine-tuned LLaMA 2 with a small FM performed better than GPT 3.5 (even with RAG) in returning references with the answers.
Conclusions
The study shows that a reliable and accessible CaLM can be developed using small FMs with a knowledge base specific to the caregiving domain.}
}
@article{ALVES2025104584,
title = {Enhancing cybersecurity in the judiciary: Integrating additional controls into the CIS framework},
journal = {Computers & Security},
volume = {157},
pages = {104584},
year = {2025},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2025.104584},
url = {https://www.sciencedirect.com/science/article/pii/S0167404825002731},
author = {Renato Solimar Alves and Jady Pamella Barbacena da Silva and Luiz Antonio {Ribeiro Junior} and Rafael Rabelo Nunes},
keywords = {Critical security controls, Cybersecurity measures, Data protection, Information security management, Judicial system security, Operational risk management, Threat mitigation, Strategies, Tailoring},
abstract = {The Judiciary faces considerable challenges protecting its critical operations from cyber threats in an increasingly digital and vulnerable landscape. This article explores the need to enhance information security practices beyond basic security controls to address operational and technological risks targeting the Judiciary. Intending to propose an expansion of the security controls suggested by the CIS Controls framework, this article focuses on critical areas such as information security management, personnel management, and technological requirements specific to the judicial context. Through qualitative analysis and consultations with experts in the field, preventive and corrective measures were identified, encompassing effective communication practices, mental health programs, and a strong culture of integrity complemented by advanced cybersecurity technologies. The results highlight the need for additional, comprehensive controls ranging from physical security to digital protection, promoting an integrated approach to risk management. The contributions of this article extend to establishing a strengthened foundation for security controls, creating a more effective defense mechanism against emerging threats, and ensuring the sustainability and efficiency of court operations. This article contributes to the evolution of security strategies in the Judiciary, with direct practical implications for risk mitigation and the protection of information assets. The work contributes to the debate on information security in the Judiciary and how to adapt and expand the application of the CIS framework.}
}
@article{YAN2024109407,
title = {New objective Liutex vector based on an optimization procedure},
journal = {International Journal of Heat and Fluid Flow},
volume = {107},
pages = {109407},
year = {2024},
issn = {0142-727X},
doi = {https://doi.org/10.1016/j.ijheatfluidflow.2024.109407},
url = {https://www.sciencedirect.com/science/article/pii/S0142727X24001322},
author = {Bowen Yan and Yiqian Wang and Yifei Yu and Chaoqun Liu},
keywords = {Vortex identification, Liutex vector, Objectivity},
abstract = {The objectivity of a vortex identification method, which is critical in capturing vortices in rotating machineries, requires that the visualized vortical structures are independent of the movement of the observer. However, the common methodology to objectivize an Eulerian vortex identification method with relative/net vorticity or relative/net velocity gradient suffers from the issues of requirement to select a spatial volume to do vorticity average and inconsistency with the non-objective counterpart in an inertial reference frame. In this regard, a new objective Liutex vector method to visualize vortices is developed in the current study, which is based on the observed intermittency of Liutex represented vortices in turbulence. The intermittency indicates that a large volume fraction of the considered domain is void of Liutex, and the rotating motion of the observer is very likely to decrease this volume fraction. Therefore, an optimization procedure is proposed to approximate the rotating angular velocity of the observer by maximizing the zero Liutex volume percentage. With the known angular velocity to offset the rotational effects of the observer’s reference frame, objective version of Eulerian vortex identification methods can be introduced. As an example, the new objective Liutex method has been applied to turbulent channel flow at Reτ=180 in arbitrarily rotating coordinate systems, and the results show that the new method is both objective, i.e. independent of observer’s motion including translation and rotation and consistent with the original Liutex method in an inertial reference frame.}
}
@article{CHEN2025244,
title = {ACSM2B rs73530508 polymorphism affects susceptibility to esophageal cancer by regulating indolepropionic acid levels},
journal = {Cancer Pathogenesis and Therapy},
volume = {3},
number = {3},
pages = {244-252},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2024.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S2949713224000752},
author = {Yun Chen and Ruijun Lin and Qianhua Luo and Tao Liu and Xiaoyan Li and Danling Zheng and Siman Su and Meini Chen and Jianxiang Huang and Yihui Huang and Shuyao Zhang},
keywords = {Esophageal cancer, Susceptibility,  rs73530508, Indolepropionic acid, Tryptophan metabolism},
abstract = {Background
Tryptophan metabolism is involved in esophageal carcinogenesis. However, its genetic mechanisms remain unclear. This study aimed to investigate the effect of genetic variants that encode tryptophan metabolism on susceptibility to esophageal cancer (EC) and elucidate the mechanisms underlying genetic variation in EC progression.
Methods
Age- and sex-matched cohorts of 167 patients with EC and 236 healthy controls were enrolled in this study. The concentrations of tryptophan and its metabolites were determined by self-assembled high-performance liquid chromatography-tandem mass spectrometry. High-throughput sequencing techniques were utilized to detect candidate coding genetic variants, and dominant genetic models were used to elucidate the genotypic associations.
Results
Tryptophan metabolism was significantly imbalanced in patients with EC, with elevated indolepropionic acid (IPA) levels reducing the risk of EC susceptibility. ACSM2B rs73530508 (A > G) mutation was associated with higher IPA levels in vivo (P = 0.0004, false discovery rate [FDR] = 0.0092) and significantly reduced the risk of EC susceptibility (odds ratio [OR]: 0.576, Padj = 0.0161). Mediation effect analysis indicated that single-nucleotide polymorphism may inhibit carcinogenesis by reducing IPA metabolism and excretion with a mediation effect of 45.54%.
Conclusions
This study identifies the potential mechanism of ACSM2B rs73530508 (A > G) in esophageal carcinogenesis and its role in driving increased IPA levels, thereby suppressing the risk of development.}
}
@article{WELHAF2024244,
title = {Mind-wandering in daily life in depressed individuals: An experience sampling study},
journal = {Journal of Affective Disorders},
volume = {366},
pages = {244-253},
year = {2024},
issn = {0165-0327},
doi = {https://doi.org/10.1016/j.jad.2024.08.111},
url = {https://www.sciencedirect.com/science/article/pii/S0165032724013387},
author = {Matthew S. Welhaf and Jutta Mata and Susanne M. Jaeggi and Martin Buschkuehl and John Jonides and Ian H. Gotlib and Renee J. Thompson},
keywords = {Mind-wandering, Major Depressive Disorder, Ecological momentary assessment, Time-lagged analyses},
abstract = {Background
A diagnostic criterion for Major Depressive Disorder (MDD) is difficulty concentrating and increased distractibility. One form of distraction that occurs in everyday life is mind-wandering. The current study aims to test how individuals with MDD and healthy controls differ in their mind-wandering in everyday life.
Methods
Adults diagnosed with MDD (n = 53) and healthy controls (n = 53) completed a week of experience sampling, with prompts administered up to eight times per day. At each prompt, participants reported the occurrence and characteristics of their mind-wandering. They also reported levels of momentary negative affect (NA), positive affect (PA), and rumination.
Results
MDD participants reported mind-wandering almost twice as often as healthy control participants. Compared to healthy participants, MDD participants rated their mind-wandering as more negative, but did not differ in terms of temporal orientation. Higher NA and lower PA predicted mind-wandering in the MDD group but not healthy controls, even after controlling for rumination. Time-lagged analyses revealed that current mind-wandering predicted future levels of PA in MDD participants but not in healthy controls; in contrast, current NA and PA did not predict future mind-wandering.
Limitations
Limitations include our examination of specific forms of mind-wandering (i.e., we did not sample the full spectrum of this construct).
Conclusions
Individuals with MDD frequently report engaging in mind-wandering in everyday life, and this appears to be coupled with affect. Mind-wandering may have maladaptive effects in MDD and could serve as a target for intervention.}
}
@article{ZAREIE2024105032,
title = {Firm digital transformation and corporate performance: The moderating effect of organizational capital},
journal = {Finance Research Letters},
volume = {61},
pages = {105032},
year = {2024},
issn = {1544-6123},
doi = {https://doi.org/10.1016/j.frl.2024.105032},
url = {https://www.sciencedirect.com/science/article/pii/S154461232400062X},
author = {Mobina Zareie and Najah Attig and Sadok {El Ghoul} and Iraj Fooladi},
keywords = {Digital technologies, Valuation, Organization capital},
abstract = {We use textual analysis to measure corporate digital transformation by the frequency of digital terms in the firm 10-K report. We then show that this digital transformation score (DGS) is associated with corporate value. Importantly, we show that organizational capital, the quality of corporate governance, information quality, and firm IPO age play non-negligible roles in shaping the value creation of corporate digital transformation. Our fresh evidence indicates that firms need to enhance their organizational capital, corporate governance, and firm information quality to benefit from their digital transformation efforts.}
}
@article{QIN2025101145,
title = {YOLOPoul: Performance evaluation of a novel YOLO object detectors benchmark for multi-class manure identification to warn about poultry digestive diseases},
journal = {Smart Agricultural Technology},
volume = {12},
pages = {101145},
year = {2025},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2025.101145},
url = {https://www.sciencedirect.com/science/article/pii/S2772375525003776},
author = {Wenxiang Qin and Xiao Yang and Yang Wang and Yongxiang Wei and Yan Zhou and Weichao Zheng},
keywords = {Poultry manure detection, Disease warning, Deep learning, Generative AI, Data augmentation},
abstract = {Digestive diseases are common in poultry and significantly affect their health and productivity. Image processing techniques have gained attention for detecting early signs of disease by analyzing abnormal poultry manure. However, building a reliable system for identifying and locating abnormal manure in real-world conditions remains challenging and requires large amounts of labeled data for supervised learning. Among deep learning models, the You Only Look Once (YOLO) detector is widely used in precision agriculture due to its speed and accuracy. Herein, a new dataset was created for abnormal poultry manure identification based on updated classification criteria, which included 5688 bounding box annotations across five categories collected from commercial chicken farms. In total, 21 state-of-the-art YOLO models from 8 YOLO versions (YOLOv3–YOLOv9) were fine-tuned and validated to establish comprehensive benchmarks. Detection accuracy in terms of mAP@0.5 ranged from 95.6 % by YOLOv3-tiny to 99.4 % by YOLOv8m, while accuracy in terms of mAP@[0.5:0.95] ranged from 72.9 % by YOLOv4-tiny to 82.2 % by YOLOv9s, with 10 models achieving scores above 80.0 % in mAP@0.5:0.95. High accuracy and efficiency were demonstrated by YOLOv8n and YOLOv8s with inference times under 3 ms. However, traditional data augmentation methods were not fully effective in expanding abnormal manure samples. To address this issue, generative models were explored for data augmentation, where denoising diffusion probabilistic models generated realistic images, showing promising potential. This research provides benchmark data for the classification of abnormal poultry manure, which will become an important resource for promoting future research on poultry disease detection and control based on big data and artificial intelligence, making a fundamental contribution to the field of poultry health monitoring.}
}
@article{RAHIMI2024103261,
title = {Effects of integrating motivational instructional strategies into a process-genre writing instructional approach on students’ engagement and argumentative writing},
journal = {System},
volume = {121},
pages = {103261},
year = {2024},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2024.103261},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X24000435},
author = {Muhammad Rahimi},
keywords = {Motivational instructional strategies, Process-genre writing instructional approach, Writing engagement, Argumentative writing, Self-determination theory, Student engagement},
abstract = {This study advances the strand of research on motivational instructional strategies, the process-genre writing instructional approach, as well as student engagement and writing achievements. To this end, motivational writing instructional strategies were integrated into the process-genre argumentative writing instructional approach and the impacts on students' writing engagement and achievements were assessed at a university in China. Quantitative data were gathered from 142 undergraduate students employing a pretest-posttest control group design. Additionally, self-report data regarding students' writing engagement and perceptions were collected from experimental groups to examine the contribution of students' perceptions of the motivational process-genre writing instructional approach to their engagement. Moreover, focus-group data were gathered from four highly-engaged and high-achieving students to identify the factors facilitating their engagement. The results showed that the experimental groups wrote significantly better argumentative essays than did the control group, and regression analyses indicated that motivational instructional strategies contributed to students' engagement significantly. Further, the thematic analysis of focus group data suggested that the three major facilitators of students’ engagement were collaborative motivational writing learning strategies, competence-boosting experiences, and active participation in creating learning opportunities. These findings show the paramount significance of incorporating the motivational strategies into the process-genre writing instructional approach. Other pedagogical implications and recommendations for further research are also discussed.}
}
@article{QIN2025107883,
title = {Intelligent Chinese patent medicine (CPM) recommendation framework: Integrating large language models, retrieval-augmented generation, and the largest CPM dataset},
journal = {Pharmacological Research},
volume = {219},
pages = {107883},
year = {2025},
issn = {1043-6618},
doi = {https://doi.org/10.1016/j.phrs.2025.107883},
url = {https://www.sciencedirect.com/science/article/pii/S1043661825003081},
author = {Suyang Qin and Yifan Wang and Tangming Cui and Jinge Ma and Xin Zhou and Xinglin Guo and Chuchu Zhang and Chongyun Zhou and Rongjuan Guo and Haiyan Li},
keywords = {Large language models (LLMs), Multi-LLMs Validation, Chinese patent medicine (CPM) dataset, retrieval-augmented generation, intelligent CPM recommendation framework, guidelines evaluation},
abstract = {Chinese patent medicines (CPMs), a vital component of healthcare systems in China and worldwide, has been increasingly utilized in clinical practice. However, approximately 70 % of CPMs are prescribed by Western medicine physicians who lack expertise in traditional Chinese medicine syndrome differentiation and treatment. Here, in this study, we constructed RAG-CPMF, an intelligent CPM recommendation framework integrating large language models (LLMs), retrieval-augmented generation (RAG), and the largest CPM dataset. Specifically, we first applied the Multi-LLMs Validation method, significantly reducing the manual proofreading workload involved in structured data extraction. Furthermore, based on this approach, we successfully established the largest CPM dataset (https://gitee.com/tcmdoc/cpm) with continuous on-line updates. Afterwards, we combined the CPM dataset and the RAG architecture, along with effective integration of generative capacity from LLMs and external data retrieval; all of which contributed to the RAG-CPMF. Finally, the accuracy of RAG-CPMF was evaluated against clinical guidelines, demonstrating that this framework significantly improved CPM recommendation accuracy compared with general-purpose LLMs.}
}
@article{TUROS2024100160,
title = {Fake video detection among secondary school students: The impact of sociocultural, media literacy and media use factors},
journal = {Telematics and Informatics Reports},
volume = {15},
pages = {100160},
year = {2024},
issn = {2772-5030},
doi = {https://doi.org/10.1016/j.teler.2024.100160},
url = {https://www.sciencedirect.com/science/article/pii/S277250302400046X},
author = {Mátyás Turós and Attila Zoltán Kenyeres and Zoltán Szűts},
keywords = {Test-based fake video detection, Fake news believability, Fake news, Political beliefs, Social media},
abstract = {The harmful political, economic and health effects of fake news on social media are well known. The present study examines the impact of two socio-cultural variables (political orientation and parents' educational attainment), one media literacy variable and two media use variables (news control, platform usage frequency and media addiction) on fake videos detection. The ability to detect fake videos among Hungarian secondary school students (N = 507) was assessed using a 16-item video test. The results of the online survey are partly consistent and partly contradictory to the literature. There is no gender difference in the ability to detect fake videos in the age group studied, and media literacy and media use do not influence the ability to detect fake videos. However, a more conservative worldview and higher parental education are associated with better detection of fake videos. The paper concludes with recommendations.}
}
@article{MA2025107688,
title = {Myth of the digital economy: Can it continually contribute to a low-carbon status and sustainable development?},
journal = {Environmental Impact Assessment Review},
volume = {110},
pages = {107688},
year = {2025},
issn = {0195-9255},
doi = {https://doi.org/10.1016/j.eiar.2024.107688},
url = {https://www.sciencedirect.com/science/article/pii/S0195925524002750},
author = {Zihao Ma and Pingdan Zhang},
keywords = {Carbon abatement, Digital economy, Empirical analysis, STIRPAT model, Sustainable development},
abstract = {Facing global warming and looming catastrophic climate change, many countries have launched actions to change themselves and their societies to attain a low-carbon status. Digital economy purportedly offers a potential way to achieve sustainable development. However, this is still debated and a consensus is elusive. Here, we propose a novel nonlinear d curve hypothesis to describe the relationship between the digital economy and carbon emissions, whereby the digital economy can no longer contribute to carbon abatement once it is overdeveloped because of a rebound in energy consumption (i.e., the overdevelopment trap). To test this hypothesis, we used county-level panel data from China and conducted an empirical analysis with expanded STIRPAT models. Through a suite of robustness tests, we find evidence supporting our hypothesis, in that nearly 30 % of our samples (N = 1450 counties) had stepped into the overdevelopment trap, with this problem being most severe in eastern China. Altogether, we believe those countries relying heavily on thermal power—and more likely to suffer from a rebound in fossil energy consumption—should take a more cautious attitude towards implementing their digital economy and consider other ways to meet their carbon abatement goals.}
}
@article{MIMOUNICHAABANE2025104413,
title = {How to build CSR image with mixed-reward loyalty programs},
journal = {Journal of Retailing and Consumer Services},
volume = {87},
pages = {104413},
year = {2025},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2025.104413},
url = {https://www.sciencedirect.com/science/article/pii/S0969698925001924},
author = {Aida Mimouni-Chaabane and Béatrice Parguel},
keywords = {Loyalty programs, Mixed rewards, CSR image, Prosocial redemption, Warm glow},
abstract = {Spurred by growing consumer demand for sustainability, many loyalty programs (LPs) offer mixed rewards consisting of self-benefiting and charity-benefiting options. Taking a social perspective, this article examines how the design of mixed-reward LPs helps to reinforce Corporate Social Responsibility (CSR) image. Results from two experiments show that mixed-reward LPs can improve a firm's CSR image as well as customer loyalty, and the importance of giving customers options. Specifically, compared to a self-benefiting reward LP, a mixed-reward LP improves CSR image, but only when customers can choose the recipient charity. Allowing customers to split their donation between multiple charities further improves CSR image through the mediating effects of LP usage (i.e., prosocial redemption) and a social benefit for the customer (i.e., warm glow). These findings suggest that LPs can be relevant drivers for doing good and offer an additional, socially-based logic to rethink their role and design.}
}
@article{LINDENBLATT2025100049,
title = {Image-matching in electrode production of lithium-ion batteries for marker-free tracking and tracing applications},
journal = {Future Batteries},
volume = {5},
pages = {100049},
year = {2025},
issn = {2950-2640},
doi = {https://doi.org/10.1016/j.fub.2025.100049},
url = {https://www.sciencedirect.com/science/article/pii/S2950264025000280},
author = {Johannes Lindenblatt and Janik Schneider and Alessandro Sommer and Rüdiger Daub},
keywords = {Tracking and tracing, Lithium-ion battery production, Image-matching, Artificial intelligence, Production automation},
abstract = {The high complexity of lithium-ion battery production is defined by many process steps and numerous parameters. Unknown cause–effect relationships lead to production deviations and costly scrap. Therefore, data-driven approaches are increasingly being used to uncover these complex interactions. Creating comprehensive, transparent data sets based on production data, enables the identification of correlations and relevant parameters, thus facilitating efficiency improvements and the optimization of the lithium-ion production. Currently, tracking and tracing of production data to individual electrode sections is performed with physical markers on uncoated electrode parts or coils. Interactions within the processing of the battery electrodes and mechanical deformation of the current collector foil can lead to illegibility of the physical markings and thus make tracking and tracing impossible. Furthermore, the resolution of the data recording is currently tied to the discrete markings. However, advances in computer vision and computing power offer a non-invasive, marker-free solution using camera images. This paper presents an approach of unique identification of electrode sections using image-matching for marker-free tracking and tracing applications. High-resolution electrode images were acquired in-line, allowing the evaluation of artificial intelligence to demonstrate the applicability of different classical and learning-based image-matching approaches for the identification of electrode sections. The results provided a clear recommendation for image-based tracking and tracing using neuronal networks. Marker-free tracking using electrode images allowed for immediate identification of electrode sections, storage of production data in a virtual electrode model, and inclusion of additional quality information derived from the images.}
}
@article{HUANG2025105310,
title = {Modeling student teachers’ self-regulated learning of complex professional knowledge: A sequential and clustering analysis with think-aloud protocols},
journal = {Computers & Education},
volume = {233},
pages = {105310},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105310},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525000788},
author = {Lingyun Huang and Ying Zhan and Shen Ba},
keywords = {Self-regulated learning, Technological Pedagogical Content Knowledge, Sequential clustering analysis, Tthink-aloud protocols},
abstract = {There has been much discussion regarding the positive relationship between self-regulated learning (SRL) and technological pedagogical content knowledge (TPACK) development for student teachers. This study continued this claim and adopted advanced analytical methods to explain how SRL influences TPACK learning. Think-aloud protocols from 39 participants were collected and transcribed when they were learning TPACK by designing technology-infused lessons with nBrowser, a computer-based learning environment. Based on models, nine critical SRL events were retrieved from participants‘ think-aloud protocols and analyzed through sequential clustering analysis. The results show two SRL groups indicating distinct self-regulatory sequential patterns. One group had a shorter sequence length and dominantly enacted elaboration activities (Low-SRL group), while the other had longer sequence lengths and engaged in diverse SRL activities (High-regulation group). Relating to TPACK performance indicated by the quality of lesson plans, the results reveal that the participants in the High-SRL group outperformed their counterparts in the Low-SRL group. The findings are consistent with previous evidence and provide implications for practitioners about the importance of student teachers’ self-regulation trajectories.}
}
@article{ROKY202589,
title = {Overview of skin cancer types and prevalence rates across continents},
journal = {Cancer Pathogenesis and Therapy},
volume = {3},
number = {2},
pages = {89-100},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2024.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S2949713224000582},
author = {Amdad Hossain Roky and Mohammed Murshedul Islam and Abu Mohammed Fuad Ahasan and Md Saqline Mostaq and Md Zihad Mahmud and Mohammad Nurul Amin and Md Ashiq Mahmud},
keywords = {Skin cancer, Prevalence, Melanoma, Non-melanoma, Melanoma types, Mortality rate},
abstract = {Skin cancer is one of the most prevalent cancers in the world, and its incidence and mortality rates are increasing continuously, mostly in regions with white-skinned inhabitants. The types of skin cancer vary in their origin and clinical appearances and also differ in their extensiveness. The continents of the world have different scenarios of skin cancer prevalence. This review aims to explore the different types of skin cancer, their clinical features, and their worldwide prevalence based on the literature. Literature from different electronic databases, including Google Scholar, ResearchGate, PubMed, Scopus, Web of Science, Embase, Cumulative Index to Nursing and Allied Health Literature (CINAHL), Elsevier, and Springer, were collected through a literature search using specific keywords such as “skin cancer”, “skin cancer types”, “melanoma”, “non-melanoma”, “skin cancer continental prevalence” or similar keywords. The search included English publications from 2000 to 2024. Melanoma skin cancer (MSC) ranks 17th in global prevalence, with the highest incidence and deaths occurring in Europe, However, Australia and New Zealand record the highest incidence and mortality rates. Asia has a lower incidence rate of melanoma, but a higher mortality rate. Superficial spreading melanoma (SSM) is the most common type of MSC. Non-melanoma skin cancers (NMSCs) have the highest incidence in North America, with the highest number of deaths occurring in Asia, Australia and New Zealand have the highest incidence rates for basal cell carcinoma (BCC). BCC is the most commonly diagnosed skin cancer worldwide and the most prevalent form of NMSCs; however, squamous cell carcinoma is the most aggressive form of NMSCs, causing more deaths. NMSCs are the most prevalent cancers worldwide, causing most skin cancer-related deaths. The prevalence of skin cancer rising globally, with several continents experiencing higher incidence and mortality rates. The types and subtypes of skin cancer are becoming more common among clinically diagnosed cancers. This review comprehensively describes skin cancer types and their prevalence worldwide. However, the actual prevalence of skin cancer in these countries should be investigated. Further research on the prevalence of skin cancer across different continents is required to develop more effective cancer management strategies and control the spread of the disease.}
}
@article{ZHANG2025102773,
title = {Ferrostatin-1 mitigates acute lung injury by reducing ferroptosis levels in gas explosions},
journal = {Tissue and Cell},
volume = {94},
pages = {102773},
year = {2025},
issn = {0040-8166},
doi = {https://doi.org/10.1016/j.tice.2025.102773},
url = {https://www.sciencedirect.com/science/article/pii/S0040816625000539},
author = {Hao Zhang and Linqiang Tian and Peng Wang and Long Li and Kunxi Wang and Yanyan Li and Yue Zhang and Lili Feng and Sanqiao Yao and Hao Guan and Wenjie Ren},
keywords = {Ferroptosis, Acute lung injury, Gas explosion, Ferrostatin-1},
abstract = {Background
Gas explosion injuries are a severe form of trauma with high incidence and mortality rates, both in daily life and industrial settings. Acute lung injury (ALI) is one of the most serious complications of gas explosion injuries and is a leading cause of mortality in such cases. However, the mechanisms underlying gas explosion-induced ALI have not been fully elucidated, and the treatment process consumes a significant amount of medical resources. Therefore, it is crucial to conduct research on the injury mechanisms of gas explosion injuries, especially the mechanisms of gas explosion-induced ALI, which can effectively improve the treatment rate of this condition. In this study, we analyzed the relationship between a novel form of cell death, ferroptosis, and gas explosion-induced ALI, and explored its specific mechanisms.
Methods
We established ALI rat model by Shock tube biological injury system, and detected lung injury-related indexes as well as ferroptosis related indexes, such as glutathione peroxidase 4（GPX4）, 4-hydroxynonenal（4HNE）, Malondialdehyde（MDA）, Fe2 + . We also investigated the therapeutic effects of the ferroptosis inhibitor ferrostatin-1 (Fer-1) in ALI induced by gas explosion, as well as its specific mechanisms of action.
Results
A rat ALI model by gas explosion was successfully established. After the gas explosion treatment, we observed that the systemic inflammatory reaction of rats was increased, and lung function, liver function, kidney function and cardiac function were damaged to different degrees. The inflammatory infiltration in the lung tissue was more severe, and the degree of lung injury and pulmonary edema increased. The ferroptosis markers GPX4 was decreased, while the levels of 4HNE, MDA and Fe2 + were increased. Treatment with Fer-1 significantly ameliorated gas explosion ALI damage and down-regulated the expression level of ferroptosis.
Conclusions
Gas explosion-induced ALI in rats is characterized by enhanced inflammatory responses and reduced antioxidant capacity in lung tissues. The specific mechanism of injury involves ferroptosis. Fer-1 has been shown to mitigate the severity of ALI caused by gas explosion by suppressing ferroptosis expression levels in lung tissues via the Nrf2/GPX4 axis.}
}
@article{NEWSTEAD2023100998,
title = {How AI can perpetuate – Or help mitigate – Gender bias in leadership},
journal = {Organizational Dynamics},
volume = {52},
number = {4},
pages = {100998},
year = {2023},
issn = {0090-2616},
doi = {https://doi.org/10.1016/j.orgdyn.2023.100998},
url = {https://www.sciencedirect.com/science/article/pii/S0090261623000426},
author = {Toby Newstead and Bronwyn Eager and Suze Wilson},
keywords = {Artificial intelligence, Generative AI, Leadership development, Gender bias, Women’s leadership},
abstract = {Generative AI tools have been adopted faster than any other technology in history. AI tools including both chatbots (e.g. ChatGPT, Bard) and long-form AI writers (e.g. Wordplay.ai, Jasper.ai) pose substantial efficiency gains for text-reliant industries, such as leadership development. However, our research shows that AI generated content can contain and perpetuate harmful leadership-related gender biases. In this article, we share evidence of how AI generated content can perpetuate gender biases in leadership development. We also offer practical strategies managers can implement to capitalize on the potential of AI in pursuit of greater gender equity in leadership.}
}
@article{LADYHINA2025107103,
title = {Methodological aspects of investigating the resistome in pig farm environments},
journal = {Journal of Microbiological Methods},
volume = {230-231},
pages = {107103},
year = {2025},
issn = {0167-7012},
doi = {https://doi.org/10.1016/j.mimet.2025.107103},
url = {https://www.sciencedirect.com/science/article/pii/S0167701225000193},
author = {Valeriia Ladyhina and Elisabeth Rajala and Susanna Sternberg-Lewerin and Leila Nasirzadeh and Erik Bongcam-Rudloff and Johan Dicksved},
keywords = {Antimicrobial resistance genes, Metagenomics, Microbiome, Environmental samples, Nanopore sequencing, Illumina sequencing},
abstract = {A typical One Health issue, antimicrobial resistance (AMR) development and its spread among people, animals, and the environment attracts significant research attention. The animal sector is one of the major contributors to the development and dissemination of AMR and accounts for more than 50 % of global antibiotics usage. The use of antibiotics exerts a selective pressure for resistant bacteria in the exposed microbiome, but many questions about the epidemiology of AMR in farm environments remain unanswered. This is connected to several methodological challenges and limitations, such as inconsistent sampling methods, complexity of farm environment samples and the lack of standardized protocols for sample collection, processing and bioinformatical analysis. In this project, we combined metagenomics and bioinformatics to optimise the methodology for reproducible research on the resistome in complex samples from the indoor farm environment. The work included optimizing sample collection, transportation, and storage, as well as DNA extraction, sequencing, and bioinformatic analysis, such as metagenome assembly and antibiotic resistance gene (ARG) detection. Our studies suggest that the current most optimal and cost-effective pipeline for ARG search should be based on Illumina sequencing of sock sample material at high depth (at least 25 M 250 bp PE for AMR gene families and 43 M for gene variants). We present a computational analysis utilizing MEGAHIT assembly to balance the identification of bacteria carrying ARGs with the potential loss of diversity and abundance of resistance genes. Our findings indicate that searching against multiple ARG databases is essential for detecting the highest diversity of ARGs.}
}
@article{KARHIY2024100069,
title = {Can a virtual human increase mindfulness and reduce stress? A randomised trial},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {2},
number = {1},
pages = {100069},
year = {2024},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2024.100069},
url = {https://www.sciencedirect.com/science/article/pii/S294988212400029X},
author = {Mariam Karhiy and Mark Sagar and Michael Antoni and Kate Loveys and Elizabeth Broadbent},
keywords = {Virtual humans, Adherence, Mindfulness, Stress, Digital health},
abstract = {Background
Stress is a significant issue amongst university students, yet limited psychological services are available. Mindfulness is effective for stress reduction and can be delivered digitally to expand access to student populations. However, digital interventions often suffer from low engagement and poor adherence. A virtual human may improve engagement and adherence through its humanlike appearance and behaviours.
Objective
To examine whether a virtual human could reduce stress in university students at least as much as a teletherapist, and more than a chatbot, using a mindfulness intervention.
Methods
Stressed university students (N = 158) were randomly allocated to the virtual human (N = 54), chatbot (N = 54), or teletherapist (N = 50). 36 participants received each condition. Participants completed one lab session and were asked to do online homework sessions at least twice weekly for four weeks. Changes in self-reported stress and mindfulness, physiological stress indices, homework completion, and perceptions of the agent were compared between groups. Thematic analysis was conducted on participants’ responses to open-ended questions about the interventions.
Results
There were significant reductions in stress and increases in mindfulness across all groups. All groups had higher peripheral skin temperature post-intervention, and only the teletherapy group had higher electrodermal activity (reflecting elevated stress) post-intervention compared to baseline. There were no significant changes in heart rate. Homework adherence was significantly higher in the virtual human group, whereas homework satisfaction and engagement were lowest in the chatbot group. Thematic analysis found that people thought the robotic voice of the virtual human could be improved, the chatbot could be improved by adding audio, and that participants experienced feelings of judgement from the teletherapist.
Discussion
Overall, results support use of virtual humans for delivering mindfulness interventions in stressed students. Virtual humans may have the advantage over teletherapy and chatbots of increasing adherence in student populations, but more work is needed to increase perceived empathy and replicate results in other populations.}
}
@article{MOORHOUSE2024103290,
title = {The effects of generative AI on initial language teacher education: The perceptions of teacher educators},
journal = {System},
volume = {122},
pages = {103290},
year = {2024},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2024.103290},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X24000721},
author = {Benjamin Luke Moorhouse and Lucas Kohnke},
keywords = {Generative AI, Initial language teacher education, ChatGPT, Teacher educators},
abstract = {Since the public release of ChatGPT in November 2022, generative AI tools—capable of creating human-like content such as audio, code, images, text, simulations, 3D objects, and videos—have gained significant attention. While the impact of these tools on language teaching and learning has been widely speculated, the perspective of language teacher educators concerning their influence on initial language teacher education (ILTE) remains unexplored. This study investigates how teacher educators, who play a crucial role in adapting ILTE to technological advancements, perceive the effects of generative AI tools on ILTE. Data were collected through in-depth interviews with thirteen English language teacher educators from all four Hong Kong government-funded universities offering ILTE. Findings reveal that participants believe generative AI tools will substantially affect the ILTE curriculum, instruction, and assessment. However, most participants believed they lacked the confidence and competence to address the implications of generative AI tools effectively. This study highlights the need for further research and training to support teacher educators in adapting ILTE to the emerging influence of generative AI.}
}
@article{MAN2024121869,
title = {Twenty-year responses of aspen stands to forest tent caterpillar defoliation and overstory dieback in Northeastern Ontario, Canada},
journal = {Forest Ecology and Management},
volume = {561},
pages = {121869},
year = {2024},
issn = {0378-1127},
doi = {https://doi.org/10.1016/j.foreco.2024.121869},
url = {https://www.sciencedirect.com/science/article/pii/S0378112724001816},
author = {Rongzhou Man},
keywords = {Defoliation and decline, Trembling aspen, Stand dynamics, Boreal mixedwood succession},
abstract = {Forest tent caterpillar (Malacosoma disstria Hbn.) is a major forest defoliator in North American boreal forests. This pest periodically affects hardwood trees such as trembling aspen (Populus tremuloides Michx.) and balsam poplar (Populus balsamifera L.) across large areas, causing mortality and altering stand attributes and long-term dynamics. In this study, I quantified the responses of aspen stands to forest tent caterpillar defoliation and overstory dieback, including short-term (5 years after dieback) and long-term (20 years later) dynamics. Results indicate that affected stands fully recovered to pre-dieback density but not basal area. Defoliation caused overstory dieback that stimulated understory growth and regeneration but the hardwood regeneration (mostly aspen) did not adequately replace hardwood trees lost to defoliation, resulting in decreased hardwood composition relative to unaffected stands. The high density in affected stands suggested possible further basal area recovery as regeneration and released understory conifers grew into main canopy, following the general trends of boreal mixedwood succession. The results support earlier projections based on residual stand attributes shortly after dieback and reported boreal species growth and mortality rates that indicate forest tent caterpillar defoliation and subsequent overstory dieback would accelerate aspen stand transition to conifer dominance and delay the availability of stands for harvesting by 40–50 years as stands recover.}
}
@article{NILASHI2024e38563,
title = {Knowledge discovery of patients reviews on breast cancer drugs: Segmentation of side effects using machine learning techniques},
journal = {Heliyon},
volume = {10},
number = {19},
pages = {e38563},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e38563},
url = {https://www.sciencedirect.com/science/article/pii/S240584402414594X},
author = {Mehrbakhsh Nilashi and Hossein Ahmadi and Rabab Ali Abumalloh and Mesfer Alrizq and Abdullah Alghamdi and Sultan Alyami},
keywords = {Knowledge discovery, Drugs, Online reviews, Breast cancer, Text mining, Machine learning, Public health},
abstract = {Breast cancer stands as the most frequently diagnosed life-threatening cancer among women worldwide. Understanding patients' drug experiences is essential to improving treatment strategies and outcomes. In this research, we conduct knowledge discovery on breast cancer drugs using patients' reviews. A new machine learning approach is developed by employing clustering, text mining and regression techniques. We first use Latent Dirichlet Allocation (LDA) technique to discover the main aspects of patients' experiences from the patients' reviews on breast cancer drugs. We also use Expectation-Maximization (EM) algorithm to segment the data based on patients' overall satisfaction. We then use the Forward Entry Regression technique to find the relationship between aspects of patients' experiences and drug's effectiveness in each segment. The textual reviews analysis on breast cancer drugs found 8 main side effects: Musculoskeletal Effects, Menopausal Effects, Dermatological Effects, Metabolic Effects, Gastrointestinal Effects, Neurological and Cognitive Effects, Respiratory Effects and Cardiovascular. The results are provided and discussed. The findings of this study are expected to offer valuable insights and practical guidance for prospective patients, aiding them in making informed decisions regarding breast cancer drug consumption.}
}
@article{ZHAO2024109536,
title = {Modification of pectin with high-pressure processing treatment of fresh orange peel before pectin extraction: Part II. The effects on gelling capacity and emulsifying properties of pectin},
journal = {Food Hydrocolloids},
volume = {149},
pages = {109536},
year = {2024},
issn = {0268-005X},
doi = {https://doi.org/10.1016/j.foodhyd.2023.109536},
url = {https://www.sciencedirect.com/science/article/pii/S0268005X23010822},
author = {Wei Zhao and Yixiang Xu and Christina Dorado and Jinhe Bai and Hoa K. Chau and Arland T. Hotchkiss and Madhav P. Yadav and Randall G. Cameron},
keywords = {Pectin gelling property, Calcium-mediated pectin gelation, Sugar-acid-mediated pectin gelation, Rheological analysis, Pectin emulsifying property, Structure-function relationship},
abstract = {The most important functionalities of pectin are gelling and emulsifying properties, which can be tailored by modifying pectin structure through chemical/enzymatic treatments or physical processes. In a companion article (Zhao et al., 2023), the modification of pectin structure with high-pressure processing (HPP) was reported. In this study, the functionalities of the HPP-modified pectins (Hp) were evaluated and compared with commercial low methoxy (LM) and high methoxy (HM) pectins. The calcium sensitivity of Hp was comparable to that of commercial LM pectin, which was remarkably higher than the control pectin extracted from untreated peel and commercial HM pectin. Hp had a dramatically higher gelling capacity for calcium-mediated gelation than the control and commercial HM pectin. The strength and viscoelastic properties of Hp-calcium gels were comparable to that of commercial LM pectin. Meanwhile, most of the Hp also showed a comparable gelling capacity for sugar-acid-mediated gelation to that of the control and commercial HM pectin. Hp also had higher emulsifying stability than the control and commercial pectins. The increased capacity of Hp for calcium-mediated gelation was attributed to the block-wise distribution of non-esterified galacturonic acid (GalA) introduced by the HPP treatment, and the higher emulsifying stability was mainly attributed to the debranching of pectin. The study further confirmed that pectin functionalities were highly correlated with its structural properties. The data reveal the great potential of producing low-cost, high-quality pectins with increased gelling capacity and a broadened scope of applications, by adding a simple HPP pretreatment of fresh source material for pectin extraction.}
}
@article{GUO2024103716,
title = {Application status of variable-frequency drive in hydrogen fuel cell air compressors from an industrial viewpoint: A review},
journal = {Sustainable Energy Technologies and Assessments},
volume = {64},
pages = {103716},
year = {2024},
issn = {2213-1388},
doi = {https://doi.org/10.1016/j.seta.2024.103716},
url = {https://www.sciencedirect.com/science/article/pii/S2213138824001127},
author = {Xiaoqiang Guo and Xiaolei Hu and Shiqi Zhang},
keywords = {Hydrogen fuel cell, Hydrogen compressor, Variable-frequency drive, Industrial application, Energy-saving},
abstract = {As an essential accessory of hydrogen fuel cells (HFC), air compressors have the problem of high energy consumption and high cost, which hinders the further development of HFC. Recently, the industry has adopted variable-frequency drive (VFD) to control the operation of HFC air compressors, and the energy-saving effect is remarkable. However, existing research mostly discusses related technologies academically and lacks data review on actual industrial applications, hindering industry standardization and maturity. Therefore, it is meaningful to summarize the current status of the HFC air compressor dedicated VFD industry chain. From the perspective of industrial application, this paper summarizes the current industrial product status of dedicated VFDs, HFC, air compressors, and motors. The purpose of this paper is to provide a useful reference guide for relevant researchers of HFCs and VFDs.}
}
@incollection{CRUZ202525,
title = {Equity, Diversity, and Inclusion and Critical Libraries: A Historical Evolution of Awareness and Informed Practice},
editor = {David Baker and Lucy Ellis},
booktitle = {Encyclopedia of Libraries, Librarianship, and Information Science (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {25-35},
year = {2025},
isbn = {978-0-323-95690-1},
doi = {https://doi.org/10.1016/B978-0-323-95689-5.00150-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780323956895001504},
author = {Jeffery Cruz},
keywords = {Affirmative action in libraries, Anti-discrimination in libraries, Critical librarianship, Decolonization in libraries, Diversity initiatives in libraries, Equal opportunity in libraries, Equity, diversity, and inclusion, Indigenization in libraries, Library and information services, Queering the library},
abstract = {In principle, libraries have espoused the values of equity, diversity, and inclusion (EDI) as evidenced by the broad range of diversity initiatives, commitments, conferences and literature within the library and information studies sector. More recently, concepts of equity and inclusion have played a role in library diversity initiatives in addition to newer concepts such as critical librarianship and the decolonization, Indigenization and queering of libraries. Starting from affirmative action and anti-discrimination policies and legislation in the 1960s, this entry reviews the historical evolution of EDI awareness and informed practice in the US and Australia over the past 65 years.}
}
@article{EID2025155767,
title = {Using Denoising Diffusion Probabilistic Models to solve the inverse sizing problem of analog Integrated Circuits},
journal = {AEU - International Journal of Electronics and Communications},
volume = {195},
pages = {155767},
year = {2025},
issn = {1434-8411},
doi = {https://doi.org/10.1016/j.aeue.2025.155767},
url = {https://www.sciencedirect.com/science/article/pii/S1434841125001086},
author = {Pedro Eid and Filipe Azevedo and Nuno Lourenço and Ricardo Martins},
keywords = {Artificial neural networks, Denoising diffusion probabilistic models, Electronic design automation},
abstract = {In this paper, we focus on using Artificial Neural Networks (ANNs), particularly diffusion models, to automate the sizing of analog Integrated Circuits (ICs), given the constraints of their performance metrics. Researchers have explored various automation methods, including meta-heuristics and optimization-based approaches, to address this challenge. However, each method presents distinct drawbacks and, at times, yields inefficient results. While studies have made some attempts using ANNs, they commonly face the hurdle of the ill-posed nature of the problem exacerbated by the scarcity of databases for training the models. Therefore, this work introduces a novel approach to automate the design process by leveraging diffusion models to enhance the existing ANNs-based framework and address the limitations of previous methodologies. Specifically, Denoising Diffusion Probabilistic Model (DDPM) to tackle the inverse problem of the analog IC sizing. DDPMs employ a noising and denoising architecture, where they learn to reconstruct input distributions by progressively adding and removing noise. Once trained, the DDPM can generate new data from pure noise. We show that even a simple DDPM can sample sizing solutions in a small amount of time, which is an important steppingstone for future research. Experimental results indicate that our models successfully sized the two tested circuits with an average median error of around 6%, surpassing the state-of-the-art approaches whose error was over 60 to 70% higher. Moreover, by taking advantage of the generative capabilities of our models, we were able to generate points for targets within the dataset, with most of them showing an error below 3%. For the more challenging targets, we managed to find solutions with errors below 10%, while the supervised approaches struggled to achieve errors under 20%.}
}
@article{FU2025200538,
title = {The impact of artificial intelligence on digital enterprise innovation},
journal = {Journal of Strategy & Innovation},
volume = {36},
number = {1},
pages = {200538},
year = {2025},
issn = {3050-7901},
doi = {https://doi.org/10.1016/j.jsinno.2025.200538},
url = {https://www.sciencedirect.com/science/article/pii/S3050790125000087},
author = {Yu Fu and Jiacheng Ni and Mengwen Fang},
keywords = {Artificial intelligence, Enterprise innovation, Digital enterprise, Text analysis},
abstract = {The digital economy is transitioning into a new phase characterized as the intelligent economy, propelled by advancements in artificial intelligence (AI). This shift is poised to inject renewed dynamism into the global economy. This paper develops a theoretical framework that elucidates the relationship between AI adoption and innovation within digital enterprises, drawing upon resource-based theory (RBT) and absorptive capacity theory (ACAP). Utilizing a sample of Chinese digital enterprises listed overseas from 2000 to 2023, this study employs Python to extract keywords associated with “artificial intelligence” from corporate annual reports, thereby constructing a proxy measure for AI adoption. We empirically investigate the impact of AI adoption on innovation within digital enterprises. Our findings demonstrate that AI adoption significantly enhances innovation in digital enterprises, a result that remains robust across a series of robustness tests. Additional analysis reveals that the absorptive capacity of enterprises mediates the relationship between AI adoption and innovation, while slack resources act as a moderating factor, attenuating the link between absorptive capacity and innovation. This paper extends our understanding of the implications of AI on broader innovation entities, elucidating the mechanisms and boundary conditions of AI application in digital enterprises. It also offers insights into how enterprises can effectively integrate AI technology, strategically configure and utilize slack resources, and ultimately enhance their innovation performance.}
}
@article{GREENE2025101949,
title = {Structure and content in the quality levels of ethical argumentation in online discussions},
journal = {Thinking Skills and Creativity},
volume = {58},
pages = {101949},
year = {2025},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2025.101949},
url = {https://www.sciencedirect.com/science/article/pii/S1871187125001981},
author = {Marita Seppänen Greene},
keywords = {Ethical argumentation, Computer-supported collaborative learning, Critical thinking, Creative thinking, Higher education},
abstract = {Learning to argue about ethical dilemmas and questions is a vital competency for a democratic society, as one’s thoughts and actions must be morally justified. Ethical argumentation is a combination of facts, emotions, and values that considers the consequences of right and wrong based on the values of individuals and communities. It requires support from both critical thinking to argue clearly, use evidence, and from creative thinking to generate new standpoints and solutions. This study developed a model to analyse undergraduate students’ ethical arguments during role play and free debate (n = 199) in asynchronous online discussions in an authentic, non-scaffolded blended-learning classroom. The instructions include the rules for critical discussion to promote respect for diverse opinions and collaboration, and a model of sound argument structure and common fallacies. Theoretical models of ethical argumentation and iterative data analysis were used to identify and evaluate the argumentation structure and content across different levels of quality. The quality of the content and structural complexity varied between acceptable and unacceptable depending on the topic and students’ engagement to argue. A considerable number of low-quality unsubstantiated arguments ‘other structures’ was also observed. The argumentation was generally fair and without personal attack. The number of fallacies and weak arguments was high for the first four of the six studied topics but significantly decreased thereafter. Students considered the ethical consequences across the topics. The results have implications for integrating critical, creative, and ethical thinking into argumentation in computer-supported collaborative learning environments and citizenship education.}
}
@article{GRAHAM2024101367,
title = {Assessing the impact of pre-lecture reading compliance on lecture comprehension in English-medium instruction courses},
journal = {Journal of English for Academic Purposes},
volume = {68},
pages = {101367},
year = {2024},
issn = {1475-1585},
doi = {https://doi.org/10.1016/j.jeap.2024.101367},
url = {https://www.sciencedirect.com/science/article/pii/S1475158524000353},
author = {Keith M. Graham},
keywords = {English-medium instruction (EMI), Higher education, Lecture comprehension, Reading compliance, Expectancy-value theory},
abstract = {This study explores the relationship between pre-lecture reading compliance and lecture comprehension in English-medium instruction (EMI) settings. The primary objective of the research was to investigate the influence of pre-lecture reading compliance on English lecture comprehension, with a secondary aim of identifying factors influencing pre-lecture reading compliance. Data were collected from 258 Taiwanese EMI students in 17 courses. A PLS-SEM model utilizing data from 249 participants evaluated the impact of pre-lecture reading compliance on lecture comprehension, accounting for English listening ability, and examined the role of reading expectancy and value in reading compliance. Additionally, open-ended responses from all 258 participants provided insights into students’ perspectives on factors affecting their reading compliance. Results indicate that academic listening ability had a large effect on lecture comprehension whereas the effect for reading compliance was small. Moreover, academic reading expectancy and value were identified as having only a small effect on pre-lecture reading compliance. Further consideration of EMI reading compliance among EMI instructors and researchers is recommended.}
}
@article{REINERS2024101444,
title = {Decoding ambivalence: The potential of cue-based design for Customer Facing Technologies},
journal = {Electronic Commerce Research and Applications},
volume = {68},
pages = {101444},
year = {2024},
issn = {1567-4223},
doi = {https://doi.org/10.1016/j.elerap.2024.101444},
url = {https://www.sciencedirect.com/science/article/pii/S1567422324000899},
author = {Sebastian Reiners and Nadine Ostern and Sam Fischer},
keywords = {Customer, Technology, Design, Ambivalence},
abstract = {When not effectively addressed, ambivalence in customers can lead to various negative outcomes, such as decreased loyalty or purchase intent. Despite this, current research has yet to account for approaches that govern ambivalent customer behavior. To close this gap, we introduce a novel research conceptualization that considers a customer’s engagement with technology as an interaction with instrumental, symbolic, identity, and aesthetic cues. Building on the results of a hermeneutic literature review and construction of a pathway model, we demonstrate the potential of a cue-based design approach for Customer Facing Technologys (CFTs). The cue-based design emphasizes the reinforcing or oppositional interactions of signals surrounding the engagement with technology, making it possible to address ambivalence. Ultimately, we propose reconsidering the way CFTs are currently investigated in research to help explain deviations in customer behavior.}
}
@article{HUANG2024617,
title = {Mitigating treatment failure of pulmonary pre-extensively drug-resistant tuberculosis: The role of new and repurposed drugs},
journal = {Journal of Microbiology, Immunology and Infection},
volume = {57},
number = {4},
pages = {617-628},
year = {2024},
issn = {1684-1182},
doi = {https://doi.org/10.1016/j.jmii.2024.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S1684118224000768},
author = {Yi-Wen Huang and Ming-Chih Yu and Chih-Bin Lin and Jen-Jyh Lee and Chou-Jui Lin and Shun-Tien Chien and Chih-Hsin Lee and Chen-Yuan Chiang},
keywords = {Bedaquiline, Clofazimine, Carbapenem, Linezolid, Delamanid},
abstract = {Background
Pre-extensively drug-resistant tuberculosis (pre-XDR-TB), defined as multidrug-resistant TB (MDR-TB) with additional resistance to any fluoroquinolone (FQ) is difficult to treat. We assessed whether the use of new or repurposed drugs (bedaquiline, delamanid, linezolid, carbapenem, clofazimine, pretomanid) mitigated treatment failure of pre-XDR-TB.
Methods
MDR-TB patients managed in the Taiwan MDR-TB consortium between July 2009–December 2019 were eligible. Treatment outcomes at 30 months were assessed. Logistic regression models were constructed to investigate factors associated with treatment outcomes.
Results
109 patients with FQ-resistant MDR-TB and 218 patients with FQ-susceptible MDR-TB were included. 60 (55.1%) patients with FQ-resistant MDR-TB and 63 (28.9%) patients with FQ-susceptible MDR-TB have been treated with new or repurposed drugs (p < 0.01). Of the 218 patients with FQ-susceptible MDR-TB, 187 (85.8%) had treatment success, 30 (13.8%) died, no treatment failure, and 1 (0.5%) was loss-to-follow-up; of the 109 patients with FQ-resistant MDR-TB, 78 (71.6%) had treatment success, 21 (19.3%) died, 9 (8.3%) had treatment failure, and 1 (0.9%) was loss-to-follow-up (p < 0.01). The use of new or repurposed drugs was not associated with treatment outcomes among patients with FQ-susceptible MDR-TB. No patients with FQ-resistant MDR-TB treated with ≥2 new or repurposed drugs within 6 months of treatment initiation had treatment failure (p = 0.03). Patients with FQ-resistant MDR-TB treated with 1 new or repurposed drugs was more likely to have treatment failure as compared with patients not treated with new or repurposed drugs (adjOR 7.06, 95% CI 1.72–29.06).
Conclusions
Proper use of new or repurposed anti-TB drugs can mitigate treatment failure in FQ-resistant MDR-TB.}
}
@article{DEFRANCISCIS20252705,
title = {Clinical applications of oligonucleotides for cancer therapy},
journal = {Molecular Therapy},
volume = {33},
number = {6},
pages = {2705-2718},
year = {2025},
issn = {1525-0016},
doi = {https://doi.org/10.1016/j.ymthe.2025.02.045},
url = {https://www.sciencedirect.com/science/article/pii/S1525001625001728},
author = {Vittorio DeFranciscis and Giovanni Amabile and Marcin Kortylewski},
keywords = {oligonucleotide, cancer therapy, immunotherapy, siRNA, antisense oligonucleotides, aptamers, delivery},
abstract = {Oligonucleotide therapeutics (ONTs) represent a rapidly evolving modality for cancer treatment, capitalizing on their ability to modulate gene expression with high specificity. With more than 20 nucleic acid-based therapies that gained regulatory approval, advances in chemical modifications, sequence optimization, and novel delivery systems have propelled ONTs from research tools to clinical realities. ONTs, including siRNAs, antisense oligonucleotides, saRNA, miRNA, aptamers, and decoys, offer promising solutions for targeting previously “undruggable” molecules, such as transcription factors, and enhancing cancer immunotherapy by overcoming tumor immune evasion. The promise of ONT application in cancer treatment is exemplified by the recent FDA approval of the first oligonucleotide-based treatment to myeloproliferative disease. At the same time, there are challenges in delivering ONTs to specific tissues, mitigating off-target effects, and improving cellular uptake and endosomal release. This review provides a comprehensive overview of ONTs in clinical trials, emerging delivery strategies, and innovative therapeutic approaches, emphasizing the role of ONTs in immunotherapy and addressing hurdles that hinder their clinical translation. By examining advances and remaining challenges, we highlight opportunities for ONTs to revolutionize oncology and enhance patient outcomes.}
}
@article{KROESE2025101205,
title = {Evaluating the automated measurement of abnormal rising and lying down behaviours in dairy cows using 3D pose estimation},
journal = {Smart Agricultural Technology},
volume = {12},
pages = {101205},
year = {2025},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2025.101205},
url = {https://www.sciencedirect.com/science/article/pii/S2772375525004368},
author = {Adrien Kroese and Niclas Högberg and Elena {Diaz Vicuna} and David Berthet and Nils Fall and Moudud Alam and Lena-Mari Tamminen},
keywords = {Animal welfare assessment, Free-stall cubicle, 3D pose estimation, Rising behaviour, Lying down behaviour, Precision livestock farming},
abstract = {The structure of cubicles can hinder cows’ movements when transitioning between postures, leading to atypical motion patterns. Assessing posture transitions relies on visual observations. This study presents a framework for complementing these assessments with kinematic measurements using 3D pose estimation. A total 809 rising and 791 lying down posture transitions were recorded over 12 cubicles by 7 synchronized cameras and processed with 3D pose estimation locating the position of the poll, withers, T13 and sacrum. First, the displacement of the keypoints was used to detect phases of the posture transitions. This detection was compared with visual observations of 200 recordings. The average mean absolute difference in detected timestamps between human and machine across all phases was 0.5 s (average σ = 0.7) and was under 0.9 s for all phases. Second, indicators were scored based on spatial use and duration, and their distribution compared to existing thresholds. We observed that 59.9 % of rising bouts and 29.1 % of lying down bouts exceeded at least one threshold. Rising delay occurred in 2.8 % of rising bouts and backwards crawling in 59.2 %. Lying down duration exceeded the threshold in 28.9 % of bouts, and rear limbs shifting duration in 8.3 %. Side lunge had a binary threshold which was not adapted to continuous sensor data. Finally, we investigated the association between indicators and found distinct dimensions for head lunge and crawling. We conclude that 3D pose is useful to score posture transition indicators, and that several indicators should be used together to capture distinct dimensions.}
}
@article{CHEN2025128918,
title = {Empowering the urban fringe: Guerrilla gardening and the creation of informal green spaces},
journal = {Urban Forestry & Urban Greening},
volume = {112},
pages = {128918},
year = {2025},
issn = {1618-8667},
doi = {https://doi.org/10.1016/j.ufug.2025.128918},
url = {https://www.sciencedirect.com/science/article/pii/S1618866725002523},
author = {Hong Chen and Yanting Zeng and Jie Bao and Chuo Li},
keywords = {Spatial justice, Aesthetic order, Spatial creation, Weapon of the weak},
abstract = {This paper explores the socio-spatial logic underlying "guerrilla" gardening and the creation of informal green spaces in the context of rapid urbanization in China. While the existing research on guerrilla horticulture often focuses on the morphological and physical characteristics of IGS, it largely overlooks their spatial ontology, formation mechanism, and broader implications for planning values and urban governance frameworks. Addressing this gap, the study examines how IGS can act as pivotal sites for reshaping urban planning paradigms, promoting spatial justice, and facilitating bottom-up governance. Using a case study of Jiulongyuan Community, located on the urban fringe of Hefei City, the research employs in-depth interviews and non-participatory observation to trace the emergence and evolution of guerrilla gardens through four distinct stages. Findings reveal that community residents use guerrilla gardening as a from of everyday resistance, challenging traditional top-down planning structures and generating new forms of spatial and political agency. This study contributes contemporary urban planning theory by emphasizing the role of value co-creation, grassroots spatial interventions, and the aesthetic order embedded in informal green practices.}
}
@article{HU2025128668,
title = {A projection module based on the shape space theory for small-sample image processing},
journal = {Expert Systems with Applications},
volume = {293},
pages = {128668},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.128668},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425022869},
author = {Gan Hu and Yuexing Han},
keywords = {Pre-shape space, Transfer learning, Manifold learning, Attention mechanism},
abstract = {The “Pre-train + Fine-tuning” (PF) paradigm offers effective tools for neural network-based image processing on limited datasets. This approach compensates for the lack of information in the small target dataset by pre-training the model on a large source dataset. However, when the target dataset is further reduced to a small-sample size, existing methods struggle to maintain the performance of the transfer model, leading to rapid performance deterioration. To address this drawback, we propose PMSS, a Projection Module based on the Shape Space theory, to enhance the transfer model’s capability in small-sample scenarios. We first pre-train the model on the source dataset and save it, then use the pre-trained model to extract features from the target dataset. These extracted features, originally in the Euclidean space, are projected into the pre-shape space through PMSS for subsequent training. Furthermore, a class-aware attention mechanism is introduced during the learning process, enhancing the feature representation to improve the model’s ability to handle small-sample tasks. Extensive experiments on 10 backbone networks and 5 datasets demonstrate PMSS’s effectiveness. Specifically, PMSS achieved accuracy improvements of 6 %, 8 %, and 13 % on CIFAR10, CIFAR100, and their small-sample subsets respectively. PMSS’s plug-and-play design requires no architectural changes, making it directly applicable to real-world systems with limited data. When compared with the latest manifold learning methods and robust transfer learning methods, PMSS achieves the state-of-the-art performance.}
}
@article{FERRARIO2024,
title = {The Role of Humanization and Robustness of Large Language Models in Conversational Artificial Intelligence for Individuals With Depression: A Critical Analysis},
journal = {JMIR Mental Health},
volume = {11},
year = {2024},
issn = {2368-7959},
doi = {https://doi.org/10.2196/56569},
url = {https://www.sciencedirect.com/science/article/pii/S2368795924000696},
author = {Andrea Ferrario and Jana Sedlakova and Manuel Trachsel},
keywords = {generative AI, large language models, large language model, LLM, LLMs, machine learning, ML, natural language processing, NLP, deep learning, depression, mental health, mental illness, mental disease, mental diseases, mental illnesses, artificial intelligence, AI, digital health, digital technology, digital intervention, digital interventions, ethics},
abstract = {Large language model (LLM)–powered services are gaining popularity in various applications due to their exceptional performance in many tasks, such as sentiment analysis and answering questions. Recently, research has been exploring their potential use in digital health contexts, particularly in the mental health domain. However, implementing LLM-enhanced conversational artificial intelligence (CAI) presents significant ethical, technical, and clinical challenges. In this viewpoint paper, we discuss 2 challenges that affect the use of LLM-enhanced CAI for individuals with mental health issues, focusing on the use case of patients with depression: the tendency to humanize LLM-enhanced CAI and their lack of contextualized robustness. Our approach is interdisciplinary, relying on considerations from philosophy, psychology, and computer science. We argue that the humanization of LLM-enhanced CAI hinges on the reflection of what it means to simulate “human-like” features with LLMs and what role these systems should play in interactions with humans. Further, ensuring the contextualization of the robustness of LLMs requires considering the specificities of language production in individuals with depression, as well as its evolution over time. Finally, we provide a series of recommendations to foster the responsible design and deployment of LLM-enhanced CAI for the therapeutic support of individuals with depression.}
}
@article{YUAN2025298,
title = {GenAI-enabled microteaching lesson study: developing prospective secondary mathematics teachers’ TPACK in an online summer camp},
journal = {International Journal for Lesson and Learning Studies},
volume = {14},
number = {3},
pages = {298-317},
year = {2025},
issn = {2046-8253},
doi = {https://doi.org/10.1108/IJLLS-11-2024-0273},
url = {https://www.sciencedirect.com/science/article/pii/S2046825325000083},
author = {Zhiqiang Yuan and Xueting Zhong and Wenyen Huang and Zhiyi Li and Xin Tang and Qi Tan},
keywords = {GenAI, Pedagogical AI agent, Digital technology, GeoGebra, Microteaching lesson study, TPACK},
abstract = {Purpose
This study aims to explore the impact and mechanisms of an online summer camp incorporating generative AI (GenAI)-enabled microteaching lesson study on the technological pedagogical content knowledge (TPACK) of prospective secondary mathematics teachers (PSMTs).
Design/methodology/approach
A mixed-methods research approach was employed, with 21 PSMTs participating in a 9-day online summer camp that included two rounds of microteaching lesson study, expert lectures, plenary discussions, and group discussions. Data were collected using pre- and post-mathematics-specific TPACK scales, teaching artifacts, and qualitative reflections to evaluate the evolution of PSMTs’ TPACK and identify key influencing factors.
Findings
The study reveals statistically significant improvements across all sub-domains of the TPACK framework among PSMTs. The degree of improvement in the TPACK sub-domain varied among participants, with some experiencing significant enhancement, others moderate gains, and a few showing smaller changes. The study identifies four critical factors driving TPACK development: expert guidance, practical exploration, collaborative learning, and ongoing reflection, which enhanced PSMTs’ incorporation of digital technologies (e.g. GeoGebra, GenAI) into their teaching practices.
Research limitations/implications
This study demonstrates that incorporating GenAI into microteaching lesson study significantly enhances TPACK, thereby highlighting its potential for structured, scaffolded teacher professional development. Additionally, the study shows that online formats can effectively support teachers’ TPACK development, offering a replicable model for future programs.
Originality/value
This study innovatively incorporates GenAI into microteaching lesson study, offering a novel approach to enhance PSMTs’ TPACK. It also validates a mathematics-specific TPACK scale and identifies key factors for effective teacher professional development in technology-integrated environment.}
}
@article{WANG20243891,
title = {Differentially Private Support Vector Machines with Knowledge Aggregation},
journal = {Computers, Materials and Continua},
volume = {78},
number = {3},
pages = {3891-3907},
year = {2024},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2024.048115},
url = {https://www.sciencedirect.com/science/article/pii/S1546221824003369},
author = {Teng Wang and Yao Zhang and Jiangguo Liang and Shuai Wang and Shuanggen Liu},
keywords = {Differential privacy, support vector machine, knowledge aggregation, data utility},
abstract = {With the widespread data collection and processing, privacy-preserving machine learning has become increasingly important in addressing privacy risks related to individuals. Support vector machine (SVM) is one of the most elementary learning models of machine learning. Privacy issues surrounding SVM classifier training have attracted increasing attention. In this paper, we investigate Differential Privacy-compliant Federated Machine Learning with Dimensionality Reduction, called FedDPDR-DPML, which greatly improves data utility while providing strong privacy guarantees. Considering in distributed learning scenarios, multiple participants usually hold unbalanced or small amounts of data. Therefore, FedDPDR-DPML enables multiple participants to collaboratively learn a global model based on weighted model averaging and knowledge aggregation and then the server distributes the global model to each participant to improve local data utility. Aiming at high-dimensional data, we adopt differential privacy in both the principal component analysis (PCA)-based dimensionality reduction phase and SVM classifiers training phase, which improves model accuracy while achieving strict differential privacy protection. Besides, we train Differential privacy (DP)-compliant SVM classifiers by adding noise to the objective function itself, thus leading to better data utility. Extensive experiments on three high-dimensional datasets demonstrate that FedDPDR-DPML can achieve high accuracy while ensuring strong privacy protection.}
}
@article{VOGELGESANG2024111306,
title = {An exemplary reanalysis of coronary computed tomography angiography diagnostic meta-analyses shows insufficient data sharing and incorrect sensitivity and specificity estimates},
journal = {Journal of Clinical Epidemiology},
volume = {170},
pages = {111306},
year = {2024},
issn = {0895-4356},
doi = {https://doi.org/10.1016/j.jclinepi.2024.111306},
url = {https://www.sciencedirect.com/science/article/pii/S0895435624000611},
author = {Felicitas Vogelgesang and Maria H. Coenen and Sabine Schueler and Peter Schlattmann and Marc Dewey},
keywords = {Diagnostic accuracy, Sensitivity, Specificity, Bivariate binomial model, Meta-analysis, Radiology},
abstract = {Objectives
To systematically evaluate the reproducibility of primary data and, the reproducibility and correctness of pooled sensitivity and specificity estimates reported in a sample of diagnostic meta-analyses.
Study Design and Setting
We conducted an exemplary systematic review of diagnostic meta-analyses comparing coronary computed tomography angiography to invasive coronary angiography in patients with suspected coronary artery disease. The objectives were to assess 1) the reproducibility of contingency tables, 2) the reproducibility of pooled sensitivity and specificity, and 3) differences to reported results when applying a recommended bivariate binomial model for pooling sensitivity and specificity. Therefore, we reproduced the contingency tables and recalculated sensitivity and specificity by utilizing both the pooling method of each meta-analysis and a bivariate binomial model. We used linear trends to assess the improvement of these objectives over time.
Results
We identified 38 diagnostic meta-analyses, each including on average 19 primary studies (range: 3 to 89 studies; total: 715—including duplicates) with an average of approximately 1800 patients per meta-analysis (range: 118 to 7516 patients). For 31 meta-analyses (82%, 95% CI: 65%, 91%), the contingency tables were reproducible; however, only 15 published them. Using the pooling method of each meta-analysis, we obtained comparable recalculated sensitivities/specificities for 28 meta-analyses (74% [57%, 86%]). Only 11 meta-analyses pooled sensitivity/specificity using a bivariate binomial model (29% [16%, 46%]). When all meta-analyses were pooled with this model, published sensitivities/specificities were confirmed for 19 of 38 meta-analyses (50% [34%, 66%]). There was only marginal improvement in data availability and application of recommended pooling methods over time.
Conclusion
Data sharing should become standard practice along with the use of appropriate pooling methods. Journal publication requirements may play a key role in enhancing the quality of scientific reporting and methodological standards which may lead to more reliable and consistent outcomes. The ability to reproduce sensitivity and specificity estimates in diagnostic imaging meta-analyses is dependent on the availability of contingency tables and the explicit reporting of pooling methods and software used.}
}
@article{CHO2025100317,
title = {Spatial Transcriptomics in Inflammatory Skin Diseases Using GeoMx Digital Spatial Profiling: A Practical Guide for Applications in Dermatology},
journal = {JID Innovations},
volume = {5},
number = {1},
pages = {100317},
year = {2025},
issn = {2667-0267},
doi = {https://doi.org/10.1016/j.xjidi.2024.100317},
url = {https://www.sciencedirect.com/science/article/pii/S2667026724000651},
author = {Christina Cho and Nazgol-Sadat Haddadi and Michal Kidacki and Gavitt A. Woodard and Saeed Shakiba and Ümmügülsüm Yıldız-Altay and Jillian M. Richmond and Matthew D. Vesely},
keywords = {Cutaneous lupus, Digital spatial profiling, Lichen planus, Psoriasis, Spatial transcriptomics},
abstract = {The spatial organization of the skin is critical for its function. In particular, the skin immune microenvironment is arranged spatially and temporally, such that imbalances in the immune milieu are indicative of disease. Spatial transcriptomic platforms are helping to provide additional insights into aberrant inflammation in tissues that are not captured by tissue processing required for single-cell RNA sequencing. In this paper, we discuss a technical and user experience overview of NanoString's GeoMx Digital Spatial Profiler to perform in-depth spatial analysis of the transcriptome in inflammatory skin diseases. Our objective is to provide potential pitfalls and methods to optimize RNA capture that are not readily available in the manufacturer’s guidelines. We use concrete examples from our experiments to demonstrate these strategies in inflammatory skin diseases, including psoriasis, lichen planus, and discoid lupus erythematosus. Overall, we hope to illustrate the potential of digital spatial profiling to dissect skin disease pathogenesis in a spatially resolved manner and provide a framework for other skin biology investigators using digital spatial profiling.}
}
@article{CHIEN2025100328,
title = {Creating an Extremely Long-lasting Neuroischemic Wound Model},
journal = {JID Innovations},
volume = {5},
number = {2},
pages = {100328},
year = {2025},
issn = {2667-0267},
doi = {https://doi.org/10.1016/j.xjidi.2024.100328},
url = {https://www.sciencedirect.com/science/article/pii/S2667026724000766},
author = {Sufan Chien and Harshini Sarojini and Arezoo Rajaee and Mohammad Bayat and Samson Chien and Girish Kotwal},
keywords = {Animal model, Neuroischemia, Rabbit, Long term, Wound},
abstract = {In wound study and dressing development, a lack of a suitable animal model that can recapitulate the complex pathophysiology of human chronic wounds has been a major hurdle. Chronic wounds are defined as wounds that heal with a significant delay, usually over a period >2–3 months, but no current animal wound model has such a longischemia. After a longexploration, our group has developed an animal wound model with ischemia and nerve damage lasting for at least 6 months. This model can be easily combined with other conditions such as diabetes and aging for wound mechanistic study and critical testing of dressings. This report presents the method that has significant utility in evaluating therapies that could become the future standard for screening all new wound dressings.}
}
@article{2024A15,
title = {Instructions for authors},
journal = {Gastrointestinal Endoscopy},
volume = {99},
number = {1},
pages = {A15-A21},
year = {2024},
issn = {0016-5107},
doi = {https://doi.org/10.1016/j.gie.2023.11.046},
url = {https://www.sciencedirect.com/science/article/pii/S001651072303122X}
}
@article{FRCERQUEIRA2024115490,
title = {Improving the sensing ability of thiazolothiazole derivatives towards metal ions},
journal = {Journal of Photochemistry and Photobiology A: Chemistry},
volume = {451},
pages = {115490},
year = {2024},
issn = {1010-6030},
doi = {https://doi.org/10.1016/j.jphotochem.2024.115490},
url = {https://www.sciencedirect.com/science/article/pii/S1010603024000340},
author = {Ana {F. R. Cerqueira} and Nuno {M. M. Moura} and Maria {G. P. M. S. Neves} and A. {Jorge Parola} and Augusto C. Tomé},
keywords = {Thiazolo[5,4-]thiazole, Chemosensor, Metal ions sensing, Optic sensor, Fluorescent probe},
abstract = {Two non-symmetrical thiazolothiazoles (TzTz) incorporating pyridin-2-yl groups were synthesized and their sensing abilities towards a series of metal ions were evaluated. The new compounds exhibited good sensing capabilities towards Cu2+ and Zn2+, enabling the differentiation between these two metal ions through spectrophotometric and spectrofluorimetric titrations. The addition of other metal ions to these TzTz derivatives does not cause noticeable effects. The results of this study highlight the high potential of TzTz derivatives for metal ions detection applications.}
}
@article{BECKER2024104861,
title = {HIF-1α is required to differentiate the neonatal Macrophage protein secretome from adults},
journal = {Cellular Immunology},
volume = {403-404},
pages = {104861},
year = {2024},
issn = {0008-8749},
doi = {https://doi.org/10.1016/j.cellimm.2024.104861},
url = {https://www.sciencedirect.com/science/article/pii/S0008874924000649},
author = {Amanda Becker and Mallory Filipp and Connor Lantz and Kristofor Glinton and Edward B. Thorp},
keywords = {, Macrophage, Regeneration, Inflammation, Immunometabolism},
abstract = {The immune response to stress diverges with age, with neonatal macrophages implicated in tissue regeneration versus tissue scarring and maladaptive inflammation in adults. Integral to the macrophage stress response is the recognition of hypoxia and pathogen-associated molecular patterns (PAMPs), which are often coupled. The age-specific, cell-intrinsic nature of this stress response remains vague. To uncover age-defined divergences in macrophage crosstalk potential after exposure to hypoxia and PAMPs, we interrogated the secreted proteomes of neonatal versus adult macrophages via non-biased mass spectrometry. Through this approach, we newly identified age-specific signatures in the secretomes of neonatal versus adult macrophages in response to hypoxia and the prototypical PAMP, lipopolysaccharide (LPS). Neonatal macrophages secreted proteins most consistent with an anti-inflammatory, regenerative phenotype protective against apoptosis and oxidative stress, dependent on hypoxia inducible transcription factor-1α (HIF-1α). In contrast, adult macrophages secreted proteins consistent with a pro-inflammatory, glycolytic phenotypic signature consistent with pathogen killing. Taken together, these data uncover fundamental age and HIF-1α dependent macrophage responses that may be targeted to calibrate the innate immune response during stress and inflammation.}
}
@article{ELYOSEPH2024,
title = {Comparing the Perspectives of Generative AI, Mental Health Experts, and the General Public on Schizophrenia Recovery: Case Vignette Study},
journal = {JMIR Mental Health},
volume = {11},
year = {2024},
issn = {2368-7959},
doi = {https://doi.org/10.2196/53043},
url = {https://www.sciencedirect.com/science/article/pii/S2368795924000246},
author = {Zohar Elyoseph and Inbar Levkovich},
keywords = {schizophrenia, mental, prognostic, prognostics, prognosis, ChatGPT, artificial intelligence, recovery, vignette, vignettes, outcome, outcomes, large language models, language model, language models, LLM, LLMs, NLP, natural language processing, GPT, Generative Pre-trained Transformers},
abstract = {Background
The current paradigm in mental health care focuses on clinical recovery and symptom remission. This model’s efficacy is influenced by therapist trust in patient recovery potential and the depth of the therapeutic relationship. Schizophrenia is a chronic illness with severe symptoms where the possibility of recovery is a matter of debate. As artificial intelligence (AI) becomes integrated into the health care field, it is important to examine its ability to assess recovery potential in major psychiatric disorders such as schizophrenia.
Objective
This study aimed to evaluate the ability of large language models (LLMs) in comparison to mental health professionals to assess the prognosis of schizophrenia with and without professional treatment and the long-term positive and negative outcomes.
Methods
Vignettes were inputted into LLMs interfaces and assessed 10 times by 4 AI platforms: ChatGPT-3.5, ChatGPT-4, Google Bard, and Claude. A total of 80 evaluations were collected and benchmarked against existing norms to analyze what mental health professionals (general practitioners, psychiatrists, clinical psychologists, and mental health nurses) and the general public think about schizophrenia prognosis with and without professional treatment and the positive and negative long-term outcomes of schizophrenia interventions.
Results
For the prognosis of schizophrenia with professional treatment, ChatGPT-3.5 was notably pessimistic, whereas ChatGPT-4, Claude, and Bard aligned with professional views but differed from the general public. All LLMs believed untreated schizophrenia would remain static or worsen without professional treatment. For long-term outcomes, ChatGPT-4 and Claude predicted more negative outcomes than Bard and ChatGPT-3.5. For positive outcomes, ChatGPT-3.5 and Claude were more pessimistic than Bard and ChatGPT-4.
Conclusions
The finding that 3 out of the 4 LLMs aligned closely with the predictions of mental health professionals when considering the “with treatment” condition is a demonstration of the potential of this technology in providing professional clinical prognosis. The pessimistic assessment of ChatGPT-3.5 is a disturbing finding since it may reduce the motivation of patients to start or persist with treatment for schizophrenia. Overall, although LLMs hold promise in augmenting health care, their application necessitates rigorous validation and a harmonious blend with human expertise.}
}
@article{CHEN2025103032,
title = {Nationalism meets machine heuristics: Investigating the effect of AI’s “nationality” on the perceived credibility of AIGC},
journal = {Technology in Society},
volume = {83},
pages = {103032},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.103032},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25002222},
author = {Junyi Chen and Weixi Zeng and Yi Mou},
keywords = {Politicized technology, Credibility, AIGC, Machine heuristic, Nationalism, Large language model},
abstract = {Against the backdrop of politicizing science and technology, it has nevertheless become a common practice to employ AI tools in political communication. This study delves into the tension between the supposedly high credibility of AI-generated content (AIGC) with its perceived objectivity and the potentially devastating impact of politicized tools. Specifically, we investigate the disparities in the perceived credibility of AIGC, stemming from various source types and nationalities. Using an online experiment conducted in China, we found that Chinese AI sources and human-AI hybrid sources with consistent Chinese national identity were perceived as more credible than their foreign (American) counterparts, whose effects were fully mediated by machine heuristics. In contrast, less credibility was directly attributed to human-AI hybrid sources with inconsistent human-AI nationalities (e.g., a Chinese journalist using American AI). Furthermore, although foreign sources were generally seen as less credible, the presence of AI in the source moderated this negative effect. These findings indicated users' perceptions of the political dimensions of AI technology.}
}
@article{JIANG2024202,
title = {Preventing the Immense Increase in the Life-Cycle Energy and Carbon Footprints of LLM-Powered Intelligent Chatbots},
journal = {Engineering},
volume = {40},
pages = {202-210},
year = {2024},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2024.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S2095809924002315},
author = {Peng Jiang and Christian Sonne and Wangliang Li and Fengqi You and Siming You},
keywords = {Large language models, Intelligent chatbots, Carbon emissions, Energy and environmental footprints, Life-cycle assessment, Global cooperation},
abstract = {Intelligent chatbots powered by large language models (LLMs) have recently been sweeping the world, with potential for a wide variety of industrial applications. Global frontier technology companies are feverishly participating in LLM-powered chatbot design and development, providing several alternatives beyond the famous ChatGPT. However, training, fine-tuning, and updating such intelligent chatbots consume substantial amounts of electricity, resulting in significant carbon emissions. The research and development of all intelligent LLMs and software, hardware manufacturing (e.g., graphics processing units and supercomputers), related data/operations management, and material recycling supporting chatbot services are associated with carbon emissions to varying extents. Attention should therefore be paid to the entire life-cycle energy and carbon footprints of LLM-powered intelligent chatbots in both the present and future in order to mitigate their climate change impact. In this work, we clarify and highlight the energy consumption and carbon emission implications of eight main phases throughout the life cycle of the development of such intelligent chatbots. Based on a life-cycle and interaction analysis of these phases, we propose a system-level solution with three strategic pathways to optimize the management of this industry and mitigate the related footprints. While anticipating the enormous potential of this advanced technology and its products, we make an appeal for a rethinking of the mitigation pathways and strategies of the life-cycle energy usage and carbon emissions of the LLM-powered intelligent chatbot industry and a reshaping of their energy and environmental implications at this early stage of development.}
}
@article{CHEN2024104651,
title = {Chat-ePRO: Development and pilot study of an electronic patient-reported outcomes system based on ChatGPT},
journal = {Journal of Biomedical Informatics},
volume = {154},
pages = {104651},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2024.104651},
url = {https://www.sciencedirect.com/science/article/pii/S1532046424000698},
author = {Zikang Chen and Qinchuan Wang and Yaoqian Sun and Hailing Cai and Xudong Lu},
keywords = {Patient Reported Outcome Measures, Large Language Model, Knowledge Distillation, Breast Cancer, Mobile Health},
abstract = {Objective
Chatbots have the potential to improve user compliance in electronic Patient-Reported Outcome (ePRO) system. Compared to rule-based chatbots, Large Language Model (LLM) offers advantages such as simplifying the development process and increasing conversational flexibility. However, there is currently a lack of practical applications of LLMs in ePRO systems. Therefore, this study utilized ChatGPT to develop the Chat-ePRO system and designed a pilot study to explore the feasibility of building an ePRO system based on LLM.
Materials and Methods
This study employed prompt engineering and offline knowledge distillation to design a dialogue algorithm and built the Chat-ePRO system on the WeChat Mini Program platform. In order to compare Chat-ePRO with the form-based ePRO and rule-based chatbot ePRO used in previous studies, we conducted a pilot study applying the three ePRO systems sequentially at the Sir Run Run Shaw Hospital to collect patients’ PRO data.
Result
Chat-ePRO is capable of correctly generating conversation based on PRO forms (success rate: 95.7 %) and accurately extracting the PRO data instantaneously from conversation (Macro-F1: 0.95). The majority of subjective evaluations from doctors (>70 %) suggest that Chat-ePRO is able to comprehend questions and consistently generate responses. Pilot study shows that Chat-ePRO demonstrates higher response rate (9/10, 90 %) and longer interaction time (10.86 s/turn) compared to the other two methods.
Conclusion
Our study demonstrated the feasibility of utilizing algorithms such as prompt engineering to drive LLM in completing ePRO data collection tasks, and validated that the Chat-ePRO system can effectively enhance patient compliance.}
}
@article{CARNEIRO2025104645,
title = {A flexible ISO 27701-based framework for assessing cybersecurity maturity: a proposition and a case application},
journal = {Computers & Security},
volume = {158},
pages = {104645},
year = {2025},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2025.104645},
url = {https://www.sciencedirect.com/science/article/pii/S0167404825003347},
author = {Fábio Dias Carneiro and Izabela Simon Rampasso and Sidney Luiz {de Matos Mello} and Tiago F.A.C. Sigahi and Hernán Lespay and Rosley Anholon},
keywords = {ISO 27701, Information security, Cybersecurity, Fuzzy TOPSIS, Higher Education Institutions},
abstract = {This study aims to propose a framework for assessing the cybersecurity management level of organizations, based on ISO 27701. To illustrate the proposed framework, and considering the relevance of cybersecurity for Higher Education Institutions (HEIs), an analysis of the reality of Federal HEIs in Brazil is conducted. To develop the proposed framework, the standard ISO 27701 was used to structure a questionnaire. The proposed data analysis combines Hierarchical Cluster Analysis (HCA), frequency analysis, and Fuzzy TOPSIS. The case application considered experts in information security of Federal HEIs in Brazil. The proposed framework presents eight steps: definition of the application focus, analysis of variables and scale proposed, questionnaire structuring, ethics committee submission, data gathering, HCA, frequency analysis, Fuzzy TOPSIS. Regarding the case application, aspects related to internal auditing, asset management and human resources training and analysis were the most critical. This study presents a comprehensive framework for guiding information security assessment in organizations. The proposed framework presents the necessary flexibility to be adjusted according to the requirements of practitioners and researchers. It can be used by companies and the government to assess their current reality and evaluate the impact of changes performed. Researchers can integrate the proposed framework into an Artificial Intelligence mechanism for risk prediction in organizations. The findings from the case application evidence the contributions of this framework to assess the reality of any kind of institution and highlight the insights that can be obtained from its analysis.}
}
@article{SHUKLA2024100605,
title = {An overview of blockchain research and future agenda: Insights from structural topic modeling},
journal = {Journal of Innovation & Knowledge},
volume = {9},
number = {4},
pages = {100605},
year = {2024},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2024.100605},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X24001446},
author = {Anuja Shukla and Poornima Jirli and Anubhav Mishra and Alok Kumar Singh},
keywords = {Structural topic modeling, Blockchain, Scenario building, Datatopia, Natural language processing, Emerging technologies},
abstract = {As a disruptive technology, blockchain has become a strategic priority for many businesses. A vast amount of research exists on blockchain's innovative nature and immense potential for multiple industries. This study aims to synthesize the existing research to classify the findings into various themes and propose avenues for further research. A total of 2,360 academic articles were analyzed using the text-mining method of structural topic modeling. The identified fifteen topics were mapped to the four quadrants of the Datatopia model, leading to the development of the Datatopia-blockchain (DBlock) framework. The results present future scenarios that provide an understanding of what is known about blockchain, its characteristics, and potential research areas. The contributions to the theory and implications to the practitioners are discussed in detail.}
}
@article{MCKINNEY2024e30106,
title = {Automated vs. manual coding of neuroimaging reports via natural language processing, using the international classification of diseases, tenth revision},
journal = {Heliyon},
volume = {10},
number = {10},
pages = {e30106},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e30106},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024061371},
author = {Alexander M. McKinney and Jessica A. Moore and Kevin Campbell and Thiago A. Braga and Jeffrey B. Rykken and Bharathi D. Jagadeesan and Zeke J. McKinney},
keywords = {ICD-10, Coding, Neuroradiology, Impact, Relevance},
abstract = {Objective
Natural language processing (NLP) can generate diagnoses codes from imaging reports. Meanwhile, the International Classification of Diseases (ICD-10) codes are the United States' standard for billing/coding, which enable tracking disease burden and outcomes. This cross-sectional study aimed to test feasibility of an NLP algorithm's performance and comparison to radiologists' and physicians' manual coding.
Methods
Three neuroradiologists and one non-radiologist physician reviewers manually coded a randomly-selected pool of 200 craniospinal CT and MRI reports from a pool of >10,000. The NLP algorithm (Radnosis, VEEV, Inc., Minneapolis, MN) subdivided each report's Impression into “phrases”, with multiple ICD-10 matches for each phrase. Only viewing the Impression, the physician reviewers selected the single best ICD-10 code for each phrase. Codes selected by the physicians and algorithm were compared for agreement.
Results
The algorithm extracted the reports' Impressions into 645 phrases, each having ranked ICD-10 matches. Regarding the reviewers' selected codes, pairwise agreement was unreliable (Krippendorff α = 0.39-0.63). Using unanimous reviewer agreement as “ground truth”, the algorithm's sensitivity/specificity/F2 for top 5 codes was 0.88/0.80/0.83, and for the single best code was 0.67/0.82/0.67. The engine tabulated “pertinent negatives” as negative codes for stated findings (e.g. “no intracranial hemorrhage”). The engine's matching was more specific for shorter than full-length ICD-10 codes (p = 0.00582x10−3).
Conclusions
Manual coding by physician reviewers has significant variability and is time-consuming, while the NLP algorithm's top 5 diagnosis codes are relatively accurate. This preliminary work demonstrates the feasibility and potential for generating codes with reliability and consistency. Future works may include correlating diagnosis codes with clinical encounter codes to evaluate imaging's impact on, and relevance to care.}
}
@article{CHOWDHURY2024105975,
title = {MMG-net: Multi modal approach to estimate blood glucose using multi-stream and cross modality attention},
journal = {Biomedical Signal Processing and Control},
volume = {92},
pages = {105975},
year = {2024},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2024.105975},
url = {https://www.sciencedirect.com/science/article/pii/S1746809424000338},
author = {Moajjem Hossain Chowdhury and Muhammad E.H. Chowdhury and Abdulrahman Alqahtani},
keywords = {Glucose monitoring, Photoplethysmography (PPG), Machine learning, Wearable device, Multi modal data},
abstract = {In the context of effective disease management for hyperglycemia patients, regular monitoring of blood glucose levels is imperative. However, traditional glucose monitoring methods suffer from invasiveness, discomfort, and potential infection. This paper introduces an innovative approach that utilizes non-invasive data sources derived from wearable devices, namely Photoplethysmography (PPG), Electrodermal Activity (EDA), and skin temperature (ST), in combination with user-provided food logs. The proposed model, MMG-Net, uses the three waveforms along with food features extracted from food logs to estimate blood glucose levels. MMG-Net delivers exceptional performance metrics, achieving a Mean Absolute Error of 13.51 mg/dL, a Mean Absolute Percentage Error of 12.57 %, and a Root Mean Square Error of 17.26 mg/dL. Notably, MMG-Net outperforms existing solutions in the estimation of blood glucose levels, solidifying its status as an innovative approach. The model's clinical precision is substantiated through Clarke Error Grid analysis, with a remarkable 99.43 % of predictions falling within clinically acceptable ranges. This paper presents a substantial advancement in non-invasive blood glucose monitoring, offering a promising avenue for enhanced disease management among hyperglycemic patients with only wearable devices.}
}
@article{PARK2024102941,
title = {Machine learning of metal-organic framework design for carbon dioxide capture and utilization},
journal = {Journal of CO2 Utilization},
volume = {89},
pages = {102941},
year = {2024},
issn = {2212-9820},
doi = {https://doi.org/10.1016/j.jcou.2024.102941},
url = {https://www.sciencedirect.com/science/article/pii/S2212982024002762},
author = {Yang Jeong Park and Sungroh Yoon and Sung Eun Jerng},
keywords = {Metal-organic framework, Carbon capture, Machine learning, High-throughput screening, Generative model},
abstract = {Metal-organic frameworks (MOFs) are attractive materials with easily tunable porous structures. Their selective carbon dioxide (CO2) capture ability can be varied by altering the functionality of the organic ligands. However, rule-based approaches to tuning and developing MOFs with high CO2 capture and conversion abilities are hindered by the numerous possible combinations of metal ions and organic linkers. Recently, machine learning (ML) has been applied to unravel key descriptors in predicting the performance of MOFs. This review summarizes recent advancements in ML models for MOFs in CO2 capture and utilization, including high-throughput screening, neural network interatomic potential, and generative models. The development of sophisticated ML models for designing high-performance MOFs will play a critical role in addressing climate change in the future. Finally, the main challenges and limitations of current approaches in designing high-performance MOFs are discussed.}
}
@article{CHAN2025105399,
title = {The balancing act between AI and authenticity in assessment: A case study of secondary school students’ use of GenAI in reflective writing},
journal = {Computers & Education},
volume = {238},
pages = {105399},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105399},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525001678},
author = {Cecilia Ka Yuk Chan and Katherine K.W. Lee},
keywords = {Generative AI, Reflective writing, Secondary school students, Case study, AI guilt, Ethical AI use},
abstract = {This study examines how secondary school students balance the use of Generative AI (GenAI) tools while maintaining authenticity in reflective writing. Reflective writing, a cognitively demanding task, can benefit from AI's ability to improve efficiency and organisation. Using a case study approach, data were collected from the reflective writing pieces of five secondary school students, as well as the accompanying GenAI chat logs and individual interviews following a three-week summer internship programme. Thematic analysis found that while GenAI supports technical quality and reduces cognitive load, it also poses challenges regarding authenticity, depth of reflection, and students' over-reliance on AI. Students reported experiencing AI guilt, particularly regarding perceived laziness, fear of judgment, and concerns over self-efficacy. The findings highlight a tension between producing polished writing and preserving personal voice. Educators must guide students to use AI ethically, ensuring that it supports rather than undermines authentic reflection.}
}
@article{ROY2024105282,
title = {Transcriptional regulation of suppressors of cytokine signaling during infection with Mycobacterium tuberculosis in human THP-1-derived macrophages and in mice},
journal = {Microbes and Infection},
volume = {26},
number = {3},
pages = {105282},
year = {2024},
issn = {1286-4579},
doi = {https://doi.org/10.1016/j.micinf.2023.105282},
url = {https://www.sciencedirect.com/science/article/pii/S1286457923001958},
author = {Trisha Roy and Anuradha Seth and Hasham Shafi and D.V. Siva Reddy and Sunil Kumar Raman and J.V.U.S. Chakradhar and Sonia Verma and Reena Bharti and Lubna Azmi and Lipika Ray and Amit Misra},
keywords = { H37Rv, SOCS1, SOCS3, Transcription factors, Time kinetics, Host-pathogen interaction},
abstract = {Mycobacterium tuberculosis (Mtb) infection leads to upregulation of Suppressors of Cytokine signaling (SOCS) expression in host macrophages (Mϕ). SOCS proteins inhibit cytokine signaling by negatively regulating JAK/STAT. We investigated this host-pathogen dialectic at the level of transcription. We used phorbol-differentiated THP-1 Mϕ infected with Mtb to investigate preferential upregulation of some SOCS isoforms that are known to inhibit signaling by IFN-γ, IL-12, and IL-6. We examined time kinetics of likely transcription factors and signaling molecules upstream of SOCS transcription, and survival of intracellular Mtb following SOCS upregulation. Our results suggest a plausible mechanism that involves PGE2 secretion during infection to induce the PKA/CREB axis, culminating in nuclear translocation of C/EBPβ to induce expression of SOCS1. Mtb-infected Mϕ secreted IL-10, suggesting a mechanism of induction of STAT3, which may subsequently induce SOCS3. We provide evidence of temporal variation in SOCS isoform exspression and decay. Small-interfering RNA-mediated knockdown of SOCS1 and SOCS3 restored the pro-inflammatory milieu and reduced Mtb viability. In mice infected with Mtb, SOCS isoforms persisted across Days 28–85 post infection. Our results suggest that differential temporal regulation of SOCS isoforms by Mtb drives the host immune response towards a phenotype that facilitates the pathogen's survival.}
}
@article{BAFRANI2024122348,
title = {Investigating the effect of hydraulic residence time, artificial aeration and plants presence on different constructed wetland designs treating oil industry effluent},
journal = {Journal of Environmental Management},
volume = {370},
pages = {122348},
year = {2024},
issn = {0301-4797},
doi = {https://doi.org/10.1016/j.jenvman.2024.122348},
url = {https://www.sciencedirect.com/science/article/pii/S030147972402334X},
author = {Ali Hasani Bafrani and Seyed Ahmad Mirbagheri and Ehsan Shafiepour and Christopher Kinsley and Alexandros Stefanakis},
keywords = {Hybrid constructed wetlands, Industrial wastewater, Nature-based solutions, Nitrogen, Treatment wetlands, Wetland plants},
abstract = {Constructed Wetlands (CW) have gained popularity over the last decades due to their cost-effectiveness, easy and simple operation and environmental compatibility in wastewater treatment. This ecological engineering technology appears particularly ideal for low-income regions. In this study, three widely used CW types (horizontal flow, vertical flow, and hybrid CW) were constructed and evaluated for their effectiveness in removing various pollution parameters (BOD5, COD, TSS, NH4-N, NO3-N, and TP) from an industrial effluent. Different configurations were tested such as CW type, hydraulic residence time, plants presence, and artificial aeration. Results showed that the hybrid CW configuration (i.e., vertical flow CW followed by horizontal subsurface flow CW) achieved the highest removal rates of all pollutants, i.e., more than 90% of BOD5, COD, TSS, and NH4-N. The single horizontal flow and vertical flow CW designs showed variations in the removal of NO3-N and TP (less than 30%), which were significantly improved (50% and 70%, respectively) by using the hybrid CW system. Artificial aeration significantly improves the performance of the CW system, especially for ammonia nitrogen and organic matter removal, while plants presence is also beneficial in the treatment performance. An 8-days HRT seems to be adequate for high removal rates in passive CW designs, though in aerated wetlands a lower HRT of 4 days seems sufficient. These findings suggest that the hybrid CW system could be a promising option for efficient wastewater treatment in developing regions.}
}
@article{GIFU20231058,
title = {An Intelligent System for Detecting Fake News},
journal = {Procedia Computer Science},
volume = {221},
pages = {1058-1065},
year = {2023},
note = {Tenth International Conference on Information Technology and Quantitative Management (ITQM 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.08.088},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923008463},
author = {Daniela Gifu},
keywords = {fake news detection, content generation, news recommender systems, AI},
abstract = {A significant task facing machine learning and natural language processing is real-time recognition of fake news generated automatically. Social media platforms contribute to the spread of uncertain information, context in which people of different backgrounds all over the world interact. The purpose of this work is to demonstrate the significant role of artificial intelligence in the remarkable generation of the content (here, content with a low degree of trust). As a result of this survey, after identifying and analyzing main research trends in fake news detection, current opportunities are highlighted where specific recommendations could be exploited as solutions for users, especially, on social media. Moreover, the experiments show that fake news can be generated easily through various interventions into the true news. It is about the fact distortion, subject-object exchange and cause confounding. Also, this work highlights the power of generating news with suspicious content using different classifiers of fake like Fakebox and the highly publicized ChatGPT.}
}
@article{BAHIRWANI2025,
title = {Relative treatment effects of first-line chemotherapy and immunotherapy for hepatocellular carcinoma: A systematic review and meta-analysis},
journal = {Cancer Pathogenesis and Therapy},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2025.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S2949713225000515},
author = {Janak Bahirwani and Suruchi {Jai Kumar Ahuja} and Madhav Changela and Het Patel and Nishit Patel and Maulik Kaneriya and Vishal Patel},
keywords = {Immunotherapy, Chemotherapy, Progression-free survival, Hepatocellular carcinoma},
abstract = {Background
Hepatocellular carcinoma (HCC) is the most common primary liver malignancy and the fourth most common cause of cancer-related mortality worldwide. Despite advances in immunotherapies and targeted treatments for HCC, chemotherapy remains a valuable first-line treatment. However, the efficacy of immunotherapy compared to that of chemotherapy is unknown. This study aimed to provide a comprehensive understanding of the effects of chemotherapy and immunotherapy on survival outcomes, response rates, and adverse effects.
Methods
A thorough literature search of multiple electronic databases, including MEDLINE (PubMed), Embase, Web of Science, Cochrane Central Register of Controlled Trials, and ClinicalTrials.gov was conducted from database inception to February 2024 to identify randomized controlled trials (RCTs) that compared first-line chemotherapy (doxorubicin, cisplatin, tislelizumab, sorafenib, and fluorouracil) with immunotherapy (pembrolizumab and nivolumab) for advanced HCC. Two reviewers independently identified the studies, obtained relevant information, and assessed the possibility of bias. The hazard ratios (HR) for progression-free survival (PFS) and overall survival (OS) were merged using random effects meta-analysis.
Results
Twenty studies with 1183 patients were examined. All studies had a high risk of bias. According to a meta-analysis, immunotherapy was linked to a significantly better PFS than chemotherapy (HR: 1.44, 95% confidence interval [CI] 1.04–2.00, I2 = 32%). OS showed a similar trend, although the difference was not statistically significant (HR: 1.26, 95% CI 0.96–1.66, I2 = 0%). Sensitivity analysis revealed that immunotherapy continued to improve PFS compared to chemotherapy while having no discernible effect on OS.
Conclusions
First-line immunotherapy may offer PFS advantages over chemotherapy for the treatment of advanced HCC. However, a high risk of bias limits definitive conclusions. Larger, higher-quality RCTs are needed to confirm the potential benefits of OS and minimize bias. Although chemotherapy remains the mainstay of treatment in regions with limited access, the widespread availability of immunotherapy makes it essential to compare both treatments to determine the most appropriate first-line option for advanced HCC.}
}
@article{GAO2024205221,
title = {Fault hazard assessment in shale gas region based on seismicity and stress},
journal = {Gas Science and Engineering},
volume = {122},
pages = {205221},
year = {2024},
issn = {2949-9089},
doi = {https://doi.org/10.1016/j.jgsce.2024.205221},
url = {https://www.sciencedirect.com/science/article/pii/S2949908924000177},
author = {Leiyu Gao and Xiangchao Shi and Cunhui Fan and Xiwen Jia and Jun Hu},
keywords = {Fault geometry, Seismic events, Fault stability, Pore pressure, Hazard assessment},
abstract = {High-pressure hydraulic fracturing and fluid injection greatly improve the production of dense shale gas and present new challenges worldwide. Hazard assessment is important for a wide range of scientific and industrial processes, particularly in oil and gas simulation and production. In this study, we report the geometric characteristics of faults in a shale gas region and perform plane and surface fitting using singular value decomposition and Gaussian process regression, respectively. The critical pore pressure and equivalent density of the critical pore pressure for fault slip were calculated using Coulomb's law, and the influence of parameter uncertainty was evaluated. Based on the relationship between the seismic event and fault, a list of the top 10 faults with seismicity was presented. Finally, geometric data, equivalent density, seismic events, and fault relationships were integrated. Comprehensive fault hazards were evaluated using the principal component analysis method. The results revealed that the fault area in the southeast was large and the depth reached the basement. Most faults tended NE, which was in the direction of easy failure and fault slip. The F92 fault has several seismic events and releases the most energy, ranking first in the top 10 hazardous fault list. These results potentially contribute to determining shale gas well location and trajectory design and reducing seismic hazards. This study enhances our understanding of fault hazard assessments.}
}
@article{TAO2025127863,
title = {Flexible and wearable electrochemical sensors for health and safety monitoring},
journal = {Talanta},
volume = {291},
pages = {127863},
year = {2025},
issn = {0039-9140},
doi = {https://doi.org/10.1016/j.talanta.2025.127863},
url = {https://www.sciencedirect.com/science/article/pii/S0039914025003534},
author = {Dan Tao and Chun Xie and Nicole Jaffrezic-Renault and Zhenzhong Guo},
keywords = {Wearable sensor, Electrochemical sensor, Flexible, Printing technology, Health monitoring, Environmental monitoring},
abstract = {Environmental safety monitoring is a crucial process that involves continuous and systematic observation and analysis of various pollutants in the environment to ensure its quality and safety. This monitoring encompasses a wide range of areas, including physical indicator monitoring (pertaining to parameters such as temperature, humidity, and wind speed), chemical indicator monitoring (focused on detecting harmful substances in environmental media such as air, water, and soil), and ecosystem monitoring (including biodiversity assessments and judgments on the health status of ecosystems). This review delves deeply into the significant advancements achieved in the field of flexible and wearable electrochemical sensors (FWESs) over the past fifteen years (from 2010 to 2024). It emphasizes the broad application of these sensors in health and environmental safety monitoring, with health monitoring primarily focusing on exhaled breath and sweat, and environmental monitoring covering temperature, humidity, and pollutants in air and water. By seamlessly integrating electrochemical principles, advanced sensor manufacturing technologies, and sensor functionalization, FWESs have opened up new avenues for non-invasive real-time monitoring of human health and environmental safety. This review highlights key developments in sensor structures, including flexible substrates, printed electrodes, and active materials. It also underscores the remarkable progress made in healthcare and environmental monitoring through the utilization of FWES. Despite these promising advancements, this emerging field still faces numerous challenges, such as improving sensor accuracy, enhancing durability, and reducing costs. The review concludes by discussing the future directions in this field, including ongoing research efforts aimed at overcoming these challenges and expanding the applications of FWESs in various sectors.}
}
@article{UPADHYAY2025,
title = {Repurposing antibiotics: A dual-action approach against bacteria-induced cancer},
journal = {Cancer Pathogenesis and Therapy},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2025.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S2949713225000254},
author = {Aditya Upadhyay and Hem {Chandra Jha} and Dharm Pal and Awanish Kumar},
keywords = {Bacteria-induced cancer, Pathogenesis, Cellular and molecular basis, Antibiotics repurposing, Cancer prevention and control},
abstract = {Antibiotic resistance and the growing burden of bacteria-induced cancers highlight the urgent need for innovative therapeutic approaches. Drug repurposing, leveraging pre-approved antibiotics for novel applications, is a promising strategy to address this challenge. Antibiotics designed to combat bacterial infections can inhibit microbial activity and target cellular mechanisms associated with oncogenesis. Chronic bacterial infections, such as those caused by Salmonella typhi, Helicobacter pylori, and Escherichia coli, contribute significantly to gallbladder, gastric, kidney, and bladder cancers. These infections induce inflammation, deoxyribonucleic acid (DNA) damage, and the disruption of cellular pathways, promoting the development of cancer. Antibiotics such as doxycycline, rifampicin, and azithromycin demonstrate anticancer properties by inhibiting angiogenesis, inducing apoptosis, and regulating key pathways such as those of interleukin (IL)-6 and autophagy. This dual action enhances chemotherapeutic efficacy and addresses bacteria-induced oncogenesis, offering a cost-effective and time-efficient alternative to traditional drug discovery. Herein, we review the intricate mechanisms by which bacteria-induced cancer arises and explore the groundbreaking potential of repurposing antibiotics as dual-action therapies in oncology. By describing the pivotal role of biofilms in persistent infections and highlighting untapped therapeutic opportunities in antibiotic repurposing, this review underscores a transformative approach to cancer treatment. This article explores the potential of repurposing antibiotic drugs for cancer treatment and highlights the prospects of drug repurposing strategies.}
}
@article{SHI2024127520,
title = {Serum trace elements and osteoarthritis: A meta-analysis and Mendelian randomization study},
journal = {Journal of Trace Elements in Medicine and Biology},
volume = {86},
pages = {127520},
year = {2024},
issn = {0946-672X},
doi = {https://doi.org/10.1016/j.jtemb.2024.127520},
url = {https://www.sciencedirect.com/science/article/pii/S0946672X24001408},
author = {Haoyan Shi and Haochen Wang and Minghao Yu and Jianbang Su and Ze Zhao and Tianqi Gao and Qian Zhang and Yingliang Wei},
keywords = {Osteoarthritis, Trace elements, Copper, Meta-analysis, Mendelian Randomization},
abstract = {Objective
This study aims to establish the correlation between shifts in serum trace element (TE) levels and the progression of osteoarthritis (OA), while also exploring the underlying causal relationship between these variables.
Methods
An investigation was conducted, which included a systematic review, a meta-analysis of observational studies, and a two-sample Mendelian randomization (MR) study.
Results
This meta-analysis revealed significant differences in serum levels of copper, manganese, cadmium, and selenium between OA patients and healthy controls, after adjusting for heterogeneity. Specifically, significant disparities were observed for copper (SMD 0.118 [95 % CI: 0.061 ∼ 0.175], P < 0.001), manganese (SMD −0.180 [95 % CI: −0.326 ∼ −0.034], P = 0.016), cadmium (SMD 0.227 [95 % CI: 0.131 ∼ 0.322], P < 0.001), and selenium (SMD −0.138 [95 % CI: −0.209 ∼ −0.068], P < 0.001), while zinc levels did not show a significant difference (SMD −0.02 [95 % CI: −0.077 ∼ 0.038], P = 0.503). Further, MR analysis suggested a causal link between genetically predicted serum copper level changes and OA development, but not for other TEs.
Conclusion
The study suggests that there is an association between the occurrence of OA and variations in serum levels of copper, manganese, cadmium, and selenium. Elevated serum copper may play a pivotal role. Further research is needed to explore the therapeutic potential of TE level modulation in OA management.}
}
@article{LAI2025,
title = {NEPC-associated CEP55 promotes cisplatin resistance in prostate cancer by regulating CDK1 phosphorylation},
journal = {Cancer Pathogenesis and Therapy},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2025.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S2949713225000771},
author = {Zhuocheng Lai and Chenxi Hu and Jirong Jie and Yongyuan Xiao and Yuanchao Zhu and Xueni Guo and Yintong Liu and Yiwei Wang and Shiyu Pang and Xiangbo Zeng and Wanlong Tan and Qiong Wang},
keywords = {Prostate cancer, Castration-resistant prostate cancer, Neuroendocrine prostate cancer, Cisplatin resistance, },
abstract = {Neuroendocrine prostate cancer (NEPC) is an aggressive subtype of castration-resistant prostate cancer (CRPC) that is typically resistant to nearly all current therapies. In this study, single-cell RNA sequencing (scRNA-seq) and dataset analyses identified Centrosomal Protein 55 (CEP55) as a critical factor in the transformation from hormone-sensitive prostate cancer (HSPC) to CRPC and, ultimately, NEPC. Subsequent bioinformatics analyses and validation with clinical samples demonstrated that CEP55 is significantly upregulated in NEPC tissues compared to HSPC and CRPC. Furthermore, while CEP55 does not appear to be associated with the immune microenvironment or cancer-associated fibroblasts (CAFs), our findings indicate that it directly mediates the plasticity of prostate cancer cells, thereby promoting NEPC progression. Specifically, in vivo and in vitro experiments confirmed that CEP55 enhances cell proliferation, migration, and invasion and the expression of NEPC biomarkers in prostate cancer. Importantly, although cisplatin is the primary treatment for NEPC clinically, CEP55 has been shown to regulate cisplatin resistance through the phosphorylation of CDK1 at the tyrosine 15 (Tyr15) site. In summary, our study identifies a key gene that influences the neuroendocrine differentiation process in prostate cancer, suggesting its potential as an important therapeutic target.}
}
@article{ZENG2025109221,
title = {Poly(Ionic Liquid) matrices embedded with liquid metal particles: A versatile solution for high-power density thermal management},
journal = {Composites Part A: Applied Science and Manufacturing},
volume = {199},
pages = {109221},
year = {2025},
issn = {1359-835X},
doi = {https://doi.org/10.1016/j.compositesa.2025.109221},
url = {https://www.sciencedirect.com/science/article/pii/S1359835X25005159},
author = {Jianhui Zeng and Taoying Rao and Ting Liang and Yimin Yao and Chaoyang Wang and Jian-Bin Xu and Liejun Li and Rong Sun},
keywords = {Thermal interface material, Polymer composite, Poly(ionic liquid), Liquid metal},
abstract = {Amid the global surge in generative AI and the resulting compute revolution, thermal management has emerged to be a pivotal determinant of its success. Innovation in thermal interface materials (TIMs) now represents a strategic frontier in shaping the trajectory of the Fourth Industrial Revolution. Conventional silicone-based TIMs face a performance dilemma comprising thermal cycling-induced interfacial delamination, aging-related increases in interfacial thermal resistance. Building on previous work that introduced poly(ionic liquid)s (PILs) as a novel alternative to silicones, this study further optimizes the molecular structure of PILs. Incorporation of ethoxy groups significantly enhances the mechanical compliance of PIL while maintaining high adhesion strength. Robust hydrogen bonding between ethoxy groups in PIL and liquid metal enables a high loading of 82 vol% without leakage, achieving a thermal conductivity of nearly 5 W m−1 K−1. Meanwhile, strong interfacial adhesion yields a interface contact thermal resistance of 0.74 ± 0.12 × 10-6 m2·K/W between the PIL/LM composite and Si, lower than that of silicone-based TIMs. The noncovalent self-healing of the PIL matrix effectively prevents crack formation in TIMs during aging. This work advances the application of PILs in TIMs and provides strategies for performance optimization, paving the way for their practical deployment as viable matrix alternatives.}
}
@article{RANA2024117550,
title = {Solution spun electrically conductive nylon 6/poly(pyrrole) nanotubes-based composite fibers},
journal = {Synthetic Metals},
volume = {303},
pages = {117550},
year = {2024},
issn = {0379-6779},
doi = {https://doi.org/10.1016/j.synthmet.2024.117550},
url = {https://www.sciencedirect.com/science/article/pii/S0379677924000122},
author = {Kiran Rana and Manjeet Jassal and Ashwini K. Agrawal},
keywords = {Electrically conductive fiber, Solution spinning, Poly(pyrrole), Nylon 6},
abstract = {Wearable electronic device applications require flexible polymer-based conducting fibers. Towards this, various conductive fillers have been used in a polymer matrix. However, it usually requires the addition of a high amount of fillers. In this study, electrically conductive composite fibers of nylon 6 (Ny)-poly(pyrrole) nanotubes (PPyNTs) have been demonstrated using the solution-spinning process. The high aspect ratio of PPyNTs can provide a good electrically conductive network and show a percolation threshold at a low concentration of PPyNTs in a nylon matrix. The composite fibers exhibited good DC electrical conductivity of ∼0.002 S/cm at only 6 wt% of PPyNTs. The influence of PPyNTs concentration on the morphology, physical, chemical, and electrical properties of the fibers have been investigated.}
}
@article{CHARYTAN2025169,
title = {Effects of dialysate potassium concentration of 3.0 mmol/l with sodium zirconium cyclosilicate on dialysis-free days versus dialysate potassium concentration of 2.0 mmol/l alone on rates of cardiac arrhythmias in hemodialysis patients with hyperkalemia},
journal = {Kidney International},
volume = {107},
number = {1},
pages = {169-179},
year = {2025},
issn = {0085-2538},
doi = {https://doi.org/10.1016/j.kint.2024.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S0085253824007221},
author = {David M. Charytan and Wolfgang C. Winkelmayer and Christopher B. Granger and John P. Middleton and Charles A. Herzog and Glenn M. Chertow and James M. Eudicone and Jeremy D. Whitson and James A. Tumlin},
keywords = {arrhythmia, atrial fibrillation, end-stage kidney disease, hemodialysis, potassium, sodium zirconium cyclosilicate},
abstract = {The optimal approach towards managing serum potassium (sK+) and hemodialysate potassium concentrations is uncertain. To study this, adults receiving hemodialysis for three months or more with hyperkalemia (pre-dialysis sK+ 5.1–6.5 mmol/l) had cardiac monitors implanted and were randomized to either eight weeks of 2.0 mmol/l potassium/1.25 mmol/l calcium dialysate without sodium zirconium cyclosilicate (SZC) (2.0 potassium/noSZC) or 3.0 mmol/l potassium/1.25 mmol/l calcium dialysate combined with SZC (3.0 potassium/SZC) on non-dialysis days to maintain pre-dialysis sK+ 4.0–5.5 mmol/l, followed by treatment crossover for another eight weeks. The primary outcome was the rate of adjudicated atrial fibrillation (AF) episodes of at least 2 minutes duration. Secondary outcomes included clinically significant arrhythmias (bradycardia, ventricular tachycardia, and/or asystole) and the proportion of sK+ measurements within an optimal window of 4.0–5.5 mmol/l. Among 88 participants (mean age: 57.1 years; 51% male; mean pre-dialysis sK+: 5.5 mmol/l) with 25.5 person-years of follow-up, 296 AF episodes were detected in nine patients. The unadjusted AF rate was lower with 3.0 potassium/SZC versus 2.0 potassium/noSZC; 9.7 vs. 13.4/person-year (modeled rate ratio 0.52; 95% confidence interval 0.41–0.65). Clinically significant arrhythmias were reduced with 3.0 potassium/SZC vs. 2.0 potassium/noSZC (6.8 vs. 10.2/person-year modeled rate ratio 0.47; 0.38; 0.58). Fewer sK+ measurements outside the optimal window occurred with 3.0 potassium/SZC (modeled odds ratio: 0.27; 0.21–0.35). Hypokalemia was less frequent (33 vs. 58 patients) with 3.0 potassium/SZC compared with 2.0 potassium/noSZC. Thus, in patients with hyperkalemia on maintenance hemodialysis, a combination of hemodialysate potassium 3.0 mmol/l and SZC on non-hemodialysis days reduced the rates of AF, other clinically significant arrhythmias, and post-dialysis hypokalemia compared with hemodialysate potassium 2.0/noSZC.}
}
@article{VANMALI2024887,
title = {Cardiovascular Magnetic Resonance-Based Tissue Characterization in Patients With Hypertrophic Cardiomyopathy},
journal = {Canadian Journal of Cardiology},
volume = {40},
number = {5},
pages = {887-898},
year = {2024},
note = {Focus Issue: Hypertrophic Cardiomyopathy in Rapid Evolution},
issn = {0828-282X},
doi = {https://doi.org/10.1016/j.cjca.2024.02.029},
url = {https://www.sciencedirect.com/science/article/pii/S0828282X24002022},
author = {Atish Vanmali and Waleed Alhumaid and James A. White},
abstract = {Hypertrophic cardiomyopathy (HCM) is a common hereditable cardiomyopathy that affects between 1:200 to 1:500 of the general population. The role of cardiovascular magnetic resonance (CMR) imaging in the management of HCM has expanded over the past 2 decades to become a key informant of risk in this patient population, delivering unique insights into tissue health and its influence on future outcomes. Numerous mature CMR-based techniques are clinically available for the interrogation of tissue health in patients with HCM, inclusive of contrast and noncontrast methods. Late gadolinium enhancement imaging remains a cornerstone technique for the identification and quantification of myocardial fibrosis with large cumulative evidence supporting value for the prediction of arrhythmic outcomes. T1 mapping delivers improved fidelity for fibrosis quantification through direct estimations of extracellular volume fraction but also offers potential for noncontrast surrogate assessments of tissue health. Water-sensitive imaging, inclusive of T2-weighted dark blood imaging and T2 mapping, have also shown preliminary potential for assisting in risk discrimination. Finally, emerging techniques, inclusive of innovative multiparametric methods, are expanding the utility of CMR to assist in the delivery of comprehensive tissue characterization toward the delivery of personalized HCM care. In this narrative review we summarize the contemporary landscape of CMR techniques aimed at characterizing tissue health in patients with HCM. The value of these respective techniques to identify patients at elevated risk of future cardiovascular outcomes are highlighted.
Résumé
La cardiomyopathie hypertrophique (CMH) est une cardiomyopathie héréditaire courante qui affecte entre 1 : 200 et 1 : 500 de la population générale. Le rôle de l'imagerie par résonance magnétique cardiovasculaire (IRM-C) dans la prise en charge de la CMH s'est développé au cours des deux dernières décennies pour devenir un élément clé informant du risque pour cette population de patients, fournissant des informations uniques relatives à la santé des tissus et son influence sur les pronostics. De nombreuses techniques matures basées sur l'IRM-C sont disponibles en clinique pour examiner l'état de santé des tissus chez les patients atteints de CMH, incluant des méthodes avec et sans contraste. L'imagerie de rehaussement tardif au gadolinium reste une technique de base pour l'identification et la quantification de la fibrose myocardique, avec de nombreuses preuves cumulées soutenant sa valeur pour la prédiction des résultats arythmiques. La cartographie T1 offre une fidélité améliorée pour la quantification de la fibrose grâce à des estimations directes de la fraction du volume extracellulaire, mais elle offre également un potentiel pour des évaluations substitutives sans contraste de l'état de santé du tissu. L'imagerie, sensible au contenu en eau des tissus, y compris l'imagerie à contraste « sang noir » pondérée en T2 et la cartographie du temps de relaxation transversal T2, a également montré un potentiel préliminaire pour aider à la discrimination du risque. Enfin, les techniques émergentes, incluant des méthodes multiparamétriques innovantes, élargissent l'utilité de l'IRM-C pour aider à la caractérisation complète des tissus en vue d'une prise en charge personnalisée de la CMH. Dans cette revue narrative, nous résumons le panorama actuel des techniques d'IRM-C visant à caractériser l'état de santé des tissus chez les patients atteints de CMH. L'intérêt de ces techniques respectives pour identifier les patients présentant un risque élevé d'effets cardiovasculaires futurs est mis en évidence.}
}
@article{SAEKI2024102049,
title = {Choice between post-reinforcer delays in pigeons: Effects of stimulus continuity and response requirement},
journal = {Learning and Motivation},
volume = {88},
pages = {102049},
year = {2024},
issn = {0023-9690},
doi = {https://doi.org/10.1016/j.lmot.2024.102049},
url = {https://www.sciencedirect.com/science/article/pii/S0023969024000912},
author = {Daisuke Saeki and Tetsuo Yamaguchi},
keywords = {Post-reinforcer delay, Stimulus continuity, Response requirement, Choice, Pigeon},
abstract = {This study examined the effects of stimulus continuity and response requirements on pigeon choices between post-reinforcer delays (from 2 s to 8 s) using concurrent-chains schedules with FR 1 schedules arranged for the choice phase. In Experiment 1, using seven pigeons, the effect of stimulus continuity, the presentation of the same stimulus (background color of the computer screen) during the post-reinforcer delay period as in the pre-reinforcer delay period, was examined. In Experiment 2, the effect of stimulus continuity was examined under the conditions where a response was required (FR 1) to initiate the post-reinforcer delay using eight pigeons. The experimental results indicated that when the same stimulus as in the pre-reinforcer delay was presented continuously during the post-reinforcer delay and a response was required to start the post-reinforcer delay, the subjects showed relatively high sensitivity to differences between post-reinforcer delays. The implications of the results are discussed from a new perspective for the analysis of self-control choices.}
}
@article{SHEN2024212902,
title = {A model for evaluating fracture leakage based on variations in bottom-hole temperature and pressure during the fracturing process},
journal = {Geoenergy Science and Engineering},
volume = {238},
pages = {212902},
year = {2024},
issn = {2949-8910},
doi = {https://doi.org/10.1016/j.geoen.2024.212902},
url = {https://www.sciencedirect.com/science/article/pii/S2949891024002720},
author = {Zhaolong Shen and Guofa Ji},
keywords = {Fracturing, Unconventional oil and gas, Fracture leakage, Leakage temperature and pressure},
abstract = {During the large-scale fracturing and exploitation of unconventional reservoirs, artificial fractures progressively widen in reservoirs with natural fracture development, which is highly prone to fracture leakage between segment clusters, thereby impacting the complexity of fracture networks. Nevertheless, the existing research on the evaluation model of fracture leakage in the fracturing process is limited and lacks precise predictive capabilities. The model has been developed to assess the variations in bottom hole pressure and bottom hole temperature during fracture extension by considering the combined effects of pressure loss, temperature exchange, along-track drag, static column pressure, and integrated heat transfer among the fracturing fluid, tubing wall, annulus, casing wall, and formation. The model is capable of evaluating the occurrence of fracture leakage by analyzing the extent of temperature and pressure variations at the base of the wellbore. The study findings compare the temperature and pressure data from 14 out of 144 actual fracture leakage sections of three wells monitored in an oilfield, and it is believed that the situation of fracture leakage can be identified when the predicted temperature changes fall within the range of −2.95 °C–7.53 °C, and the predicted pressure changes range from −0.87 MPa to 6.55 MPa. The model yields an average error of 4.09% for pressure and 5.73% for temperature. Moreover, the model demonstrates high overall prediction accuracy, which holds significant implications for promptly identifying inter-segmental fracture leakage and facilitating the efficient development of oil and gas fields.}
}
@article{PAAUWE2025101076,
title = {Bridging the research-practice gap in modern human resource management},
journal = {Human Resource Management Review},
volume = {35},
number = {2},
pages = {101076},
year = {2025},
issn = {1053-4822},
doi = {https://doi.org/10.1016/j.hrmr.2025.101076},
url = {https://www.sciencedirect.com/science/article/pii/S1053482225000014},
author = {Jaap Paauwe and Karina {Van De Voorde}},
keywords = {Knowledge transfer challenge, Knowledge production challenge, Human resource management science-practice gap},
abstract = {As an applied field of management, human resource management (HRM) scholars strive to impact practice, which is still considered a major challenge. This paper focuses on how academic work can be meaningfully integrated with modern HRM practice by showing how rigorous academic work can successfully inform HRM in practice and how scholars and practitioners can co-create rigorous and relevant HRM knowledge. In particular, we illustrate how theoretical insights connected to the shaping, implementation, embeddedness, impact, and effectiveness of HRM practices are helpful in addressing core questions related to progress in a practical way, well-being, and performance at work. In addition, we show how HRM scholars and practitioners can collectively develop knowledge about emerging HRM topics through co-sponsored PhD research. We conclude by reflecting upon the role of academia and practice in bridging the HRM's science-practice gap.}
}
@article{HEMALATHA2024138322,
title = {Indole-imidazole hybrid Schiff base for the selective detection of the explosive picric acid via fluorescence “turn-off” process: Experimental and theoretical DFT-D3 study},
journal = {Journal of Molecular Structure},
volume = {1311},
pages = {138322},
year = {2024},
issn = {0022-2860},
doi = {https://doi.org/10.1016/j.molstruc.2024.138322},
url = {https://www.sciencedirect.com/science/article/pii/S0022286024008421},
author = {V. Hemalatha and V. Vijayakumar},
keywords = {Indole imidazole hybrid Schiff base, Turn-off sensor, ICT-PET-FRET, Picric acid, TEA treatment},
abstract = {A compound containing a heteroatom and Schiff base, 3-(4,5-Diphenyl-1H-imidazol-2-yl)-1H-indole (INBIL) has been synthesized through the one-pot condensation of indole-3-carbaldehyde with benzil in ethanol and characterized using various analytical parameters like FT-IR, NMR; its thermal and chemical stability also established. The synthesized INBIL showed a 'turn off' luminescent property that has been used to detect picric acid. This luminescent sensor has a broad emission band at 415 nm in acetonitrile due to the conjugation of its double bond. It is worth noting that INBIL can be recycled through TEA treatment. The chemosensor exhibited the highest sensitivity with Ksv = 1.51 × 10−6 M, and a detection limit of 2.91 × 10−7 M, with perfect linearity up to 22 µL. The binding stoichiometry ratio between INBIL and picric acid was predicted to be 1:1 using Job's plot, which was confirmed by 1H NMR analysis. Finally, DFT-D3 calculations were used to calculate the excited molecule's singlet and triplet energy states.}
}
@article{MUTAVHATSINDI2024106173,
title = {Baseline and end-of-treatment host serum biomarkers predict relapse in adults with pulmonary tuberculosis},
journal = {Journal of Infection},
volume = {89},
number = {1},
pages = {106173},
year = {2024},
issn = {0163-4453},
doi = {https://doi.org/10.1016/j.jinf.2024.106173},
url = {https://www.sciencedirect.com/science/article/pii/S0163445324001075},
author = {Hygon Mutavhatsindi and Charles M. Manyelo and Candice I. Snyders and Ilana {Van Rensburg} and Martin Kidd and Kim Stanley and Gerard Tromp and Reynaldo Dietze and Bonnie Thiel and Paul D. {van Helden} and John T. Belisle and John L. Johnson and W. Henry Boom and Gerhard Walzl and Novel N. Chegou},
keywords = {Tuberculosis, Treatment response, Relapse, Biomarkers, Biosignatures},
abstract = {Summary
Background
There is a need for new tools for monitoring of the response to TB treatment. Such tools may allow for tailored treatment regimens, and stratify patients initiating TB treatment into different risk groups. We evaluated combinations between previously published host biomarkers and new candidates, as tools for monitoring TB treatment response, and prediction of relapse.
Methods
Serum samples were collected at multiple time points, from patients initiating TB treatment at research sites situated in South Africa (ActionTB study), Brazil and Uganda (TBRU study). Using a multiplex immunoassay platform, we evaluated the concentrations of selected host inflammatory biomarkers in sera obtained from clinically cured patients with and without subsequent relapse within 2 years of TB treatment completion.
Results
A total of 130 TB patients, 30 (23%) of whom had confirmed relapse were included in the study. The median time to relapse was 9.7 months in the ActionTB study (n = 12 patients who relapsed), and 5 months (n = 18 patients who relapsed) in the TBRU study. Serum concentrations of several host biomarkers changed during TB treatment with IL-6, IP-10, IL-22 and complement C3 showing potential individually, in predicting relapse. A six-marker signature comprising of TTP, BMI, sICAM-1, IL-22, IL-1β and complement C3, predicted relapse, prior to the onset of TB treatment with 89% sensitivity and 94% specificity. Furthermore, a 3-marker signature (Apo-CIII, IP-10 and sIL-6R) predicted relapse in samples collected at the end of TB treatment with sensitivity of 71% and specificity of 74%. A previously identified baseline relapse prediction signature (TTP, BMI, TNF-β, sIL-6R, IL-12p40 and IP-10) also showed potential in the current study.
Conclusion
Serum host inflammatory biomarkers may be useful in predicting relapse in TB patients prior to the initiation of treatment. Our findings have implications for tailored patient management and require prospective evaluation in larger studies.}
}
@article{WANG2024235417,
title = {A multi-dimensional machine learning framework for accurate and efficient battery state of charge estimation},
journal = {Journal of Power Sources},
volume = {623},
pages = {235417},
year = {2024},
issn = {0378-7753},
doi = {https://doi.org/10.1016/j.jpowsour.2024.235417},
url = {https://www.sciencedirect.com/science/article/pii/S0378775324013697},
author = {Sijing Wang and Meiyuan Jiao and Ruoyu Zhou and Yijia Ren and Honglai Liu and Cheng Lian},
keywords = {State of charge, Median filtering, Continuous wavelet transform, Feature cross, Random forest},
abstract = {Accurate state of charge (SOC) estimation is essential for battery safe and efficient utilization. As artificial intelligence technologies evolve, data-driven methods have become mainstream for estimating SOC. However, the technique can significantly deteriorate model performance when encountering poor or insufficient data quality. In this paper, we apply median filtering to eliminate extreme noise and utilize continuous wavelet transform to extract time-frequency features from voltage signals. Additionally, we generate novel features via feature crossing. We then apply dimensionality reduction via the random forest method to decrease computational expense. Finally, we select a convolutional neural network (CNN) as the base model to learn optimized features for more precise SOC estimation. To confirm the efficacy of our proposed method, this study compares it with CNN, long short-term memory (LSTM), bidirectional LSTM (BILSTM), and a CNN-BILSTM model combined with an attention mechanism. These comparisons are conducted under different temperatures and operating conditions. The results indicate that this method achieves a mean absolute error and a root mean square error of less than 2.89 % and 3.71 %, respectively, in SOC estimation, demonstrating superior accuracy compared to other models. This study underscores the significance of feature engineering techniques in SOC estimation.}
}