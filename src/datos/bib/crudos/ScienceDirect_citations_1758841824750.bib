@article{GUO2025122905,
title = {Biologically logic-gated Trojan-horse strategy for personalized triple-negative breast cancer precise therapy by selective ferroptosis and STING pathway provoking},
journal = {Biomaterials},
volume = {315},
pages = {122905},
year = {2025},
issn = {0142-9612},
doi = {https://doi.org/10.1016/j.biomaterials.2024.122905},
url = {https://www.sciencedirect.com/science/article/pii/S0142961224004393},
author = {Shuai Guo and Tianwang Guan and Yushen Ke and Yuping Lin and Rundong Tai and Jujian Ye and Zhilin Deng and Shaohui Deng and Caiwen Ou},
keywords = {Biological logic-gate, Stimulator interferon genes (STING) pathway, Ferroptosis, Triple-negative breast cancer (TNBC), Trojan-horse strategy},
abstract = {Amidst the therapeutic quandaries associated with triple-negative breast cancer (TNBC), an aggressive malignancy distinguished by its immune resistance and limited treatment avenues, the urgent need for innovative solutions is underscored. To conquer the dilemma, we present a groundbreaking approach that ingeniously employs DNA-fragments-containing exosomes (DNA-Exo) and the concept of “biological logic-gates” to achieve precise homing and controlled selective activation of ferroptosis and stimulator interferon genes (STING) pathways. Leveraging insights from our previous research, a nano-Trojan-horse, Fe0@HMON@DNA-Exo, is engineered via in situ Fe0 synthesis within the glutathione (GSH)-responsiveness degradable hollow mesoporous organosilica nanoparticles (HMON) and subsequently enveloped in DNA-Exo derived from 7-ethyl-10-hydroxycamptothecin (SN38)-treated 4T1 cells. Emphasizing the precision of our approach, the DNA-Exo ensures specific ‘homing’ to TNBC cells, rendering a targeted delivery mechanism. Concurrently, the concept of “biological logic-gates” is employed to dictate a meticulous and selective activation of STING in antigen-presenting cells (APCs) under OR logic-gating with robust immune response and Fe0-based ferroptosis in TNBC cells under AND logic-gating with reactive oxygen species (ROS) storm generation. In essence, our strategy exhibits great potential in transforming the “immunologically cold” nature of TNBC, enabling precise control over cellular responses, illuminating a promising therapeutic paradigm that is comprehensive and productive in pursuing precision oncology and paving the way for personalized TNBC therapies.}
}
@article{DIPAOLO2025105072,
title = {Leveraging social capital for destination promotion in the metaverse: The Enoverse case},
journal = {Tourism Management},
volume = {107},
pages = {105072},
year = {2025},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2024.105072},
url = {https://www.sciencedirect.com/science/article/pii/S0261517724001912},
author = {Francesco {Di Paolo} and Debora Bettiga and Lucio Lamberti},
abstract = {This study examines the challenges of metaverse-driven community innovation in the context of rural tourism. Through an in-depth case study, we analyse the social capital dynamics within an Italian winery consortium that ventured into the metaverse through a project called Enoverse to promote local wine and rural territory. The results show that the complexity and novelty inherent in the implementation of a presence in the metaverse to provide a consistent and authentic territorial and product experience requires and fosters stakeholder cohesion and participation. This promotes tourism by enhancing stakeholder engagement, inclusion, and satisfaction. Drawing on social capital theory, the establishment of network mechanisms and actor connectivity facilitates innovative promotion of rural destinations. This study contributes to the growing body of literature on the role of virtual environments in promoting tourism, specifically in the wine industry.}
}
@article{HUA2025104119,
title = {Macroeconomic effects of CBDC negative interest policy in an open economy: A comparison of quantity and price rules},
journal = {International Review of Economics & Finance},
volume = {100},
pages = {104119},
year = {2025},
issn = {1059-0560},
doi = {https://doi.org/10.1016/j.iref.2025.104119},
url = {https://www.sciencedirect.com/science/article/pii/S1059056025002825},
author = {Qiuling Hua and Zepeng Qiu and Tingfeng Jiang and Ke Tang},
keywords = {CBDC, Negative interest rate, Quantity-based monetary policy, Price-based monetary policy},
abstract = {We construct a Dynamic Stochastic General Equilibrium (DSGE) model of a small open economy to investigate the effects of central bank digital currency (CBDC) negative interest rates on various sectors of the macroeconomy. Furthermore, we analyze the heterogeneous responses of quantity-based and price-based monetary policies. Our findings can be summarized as follows. (1) In an open economy, the CBDC negative interest rate policy can enhance the central bank's macroeconomic regulatory capacity during recessions by breaking the zero lower bound constraint on deposit interest rates. This provides a novel monetary policy tool to prevent "liquidity trap". (2) CBDC negative interest rates can strengthen the effectiveness of the quantity-based and price-based monetary policies. Specifically, it not only amplifies the short-term effects of quantity-based monetary policy and the medium- and long-term effects of price-based monetary policy, but also prolongs the effective duration of quantity-based monetary policy and reduces the transmission time lag of price-based monetary policy. (3) CBDC negative interest rates can strengthen the linkage between long-term and short-term monetary policy tools, increase the sensitivity of macroeconomic sectors to foreign monetary policy shocks, and enhance the smooth functioning of the monetary policy transmission mechanism.}
}
@article{MAZIRIRI2024100051,
title = {From perceived parental entrepreneurial passion to technopreneurship intention: The moderating role of perseverance and perceived parental entrepreneurial rewards},
journal = {Sustainable Technology and Entrepreneurship},
volume = {3},
number = {1},
pages = {100051},
year = {2024},
issn = {2773-0328},
doi = {https://doi.org/10.1016/j.stae.2023.100051},
url = {https://www.sciencedirect.com/science/article/pii/S2773032823000147},
author = {Eugine Tafadzwa Maziriri and Mufaro Dzingirai and Brighton Nyagadza and Brian Mabuyana},
keywords = {Technopreneurship, Technopreneurship intention, Parental entrepreneurship, Passion, Parental entrepreneurial rewards},
abstract = {In light of significant advancements in both theoretical and practical aspects of technopreneurship, supported by empirical research, there remains an unexplored area within the academic domain pertaining to the impact of perceived parents’ entrepreneurial passion towards a career in technopreneurship and technopreneurship intention among Generation Z students remains unexplored in the academic domain. This study thus aims to examine how perceived parents’ entrepreneurial passion, perceived desirability and perceived feasibility would stimulate attitude towards a career in technopreneurship and technopreneurship intention among Generation Z students in Zimbabwe. It is based on a nomothetic quantitative methodology, where a survey was applied to collect responses from Generation Z university students in the Harare Metropolitan Province of Zimbabwe. Through structural equation modelling, the findings are validated, confirming that perceived parents’ entrepreneurial passion, perceived desirability and perceived feasibility do indeed influence attitudes towards pursuing a career in technopreneurship. The study also discovered that attitude towards a career in technopreneurship has a positive and a significant impact on technopreneurship intention. Moreover, the results support the moderation role of perseverance and perceived parental entrepreneurial rewards on the nexus between attitude towards a career in technopreneurship and technopreneurship intention. Based on the results, the study concludes that perceived parents’ entrepreneurial passion, perceived desirability and perceived feasibility would stimulate attitude towards a career in technopreneurship and technopreneurship intention among Generation Z students.}
}
@article{WANG2025100449,
title = {Challenges and perspectives towards multi-physics modeling for porous electrode of ultrahigh performance durable polymer electrolyte membrane fuel cells},
journal = {eTransportation},
volume = {25},
pages = {100449},
year = {2025},
issn = {2590-1168},
doi = {https://doi.org/10.1016/j.etran.2025.100449},
url = {https://www.sciencedirect.com/science/article/pii/S2590116825000566},
author = {Ning Wang and Tao Lai and Wenkai Wang and Zhiguo Qu and Xuhui Wen and Guangyou Xie and Wenquan Tao},
keywords = {PEMFCs, Porous electrodes, Multi-physics transfers, Cross-scale modeling, Perspective},
abstract = {The development of ultrahigh-performance, durable polymer electrolyte membrane fuel cells (PEMFCs) is crucial for achieving large-scale commercialization. A comprehensive insight into multi-physics phenomena within advanced porous electrode designs provide motivation for the ambitious targets. Modeling is an indispensable tool in multi-physics transfer understanding and offers a promising pathway for electrode structural designs and material architecture selections. Despite the progress, the modeling community continues to face significant challenges, including oversimplification, difficulties in coupling complex features, unclear physical knowledge, and unavoidable discrepancies. This perspective highlights the current status of porous electrode modeling, identifies ongoing challenges, and explores future directions for key technologies and potential countermeasures. Specifically, the characteristics and limitations of macro-scale, meso-scale, and micro-scale models regarding intricate porous electrode microstructures are compared, including ordered structure, mesoporous carbon support, various catalyst architectures, etc. Potential solutions to these challenges are proposed for the next generation of porous electrode designs. Furthermore, three alternatives to advancing cross-scale, full-morphology, and full-coupling modeling are developed and discussed, including layer-by-layer physical property transfer, interfacial data transfer and direct numerical simulation, and data-driven assisted cross-scale modeling, which are expected to be evaluated and validated in the foreseeable future.}
}
@article{ZHANG2024100115,
title = {Researching L2 investment in EMI courses: Techno-reflective narrative interviews},
journal = {Research Methods in Applied Linguistics},
volume = {3},
number = {2},
pages = {100115},
year = {2024},
issn = {2772-7661},
doi = {https://doi.org/10.1016/j.rmal.2024.100115},
url = {https://www.sciencedirect.com/science/article/pii/S2772766124000211},
author = {Yue Zhang},
keywords = {Investment, L2 investment, Identity, Translanguaging, Interview},
abstract = {In response to the call for integrating a praxis orientation to understand processes of language development through active engagement with teachers and learners, this article introduces techno-reflective narrative interview (TRNI) as a tool to understand how learners invest in their English as a second language (ESL) language and literacy practices as social practices in English medium instruction (EMI) courses. It is timely in integrating both technical and critical guidance for methodological innovations in the field of applied linguistics. To illustrate how this aim is achieved, this article first justifies the significance and theoretical basis of TRNI by elaborating on the definitions of and underpinning rationale for it, followed by the relationship among second language (L2) learners, investment, and TRNI. It then discusses the methods adopted by the 69 most cited empirical studies from Google Scholar that used the model of L2 investment as the theoretical model and compares these methods with TRNI. Finally, it discusses how TRNI was developed and adopted in two action research projects conducted by the author and two lecturers among local undergraduate students in the Hong Kong context. Through these steps, I demonstrate how TRNIs can be adopted or adapted to provide an interactive space for ESL learners to reconstruct and perform their English speaker and learner identities, share their learning experiences with the agency to introduce their positions, voices, and stories, and therefore, claim legitimacy as English users in EMI courses.}
}
@article{WANG2025111077,
title = {Toward sustainable diffusion-based AIGC: Design and online orchestration in distributed edge networks},
journal = {Computer Networks},
volume = {259},
pages = {111077},
year = {2025},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2025.111077},
url = {https://www.sciencedirect.com/science/article/pii/S1389128625000453},
author = {Fei Wang and Lei Jiao and Konglin Zhu and Lingjun Pu and Lin Zhang},
keywords = {AIGC, Edge networks, Diffusion model, Fine-tuning, Online optimization},
abstract = {Artificial intelligence-generated content (AIGC) is an automated method that generates the content according to its knowledge and the intent information. Deploying the AIGC model in edge networks unlocks new possibilities. Unfortunately, realizing AIGC in distributed edge networks faces critical challenges, including the interdependent control decisions, the complex trade-offs between energy consumption and total variation (TV) distance, the extension of TV distance due to insufficient denoising steps, the restriction of AIGC inferencing deadlines, and the uncertainty of AIGC task arrivals. In this paper, targeting AIGC tasks, we design polynomial-time online algorithms to overcome all these challenges. Firstly, we formulate distributed AIGC as a non-linear mixed-integer program for long-term total cost optimization. Subsequently, we propose a novel algorithmic approach that generates candidate inferencing schedules, reformulates the original problem into a new schedule selection problem, and solves this new problem using an online primal–dual-based algorithm. Moreover, we rigorously prove that our approach leads to a constant competitive ratio for the long-term total cost. Through extensive evaluations using real-world data, the superior practical performance of our approach is demonstrated, reducing the total cost by more than 50% compared to various alternative methods.}
}
@article{BECKER2024103917,
title = {System shift in rice: Processes and pathways of change in rice-based production systems of Southeast Asia},
journal = {Agricultural Systems},
volume = {217},
pages = {103917},
year = {2024},
issn = {0308-521X},
doi = {https://doi.org/10.1016/j.agsy.2024.103917},
url = {https://www.sciencedirect.com/science/article/pii/S0308521X24000672},
author = {Mathias Becker and Richelyn Clavero and Ohnmar Min Khin and Sichantha Kong and Zar Ni Maung and Punlork Men and Shyam Pariyar and Manuel José C. Regalado and Sophoanrith Ro and Kyaw Kyaw Win},
keywords = {Cambodia, Diversification, Myanmar, , Philippines, Sustainable intensification, System shifts},
abstract = {CONTEXT
Predicting future production trends and associated land use and management practices requires an understanding of past changes in productivity and of pathways of evolving system configurations. We argue that rice systems' evolution reflects a process of adaptation to changing availabilities of production resources and the adoption of technological innovations and that differs by marginality/favorability of sites. Understanding past change trends and their determinants can help avoiding undesirable future developments and guide policy decisions for a sustained supply of rice.
OBJECTIVE
We aimed to assess agronomic system change and practices, to quantify pathways of change and to identify likely drivers of but also possible risks or opportunities associated with observed patterns of agronomic system transformation in six representative lowland rice production environments in Asia.
METHODS
We implemented a diachronic analysis (years 2000 vs. 2018) of rice production practices and yield attributes in 1024 households. We documented changes between 2000 and 2018 in lowland rice-based systems in six rice-growing environments in the Philippines, Myanmar and Cambodia, differentiating marginal and favorable sites in irrigated and in rainfed environments.
RESULTS AND CONCLUSION
Farmers' household attributes, resource endowment, rice yields, and key constraints differed among sites. We observed relatively low annual yield in marginal (2.2–3.0 t/ ha) than favorable (3.3–8.9 t/ ha) sites depending on countries and seasons. The farmers adopted intensification related agronomic practices has increased significantly between 2000 and 2018, especially in dry season (i.e., improved seeds by 28%, mechanical tillage by 52%, direct seeding by 21%, combined harvester by 62%). The marginality of climatic and edaphic conditions, the systems' evolutionary state in 2000, and differential pressures (policy environment), opportunities (technological change) and household attributes (resource endowment) determined the observed transition pathways across study sites.
SIGNIFICANCE
The trends towards maximizing land use intensity (double or multiple cropping), converging in the emergence of high-input and highly mechanized (laborsaving) in irrigated, and diversified rotations in rainfed rice production systems may help to elucidate agricultural research needs and potentially predict the requirements for future sustainable intensification of rice-based systems. Additionally, we argue for a continued need for further mechanization of rice establishment, especially shifting from transplanting to direct seeding during dry and wet seasons, and of the rice harvest, especially during wet season under fully irrigated environments.}
}
@article{STREMERSCH20241,
title = {How can academics generate great research ideas? Inspiration from ideation practice},
journal = {International Journal of Research in Marketing},
volume = {41},
number = {1},
pages = {1-17},
year = {2024},
issn = {0167-8116},
doi = {https://doi.org/10.1016/j.ijresmar.2023.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S016781162300071X},
author = {Stefan Stremersch},
keywords = {Research, Ideation, Innovation, Scientometrics, Marketing},
abstract = {How can academic scholars come up with great ideas, such that their research becomes even more important, relevant, and interesting? Based on ideation practices of sophisticated companies, this paper triggers academic researchers to self-reflect on: (1) the source used for ideation, (2) the scope applied to ideation, (3) the sharing of ideas during ideation, and (4) the selection of ideas. The paper also offers concrete improvements that researchers can implement in their ideation practices on ideation processes, tools, and methods along three ideation phases: domain exploration, domain immersion, and research project design. It reviews recent advances in AI and how researchers can leverage AI in their research ideation. The paper aims to stimulate more research on (academic) research ideation (i.e., “more research on research”) and advances a research agenda.}
}
@incollection{2023443,
title = {Index},
editor = {Kevin Gillmann and Kaweh Mansouri},
booktitle = {The Science of Glaucoma Management},
publisher = {Academic Press},
pages = {443-458},
year = {2023},
isbn = {978-0-323-88442-6},
doi = {https://doi.org/10.1016/B978-0-323-88442-6.00049-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780323884426000492}
}
@article{HE2025105245,
title = {A systematic review of the use of log-based process data in computer-based assessments},
journal = {Computers & Education},
volume = {228},
pages = {105245},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105245},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525000132},
author = {Surina He and Ying Cui},
keywords = {Computer-based assessment, Log-based process data, Systematic review},
abstract = {In recent decades, log-based process data has been increasingly used in computer-based assessments to examine test-takers' response patterns and latent traits. This study provides a systematic review of the use of log-based process data in computer-based assessments. Following the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guideline, we identified 2548 publications, of which 330 were finally included in this study after careful screening and full-text review. The results of this study can assist researchers in better understanding: (1) what are the trends in using log-based process data in computer-based assessments, (2) which process indicators have been constructed from raw log files, (3) what latent constructs have been inferred from process indicators and at what inferential levels, and (4) what are the benefits, challenges, and future recommendations for using log-based process data. By examining these questions, we conclude that the use of log-based process data in computer-based assessment shows many potentials for enhancing the assessment. Therefore, more study using log-based process data in various fields is encouraged to better understand test-takers’ underlying response processes during assessments. Additionally, there is also a considerable demand for validating process indicators and the generalizability of findings.}
}
@article{AN2025128684,
title = {Machine learning-assisted development of conductive polymers},
journal = {Polymer},
volume = {333},
pages = {128684},
year = {2025},
issn = {0032-3861},
doi = {https://doi.org/10.1016/j.polymer.2025.128684},
url = {https://www.sciencedirect.com/science/article/pii/S0032386125006706},
author = {Jin An and Tailai Chen and Hossein Pouri and Tianlong Liu and Jin Zhang},
keywords = {Machine learning, Conductive polymers, Interdisciplinary integration, Computational analysis},
abstract = {Machine learning (ML) techniques are increasingly being used to predict and enhance the performance of new materials, including conductive polymers, which are valued for their unique electrical properties. These materials are crucial for a range of applications, such as electronics, energy storage, and sensors. This paper provides a comprehensive review of the properties and applications of major types of conductive polymers, including intrinsic, doped, and nanocomposite-based systems. The concept of “Face IDs” is introduced as an analogy for the key chemical features and properties of conductive polymers, helping to translate complex chemical structures, fabrication parameters, and performance indicators into machine-readable descriptors. This approach bridges experimental polymer science with advanced data-driven methodologies. Additionally, the paper explores the current progress of ML-assisted design in advancing conductive polymers, with a focus on optimizing properties such as electrical conductivity, mechanical strength, and thermal stability. However, challenges persist in applying ML for the development of new conductive polymers with desired properties, such as the limited availability of high-quality datasets, the complexity of polymer structures, and the need for better models for reverse design. This review aims to facilitate collaboration between researchers in the fields of polymer science and ML, highlighting the potential of interdisciplinary efforts to drive innovation in the development of next-generation conductive polymers.}
}
@article{ZHOU2024117951,
title = {Machine learning models of intermittent operation of RO wellhead water treatment for salinity reduction and nitrate removal},
journal = {Desalination},
volume = {588},
pages = {117951},
year = {2024},
issn = {0011-9164},
doi = {https://doi.org/10.1016/j.desal.2024.117951},
url = {https://www.sciencedirect.com/science/article/pii/S0011916424006623},
author = {Yang Zhou and Nora Marki and Bilal Khan and Christian Aguilar and Yakubu Jarma and Yoram Cohen},
keywords = {Wellhead water treatment, Reverse osmosis, Machine learning, Nitrate removal, Salt passage, Intermittent RO operation},
abstract = {Machine learning models were developed for intermittent multi-mode operation of a wellhead reverse osmosis water purification and desalination system to predict salt passage, nitrate passage, and permeate flux. The models, based on long short-term memory (LSTM) recurrent neural network (RNN) architecture, included an attention mechanism to increase model performance in proximity of the regulatory limit for nitrate. Training and testing of the models for the Startup, Production, Shutdown and Flushing operational modes were based on operational data (consisting of 22 process variables per data sample) acquired every 2–5 s over a six-month period. The significant sets of model input attributes for the different operational modes were assessed via Spearman ranking correlation, Self-Organizing Map (SOM) analysis and feed forward feature selection (FFFS). Although the variability of nitrate passage, salt passage and permeate flux was significant over the four operational modes, prediction performance for the three outcomes were with R2 and Average Absolute Relative Error (AARE) of 0.78–0.95 and 2.96–6.16 %, respectively. Model updates post membrane elements replacement demonstrated similar levels of prediction accuracy. The study results suggest that there is merit in exploring the utility of multi-mode models for sensor fault detection, data imputation, and for potential use in model-predictive control.}
}
@article{XU2025100135,
title = {What makes children perceive or not perceive minds in generative AI?},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {4},
pages = {100135},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100135},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000192},
author = {Ying Xu and Trisha Thomas and Chi-Lin Yu and Echo Zexuan Pan},
keywords = {Generative AI, Children, Mind perception, Communication, Speech, Embodiment},
abstract = {Children are increasingly engaging in dialogue and interactions with generative AI agents that can mimic human behaviors, raising questions about how children perceive and communicate with AI compared to humans. In an experimental study with 119 children aged 4–8, participants co-created stories in three conditions: with a generative AI agent via a speaker, with a physically present human partner, or with a human partner who was hidden and audible only through a speaker. Results showed a clear distinction in children's communication and perception of visible human partners compared to AI. Nuanced differences also emerged in children's perceptions of hidden human partners versus AI. When physical appearance was absent, children relied on linguistic and paralinguistic cues to assess human-likeness and form perceptions, but physical appearance became a more dominant factor when available. These results shed light on implications for the design of child-facing AI technologies, offering insights into how speech and physical features can be optimized to meet children's developmental and communicative needs.}
}
@article{YAO2025113333,
title = {Incorporating vision-based artificial intelligence and large language model for smart traffic light control},
journal = {Applied Soft Computing},
volume = {179},
pages = {113333},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2025.113333},
url = {https://www.sciencedirect.com/science/article/pii/S1568494625006441},
author = {Jiarong Yao and Jiangpeng Li and Xiaoyu Xu and Chaopeng Tan and Kim Hui Yap and Rong Su},
keywords = {Adaptive Traffic Signal Control, Computer Vision, Large Language Models, YOLO Object Detection, Reinforcement Learning},
abstract = {The increasingly complicated urban traffic patterns lead traffic signal control to a new trend of higher flexibility and quicker response, which becomes possible with advances in both sensor technology and artificial intelligence. Though in its early stage, existing intelligent signal controllers equipped with reinforcement learning (RL)-based feature extractor and large language model (LLM)-driven scenario understanding and decision support already demonstrate powerful data digesting ability. This study thus proposes a smart traffic light control system integrating a vision-based perception tool to extract traffic state from real-time snapshot image of the intersection, and an LLM agent controller for signal phase switching upon scenario analysis. An indicator describing the urgency for green time at phase level is defined to abstract the contextual information regarding the competition of multiple approaching traffic flows, which augments the LLM with domain-specific logical reasoning for signal control action generation, aimed at assigning green time to the flows with the most compelling needs. With a RL-based controller providing initial control decision as backup, the proposed method is able to handle both pre-trained and out-of-distribution scenarios through real-time traffic state diagnosis and knowledgeable reasoning. Simulation evaluation on different intersection layouts and vehicle compositions is conducted with horizontal comparison of five benchmarks. A decrease in average waiting time was realized by more than 5 % under normal traffic scenario and 20 % under emergency vehicle scenario, respectively. Further, comprehensive analysis was conducted to explore the applicability of the proposed method and feasibility for real-world application in unmanned aerial vehicle (UAV)-based intelligent traffic management.}
}
@article{YU2024101551,
title = {An ESTs detection research based on paper entity mapping: Combining scientific text modeling and neural prophet},
journal = {Journal of Informetrics},
volume = {18},
number = {4},
pages = {101551},
year = {2024},
issn = {1751-1577},
doi = {https://doi.org/10.1016/j.joi.2024.101551},
url = {https://www.sciencedirect.com/science/article/pii/S1751157724000646},
author = {Dejian Yu and Bo Xiang},
keywords = {Emerging scientific topic, Scientific text modeling, Neural prophet, Strategic market theory, Knowledge diffusion},
abstract = {Existing studies on the detection of emerging scientific topics (ESTs) overemphasize the newness and neglect content innovation of knowledge. Moreover, they also ignore the lag existing in knowledge diffusion. In this paper, we propose a four-stage detection framework for ESTs that maps emerging attributes from paper entities to scientific topics. Empirical studies based on two significantly different disciplinary datasets, IS-LS, and AI, which contain 73,601 and 255,620 publications, respectively, are employed to validate our approach. First, we generate 29 and 47 candidate scientific topics based on topic modeling, respectively. Second, we represent the novelty of paper entities based on pre-trained language models, which is mapped to scientific topic entities along with knowledge distributions to obtain topic emerging attributes: topic novelty, relative share and growth. Third, we propose to predict future trends of these attributes with Neural Prophet, which outperforms four baseline models in R2, MAE and RMSE. Finally, combining future values of candidate scientific topics, they are grouped into 8 clusters containing two ESTs types through strategic market theory and clustering model. From the correlation and feature distribution analysis of emerging attributes, we discover the existence of resilience and scale advantage in the diffusion of scientific knowledge. There also exists significant uncertainty in previous citation-based scientific topic evaluation patterns caused by the complexity of citation behavior. Overall, this research enriches theoretical knowledge and detection frameworks of ESTs, and provides detailed insights into comprehensive assessment and dissemination of scientific topics.}
}
@article{KUMAR2024107457,
title = {Dual attention and channel transformer based generative adversarial network for restoration of the damaged artwork},
journal = {Engineering Applications of Artificial Intelligence},
volume = {128},
pages = {107457},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.107457},
url = {https://www.sciencedirect.com/science/article/pii/S095219762301641X},
author = {Praveen Kumar and Varun Gupta and Manan Grover},
keywords = {Attention mechanism, Artwork restoration, Image translation, Generative adversarial networks, Transformers, Deep learning},
abstract = {Artworks are treasures of valuable cultural and historical heritage. Artworks get damaged due to environmental and other factors. The artificial intelligence-based restoration of digitized artwork images can guide the artists in physically restoring the damaged artworks. Previous methods have not been able to restore artwork images well. This paper proposes a dual (spatial and channel) attention and channel transformer-based generative adversarial network to restore damaged artwork images digitally. The proposed generative adversarial network has spatial and channel attention layers in the encoder part of the generator and a channel transformer between skip connections from the encoder to the decoder part of the generator. Spatial and channel attention helps learn inter-spatial and inter-channel global relationships among image features. Channel transformer ensures multiscale feature fusion and reduces the semantic gap between encoder and decoder layer features. Moreover, the proposed network has been trained using a linear combination of perceptual, adversarial, and structured similarity index measure loss, which helps better train the network. Further, the proposed network has been validated on two different datasets, and the results indicate that the proposed method outperforms state-of-the-art artwork restoration methods.}
}
@article{LUO2024124098,
title = {Dynamic Attribute-guided Few-shot Open-set Network for medical image diagnosis},
journal = {Expert Systems with Applications},
volume = {251},
pages = {124098},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124098},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424009643},
author = {Yiwen Luo and Xiaoqing Guo and Li Liu and Yixuan Yuan},
keywords = {Few-shot learning, Open-set recognition, Attribute generation, Dynamic feature alignment},
abstract = {The scarcity of data on rare diseases poses a significant challenge to the development of diagnostic systems. While few-shot learning (FSL) offers promise in low-data regimes, it often struggles in open-set scenarios, failing to identify unknown diseases. In this paper, we introduce a Dynamic Attribute-guided Few-shot Open-set Network (DAFON), representing the first effort to simultaneously address closed-set classification and open-set recognition in rare disease diagnosis. To alleviate incomprehensive category knowledge stemming from data scarcity, we propose a Global Attribute Generator to create attributes and produce image attribute activations for closed-set data as auxiliary information. An attribute space is then constructed and employed to generate the pseudo open-set attribute activations using a designed Open-set Data Sampler. By incorporating closed-set and open-set attribute activations as conditions, we propose a Dynamic Attribute Guided Alignment module to align feature space with attribute space, so as to derive feature space with intra-class compactness for closed-set and open-set classes. Our DAFON achieves state-of-the-art performance on two public medical image datasets, demonstrating its effectiveness for FSOSR in medical image diagnosis.}
}
@article{WANG2025125577,
title = {Automobile exterior emotional design method based on deep learning and multiple views imagery integrating calculation},
journal = {Expert Systems with Applications},
volume = {262},
pages = {125577},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125577},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424024448},
author = {Su Wang and Yuelin Liu and Li Sun and Guoqiang Chen},
keywords = {Automobile exterior emotion design, User emotional needs, Kansei engineering (KE), ResNet101-Attention, Multiple views imagery, LoRA},
abstract = {In the context of the increasingly dynamic experience economy, users’ emotional experience with automobile has become a leading factor in consumption, making automobile exterior crucial carriers of emotional needs and design expression. However, users’ emotion expression is from three-dimensional automobile entities, with a single perspective potentially causing deviations. Thus, this paper presents a novel automobile exterior emotion design method based on deep learning and multiple views imagery integrating calculation. This approach enables a seamless transition from users’ emotional needs to automobile exterior design. First, we explore users’ emotional evaluation of automobile exterior using the semantic differential method. The improved model of ResNet101-Attention mechanism was used to predict users’ emotion. Additionally, based on above emotional evaluation values, this study proposed a calculation method of multiple views automobile imagery integrating using the Analytic Hierarchy Process and Entropy Weight, calculate the automobile imagery weights of different views, and obtain the final automobile exterior emotional imagery. Finally, the Captum toolkit and the LoRA fine-tuning training technique are used to construct an automobile exterior design optimization generation model, producing a design that meets users’ emotion needs. By comparing the results obtained using both manual and automatic evaluations, and comparing to classical deep learning models. we verify the model’s validity and the advantages of the proposed method. This intelligent method assists designers in quickly identifying users’ responses for automobile design and provides automobile design that meet their emotional needs.}
}
@article{MENI2024121239,
title = {Entropy-based guidance of deep neural networks for accelerated convergence and improved performance},
journal = {Information Sciences},
volume = {681},
pages = {121239},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.121239},
url = {https://www.sciencedirect.com/science/article/pii/S0020025524011538},
author = {Mackenzie J. Meni and Ryan T. White and Michael L. Mayo and Kevin R. Pilkiewicz},
abstract = {Neural networks have dramatically increased our capacity to learn from large, high-dimensional datasets across innumerable disciplines. However, their decisions are not easily interpretable, their computational costs are high, and building and training them are not straightforward processes. To add structure to these efforts, we derive new mathematical results to efficiently measure the changes in entropy as fully-connected and convolutional neural networks process data. By measuring the change in entropy as networks process data effectively, patterns critical to a well-performing network can be visualized and identified. Entropy-based loss terms are developed to improve dense and convolutional model accuracy and efficiency by promoting the ideal entropy patterns. Experiments in image compression, image classification, and image segmentation on benchmark datasets demonstrate these losses guide neural networks to learn rich latent data representations in fewer dimensions, converge in fewer training epochs, and achieve higher accuracy.}
}
@article{HARDCASTLE2025114979,
title = {The co-existence of brand value co-creation and co-destruction across the customer journey in a complex higher education brand},
journal = {Journal of Business Research},
volume = {186},
pages = {114979},
year = {2025},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.114979},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324004831},
author = {Kimberley Hardcastle and Prabash Edirisingha and Paul Cook and Matthew Sutherland},
keywords = {Complex Service Brands, Value Co-Creation, Value Co-Destruction, Value-in-Use, Stakeholders, Experiential Customer Journey},
abstract = {Brand value co-creation (VCC) and value co-destruction (VCD) have critical implications for brand experience. This study addresses theoretical gaps in the brand value co-creation literature by empirically exploring how multiple stakeholders with competing interests generate resource imbalances, revealing the coexistence of VCC and VCD within a complex service setting. Drawing from the higher education (HE) context, this research maps the customer experiential journey of focal primary stakeholders through netnography, focus groups and semi-structured in-depth interviews. We examine brand value dynamics at key touchpoints (pre-purchase, initial purchase and established consumption). Findings unveil four experiential states and demonstrate the dynamic interplay between VCC and VCD, shaping interpretations of value-in-use. Data extends current theoretical understandings by illustrating how these phenomena coexist within specific contexts, emphasising their tangible impact on brand value. Implications extend to practitioners seeking to manage stakeholder interactions, resources and value outcomes in diverse service environments.}
}
@article{TEE202417191,
title = {Toward the Design of Allosteric Effectors: Gaining Comprehensive Control of Drug Properties and Actions},
journal = {Journal of Medicinal Chemistry},
volume = {67},
number = {19},
pages = {17191-17206},
year = {2024},
issn = {1520-4804},
doi = {https://doi.org/10.1021/acs.jmedchem.4c01043},
url = {https://www.sciencedirect.com/science/article/pii/S1520480424009475},
author = {Wei-Ven Tee and Sylvester J. M. Lim and Igor N. Berezovsky},
abstract = {While the therapeutic potential of allosteric drugs is increasingly realized, the discovery of effectors is largely incidental. The rational design of allosteric effectors requires new state-of-the-art approaches to account for the distinct characteristics of allosteric ligands and their modes of action. We present a broadly applicable computational framework for obtaining allosteric site–effector pairs, providing targeted, highly specific, and tunable regulation to any functional site. We validated the framework using the main protease from SARS-CoV-2 and the K-RasG12D oncoprotein. High-throughput per-residue quantification of the energetics of allosteric signaling and effector binding revealed known drugs capable of inducing the required modulation upon binding. Starting from fragments of known well-characterized drugs, allosteric effectors and binding sites were designed and optimized simultaneously to achieve targeted and specific signaling to distinct functional sites, such as, for example, the switch regions of K-RasG12D. The generic framework proposed in this work will be instrumental in developing allosteric therapies aligned with a precision medicine approach.
}
}
@article{STETTINGER2025100320,
title = {Exploring the potential of standardized behaviour competencies in automated driving systems},
journal = {IFAC Journal of Systems and Control},
volume = {33},
pages = {100320},
year = {2025},
issn = {2468-6018},
doi = {https://doi.org/10.1016/j.ifacsc.2025.100320},
url = {https://www.sciencedirect.com/science/article/pii/S2468601825000264},
author = {Georg Stettinger and Patrick Weissensteiner and Nayel Fabian Salem and Marcus Nolte and Siddartha Khastgir},
keywords = {ADS regulation, Behaviour competencies, Manoeuvre, Operational design domain, Risk assessment, Standards, Trustworthy},
abstract = {This paper presents a comprehensive impact assessment to explore the potential benefits of harmonized behaviour competencies (BC) for automated driving systems (ADS). Typically, ADS-equipped vehicles operate within certain boundaries specified by an operational design domain (ODD), utilizing the relevant implemented BCs. Nonetheless, many regulatory and standardization-relevant documents employ BC attributes in a non-harmonized manner. The study delves into BC-related activities and applications throughout the entire ADS life cycle, affecting all aspects of the ADS value chain, to gain a deeper understanding of the diverse needs of various stakeholders. BCs are linked to one of the four primary requirement sources at the system level. ADS-related BCs are defined through a multidisciplinary approach driven by their underlying core operating principle: the well-known sense-plan-act cycle. The crucial element within the BC specification is the identified manoeuvre pool, which forms the basis for implementing any route from point A to point B. The individual manoeuvres within the manoeuvre pool are defined by considering the needs of multiple stakeholders. They are based on three essential components: the initial condition, the expected manoeuvre, and the final condition. Furthermore, trustworthy behaviour competencies are specified, encompassing three pillars: robustness, ethics, and lawfulness. Following a detailed stakeholder analysis, several related applications are discussed to highlight the concrete advantages of implementing standardized BCs. The study concludes with a summary of the impact analysis, emphasizing key findings and action points. Lastly, a roadmap is proposed to integrate trustworthy BCs into future ADS. Concretely, the authors developed the following innovations within the scope of this article: (1) Concept for trustworthy behaviour competencies driven by law, ethics, and robustness. (2) Robustness is defined as passenger & ODD awareness and plannable & executable manoeuvre. (3) Manoeuvre pool necessary to implement an arbitrary route from point A to point B. (4) Manoeuvre specification via initial condition, expected behaviour, and final condition. (5) The potential benefits of harmonized behaviour competencies drive impact assessment.}
}
@article{WANG2023109342,
title = {Supplementation of chestnut tannins in diets can improve meat quality and antioxidative capability in Hu lambs},
journal = {Meat Science},
volume = {206},
pages = {109342},
year = {2023},
issn = {0309-1740},
doi = {https://doi.org/10.1016/j.meatsci.2023.109342},
url = {https://www.sciencedirect.com/science/article/pii/S0309174023002486},
author = {Zhongyu Wang and Long Guo and Xing Ding and Fadi Li and Hui Xu and Shirong Li and Xinji Wang and Kaidong Li and Xiangpeng Yue},
keywords = {Chestnut tannins, Hu sheep, 16S rRNA, Transcriptomes, Meat quality, Antioxidant status},
abstract = {Chestnut tannins (CNT), as a source of hydrolyzable tannins, positively affect the antioxidant status of livestock. In the current study, 90 male Hu lambs were used to investigate the effect of dietary CNT intake on growth performance, nutrient digestibility, meat quality and oxidative stability, rumen microbial, and the transcriptomes of muscle and liver. A completely randomized design with three CNT intake levels (0, 0.3%, and 0.6%) was used. Rumen microbial and nutrient digestibility were not significantly altered by CNT intake. Diets with 0.3% CNT intake significantly reduced the shear force, yellowness at 24 h, and C20:2 polyunsaturated fatty acids of lamb meat and malondialdehyde in serum and longissimus thoracis (LT) muscle. Meanwhile, the 0.3% CNT diet significantly increased average daily gain during the 1– 21 days and 64– 90 days, dry matter intake during the 1– 21 days, the slaughter weight, and liver index of lambs. The 0.3% CNT diet significantly increased C26:0 saturated fatty acids, total antioxidant capacity, glutathione peroxidase, superoxide dismutase, and catalase in LT muscle. The meat shelf life of 0.3% CNT and 0.6% CNT groups was prolonged by 8.7 h and 5.4 h, respectively. Transcriptomic analysis revealed that CNT supplementation can induce the expression of antioxidant enzyme gene (CAT, SOD1), and the differentially expressed genes were mainly involved in antioxidant activity, transferase activity, and adenosine triphosphate binding. These results suggest that 0.3% CNT intake can relieve the oxidative stress of lambs, and improve the stability of meat color and meat tenderness, due to the enhanced antioxidative capacity.}
}
@article{LI2025e41159,
title = {Digital technology administrative penalties and green technology innovation: Evidence from China},
journal = {Heliyon},
volume = {11},
number = {1},
pages = {e41159},
year = {2025},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e41159},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024171903},
author = {Hong Li and Xiaohui Chen},
keywords = {Digital technology administrative penalties (DTAP), Green technology innovation (GTI), Digital industrialization, Financial technology, Signal theory},
abstract = {In digital economy era, digital technology is a key force to promote green technological innovation (GTI). Digital technology administrative penalties (DTAP) are an important means to regulate the development of digital technology enterprises, but its ability to effectively guide digital technology enterprises to better serve GTI remains to be further examined. DTAP sends signals to physical enterprises, financial enterprises, and individuals, thereby affecting the allocation of resources, such as technology, talent, and funds. Green technology innovation requires support from these resources, raising the question of how DTAP may affect GTI. This study proposes hypotheses based on signal theory and uses urban data from China from 2008 to 2020 to empirically test the impact of DTAP on GTI. The research findings indicate that DTAP is conducive to improving regional GTI, and DTAP facilitates GTI by fostering digital industrialization and financial technology development. The heterogeneity analysis reveals that the DTAP has a stronger promotion effect on the GTI in municipalities and low-carbon pilot cities. Our research is meaningful and can serve as a reference for other developing countries to standardize administrative supervision of the digital economy and promote the green economic transformation.}
}
@article{ZHANG2025107596,
title = {CMPNet: A cross-modal multi-scale perception network for RGB-T crowd counting},
journal = {Future Generation Computer Systems},
volume = {164},
pages = {107596},
year = {2025},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.107596},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X24005600},
author = {Shihui Zhang and Kun Chen and Gangzheng Zhai and He Li and Shaojie Han},
keywords = {RGB-T crowd counting, Cross-modal perception fusion, Multi-scale feature aggregation, Spatial context awareness},
abstract = {The cross-modal crowd counting method demonstrates better scene adaptability under complex conditions by introducing independent supplementary information. However, existing methods still face problems such as insufficient fusion of modal features, underutilization of crowd structure, and the neglect of scale information. In response to the above issues, this paper proposes a cross-modal multi-scale perception network (CMPNet). Specifically, CMPNet mainly consists of a cross-modal perception fusion module and a multi-scale feature aggregation module. The cross-modal perception fusion module effectively suppresses noise features while sharing features between different modalities, thereby significantly improving the robustness of the crowd counting process. The multi-scale feature aggregation module obtains rich crowd structure information through a spatial context aware graph convolution unit, and then integrates feature information from different scales to enhance the network’s perception ability of crowd density. To the best of our knowledge, CMPNet is the first attempt to model the crowd structure and mine its semantics in the field of cross-modal crowd counting. The experimental results show that CMPNet achieves state-of-the-art performance on all RGB-T datasets, providing an effective solution for cross-modal crowd counting. We will release the code at https://github.com/KunChenKKK/CMPNet.}
}
@incollection{DORNELAS20241,
title = {Chapter One - Living in the age of artificial intelligence: advancement or fate?},
editor = {Carolina Machado and J. Paulo Davim},
booktitle = {Artificial Intelligence in Production Engineering and Management},
publisher = {Woodhead Publishing},
pages = {1-28},
year = {2024},
series = {Woodhead Publishing Reviews: Mechanical Engineering Series},
isbn = {978-0-12-819471-3},
doi = {https://doi.org/10.1016/B978-0-12-819471-3.00006-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128194713000069},
author = {Jairo Simião Dornelas},
keywords = {Artificial intelligence, artificial intelligence applications, artificial intelligence areas, artificial intelligence social perspective, artificial intelligence organizational perspective, information technology},
abstract = {The advancement of information technology in society—seen in the use of computers—on the threshold of its 60 years of methodical, visible, and continuous appearance, brought it an aura of indispensability, which is denoted in the transposition of programmable activities from man to machine. This finding reinforces the evolution of use, since now and potentially increasingly in the future, it will be cognitive tasks, and perhaps creative ones, that will be the object of this transfer, in the so-called rise of artificial intelligence. It is precisely this trajectory with some academic structure that we wanted to narrate. To this end, based on a concept of intelligence and its understanding when transposed to the scope of machines, it is outlined what would be the most widespread approaches for this achievement. This implies knowing implementation tactics and areas of use, as well as predicting areas in which efforts to develop new artifacts are added. Examples of how companies to appropriate artificial intelligence routines in real applications, which are required in the software market, are also highlighted, and the report concludes with a brief but intriguing survey with any people, about artificial intelligence, its use and possibilities management, and social governance.}
}
@article{ZHANG2025,
title = {Small-World Phenomenon of Global Open-Source Software Collaboration on Github:},
journal = {Journal of Global Information Management},
volume = {33},
number = {1},
year = {2025},
issn = {1062-7375},
doi = {https://doi.org/10.4018/JGIM.387412},
url = {https://www.sciencedirect.com/science/article/pii/S106273752500071X},
author = {Guoying Zhang and Joseph H. Schuessler and Chris Y. Shao},
keywords = {GitHub collaboration network, open-source software collaboration, social network analysis, small-world phenomenon, GitHub Innovation Graph},
abstract = {ABSTRACT
This study employs social network analysis to investigate the dynamics of collaboration regarding open-source software development on GitHub. Specifically, the study focuses on collaboration among various economies as defined by the International Organization for Standardization in ISO 3166-1 (2020). Collaboration data, such as Git pulls and pushes from the GitHub Innovation Graph from 2020 to 2023, were adopted as primary sources. Around 190 eligible economies were included in the analysis based on their collaboration efforts. The study constructed a directed, weighted network to map these collaborations, identify key economies, and validate the small-world phenomenon discussed by Watts and Strogatz in 1998. Network centrality statistics were summarized, and network communities were identified. The small-world phenomenon was validated by benchmarking the small-worldness index proposed by Humphries and Gurney in 2008. Furthermore, this study shows that variations in developer counts, repository volumes, or organization presence do not significantly influence an economy’s centrality measures, such as closeness and eigenvector centralities.}
}
@article{GALLI20251,
title = {The quadratic knapsack problem},
journal = {European Journal of Operational Research},
volume = {326},
number = {1},
pages = {1-12},
year = {2025},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2024.12.032},
url = {https://www.sciencedirect.com/science/article/pii/S0377221724009743},
author = {Laura Galli and Silvano Martello and Paolo Toth},
keywords = {Quadratic knapsack problem, Linearization, Upper bounds, Exact solution, Approximation, Heuristics, Metaheuristics, Computational results},
abstract = {The quadratic knapsack problem is a relevant NP-hard combinatorial optimization problem, inspired, since the Seventies, by a number of real-world applications. After its formal definition in 1980, it was subject to intensive research, especially in the last two decades. No recent review on this problem appeared in the literature after a well-known survey, published in 2007 but updated to 2003. The purpose of this work is to provide a thorough overview of classical and recent results on the quadratic knapsack problem. We examine mathematical models, linearizations and reformulations. We review upper bounds, exact algorithms, heuristic and metaheuristic approaches, and provide a comparison of their computational performance.}
}
@article{LIN2025115621,
title = {Active multi-mode data analysis to improve fault diagnosis in AHUs},
journal = {Energy and Buildings},
volume = {337},
pages = {115621},
year = {2025},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2025.115621},
url = {https://www.sciencedirect.com/science/article/pii/S0378778825003512},
author = {Guanjing Lin and John House and Yimin Chen and Jessica Granderson and Wanpeng Zhang},
keywords = {Fault diagnosis, Air handling unit, Multi-mode data analysis, Energy management and information system, Smart building},
abstract = {Faults in heating, ventilation and air conditioning systems can lead to increased energy consumption, occupant comfort issues, and reduced equipment lifetime. Commercial fault detection and diagnosis (FDD) tools has been increasingly deployed in U.S. commercial buildings. While they are helping to achieve energy efficiency and operational reliability, there remain gaps in their fault diagnostic capabilities. The diagnostic results often contain multiple distinct candidate root causes (CRCs) or offer no insight into CRCs. This study developed a novel active rule-based multi-mode data analysis method to enhance diagnostic resolution by applying proven rule sets and additional new rules to data from multiple known operational modes. The proposed method was demonstrated using enhanced air handling unit performance assessment rule sets and validated with the simulated data of two air handling units. New metrics, namely, reduced number of CRCs and improvement ratio, were developed to quantify the improvement of fault diagnostic resolution. The validation results showed that the proposed method effectively reduced the number of CRCs in contrast to analyzing data solely for a single mode of operation. It achieved a median improvement ratio of 80% in 19 test cases.}
}
@article{DARTORA2023113569,
title = {Understanding the effect of fermentation time on physicochemical characteristics, sensory attributes, and volatile compounds in green tea kombucha},
journal = {Food Research International},
volume = {174},
pages = {113569},
year = {2023},
issn = {0963-9969},
doi = {https://doi.org/10.1016/j.foodres.2023.113569},
url = {https://www.sciencedirect.com/science/article/pii/S0963996923011171},
author = {Bruna Dartora and Lilian Raquel Hickert and Mariana Fensterseifer Fabricio and Marco Antônio Zachia Ayub and Júnior Mendes Furlan and Roger Wagner and Karla Joseane Perez and Voltaire Sant'Anna},
keywords = {Fermented beverage, Aromatic compounds, Metagenomics, Sensory analysis},
abstract = {Kombuchas are a trend in the fermented beverage field and the effect of fermentation time on their characteristics is necessary to better understand the process, mainly concerning volatile compounds, which are scarce information in the current literature. Thus, the present work aimed to evaluate the features of green tea kombucha during fermentation, monitoring the changes in pH, acidity, turbidity, polyphenols, ethanol, acetic acid, volatile compounds, and sensory profile and acceptance up to 14 days of fermentation. Kombuchas’ pH and acidity decreased through time as expected, but after 4 days of fermentation, the beverage exceeded the Brazilian legal limits of acidity (130 mEq/L) and produced more than 0.5% AVB, which labels the beverage as alcoholic. Total polyphenols and condensed tannins content enhanced until the seventh day of fermentation and remained constant. Fermentation highly impacted the aroma of the infusion with a high formation of volatile acids, such as alcohols, esters, and ketones. Aldehydes were degraded during the bioprocess. Sensory characterization of kombucha showed that fermentation of 4 days increased perceived turbidity; vinegar, citric fruit, acid, and alcoholic aroma; and produced the beverage with sour, bitter, and vinegar flavor. Thus, the fermentation time of kombuchas must be controlled as they rapidly change and impact on the physicochemical parameters and sensory profile of the beverage can be negative.}
}
@article{LI2025102009,
title = {Unveiling civil servants' preferences: Human-machine matching vs. regulating algorithms in algorithmic decision-making——Insights from a survey experiment},
journal = {Government Information Quarterly},
volume = {42},
number = {1},
pages = {102009},
year = {2025},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2025.102009},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X25000036},
author = {Huanhuan Li and Zongfeng Sun and Jiacheng Xi},
keywords = {Algorithmic decision-making, Human-machine matching, Algorithm regulation, Trust perception, Usage inclinations},
abstract = {While research has explored trust in algorithmic decision-making, the factors shaping civil servants' trust perceptions remain underexamined. Using public value theory and technology adoption frameworks, this study employs a survey experiment to analyze the effects of human-machine matching and algorithm regulation on civil servants' trust and adoption inclination. The findings indicate that both factors independently influence adoption inclination, with trust perceptions mediating this relationship, but no interaction effect is observed. Addressing gaps in technology acceptance and ethical frameworks, this study highlights the importance of algorithm regulation and human-machine matching in advancing algorithmic governance and achieving public value through procedural and performance dimensions, offering practical implications for policy and governance.}
}
@article{DUI2025106523,
title = {A IoT-based novel methodology to optimize multidimensional flood resilience of drainage systems for sponge city},
journal = {Sustainable Cities and Society},
volume = {130},
pages = {106523},
year = {2025},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2025.106523},
url = {https://www.sciencedirect.com/science/article/pii/S2210670725003981},
author = {Hongyan Dui and Huanqi Zhang and Shaomin Wu},
keywords = {Sponge city, Multidimensional flood resilience, Drainage system, Optimization strategy},
abstract = {With the study of intra-city flooding, the construction of sponge cities has advanced significantly. Sponge cities enhance a city’s capacity to absorb and retain rainwater, thereby reducing the frequency and severity of urban flooding. However, in recent years, extreme rainfall events have led to poor performance in terms of rainwater absorption, storage, and release, resulting in severe casualties and significant economic losses. This paper focuses on both the internal operation and external environment of sponge city drainage systems. Externally, the goal is to reduce surface runoff after heavy rainfall, while internally, the aim is to improve the drainage system's ability to prevent, withstand, and recover from exceptionally heavy rainstorms. A novel multidimensional flood resilience assessment method is proposed, leveraging Internet of Things (IoT) technology to evaluate the performance of sponge cities. Corresponding multidimensional flood resilience optimization strategies are introduced to enhance surface runoff management after rainfall and improve the sponge city performance in the prevention, resistance, and recovery stages. Finally, a software, Storm Water Management Model (SWMM), was used to simulate an area in of Zhengzhou City during the “720″ rainstorm, validating the feasibility of the proposed method.}
}
@article{KALIISA2025105246,
title = {A Topical Review of Research in Computer-Supported Collaborative Learning: Questions and Possibilities},
journal = {Computers & Education},
volume = {228},
pages = {105246},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105246},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525000144},
author = {Rogers Kaliisa and Sonsoles López-Pernas and Kamila Misiejuk and Crina Damşa and Márta Sobocinski and Sanna Järvelä and Mohammed Saqr},
keywords = {Computer supported collaborative learning, CSCL, Collaborative learning, Collaborative processes, Bibliometric analysis},
abstract = {This study maps the evolution and state of Computer-Supported Collaborative Learning (CSCL) research, analyzing 6388 documents published between 1990 and 2022. The findings highlight the sustained engagement of a core group of scholars and the field's geographic concentration in Western countries, particularly the USA and Europe. While the field remains productive and diverse, recent trends reflect a growing emphasis on integrating emerging technologies such as learning analytics, augmented and virtual reality, and artificial intelligence (AI) into collaborative learning contexts. The study uncovers a tension within CSCL between its epistemological and methodological diversity and the need for theoretical coherence. This diversity has allowed the field to adapt and innovate but raises concerns about fragmentation and the risk of losing a unified identity. For example, while scripting remains a foundational topic, debates persist on balancing instructional guidance with learner agency to foster productive collaboration. Looking ahead, the study underscores the need for CSCL to develop integrative theoretical frameworks that bridge its rich historical foundations with the challenges posed by large-scale, distributed, and technology-mediated collaboration. Addressing these challenges, such as aligning AI innovations with existing theories and ensuring cumulative knowledge-building, will be critical for the field's ability to sustain its relevance and influence in understanding collaborative learning in complex educational environments.}
}
@article{HAEFNER2023122878,
title = {Implementing and scaling artificial intelligence: A review, framework, and research agenda},
journal = {Technological Forecasting and Social Change},
volume = {197},
pages = {122878},
year = {2023},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2023.122878},
url = {https://www.sciencedirect.com/science/article/pii/S0040162523005632},
author = {Naomi Haefner and Vinit Parida and Oliver Gassmann and Joakim Wincent},
keywords = {Artificial intelligence, Machine learning, Review, Scaling, Innovation, Technology},
abstract = {Artificial intelligence (AI) will have a substantial impact on firms in virtually all industries. Without guidance on how to implement and scale AI, companies will be outcompeted by the next generation of highly innovative and competitive companies that manage to incorporate AI into their operations. Research shows that competition is fierce and that there is a lack of frameworks to implement and scale AI successfully. This study begins to address this gap by providing a systematic review and analysis of different approaches by companies to using AI in their organizations. Based on these experiences, we identify key components of implementing and scaling AI in organizations and propose phases of implementing and scaling AI in firms.}
}
@article{JANSON2023107954,
title = {How to leverage anthropomorphism for chatbot service interfaces: The interplay of communication style and personification},
journal = {Computers in Human Behavior},
volume = {149},
pages = {107954},
year = {2023},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2023.107954},
url = {https://www.sciencedirect.com/science/article/pii/S0747563223003059},
author = {Andreas Janson},
keywords = {Chatbots, Conversational agents, Anthropomorphic design, Social presence, Empathy, Trust},
abstract = {Although chatbots are oftentimes used in customer service encounters, interactions are oftentimes perceived as not satisfactory. One key aspect for designing chatbots is the use of anthropomorphic design elements. In this experimental study, we examine the two anthropomorphic chatbot design elements of personification, which includes a human-like appearance, and social orientation of communication style, which means a more sensitive and extensive communication. We tested the influence of the two design elements on social presence, satisfaction, trust and empathy towards a chatbot. First, the results show a significant influence of both anthropomorphic design elements on social presence. Second, our findings illustrate that social presence influences trusting beliefs, empathy, and satisfaction. Third, social presence acts as a mediator for both anthropomorphic design elements for satisfaction with a chatbot. Our implications provide a better understanding of anthropomorphic chatbot design elements when designing chatbots for short-term interactions, and we offer actionable implications for practice that enable more effective chatbot implementations.}
}
@article{PENG2025104303,
title = {3D modeling from a single image via a novel dual-decoder framework for Agile design},
journal = {Computers in Industry},
volume = {169},
pages = {104303},
year = {2025},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2025.104303},
url = {https://www.sciencedirect.com/science/article/pii/S0166361525000685},
author = {Jieyang Peng and Andreas Kimmig and Simon Kreuzwieser and Zhibin Niu and Xiaoming Tao and Jivka Ovtcharova},
keywords = {Computer-aided design, 3D entities prediction, Dual-decoder architecture, Agile design, Intelligent manufacturing},
abstract = {In the fast-paced manufacturing industry, rapid and efficient product design is essential for meeting customer demands and maintaining a competitive edge. Despite advancements, transforming 2D design concepts into accurate 3D models remains a complex challenge, primarily due to the non-differentiability of traditional rendering processes that hinder gradient-based optimizations. To address this limitation, this paper introduces an innovative dual-decoder architecture that effectively separates the shape and color components of 3D models. By assigning separate decoders for vertex positions and color assignment, our proposed model enables targeted optimization of each, leading to more refined and authentic 3D reconstructions. Moreover, we have overcome the non-differentiability issue, enabling gradient-based learning through the incorporation of differentiable rendering techniques. These techniques facilitate gradient-based optimization, paving the way for data-driven enhancements in the design process. Our empirical research has demonstrated the effectiveness of our approach in generating high-fidelity 3D models from 2D inputs. Additionally, we have shed light on the sensitivity of hyperparameters within our framework, offering valuable insights for future model refinement and optimization. In summary, our research provides valuable insights into enhancing 3D modeling frameworks, thereby contributing to incremental progress in the field of computer-aided design and manufacturing.}
}
@article{CHAO2024e35468,
title = {From hate to harmony: Leveraging large language models for safer speech in times of COVID-19 crisis},
journal = {Heliyon},
volume = {10},
number = {16},
pages = {e35468},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e35468},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024114995},
author = {August F.Y. Chao and Chen-Shu Wang and Bo-Yi Li and Hong-Yan Chen},
abstract = {This study investigates the rampant spread of offensive and derogatory language during the COVID-19 pandemic and aims to mitigate it through machine learning. Employing advanced Large Language Models (LLMs), the research develops a sophisticated framework adept at detecting and transforming abusive and hateful speech. The project begins by meticulously compiling a dataset, focusing specifically on Chinese language abuse and hate speech. It incorporates an extensive list of 30 pandemic-related terms, significantly enriching the resources available for this type of research. A two-tier detection model is then introduced, achieving a remarkable accuracy of 94.42 % in its first phase and an impressive 81.48 % in the second. Furthermore, the study enhances paraphrasing efficiency by integrating generative AI techniques, primarily Large Language Models, with a Latent Dirichlet Allocation (LDA) topic model. This combination allows for a thorough analysis of language before and after modification. The results highlight the transformative power of these methods. They show that the rephrased statements not only reduce the initial hostility but also preserve the essential themes and meanings. This breakthrough offers users effective rephrasing suggestions to prevent the spread of hate speech, contributing to more positive and constructive public discourse.}
}
@article{LU2023102867,
title = {Information sharing decisions in all-pay auctions with correlated types},
journal = {Journal of Mathematical Economics},
volume = {107},
pages = {102867},
year = {2023},
issn = {0304-4068},
doi = {https://doi.org/10.1016/j.jmateco.2023.102867},
url = {https://www.sciencedirect.com/science/article/pii/S0304406823000605},
author = {Jingfeng Lu and Hongkun Ma and Zhewei Wang},
keywords = {All-pay auctions, Contests, Correlated types, Information disclosure, Pure/mixed strategy equilibrium},
abstract = {In many real-life competitions, contestants may not be aware of their own type (e.g., value or ability) prior to the contest. Furthermore, contestants’ types, which are observed privately after entering the competition, are frequently correlated with one another. We examine a two-stage competition that involves two players with correlated (binary) types. In the first stage, players decide simultaneously or sequentially on the probabilities they use to disclose or conceal their type, which will become their private information later on. In the second stage, each player privately observes their own type and commits to disclosing or concealing it, after which they compete in an all-pay auction. We discover that information sharing does not occur when players’ types are negatively correlated. However, when players’ types are positively correlated, information is partially shared in all equilibria examined in this study. In an asymmetric pure strategy equilibrium, one player shares his information with probability one and the other player with probability zero. In a symmetric mixed strategy equilibrium, each player shares his information with the same positive probability.}
}
@article{GUARRASI2024110825,
title = {Multimodal explainability via latent shift applied to COVID-19 stratification},
journal = {Pattern Recognition},
volume = {156},
pages = {110825},
year = {2024},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2024.110825},
url = {https://www.sciencedirect.com/science/article/pii/S0031320324005764},
author = {Valerio Guarrasi and Lorenzo Tronchin and Domenico Albano and Eliodoro Faiella and Deborah Fazzini and Domiziana Santucci and Paolo Soda},
keywords = {XAI, Multimodal deep learning, Joint fusion, Classification, COVID-19},
abstract = {We are witnessing a widespread adoption of artificial intelligence in healthcare. However, most of the advancements in deep learning in this area consider only unimodal data, neglecting other modalities. Their multimodal interpretation necessary for supporting diagnosis, prognosis and treatment decisions. In this work we present a deep architecture, which jointly learns modality reconstructions and sample classifications using tabular and imaging data. The explanation of the decision taken is computed by applying a latent shift that, simulates a counterfactual prediction revealing the features of each modality that contribute the most to the decision and a quantitative score indicating the modality importance. We validate our approach in the context of COVID-19 pandemic using the AIforCOVID dataset, which contains multimodal data for the early identification of patients at risk of severe outcome. The results show that the proposed method provides meaningful explanations without degrading the classification performance.}
}
@incollection{NAYYAR2025309,
title = {Chapter 11 - Future trends in large language models and prompt engineering},
editor = {Anand Nayyar and Ajantha Devi Vairamani and Kuldeep Kaswan},
booktitle = {Mastering Prompt Engineering},
publisher = {Morgan Kaufmann},
pages = {309-336},
year = {2025},
isbn = {978-0-443-33904-2},
doi = {https://doi.org/10.1016/B978-0-443-33904-2.00009-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443339042000094},
author = {Anand Nayyar and Ajantha Devi Vairamani and Kuldeep Kaswan},
keywords = {Artificial intelligence, Bidirectional encoder, Contrastive language-image pre-training, Natural language processing},
abstract = {The chapter delves into the transformative landscape of Large Language Models (LLMs) and prompt engineering, highlighting their impact on various sectors and the future of human-Artificial intelligence (AI) collaboration. It begins by examining recent advancements in LLM architectures and training techniques, emphasizing the evolution from traditional models to multimodal systems capable of processing diverse data types. The chapter discusses the significance of augmented prompt engineering as a means to enhance the synergy between human creativity and AI capabilities, facilitating more effective content generation across fields such as marketing, education, and healthcare. Additionally, the chapter addresses the critical need for explainability and interpretability in LLMs, advocating for transparency to build user trust and ensure ethical AI applications. It explores the democratization of access to AI technologies, emphasizing the role of user-friendly tools that enable individuals with varying technical expertise to engage with AI effectively. Interdisciplinary collaboration is presented as a key strategy for improving prompt engineering, drawing insights from linguistics, cognitive science, and ethics to foster innovation and address ethical concerns. The chapter concludes with a discussion on the potential of human-AI co-creation, envisioning a future where collaborative efforts lead to meaningful outcomes and enhanced creativity. By synthesizing these themes, the chapter provides a comprehensive roadmap for navigating the evolving landscape of LLMs and prompt engineering, underscoring their potential to positively impact society while addressing the challenges that lie ahead.}
}
@article{MA2025112700,
title = {Semantic-based topic model for public opinion analysis in sudden-onset disasters},
journal = {Applied Soft Computing},
volume = {170},
pages = {112700},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2025.112700},
url = {https://www.sciencedirect.com/science/article/pii/S1568494625000110},
author = {Yulong Ma and Xinsheng Zhang and Runzhou Wang},
keywords = {Sudden-onset disaster, Topic model, Latent Dirichlet allocation, Distributional semantics},
abstract = {Sudden-onset disasters have put forward more stringent requirements for the government to carry out public opinion analysis work. However, most existing topic models ignore the contextual semantics of disaster texts, and fail to balance the robustness and the training cost. To address these issues, a neural clustering topic model is proposed in this work. The topic probability distribution of the LDA model is integrated with the distribution semantic vector generated by a lite BERT. The fused vectors are reconstructed by a nonlinear manifold learning algorithm, and re-clustered into topics by a mini-batch based k-means++ algorithm. Compared to state-of-the-art models on three sudden-onset disaster datasets, the proposed model shows an increase of 1.79 % in average topic coherence and 33.87 % in topic diversity. Meanwhile, the inference time is reduced by 84.09 % on average. The visual study of the latent process of the proposed model reflects that its ability to compact intra-cluster vector distances and sparse inter-cluster vector distances is the potential reason for its better performance. It can be considered that the application of the proposed model can help the government enhance its ability to manage negative public opinions in sudden-onset disasters.}
}
@article{CHAN2025112449,
title = {Identifying inconsistent software defect predictions with symmetry metamorphic relation pattern},
journal = {Journal of Systems and Software},
volume = {227},
pages = {112449},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2025.112449},
url = {https://www.sciencedirect.com/science/article/pii/S0164121225001177},
author = {Pak Yuen Patrick Chan and Jacky Keung and Zhen Yang},
keywords = {Metamorphic testing, Metamorphic relation patterns, Software defect prediction, Explainable artificial intelligence},
abstract = {Determining inconsistent software defect predictions in machine learning-based systems poses a significant challenge. To address this issue, we propose the utilization of Metamorphic Testing (MT) incorporating the “symmetry” metamorphic relation pattern (MRP) to transform the training datasets for training follow-up systems. In contrast, original datasets are employed to train source systems. By comparing the occurrence of inconsistent predictions between source and follow-up systems and analysing the efficacy of this approach, we aim to shed light on its effectiveness. Additionally, Explainable Artificial Intelligence (XAI) is employed to explain the inconsistencies observed. The results demonstrate that the “symmetry” MRP can induce inconsistent predictions, and XAI techniques can effectively elucidate such inconsistencies. Moreover, we find that the ordering of small-sized and imbalanced datasets can contribute to inconsistencies when using the KMeans, Random Forests or Convolutional Neural Network algorithm for software defect prediction systems. To further advance this research, future studies can extend the proposed approach by incorporating additional MRPs in domains that utilize machine learning algorithms to identify and explain inconsistencies. Another promising research avenue involves investigating the relationship between data imbalance, dataset size, and MRPs to enhance the identification of inconsistencies and derive more robust MRs.}
}
@article{CASTELLANOSREYES2025101001,
title = {Transforming online learning research: Leveraging GPT large language models for automated content analysis of cognitive presence},
journal = {The Internet and Higher Education},
volume = {65},
pages = {101001},
year = {2025},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2025.101001},
url = {https://www.sciencedirect.com/science/article/pii/S1096751625000107},
author = {Daniela Castellanos-Reyes and Larisa Olesova and Ayesha Sadaf},
keywords = {Cognitive presence, Online learning, Artificial intelligence in education, Automated content analysis, Discussion boards, Large language models, GPT},
abstract = {The last two decades of online learning research vastly flourished by examining discussion board text data through content analysis based on constructs like cognitive presence (CP) with the Practical Inquiry Model (PIM). The PIM sets a footprint for how cognitive development unfolds in collaborative inquiry in online learning experiences. Ironically, content analysis is a resource-intensive endeavor in terms of time and expertise, making researchers look for ways to automate text classification through ensemble machine-learning algorithms. We leveraged large language models (LLMs) through OpenAI's Generative Pre-Trained Transformer (GPT) models in the public API to automate the content analysis of students' text data based on PIM indicators and assess the reliability and efficiency of automated content analysis compared to human analysis. Using the seven steps of the Large Language Model Content Analysis (LACA) approach, we proposed an AI-adapted CP codebook leveraging prompt engineering techniques (i.e., role, chain-of-thought, one-shot, few-shot) for the automated content analysis of CP. We found that a fine-tuned model with a one-shot prompt achieved moderate interrater reliability with researchers. The models were more reliable when classifying students' discussion board text in the Integration phase of the PIM. A cost comparison showed an obvious cost advantage of LACA approaches in online learning research in terms of efficiency. Nevertheless, practitioners still need considerable data literacy skills to deploy LACA at a scale. We offer theoretical suggestions for simplifying the CP codebook and improving the IRR with LLM. Implications for practice are discussed, and future research that includes instructional advice is recommended.}
}
@article{ZHANG2025100385,
title = {U.S. college students’ acceptability and educational benefits of ChatGPT from a digital divide perspective},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100385},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100385},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000256},
author = {Ceciley (Xinyi) Zhang and Laurent H. Wang and Ronald E. Rice},
keywords = {Acceptability, Adoption, ChatGPT, College students, Digital divide},
abstract = {ChatGPT has diffused widely and rapidly, with diverse positive and negative implications. In educational settings it is important to understand students' perceptions of the acceptability of ChatGPT for various learning activities and to examine whether prior digital divide concerns pertain to this digital innovation, in order to provide guidance for users, inform policymakers and other stakeholders, and extend digital divide research. The purpose is to investigate the associations of socioeconomic status (SES, both family and student), gender, and race/ethnicity with students’ perceived acceptability of common ChatGPT activities as well as their opinion about how beneficial ChatGPT is for college education, and additionally, whether such relationships differ based on adoption experience. We analyzed survey data quantitatively in two phases (N = 360 and 1267), applying measurement reliability and validity, correlations, and structural equation modeling. The results indicate that students with higher family SES and lower individual SES, and females, tend to view the acceptability of ChatGPT uses more positively, although racial/ethnic minorities are more critical of displacement activities. ChatGPT adopters perceive two dimensions of ChatGPT activities (academic support and academic displacement) as more acceptable than do non-adopters, and they also perceive uses for academic support more positively than for displacement. Moreover, adoption is a significant moderator of some of these associations. At this early stage of ChatGPT diffusion, these digital divide influences on acceptability and general opinion are weak and variable. The discussion further considers theoretical and practical implications for digital education in the AI era.}
}
@article{CIVAI2025106192,
title = {The role of attention and frames on third-party punishment and compensation choices},
journal = {Cognition},
volume = {263},
pages = {106192},
year = {2025},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2025.106192},
url = {https://www.sciencedirect.com/science/article/pii/S0010027725001325},
author = {Claudia Civai and Valerio Capraro and Luca Polonio},
keywords = {Injustice perception, Third-party punishment and compensation, Attentional processes, Information frames, Choice process},
abstract = {People often forgo their own self-interest to react to fairness and justice violations, even when not directly affected by the infraction. There are different ways to react to an injustice: some may prefer to punish the perpetrator, and others to compensate the victim. Here, our focus is on the role played by attention to determine these choices, investigating the relationship between attentional mechanisms and punishment/compensation in five preregistered experiments (N = 1157). Two eye-tracking experiments showed that people who focus more on the offender's payoff are more likely to punish, and when an exogenous stimulation increases the focus on the offender's payoff, people spend more to punish. An offender bias was also found, meaning that people, overall, prefer to focus on the offender's, rather than the victim's, payoff, and punish more than compensate. This was confirmed in three behavioural experiments, where people were exposed to either the offender's or the victim's payoff: when given the choice, people prefer to reveal the offender's payoff, and then punish; however, when randomly exposed to the victim's payoff, the preference for punishment disappears. Affective empathy boosts this effect: higher empathy leads to more punishment (or compensation) when the offender's (or victim's) payoff is revealed. These findings suggest that, whilst people have an intrinsic motivation to search for information that matches their preference (i.e., the offender's payoff and punishment), when exposed to an alternative piece of information (i.e., the victim's payoff), they modify their behaviour. Implications for understanding information bubbles and ways to overcome them are discussed.}
}
@article{TABATABAEI2023212023,
title = {EOR screening using optimized artificial neural network by sparrow search algorithm},
journal = {Geoenergy Science and Engineering},
volume = {229},
pages = {212023},
year = {2023},
issn = {2949-8910},
doi = {https://doi.org/10.1016/j.geoen.2023.212023},
url = {https://www.sciencedirect.com/science/article/pii/S2949891023006103},
author = {S. Mostafa Tabatabaei and Nikta Attari and S. Amirali Panahi and Mojtaba Asadian-Pakfar and Behnam Sedaee},
keywords = {EOR, Sparrow search algorithm (SSA), Particle swarm optimization (PSO), Artificial neural network (ANN), Deep learning, Meta-heuristic algorithms},
abstract = {Enhanced oil recovery (EOR) is a crucial aspect of reservoir engineering, and the use of machine-learning algorithms in the initial stages of screening has been widely accepted as a fast and efficient method for screening the most suitable EOR method. This study presents an artificial neural network (ANN) that recommends the most suitable EOR method based on historical reservoir data. Data from EOR projects worldwide were collected, pre-processed, and then used to build the ANN, which initially achieved a 69% accuracy. The neural network was optimized using the Sparrow Search Algorithm (SSA) and compared with the Particle Swarm Optimization (PSO) algorithm, with a focus on weight and hyperparameter optimization. Validation of the neural network’s prediction was done using recall, precision, and the F1 score. Weight optimization yielded an accuracy of 68% with SSA and 34% with PSO, which were insufficient results for EOR prediction. However, hyperparameter optimization was applied, resulting in an accuracy of 94% with SSA and 90% with PSO. The SSA approach demonstrated faster convergence and higher accuracy in both optimization paths, highlighting its potential for optimizing the neural network in predicting the appropriate EOR method for a given reservoir.}
}
@incollection{KORNHAUSER2024111,
title = {Chapter 5 - The role of automotive artificial intelligence},
editor = {Alain L. Kornhauser and Michael L. Sena},
booktitle = {The Real Case for Driverless Mobility},
publisher = {Elsevier},
pages = {111-130},
year = {2024},
isbn = {978-0-443-23685-3},
doi = {https://doi.org/10.1016/B978-0-443-23685-3.00001-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780443236853000017},
author = {Alain L. Kornhauser and Michael L. Sena},
keywords = {Artificial intelligence (AI), Artificial general intelligence (AGI), Automotive artificial intelligence (AAI), Big data, Driver monitoring systems},
abstract = {Driverless vehicles will use artificial intelligence (AI). AI-equipped vehicles will interpret and learn from external data and imitate the physical and mental processes used to drive motorized vehicles. The purpose of this chapter is to explain the different types of artificial intelligence, to what extent they are being used today in the design and operation of motorized vehicles, and how they can be put to use for both driving vehicles without human intervention and improving their safe operation. We also discuss the non-technological implications of automotive AI, including its effects on privacy, the assignment of liability in case of an accident, and the reasons for establishing laws and standards that precede the introduction of driverless vehicles, not reacting to their presence.}
}
@article{KNOTH2024100225,
title = {AI literacy and its implications for prompt engineering strategies},
journal = {Computers and Education: Artificial Intelligence},
volume = {6},
pages = {100225},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100225},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000262},
author = {Nils Knoth and Antonia Tolzin and Andreas Janson and Jan Marco Leimeister},
keywords = {Large language model, AI literacy, Prompt engineering, AI interaction, Education},
abstract = {Artificial intelligence technologies are rapidly advancing. As part of this development, large language models (LLMs) are increasingly being used when humans interact with systems based on artificial intelligence (AI), posing both new opportunities and challenges. When interacting with LLM-based AI system in a goal-directed manner, prompt engineering has evolved as a skill of formulating precise and well-structured instructions to elicit desired responses or information from the LLM, optimizing the effectiveness of the interaction. However, research on the perspectives of non-experts using LLM-based AI systems through prompt engineering and on how AI literacy affects prompting behavior is lacking. This aspect is particularly important when considering the implications of LLMs in the context of higher education. In this present study, we address this issue, introduce a skill-based approach to prompt engineering, and explicitly consider the role of non-experts' AI literacy (students) in their prompt engineering skills. We also provide qualitative insights into students’ intuitive behaviors towards LLM-based AI systems. The results show that higher-quality prompt engineering skills predict the quality of LLM output, suggesting that prompt engineering is indeed a required skill for the goal-directed use of generative AI tools. In addition, the results show that certain aspects of AI literacy can play a role in higher quality prompt engineering and targeted adaptation of LLMs within education. We, therefore, argue for the integration of AI educational content into current curricula to enable a hybrid intelligent society in which students can effectively use generative AI tools such as ChatGPT.}
}
@article{WANG2024103508,
title = {Charting the trajectory of language teacher cognition development: What 15 years of research in System informs us},
journal = {System},
volume = {127},
pages = {103508},
year = {2024},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2024.103508},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X24002902},
author = {Yonghua (Yoka) Wang and Lawrence Jun Zhang},
keywords = {Language teacher cognition, Teacher beliefs, Teacher learning, Teacher professional development},
abstract = {Teacher education has always been what our journal, System, plays much emphasis on, and this emphasis has gradually strengthened as research into teacher cognition has gained popularity, particularly following Borg's influential work in 2006. While earlier studies by Wood (1996) have already examined teacher beliefs and their relationships with classroom practices, the mounting attention to this area has significantly shaped the scope of our journal. In the interest of helping our readers to have a fresh memory of how System has been playing an ever-increasing role in disseminating information related to language teaching and learning, and in this case, research into language teacher cognition, we present a historical overview of studies on teacher cognition that have been published in System over the past fifteen years. In doing so, we would like to show the major themes and trends in teacher cognition research reflected in System from 2008 to 2023 and how System has contributed to advancing this line of study. It is hoped that, with our systematic documentation of important work that has been done along these lines in our journal, we aspire to retain our focus on teacher cognition in our journal in the years to come.}
}
@article{KLIMAS2025287,
title = {The 5-dimensional behavioural coopetitor profile: How to measure it?},
journal = {Industrial Marketing Management},
volume = {124},
pages = {287-303},
year = {2025},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2024.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S0019850124002013},
author = {Patrycja Klimas and Karina Sachpazidu and Sylwia Stańczyk and Arkadiusz Kawa and Michał Nadolny},
keywords = {Coopetition, Coopetitor profiles, Behavioural approach, Behavioural features, Operationalization, Scale development, Scale validation},
abstract = {This paper investigates the behavioural component of the coopetitor profile, its operationalization and measurement. First, the general coopetitor profile framework is presented together with its four main components. Second, the behavioural component of this profile is shown as covering specific behavioural features describing coopetitors. Third, operationalizations for these behavioural features are offered and tested. Our research process combines desk and field research. We develop the concept of the coopetitor profile through literature analysis, as well as integrating existing measurement approaches to operationalize the identified behavioural features, and test these operationalizations via a large-scale study of 1216 Polish manufacturing companies. We present the original concept of the coopetitor profile, consisting of four components: strategic, cultural, resource-competency and behavioural. Using the lens of partner fit, we discuss the relevance of profiling coopetitors for partner selection, and coopetition establishment and management. We conceptualize and operationalize eleven behavioural features, resulting in a robust model for a five-dimensional behavioural profile covering conflict, formality, intensity of competition, investments and trust. This study contributes to the literature by examining the less-explored aspects of coopetition - coopetitor profile, behavioural approach and behavioural features. The primary methodological contribution is developing and validating a pioneering multi-item scale for measuring the multidimensional behavioural component of the profile of coopetitors.}
}
@article{HALLAM2024107452,
title = {Comprehensive functional characterization of complement factor I rare variant genotypes identified in the SCOPE geographic atrophy cohort},
journal = {Journal of Biological Chemistry},
volume = {300},
number = {7},
pages = {107452},
year = {2024},
issn = {0021-9258},
doi = {https://doi.org/10.1016/j.jbc.2024.107452},
url = {https://www.sciencedirect.com/science/article/pii/S0021925824019537},
author = {Thomas M. Hallam and Anneliza Andreadi and Scott J. Sharp and Vicky Brocklebank and Emanuela Gardenal and Anna Dreismann and Rashi Arora and Marcus Dennis and Christina Flaxel and Edward Hall and Carel Hoyng and Peter {Charbel Issa} and Nicolas Leveziel and Fanni Molnár and Rafael Navarro and Todd Schneiderman and David Steel and Ramin Tadayoni and Tongalp Tezel and Michel Weber and Andrew J. Lotery and Kevin J. Marchbank and Claire L. Harris and Amy V. Jones and David Kavanagh},
keywords = {complement, complement system, enzyme mutation, retinal degeneration, innate immunity, complement factor I, age-related macular degeneration (AMD), atypical hemolytic uremic syndrome (aHUS), C3 glomerulopathy(C3G)},
abstract = {Rare variants (RVs) in the gene encoding the regulatory enzyme complement factor I (CFI; FI) that reduce protein function or levels increase age-related macular degeneration risk. A total of 3357 subjects underwent screening in the SCOPE natural history study for geographic atrophy secondary to age-related macular degeneration, including CFI sequencing and serum FI measurement. Eleven CFI RV genotypes that were challenging to categorize as type I (low serum level) or type II (normal serum level, reduced enzymatic function) were characterized in the context of pure FI protein in C3b and C4b fluid phase cleavage assays and a novel bead-based functional assay (BBFA) of C3b cleavage. Four variants predicted or previously characterized as benign were analyzed by BBFA for comparison. In all, three variants (W51S, C67R, and I370T) resulted in low expression. Furthermore, four variants (P64L, R339Q, G527V, and P528T) were identified as being highly deleterious with IC50s for C3b breakdown >1 log increased versus the WT protein, while two variants (K476E and R474Q) were ∼1 log reduced in function. Meanwhile, six variants (P50A, T203I, K441R, E548Q, P553S, and S570T) had IC50s similar to WT. Odds ratios and BBFA IC50s were positively correlated (r = 0.76, p < 0.01), while odds ratios versus combined annotation dependent depletion (CADD) scores were not (r = 0.43, p = 0.16). Overall, 15 CFI RVs were functionally characterized which may aid future patient stratification for complement-targeted therapies. Pure protein in vitro analysis remains the gold standard for determining the functional consequence of CFI RVs.}
}
@article{KOLLAROS2025113763,
title = {Uncovering the hidden dynamics of pollination in kiwifruit maturity and ripening},
journal = {Postharvest Biology and Technology},
volume = {230},
pages = {113763},
year = {2025},
issn = {0925-5214},
doi = {https://doi.org/10.1016/j.postharvbio.2025.113763},
url = {https://www.sciencedirect.com/science/article/pii/S0925521425003758},
author = {Marios Georgios Kollaros and Michail Michailidis and Alexandra Poulouktsi and Daniil Achilleas Pavlidis and Christina Skodra and Chrysanthi Polychroniadou and Martina Samiotaki and Katerina Karamanoli and Georgia Tanou and Athanassios Molassiotis},
keywords = {Artificial pollination, Fruit quality, Open-field pollination, Proteomics, Postharvest, Tissue-specific, Volatiles},
abstract = {Artificial pollination has gained increasing attention in kiwifruit cultivation; however, how different pollination methods influence fruit maturity and ripening remains poorly understood. To address this, the physiological, metabolomic, proteomic and gene expression impact of pollination methods (artificial versus open-field pollination) on the pericarp, placenta and seed tissue of Actinidia chinensis var. deliciosa A. Chev. ‘Hayward’ kiwifruit at maturity harvest and during postharvest ripening following short and long cold storage was investigated. Artificial pollination enhanced fruit set and seed number, resulting in increased fruit size and weight at harvest compared to open-field pollination, supporting its role in improving kiwifruit yield. Metabolomic analysis revealed that carbon is primarily redirected from sugar synthesis toward organic acid production in artificially pollinated fruit. Tissue-specific proteomic analysis indicated that artificial pollination alters plant growth regulator dynamics and induce extensive stress-associated responses. Moreover, artificial pollination accelerated kiwifruit ripening as evidenced by increased ethylene production and faster fruit softening. These changes were accompanied by altered expression of genes and proteins involved in ethylene signaling and cell wall structure, potentially reducing postharvest longevity. Additionally, artificial pollination decreased key esters and increased aldehydes, thus altering aroma volatile profiles. It also reduced the levels of important polyphenols, particularly catechin, epicatechin and procyanidin B2, which aligned with observed changes in gene expression. These findings highlight a critical trade-off: while artificial pollination enhances yield, it also modulates physiological processes that may compromise postharvest fruit quality. Overall, this study provides new insights into how pollination influences kiwifruit maturity and ripening, supporting pollination-based strategies to enhance both fruit yield and quality.}
}
@article{PARASAR2024105351,
title = {Root exudation drives abiotic stress tolerance in plants by recruiting beneficial microbes},
journal = {Applied Soil Ecology},
volume = {198},
pages = {105351},
year = {2024},
issn = {0929-1393},
doi = {https://doi.org/10.1016/j.apsoil.2024.105351},
url = {https://www.sciencedirect.com/science/article/pii/S0929139324000829},
author = {Bhaskar Jyoti Parasar and Indrani Sharma and Niraj Agarwala},
keywords = {Abiotic stress factors, Root exudates, Nutrient cycling, Plant-microbe interactions},
abstract = {Plants under changing conditions release different blends of root exudates, which can play key role in modulating rhizospheric microbiome and soil nutrient cycling. Correlational network analysis of stress alleviated root exudate compounds with the different rhizospheric microbes, depicts a significant relationship of plant associated microbes and exuded chemicals during stress condition/alleviation. Therefore, understanding the root associated structural and functional attributes with respect to the change in the environmental factors, modulating rhizospheric microbiome is utmost necessary. Here, we highlight the current knowledge of abiotic stress induced alteration in root exudates composition; and resulting modulation in the rhizospheric microbiome to alleviate plants from stress regimes. Understanding plant-root exudation-microbiome dynamics during stress condition can provide a way to develop innnovative solutions that can revolutionize sustainable agriculture.}
}
@article{SELCUK2025106136,
title = {AI-driven civil litigation: Navigating the right to a fair trial},
journal = {Computer Law & Security Review},
volume = {57},
pages = {106136},
year = {2025},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2025.106136},
url = {https://www.sciencedirect.com/science/article/pii/S2212473X25000094},
author = {Seyhan Selçuk and Nesibe {Kurt Konca} and Serkan Kaya},
keywords = {AI in legal proceedings, Automated legal reasoning, ECHR article 6, European union AI act, Judicial independence and AI, Publicity principle in AI justice, Right to a fair trial},
abstract = {The integration of artificial intelligence (AI) into legal proceedings has gained significant traction in recent years, particularly following the Covid-19 pandemic. As part of the broader movement toward the digitalization of legal systems, AI is seen as a tool to improve access to justice, enhance efficiency, and adopt a human-centered approach. However, the rapid advancement of AI necessitates careful consideration of fundamental human rights, especially the right to a fair trial as enshrined in Article 6 of the European Convention on Human Rights (ECHR). Recently, the European Union's Artificial Intelligence Act classifies AI systems used in the judiciary as high-risk, requiring impact assessments on fundamental rights, including the right to a fair trial. This paper explores the impact of AI-driven judicial tools on the right to a fair trial, focusing on key components such as the right to be heard, judicial independence, impartiality, and the principle of publicity. This paper explores the impact of AI-driven judicial tools on the right to a fair trial, focusing on key components such as the right to be heard, judicial independence, impartiality, and the principle of publicity, while examining the risks and opportunities posed by AI in civil litigation, including challenges like algorithmic discrimination, digital exclusion, and the potential erosion of human judges' cognitive abilities.}
}
@article{WULFERT2024104035,
title = {Follow the flow: An exploratory multi-case study of value creation in e-commerce ecosystems},
journal = {Information & Management},
volume = {61},
number = {8},
pages = {104035},
year = {2024},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2024.104035},
url = {https://www.sciencedirect.com/science/article/pii/S0378720624001174},
author = {Tobias Wulfert and Robert Woroch and Gero Strobel},
keywords = {E-commerce, Business ecosystems, Platforms, Value creation, Value network analysis, Multi-case study},
abstract = {Platform-based ecosystems dominate e-commerce, generating value through participant growth and resulting network effects. However, research has lacked any conceptualization of value creation in e-commerce ecosystems. This paper fills this gap by providing a theoretically grounded and empirically validated conceptualization of value creation and exchange, including roles, value creation activities, and value flows among participants. The model integrates insights from a systematic literature review and a multi-case study of ten leading e-commerce ecosystems. Furthermore, an extension to the e3-value notation is proposed by introducing ecosystem segments, allowing for a higher level of abstraction of meta-roles and individual ecosystem participants.}
}
@incollection{KHAN202545,
title = {Chapter 3 - Overview of AI technologies and their impact on healthcare},
editor = {Sameer Mohommed Khan},
booktitle = {Fundamentals of AI for Medical Education, Research and Practice},
publisher = {Academic Press},
pages = {45-71},
year = {2025},
isbn = {978-0-443-33584-6},
doi = {https://doi.org/10.1016/B978-0-443-33584-6.00003-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780443335846000037},
author = {Sameer Mohommed Khan},
keywords = {AI technologies in healthcare, Artificial neural network (ANN), Convolutional neural network (CNN), Deep learning, Feed forward neural network (FNN), Intelligent tutoring system (ITS), Internet of things (IOT), Machine learning, Perceptron, Reinforcement learning, Smart health card},
abstract = {In recent years, artificial intelligence (AI) has become more and more common, especially in the healthcare industry. Its influence has been so big that it has established itself as a pillar of the medical industry. Over the past few years, the application of AI technology to numerous fields in medical research and patient care has resulted in more precise diagnosis, individualized treatment regimens, and better patient outcomes. AI has a broad use in healthcare, including the analysis of radiological images for the purpose of early disease identification and the use of electronic health data to predict patient outcomes. As a result, millions of people worldwide may now receive the best treatment possible thanks to smarter, quicker, and more effective healthcare procedures. The chapter introduces the reader to various AI technologies and explores how a wide range of technologies, including computer vision, robotic processing automation, natural language processing, and machine learning, have significantly improved patient care and allowed for more accurate diagnosis and treatment.}
}
@article{VANNGUYEN2023109558,
title = {Digital transformation for cost estimation system via meta-learning and an empirical study in aerospace industry},
journal = {Computers & Industrial Engineering},
volume = {184},
pages = {109558},
year = {2023},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2023.109558},
url = {https://www.sciencedirect.com/science/article/pii/S036083522300582X},
author = {Tran Hong {Van Nguyen} and Pei-Min Huang and Chen-Fu Chien and Chung-Kai Chang},
keywords = {Digital transformation, Cost estimation, Aerospace manufacturing, Artificial intelligence, Decision support system},
abstract = {It is increasingly challenging to estimate product cost to optimize the quotation decision for aerospace manufacturing companies owing to the diversity of designations, intermittent demands, complicated decision procedure between different functional departments, and knowledge gaps among the involved decision makers. There is a need of effective solutions to support digital transformation of manual approach in which it can expedite and enhance the accuracy of cost estimation by automating specific tasks and streamlining decision processes. Although a number of studies have been done to enhance the performance of forecasting models, little research has been done to address the interrelations between cost estimation model and the associated decisions for quotation. Focusing on realistic needs, this study aims to develop a digital cost estimation system by integrating data-driven methodologies, search engines, and rule-based decision mechanism based on domain knowledge for improving the accuracy of cost estimation and the effectiveness of quotation for revenue management. An empirical study was conducted in a global aerospace manufacturer in Taiwan for validation. The results have shown the practical viability for the proposed framework with better performance than conventional approaches. The developed solution has been implemented.}
}
@article{HAFFNER2025101905,
title = {Directions for future IS research on sports digitalisation: A stakeholder perspective},
journal = {The Journal of Strategic Information Systems},
volume = {34},
number = {2},
pages = {101905},
year = {2025},
issn = {0963-8687},
doi = {https://doi.org/10.1016/j.jsis.2025.101905},
url = {https://www.sciencedirect.com/science/article/pii/S0963868725000204},
author = {Lily Haffner and Ilan Oshri and Julia Kotlarsky},
keywords = {Sports Digitalisation, Stakeholder Perspective, Theoretical Review, Sports},
abstract = {In this theoretical review, we analyse the IS literature on the rapidly evolving strategic phenomenon of sports digitalisation. We provide insights on how sports digitalisation is currently understood in the IS literature when examined from a stakeholder perspective. Our analysis identifies the key stakeholders involved in sports, the competition stages (i.e., before, during, or after), the nature of digitalisation in sports, and the key outcomes on which the literature focuses (behavioural, cognitive, and performance-related). Our analysis also points out several gap areas in the extant literature: the lack of attention paid to non-competing stakeholders (e.g., managers, referees, spectators) and the behavioural impact of digitalisation on stakeholders during competitions; and the current focus on analysing the effect of a single digitalisation solution on a single stakeholder. Building on these findings, we propose three future directions to advance research on sports digitalisation. First, future research needs to examine the effect of digitalisation on an eco-system of sports stakeholders. Second, the use of naturalistic reality images as a data source would enhance research during competition. Last, future studies need to consider the blending of borrowed (behavioural and cognitive) theories and novel digitally-enhanced concepts to strengthen the theoretical foundations of sports digitalisation in Information Systems.}
}
@article{KNIGHT2024102972,
title = {The evolution of contemporary education hubs: Fad, brand or innovation?},
journal = {International Journal of Educational Development},
volume = {104},
pages = {102972},
year = {2024},
issn = {0738-0593},
doi = {https://doi.org/10.1016/j.ijedudev.2023.102972},
url = {https://www.sciencedirect.com/science/article/pii/S0738059323002481},
author = {Jane Knight},
keywords = {Education hub, Education city, Knowledge city, Research/innovation, Branch campus, Transnational education},
abstract = {The purpose of this article is to examine the evolution of education hubs over the last two decades and revisit the question as to whether they are a fad, brand or innovation. Key features of ten different education hub countries, at different stages of development and sustainability, are analyzed leading to the identification of contemporary trends and challenges for student, talent/workforce and knowledge/innovation hubs. Given that education hubs are a seriously understudied phenomenon, critical issues relating to potential impact of geo-political instability, recognition of credentials, quality assurance, recruitment and retention of students for workforce and transition to knowledge economy, collaboration and/or competition between local/foreign actors, research integrity and knowledge security, private ownership/funders of branch campuses, will be of interest to policy makers, academic leaders, and researchers/scholars.}
}
@article{LI2024128185,
title = {Urban park attributes as predictors for the diversity and composition of spontaneous plants − A case in Beijing, China},
journal = {Urban Forestry & Urban Greening},
volume = {91},
pages = {128185},
year = {2024},
issn = {1618-8667},
doi = {https://doi.org/10.1016/j.ufug.2023.128185},
url = {https://www.sciencedirect.com/science/article/pii/S1618866723003564},
author = {Xiaopeng Li and Xiaolu Li and Mengyuan Zhang and Qinyu Luo and Yilun Li and Li Dong},
keywords = {Taxonomic composition, Urban parks, Diversity and similarity, Landscape pattern, Planting design},
abstract = {Urban biodiversity homogenization and native species habitat loss are becoming increasingly severe. The overuse of lawn grasses and cultivars in green spaces is one of the most important drivers. Scholars have asserted that spontaneous vegetation provides various ecological benefits and should be widely incorporated in planting design. Factors influencing spontaneous plant diversity have mainly been studied in specific habitats or at the city scale, and findings surrounding the attributes of urban parks that support the diversity of spontaneous plants are lacking. This study aimed to provide a perspective on conserving spontaneous plants through inferring the urban park attributes associated with plant diversity. Twenty-two urban park samples in Beijing were examined to identify the correlation between various park variables and spontaneous vegetation. This study recorded 199 spontaneous plant species, with large historic parks containing the most number of species. Park size was a remarkable predictive variable for the diversity of spontaneous plants. Species richness and diversity in large parks were significantly higher than in small parks; not only in total richness due to the species–area relationship but also in richness and diversity at the community level independent of plot number. Microhabitat heterogeneity and the percentage of green area had the strongest positive association with the richness of spontaneous plants. In contrast, the maintenance intensity, perimeter–area ratio, and fragmentation of green area, deciduous forest, and open lawn patches had negative associations with spontaneous plant richness. Redundancy analysis demonstrated that park area, maintenance intensity, microhabitat heterogeneity, and deciduous forest patches were the most remarkable variables predicting species composition. The correlations of variables related to water and open lawn patches with spontaneous plant diversity were more evident in summer. The predicted variables were also more significantly correlated with the diversity of exotic species in summer than in spring. Perennial herbs were more sensitive to the evaluated park attributes. This study elucidates how spontaneous plants are associated with the attributes of urban parks in Beijing, with critical implications for other large cities.}
}
@article{2024A9,
title = {Guide for Authors},
journal = {Journal of the American Society of Echocardiography},
volume = {37},
number = {7},
pages = {A9-A18},
year = {2024},
note = {35th ASE Annual Scientific Sessions},
issn = {0894-7317},
doi = {https://doi.org/10.1016/S0894-7317(24)00239-6},
url = {https://www.sciencedirect.com/science/article/pii/S0894731724002396}
}
@article{FUNA2025101221,
title = {Policy guidelines and recommendations on AI use in teaching and learning: A meta-synthesis study},
journal = {Social Sciences & Humanities Open},
volume = {11},
pages = {101221},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2024.101221},
url = {https://www.sciencedirect.com/science/article/pii/S2590291124004182},
author = {Aaron A. Funa and Renz Alvin E. Gabay},
keywords = {AI ethics, AI integration, AI in education, AI in teaching and learning, Artificial intelligence, ChatGPT},
abstract = {As artificial intelligence becomes increasingly integral to educational systems, understanding policy guidelines and recommendations from various sources is crucial. This meta-synthesis examines AI policies and guidelines from peer-reviewed articles, reports, books, and websites from 2020 to 2024, with a focus on their implications for teaching and learning. Using a thematic analysis approach, the study categorizes findings into key themes and subthemes. Under the theme of policies and guidelines, notable subthemes include ethical AI use, AI literacy, and inclusivity and equity. In terms of implementation strategies, the synthesis identifies crucial areas such as student orientation and professional development, enhanced teaching tools and data-driven insights, improved student learning outcomes and engagement, and streamlined administrative processes. The study also determines practical constraints that challenge the successful integration of AI in education, including technical and integration challenges, training and support issues, ethical and fairness concerns, cost and accessibility, transparency and privacy issues, and misalignment with educational goals. Future research may explore the long-term impacts of AI integration policies and guidelines, refine practical implementation strategies, and foster collaboration among researchers, educators, and policymakers to tackle ongoing challenges and maximize AI's potential in education.}
}
@article{MODEEL2025,
title = {Emerging Risk Factors and the Role of Gut Microbiota in Immunomodulation and Therapeutic Implications in Colorectal Cancer},
journal = {Cancer Pathogenesis and Therapy},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2025.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S294971322500076X},
author = {Sonakshi Modeel and Sneha Siwach and Padma Dolkar and Meenu Chaurasia and Pankaj Yadav and Apoorva Atri and Aarzoo Yadav and Tarana Negi and Ram Krishan Negi},
keywords = {Colorectal cancer, CRC therapy, Gastrointestinal Microbiome, Immunomodulation, Probiotics, Risk factors},
abstract = {The pathophysiology of many ailments, including neurological, gastrointestinal, and metabolic problems, is well known to be influenced by intestinal dysbiosis. Clinical research has provided evidence suggesting a strong correlation between dysbiosis of the gut microbiome and colorectal cancer (CRC) development. The active reprogramming of metabolic pathways to boost glycolysis, fatty acid production, lipogenesis, and glutaminolysis constitutes a major metabolic shift in cancer development, including CRC. The complex combination of different factors leads to CRC, making it an environmental disease. These factors include food and lifestyle choices, genetics and family history, age, underlying intestinal diseases, and dysbiosis of the gut microbiota. One of the primary risk factors for carcinoma development is diet, which impacts an individual's gut microbiome. In addition to impacting CRC formation, the gut microbiome also has immunomodulatory effects, including various immunological interactions and the underlying mechanisms governing them. Microbial interactions in CRC have been extensively studied, yet numerous unresolved queries exist on how gut bacteria can influence treatment. It is possible to perform microbiome-driven immunotherapies focusing on probiotics, prebiotics, and synbiotics. However, large-scale treatment utilization in CRC patients is limited by several issues, including variations in the microbial makeup of each patient's gut and a lack of established methods. The study highlights the impact of several risk factors, including dysbiosis of the gut microbiome and different approaches to halting and treating CRC progression with a focus on diet changes and modulation of the gut flora. Given the foregoing, we propose that if research gaps are addressed and immunotherapy is paired with microbial interventions, microbiota-based therapeutics could potentially impede the growth of tumors and treat CRC.}
}
@article{HADAN2024100095,
title = {The great AI witch hunt: Reviewers’ perception and (Mis)conception of generative AI in research writing},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {2},
number = {2},
pages = {100095},
year = {2024},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2024.100095},
url = {https://www.sciencedirect.com/science/article/pii/S2949882124000550},
author = {Hilda Hadan and Derrick M. Wang and Reza Hadi Mogavi and Joseph Tu and Leah Zhang-Kennedy and Lennart E. Nacke},
keywords = {Artificial intelligence, Generative AI, Reviewer perception, Research writing, AI writing augmentation},
abstract = {Generative AI (GenAI) use in research writing is growing fast. However, it is unclear how peer reviewers recognize or misjudge AI-augmented manuscripts. To investigate the impact of AI-augmented writing on peer reviews, we conducted a snippet-based online survey with 17 peer reviewers from top-tier HCI conferences. Our findings indicate that while AI-augmented writing improves readability, language diversity, and informativeness, it often lacks research details and reflective insights from authors. Reviewers consistently struggled to distinguish between human and AI-augmented writing but their judgements remained consistent. They noted the loss of a “human touch” and subjective expressions in AI-augmented writing. Based on our findings, we advocate for reviewer guidelines that promote impartial evaluations of submissions, regardless of any personal biases towards GenAI. The quality of the research itself should remain a priority in reviews, regardless of any preconceived notions about the tools used to create it. We emphasize that researchers must maintain their authorship and control over the writing process, even when using GenAI's assistance.}
}
@article{KUO2023110976,
title = {A semantic web-based risk assessment framework for collaborative planning to enhance overall supply chain effectiveness for semiconductor industry},
journal = {Applied Soft Computing},
volume = {149},
pages = {110976},
year = {2023},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2023.110976},
url = {https://www.sciencedirect.com/science/article/pii/S1568494623009948},
author = {Hsuan-An Kuo and Chen-Fu Chien and Hans Ehm and Thomas Ponsignon},
keywords = {Semantic web, Semiconductor manufacturing, Overall supply chain effectiveness, System interoperability, Root cause diagnosis},
abstract = {Semiconductor supply chain uncertainty is increasingly complicated due to shortening product life cycles, demand fluctuation and a series of collaborative decisions, yet little research focuses on risk assessment from operational planning level to supply chain planning level. Limitations of existing approaches can be traced in part to the lack of a framework within which the decisions involved in different levels can be integrated and aligned in light of supply chain dynamics. This study aims to develop a semantic web based risk assessment framework to integrate collaborative planning and enable the interpretability among real world and simulation modelling. This study starts by proposing a performance elevation metric from interpreting planning level for overall supply chain effectiveness. This study further constructs an ontology for planning and control decisions to support building the risk assessment simulation model to ensure information system interoperability and link domain knowledge for semiconductor supply chain network resilience. For validation, a simulation model is constructed for backend production from a leading semiconductor company in Germany. The contribution of the proposed semantic web-based framework provides the interoperability for supporting supply chain management and reduces the gaps between simulation modelling and physical setting to enhance overall supply chain effectiveness.}
}
@article{VONGILLERN2024104404,
title = {Media literacy, digital citizenship and their relationship: Perspectives of preservice teachers},
journal = {Teaching and Teacher Education},
volume = {138},
pages = {104404},
year = {2024},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2023.104404},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X2300392X},
author = {Sam {von Gillern} and Matthew Korona and William Wright and Hillary Gould and Brandon Haskey-Valerius},
keywords = {Media literacy, Digital citizenship, Preservice teachers},
abstract = {Scholarship has examined media literacy and digital citizenship in various ways, yet limited research has examined connections between these concepts, which may have implications for teaching and learning. This case study investigated 111 preservice teachers’ perspectives on media literacy, digital citizenship, and their relationship via examining their responses to essay questions. Data analysis revealed central themes in their perceptions of media literacy, digital citizenship, and their relationship, which aligned with both empowerment and protectionist perspectives of media and digital engagement. This study illuminates relational understandings of media literacy and digital citizenship and demonstrates the value of teaching them in concert.}
}
@article{MALAKAR2025109540,
title = {Compact representation for memory-efficient storage of images using genetic algorithm-guided key pixel selection},
journal = {Engineering Applications of Artificial Intelligence},
volume = {139},
pages = {109540},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.109540},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624016981},
author = {Samir Malakar and Nirwan Banerjee and Dilip K. Prasad},
keywords = {Compact representation, Genetic algorithm, Memory efficient, Gaussian kernel, Storage reduction},
abstract = {In the past few years, we have observed rapid growth in digital content. Even in the biological domain, the arrival of microscopic and nanoscopic images and videos captured for biological investigations increases the need for space to store them. Hence, storing these data in a storage-efficient manner is a pressing need. In this work, we have introduced a compact image representation technique with an eye on preserving the shape that can shrink the memory requirement to store. The compact image representation is different from image compression since it does not include any encoding mechanism. Rather, the idea is that this mechanism stores the positions of key pixels, and when required, the original image can be regenerated. The genetic algorithm is used to select key pixels, while the Gaussian kernel performs the reconstruction task with the help of the positions of the selected key pixels. The model is tested on four different datasets. The proposed technique shrinks the memory requirement by 87% to 98% while evaluated using the bit reduction rate. However, the reconstructed images’ quality is a bit low when evaluated using metrics like structural similarity index (ranges between 0.81 to 0.94), or root means squared error (ranges between 0.06 to 0.08). To investigate the impact of quality reduction in reconstructed images in real-life applications, we performed image classification using reconstructed samples and found 0.13% to 2.30% classification accuracy reduction compared to when classification is done using original samples. The proposed model’s performance is comparable to state-of-the-art’s similar solutions.}
}
@article{MUKHERJEE2025104402,
title = {Factors impeding buy now, pay later (BNPL) adoption in India: A mixed-method approach},
journal = {Journal of Retailing and Consumer Services},
volume = {87},
pages = {104402},
year = {2025},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2025.104402},
url = {https://www.sciencedirect.com/science/article/pii/S096969892500181X},
author = {Shreya Mukherjee},
keywords = {Buy now pay later (BNPL), Decision making trial and evaluation laboratory (DEMATEL), Financial technology adoption, Mixed-methods, Behavioral finance, Netnography, Innovation resistance theory},
abstract = {Buy Now, Pay Later (BNPL) services are reshaping digital credit access in India, yet their adoption remains limited due to complex and interrelated consumer barriers. While previous research has explored general fintech or digital payment adoption, there is a significant gap in understanding BNPL-specific barriers, particularly how these barriers influence one another within India’s distinct socio-economic and regulatory landscape. India’s rapid fintech growth, large unbanked population, evolving regulatory environment, and uneven levels of digital and financial literacy make it a unique and urgent case for such inquiry. Thus, this study aims to identify and rank the key barriers to BNPL adoption in the Indian context and analyze their causal interrelationships, and adopts a sequential mixed-methods design for the same. In the qualitative phase, a netnographic analysis of BNPL app reviews—supported by existing literature (specifically Innovation Resistance Theory) and expert insights—was used to identify barriers. In the quantitative phase, the ‘Decision-Making Trial and Evaluation Laboratory’ (DEMATEL) method was employed to analyze seven identified barriers, categorize them into causal and effect groups, and assess their interdependencies. The findings reveal digital illiteracy as the most influential causal barrier, affecting others such as inertia, privacy concerns, hidden fees and high penalty fees, and negative credit profiles. Impulse buying and regulatory concerns also emerged as key causal factors. The study offers practical recommendations, such as financial education, responsible lending, and regulatory reform, and contributes to BNPL literature by applying a novel methodological lens to an underexplored market. These insights can guide stakeholders seeking to responsibly scale BNPL adoption in India.}
}
@article{ESPANA2025102373,
title = {Ethical reasoning methods for ICT: What they are and when to use them},
journal = {Data & Knowledge Engineering},
volume = {155},
pages = {102373},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2024.102373},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X24000971},
author = {Sergio España and Chris {van der Maaten} and Jens Gulden and Óscar Pastor},
keywords = {Conceptual modelling, Ethics, Ethical reasoning, Sustainability assessment, Method engineering, Situational factors},
abstract = {Information and communication technology (ICT) brings about numerous advantages across various domains of our lives. However, alongside these benefits, there is a growing awareness of its potential negative ethical, social, and environmental impacts. Consequently, stakeholders ranging from conceptual modellers to policy makers often find themselves grappling with ethical considerations stemming from ICT engineering and usage. This paper presents a review of 10 ethical reasoning methods suitable for the ICT domain. We have employed a method engineering technique to author metamodels for the methods, which were subsequently subjected to validation by experts proficient in the respective methods. Following a situational method engineering approach, we have also characterised each ethical reasoning method and validated the characterisation with the experts. This has allowed us to develop a tool that helps select the method that is most suitable for a given ethical reasoning situation. Furthermore, we deliberate on the practical application of ethical reasoning methods within conceptual modelling contexts. We are confident that we have laid the groundwork for further research into ethical reasoning of ICT, with a specific emphasis on its role during conceptual modelling.}
}
@article{BEG2025120538,
title = {Correlative activation free energy (CAFE) model: Application to viscous processes in inorganic oxide glass-formers},
journal = {Acta Materialia},
volume = {283},
pages = {120538},
year = {2025},
issn = {1359-6454},
doi = {https://doi.org/10.1016/j.actamat.2024.120538},
url = {https://www.sciencedirect.com/science/article/pii/S1359645424008838},
author = {Cameran Beg and Jaemin Byeon and Nova Berman and John Kieffer},
keywords = {Viscosity, Glass transition, Transition state theory, Logistic function, Energy landscape},
abstract = {We explore the concept of correlative activation free energy (CAFE) for the analysis and interpretation of viscosity data of a collection of 847 inorganic oxide glass formers that exhibit various degrees of non-Arrhenius behavior. The CAFE model formalism is strictly based on transition state theory and accounts for the variation in the activation barrier height for the viscous dissipation due to the structural evolution the system undergoes upon traversing the glass transition regime. Thus, fitting parameters are meaningful in a statistical thermodynamic context. Compared to the VFT and MYEGA equations, fits using the CAFE model are more robust when extrapolating to infinite temperature because the latter encodes non-enthalpic contributions to the rate coefficient more realistically. The CAFE model-based analysis reveals a strong connection between melt fragility and the degree of change in the potential energy landscape with temperature. Accordingly, while the average ground-state potential energy of the glass forming liquid gradually increases with temperature, the energy of the activated state remains relatively invariant. Our analysis also allows one to estimate the number of atoms involved in the viscous relaxation process, which ranges from approximately 10 to 50 atoms for the oxide glass formers studied. We observe that thermally activated dynamic phenomena exhibited by glassy networks, such as the mixed alkali effect, persist into the supercooled liquid state.}
}
@article{SOROOSHIAN2025146,
title = {Influencer marketing: service supplier selection},
journal = {Management Decision},
volume = {63},
number = {13},
pages = {146-173},
year = {2025},
issn = {0025-1747},
doi = {https://doi.org/10.1108/MD-12-2023-2366},
url = {https://www.sciencedirect.com/science/article/pii/S0025174725000035},
author = {Shahryar Sorooshian},
keywords = {Influencer marketing, Service supplier, Social media influencer, Internet celebrities, Influencer endorsement},
abstract = {Purpose
The main objective of this study is to lay the groundwork for a systematic approach to selecting social media influencers (SMI) for influencer marketing campaigns.
Design/methodology/approach
This study achieves its objective by presenting an innovative framework that combines the ordinal priority approach (OPA) with the Delphi method. This hybrid approach is applied to an academic event promotion case study. The original 22 selection criteria for SMIs were derived from the Delphi evaluation. These criteria were subsequently ranked using modified OPA to select influencers in a systematic and hierarchical fashion.
Findings
This research proves the effectiveness of the framework by applying it to a case study. Three top-level critical criteria, 13 intermediate-level criteria and six additional criteria are revealed by this hierarchical prioritization of SMI selection criteria. This methodical procedure allows for a more logical and educated decision-making process in selecting the best influencers for marketing campaigns. This research also proves the feasibility of the proposed model.
Practical implications
Better influencer marketing campaigns and marketing resource allocation are possible outcomes of the suggested framework, which marketers and businesses can use as a more organized and objective tool for selecting SMIs.
Originality/value
This study contributes to the field of influencer marketing by developing and validating a novel decision framework. This work not only fills the gap in existing research regarding quantitative decision-making models for SMI selection but also expands applications of the OPA method to address service supplier selection problems.}
}
@article{GARRARD2024171282,
title = {Identifying potential high-risk zones for land-derived plastic litter to marine megafauna and key habitats within the North Atlantic},
journal = {Science of The Total Environment},
volume = {922},
pages = {171282},
year = {2024},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2024.171282},
url = {https://www.sciencedirect.com/science/article/pii/S0048969724014219},
author = {Samantha L. Garrard and James R. Clark and Nicola Martin and Sarah E. Nelms and Zara L.R. Botterell and Matthew Cole and Rachel L. Coppock and Tamara S. Galloway and Dannielle S. Green and Megan Jones and Pennie K. Lindeque and Heidi M. Tillin and Nicola J. Beaumont},
keywords = {Marine plastic pollution, Land-derived plastic litter, North Atlantic, Marine megafauna, Biogenic habitats, Risk assessment},
abstract = {The pervasive use of plastic in modern society has led to plastic litter becoming ubiquitous within the ocean. Land-based sources of plastic litter are thought to account for the majority of plastic pollution in the marine environment, with plastic bags, bottles, wrappers, food containers and cutlery among the most common items found. In the marine environment, plastic is a transboundary pollutant, with the potential to cause damage far beyond the political borders from where it originated, making the management of this global pollutant particularly complex. In this study, the risks of land-derived plastic litter (LDPL) to major groups of marine megafauna – seabirds, cetaceans, pinnipeds, elasmobranchs, turtles, sirenians, tuna and billfish – and a selection of productive and biodiverse biogenic habitats – coral reefs, mangroves, seagrass, saltmarsh and kelp beds – were analysed using a Spatial Risk Assessment approach. The approach combines metrics for vulnerability (mechanism of harm for megafauna group or habitat), hazard (plastic abundance) and exposure (distribution of group or habitat). Several potential high-risk zones (HRZs) across the North Atlantic were highlighted, including the Azores, the UK, the French and US Atlantic coasts, and the US Gulf of Mexico. Whilst much of the modelled LDPL driving risk in the UK originated from domestic sources, in other HRZs, such as the Azores archipelago and the US Gulf of Mexico, plastic originated almost exclusively from external (non-domestic) sources. LDPL from Caribbean islands - some of the largest generators of marine plastic pollution in the dataset of river plastic emissions used in the study - was noted as a significant input to HRZs across both sides of the Atlantic. These findings highlight the potential of Spatial Risk Assessment analyses to determine the location of HRZs and understand where plastic debris monitoring and management should be prioritised, enabling more efficient deployment of interventions and mitigation measures.}
}
@article{NI2025126420,
title = {Enhancing supply chain resilience and efficiency of HVAC systems in semiconductor manufacturing facilities using graph-based large multimodal models},
journal = {Applied Energy},
volume = {398},
pages = {126420},
year = {2025},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2025.126420},
url = {https://www.sciencedirect.com/science/article/pii/S030626192501150X},
author = {Hsiao-Ping Ni and Chi-Yun Liu and Fermodelie Paul and Wai Oswald Chong and Jui-Sheng Chou},
keywords = {Large multimodal model, Graph neural network, HVAC systems, Semiconductor manufacturing facilities, Supply chain management, Circular economy},
abstract = {Semiconductor manufacturing facilities (SMFs) demand ultra-precise environmental conditions maintained by specialized HVAC systems, critical for a resilient and sustainable semiconductor supply chain. While AI-driven solutions have been applied to generic supply chain optimization, they often fail in addressing the unique challenges of SMFs, where HVAC systems must maintain sub-0.1 °C temperature stability, account for 40–60 % of facility energy consumption, and comply with stringent cleanroom standards. This paper proposes an innovative framework that integrates graph-based large multimodal models (G-LMMs), enhanced by graph neural networks (GNNs), to optimize SMF HVAC supply chains across the Design, Construction, Installation, Maintenance, and Operation (DCIMO) phases. GNNs enable the capture and analysis of complex relationships within HVAC systems, facilitating real-time anomaly detection and optimized material flows. Unlike conventional AI models, G-LMMs combine GNNs with multimodal data processing to achieve three key advancements: (1) real-time anomaly detection, (2) automated compliance monitoring, and (3) circular economy integration through resource reuse. G-LMMs enhance supply chain visibility by harmonizing diverse data types while meeting SMFs' precision requirements. As the first framework to unify GNNs and multimodal AI for HVAC optimization, this approach represents a paradigm shift in sustainable semiconductor manufacturing, with broader implications for industries reliant on precision-controlled environments.}
}
@article{BAIER2022325,
title = {Success factors of process digitalization projects – insights from an exploratory study},
journal = {Business Process Management Journal},
volume = {28},
number = {2},
pages = {325-347},
year = {2022},
issn = {1463-7154},
doi = {https://doi.org/10.1108/BPMJ-07-2021-0484},
url = {https://www.sciencedirect.com/science/article/pii/S146371542200019X},
author = {Marie-Sophie Baier and Jannik Lockl and Maximilian Röglinger and Robin Weidlich},
keywords = {Business process management, Digitalization, Success factors, Literature review, Exploratory interviews},
abstract = {Purpose
In an exploratory approach, the authors conducted a structured literature review to extract candidate process digitalization project (PDP) success factors (SFs) from the literature on business process management (BPM), project management (PM) and digitalization. After that, the authors validated, refined and extended these intermediate results through interviews with 21 members of diverse PDP teams. Finally, the authors proposed the PDP success model by linking the candidate SFs with relevant success criteria.
Design/methodology/approach
Digitalization substantially impacts organizations, which increasingly use digital technologies (DTs) to improve and innovate their business processes. While there are methods and tools for identifying process digitalization ideas and related projects (PDPs), guidance on the successful implementation of PDPs is missing. Hence, the authors set out to explore PDP SFs.
Findings
The PDP success model covers 38 PDP success factor candidates, whereof 28 are already backed by the literature and ten have emerged during the interviews. Furthermore, the SFs are structured according to seven categories from the literature covering a broad range of sociotechnical topics (i.e. strategy, structure, culture, people, process, project and technology) as well as equipped with preliminary success rationales.
Originality/value
The work is the first to systematically explore PDP SFs. The PDP success model shows that PDPs require a unique set of SFs, which combine established and hitherto underrepresented knowledge. It extends the knowledge on BPM and serves as foundation for future (confirmatory) research on business process digitalization and the successful implementation of PDPs.}
}
@article{JANG2024107557,
title = {Effects of time-of-use pricing for residential customers and wholesale market consequences in South Korea},
journal = {Energy Economics},
volume = {134},
pages = {107557},
year = {2024},
issn = {0140-9883},
doi = {https://doi.org/10.1016/j.eneco.2024.107557},
url = {https://www.sciencedirect.com/science/article/pii/S0140988324002652},
author = {Heesun Jang and Seongman Moon and Jihyo Kim},
keywords = {Time-of-use pricing, Residential electricity, Wholesale market, Load transfer, Producer surplus},
abstract = {Using a large-scale pilot test on time-of-use (TOU) pricing for residential customers, this study analyzes the effects of TOU pricing on the load patterns of residential customers and on producer surplus in South Korea. We estimate the difference in the electricity demand functions of residential customers across peak, intermediate, and off-peak periods before and after TOU pricing. In addition, we assess the supply curve in the wholesale electricity market and calculate the changes in electricity purchase costs by integrating the supply curve over the range of consumption changes across the periods. This study simulates the effects of TOU pricing on producer surplus that would be obtained if all residential customers in South Korea switch from increasing block pricing to TOU pricing. Our results show that TOU pricing can be an effective measure for load transfer and simultaneously increase producer surplus. We find that although the revenue of electric utility generally decreases, the cost savings are greater and thus producer surplus increases. The results can be a valuable reference for the South Korean government regarding the nationwide expansion of TOU for residential electricity in the future.}
}
@article{YI2025,
title = {Bridging Technology and Pretest Genetic Services: Quantitative Study of Chatbot Interaction Patterns, User Characteristics, and Genetic Testing Decisions},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/73391},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125012646},
author = {Yang Yi and Lauren Kaiser-Jackson and Jemar R Bather and Melody S Goodman and Daniel Chavez-Yenter and Richard L Bradshaw and Rachelle Lorenz Chambers and Whitney F Espinel and Rachel Hess and Devin M Mann and Rachel Monahan and David W Wetter and Ophira Ginsburg and Meenakshi Sigireddi and Kensaku Kawamoto and Guilherme {Del Fiol} and Saundra S Buys and Kimberly A Kaphingst},
keywords = {cancer genetics, chatbot delivery, user interaction, genetic testing, pretest genetic services},
abstract = {Background
Among the alternative solutions being tested to improve access to genetic services, chatbots (or conversational agents) are being increasingly used for service delivery. Despite the growing number of studies on the accessibility and feasibility of chatbot genetic service delivery, limited attention has been paid to user interactions with chatbots in a real-world health care context.
Objective
We examined users’ interaction patterns with a pretest cancer genetics education chatbot as well as the associations between users’ clinical and sociodemographic characteristics, chatbot interaction patterns, and genetic testing decisions.
Methods
We analyzed data from the experimental arm of Broadening the Reach, Impact, and Delivery of Genetic Services, a multisite genetic services pragmatic trial in which participants eligible for hereditary cancer genetic testing based on family history were randomized to receive a chatbot intervention or standard care. In the experimental chatbot arm, participants were offered access to core educational content delivered by the chatbot with the option to select up to 9 supplementary informational prompts and ask open-ended questions. We computed descriptive statistics for the following interaction patterns: prompt selections, open-ended questions, completion status, dropout points, and postchat decisions regarding genetic testing. Logistic regression models were used to examine the relationships between clinical and sociodemographic factors and chatbot interaction variables, examining how these factors affected genetic testing decisions.
Results
Of the 468 participants who initiated a chat, 391 (83.5%) completed it, with 315 (80.6%) of the completers expressing a willingness to pursue genetic testing. Of the 391 completers, 336 (85.9%) selected at least one informational prompt, 41 (10.5%) asked open-ended questions, and 3 (0.8%) opted for extra examples of risk information. Of the 77 noncompleters, 57 (74%) dropped out before accessing any informational content. Interaction patterns were not associated with clinical and sociodemographic factors except for prompt selection (varied by study site) and completion status (varied by family cancer history type). Participants who selected ≥3 prompts (odds ratio 0.33, 95% CI 0.12-0.91; P=.03) or asked open-ended questions (odds ratio 0.46, 95% CI 0.22-0.96; P=.04) were less likely to opt for genetic testing.
Conclusions
Findings highlight the chatbot’s effectiveness in engaging users and its high acceptability, with most participants completing the chat, opting for additional information, and showing a high willingness to pursue genetic testing. Sociodemographic factors were not associated with interaction patterns, potentially indicating the chatbot’s scalability across diverse populations provided they have internet access. Future efforts should address the concerns of users with high information needs and integrate them into chatbot design to better support informed genetic decision-making.}
}
@incollection{2025391,
title = {Index},
editor = {Kanti Bhooshan Pandey and David J. Newman and Chukwuebuka Egbuna},
booktitle = {Drug Discovery and One Health Approach in Combating Infectious Diseases},
publisher = {Elsevier},
pages = {391-408},
year = {2025},
series = {Drug Discovery Update},
isbn = {978-0-443-27461-9},
doi = {https://doi.org/10.1016/B978-0-443-27461-9.20001-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443274619200012}
}
@article{GANT2024104829,
title = {High strain rate responses of some metals and alloys using a plate impact driven ring expansion test (PIDRET)},
journal = {International Journal of Impact Engineering},
volume = {184},
pages = {104829},
year = {2024},
issn = {0734-743X},
doi = {https://doi.org/10.1016/j.ijimpeng.2023.104829},
url = {https://www.sciencedirect.com/science/article/pii/S0734743X2300338X},
author = {Fanny Gant and Gabriel Seisson and Patrice Longère and Skander El Mai and Jean-Luc Zinszner},
keywords = {Ring expansion, Dynamic fracture, Necking, Fragmentation},
abstract = {A plate impact driven ring expansion test (PIDRET) has been developed to investigate the high strain rate response of metals and alloys under radial expansion. Combining photonic Doppler velocimetry (PDV) probes and ultra-high-speed cameras, it allows for measuring the radial expansion velocity of the ring and for recording the different stages of the ring deformation until necking and ultimate fragmentation. Four metallic materials with different physical and mechanical properties are tested under the same loading conditions leading to strain rates around 104 s−1. The materials exhibit different responses in terms of deformation history and fracture. A comparison is made on (i) the postmortem microstructure and ductility between low strain rate tension loaded specimens and high-strain rate expansion loaded rings and (ii) numbers of necks and fragments between experimental results and theoretical estimations.}
}
@article{VARCHANDI2024100488,
title = {An integrated best–worst method and fuzzy TOPSIS for resilient-sustainable supplier selection},
journal = {Decision Analytics Journal},
volume = {11},
pages = {100488},
year = {2024},
issn = {2772-6622},
doi = {https://doi.org/10.1016/j.dajour.2024.100488},
url = {https://www.sciencedirect.com/science/article/pii/S2772662224000924},
author = {Sahar Varchandi and Ashkan Memari and Mohammad Reza Akbari Jokar},
keywords = {Multi-criteria decision-making, Fuzzy TOPSIS, Best–worst method, Supplier selection, Sustainability, Resiliency},
abstract = {Achieving a balance between economic, environmental, and social factors in supplier selection while prioritizing business continuity poses a considerable challenge. It is imperative to guarantee that selected suppliers adhere to sustainability and resilience requirements while supporting the company’s economic advancement. This study addresses this challenge through a novel approach that combines the Best–Worst Method (BWM) with the Fuzzy Technique Order of Preference by Similarity to Ideal Solution (F-TOPSIS). Integrating these methodologies reduces the burden of pairwise comparisons, a common challenge in supplier selection using multi-criteria decision-making, thereby streamlining the evaluation process. To assess the effectiveness of the proposed model, we implemented our method on an actual case study of e-commerce and conducted a sensitivity analysis of the results. The findings suggest that the proposed method offers improved consistency in rankings across criteria compared to traditional BWM. It also makes a balance between simplicity and accuracy, ensuring that selected suppliers are equipped to handle disruptions and uncertainties. This aligns practical simplicity with theoretical rigor which makes the proposed method more accessible and manageable for practitioners in real-world settings.}
}
@article{KARTASHOV2025117742,
title = {A large language model and denoising diffusion framework for targeted design of microstructures with commands in natural language},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {437},
pages = {117742},
year = {2025},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2025.117742},
url = {https://www.sciencedirect.com/science/article/pii/S0045782525000143},
author = {Nikita Kartashov and Nikolaos N. Vlassis},
keywords = {Microstructure design, Large language models, Denoising diffusion probabilistic models, Natural language processing},
abstract = {Microstructure plays a critical role in determining the macroscopic properties of materials, with applications spanning alloy design, MEMS devices, and tissue engineering, among many others. Computational frameworks have been developed to capture the complex relationship between microstructure and material behavior. However, despite these advancements, the steep learning curve associated with domain-specific knowledge and complex algorithms restricts the broader application of these tools. To lower this barrier, we propose a framework that integrates Natural Language Processing (NLP), Large Language Models (LLMs), and Denoising Diffusion Probabilistic Models (DDPMs) to enable microstructure design using intuitive natural language commands. Our framework employs contextual data augmentation, driven by a pretrained LLM, to generate and expand a diverse dataset of microstructure descriptors. A retrained Named Entity Recognition (NER) model extracts relevant microstructure descriptors from user-provided natural language inputs, which are then used by the DDPM to generate microstructures with targeted mechanical properties and topological features. The NLP and DDPM components of the framework are modular, allowing for separate training and validation, which ensures flexibility in adapting the framework to different datasets and use cases. A surrogate model system is employed to rank and filter generated samples based on their alignment with target properties. This work introduces a comprehensive framework that bridges natural language processing and mechanics, addressing key challenges such as the lack of training data, syntax invariance in textual descriptors, and precision in text embeddings. Demonstrated on a database of nonlinear hyperelastic microstructures, this framework serves as a prototype for accessible inverse design of microstructures, starting from intuitive natural language commands.}
}
@article{OH20241,
title = {The role of temperament and character in the anxiety-depression spectrum among Korean adults},
journal = {Journal of Affective Disorders},
volume = {359},
pages = {1-13},
year = {2024},
issn = {0165-0327},
doi = {https://doi.org/10.1016/j.jad.2024.05.052},
url = {https://www.sciencedirect.com/science/article/pii/S0165032724007857},
author = {Hyun Sook Oh and C. Robert Cloninger},
keywords = {Anxiety, Depression, Temperament and character, Resilience, Complex adaptive systems, Korean adults},
abstract = {Background
Temperament and character are useful in risk assessment and therapy of individuals in the anxiety-depression spectrum but understudied in South Korea.
Objective
The study aimed to identify the temperament and character features associated with anxiety and/or depression in individuals with clinical disorders and in the general population.
Methods
A representative sample of 1384 Korean adults over 18 years old (58 % female) were assessed with the Beck Depression Inventory (BDI), State-Trait Anxiety Inventory (STAI), and Temperament and Character Inventory (TCI). Multivariate analyses, including structural equation modeling and complex systems analysis, evaluated how personality influenced risk and resilience for anxiety and/or depression.
Results
The three groups with anxiety and/or depression were strongly distinguished by temperament and character: (i) In AD (n = 58), Harm Avoidance and Reward Dependence were higher than in DD, and Self-directedness was higher than in AD+DD; (ii) In DD (n = 90), Persistence, Self-Directedness and Cooperativeness were higher than in AD+DD; and (iii) In AD+DD (n = 101), Harm Avoidance was highest and Persistence and Self-directedness were lowest (i.e., they were lowest in Resilience). Structural equation models confirmed these risk relations with strong character development reducing the adverse effects of emotional hyperreactivity from extreme temperaments.
Limitations
Self-reports were measured only at one point in time, requiring collateral experimental data to support causal interpretation.
Conclusions
Interactions of temperament and character are strongly predictive of risk and resilience to anxiety and/or depression by regulating both positive and negative affect. Character mediates the adverse effects of extreme temperaments on affect.}
}
@article{YU2024115069,
title = {KCNH5 deletion increases autism susceptibility by regulating neuronal growth through Akt/mTOR signaling pathway},
journal = {Behavioural Brain Research},
volume = {470},
pages = {115069},
year = {2024},
issn = {0166-4328},
doi = {https://doi.org/10.1016/j.bbr.2024.115069},
url = {https://www.sciencedirect.com/science/article/pii/S0166432824002250},
author = {Lele Yu and Yamei Liu and Junyu Xia and Shini Feng and Fuxue Chen},
keywords = {, Autism spectrum disorder, Synaptic density, Electrophysiology, AKT/mTOR pathway},
abstract = {Recent clinical studies have highlighted mutations in the voltage-gated potassium channel Kv10.2 encoded by the KCNH5 gene among individuals with autism spectrum disorder (ASD). Our preliminary study found that Kv10.2 was decreased in the hippocampus of valproic acid (VPA) - induced ASD rats. Nevertheless, it is currently unclear how KCNH5 regulates autism-like features, or becomes a new target for autism treatment. We employed KCNH5 knockout (KCNH5-/-) rats and VPA - induced ASD rats in this study. Then, we used behavioral assessments, combined with electrophysiological recordings and hippocampal brain slice, to elucidate the impact of KCNH5 deletion and environmental factors on neural development and function in rats. We found that KCNH5-/- rats showed early developmental delay, neuronal overdevelopment, and abnormal electroencephalogram (EEG) signals, but did not exhibit autism-like behavior. KCNH5-/- rats exposed to VPA (KCNH5-/--VPA) exhibit even more severe autism-like behaviors and abnormal neuronal development. The absence of KCNH5 excessively enhances the activity of the Protein Kinase B (Akt)/Mechanistic Target of Rapamycin (mTOR) signaling pathway in the hippocampus of rats after exposure to VPA. Overall, our findings underscore the deficiency of KCNH5 increases the susceptibility to autism under environmental exposures, suggesting its potential utility as a target for screening and diagnosis in ASD.}
}
@article{DEMIRHAN2025125,
title = {A deep learning framework for prediction of crop yield in Australia under the impact of climate change},
journal = {Information Processing in Agriculture},
volume = {12},
number = {1},
pages = {125-138},
year = {2025},
issn = {2214-3173},
doi = {https://doi.org/10.1016/j.inpa.2024.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S2214317324000246},
author = {Haydar Demirhan},
keywords = {Cereal grains, Crop yield, Crop production, Deep learning, Temperature anomalies, Climate change},
abstract = {Accurate prediction of crop yields is essential to ensure food security. In this study, a new deep neural networks framework is developed to predict crop yields in Australia, considering the impact of climate change, fertilizer use, and crop area. It is implemented for oats, corn, rice, and wheat crops, and its forecasting performance is benchmarked against five statistical and machine learning methods. All the software codes for the implementation of the proposed framework are freely available. The proposed framework shows the highest forecasting performance for all the considered crop types. It provides 23%, 38%, 39%, and 40% lower average mean absolute error than the benchmark methods for oat, corn, rice, and wheat crops, respectively. The reductions in average root mean squared error are 19%, 25%, 37%, and 29% over the benchmark methods. Then, it is used to predict yields of the considered crops in Australia towards 2025 under six different climate change scenarios. It is observed that although climate change has some boosting impact on crop yield, it is not sustainable to meet the demand. However, it is possible to keep crop yields rising while mitigating climate change.}
}
@article{YUE2025128816,
title = {Enhancing decision support for type 2 diabetes mellitus comorbidity risk prediction: An end-to-end multi-task learning model},
journal = {Expert Systems with Applications},
volume = {294},
pages = {128816},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.128816},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425024339},
author = {Jianjin Yue and Li Luo and Mengzhuo Guo and Chenxi Xu},
keywords = {Disease risk prediction, Multi-task learning, Clinical decision-making support, Comorbidity, Type 2 diabetes mellitus, Machine learning},
abstract = {The incidence of comorbidities exacerbates the affliction of patients with Type 2 Diabetes Mellitus (T2DM) and increases the complexity of therapeutic interventions for physicians, resulting in adverse patient outcomes. Accurate identification and prediction of the comorbidity risk in T2DM facilitates improved clinical diagnostic decisions and enhanced patient prognoses. Existing studies frequently utilize single-task learning (STL) models to assess individual disease risks in T2DM comorbidity, overlooking the intricate relationships between various diseases and thus failing to capture their inherent connections, which leads to inaccurate risk predictions. To this end, we propose an end-to-end multi-gate mixture-of-self-attention-based-experts (MMAE) model under the multi-task learning (MTL) scheme. The proposed MMAE model is based on the self-attention mechanism and incorporates a new comorbidity diffusion coefficient (CDC) index to characterize correlations between diseases. We conduct comparative experiments against eight baselines on a real-world dataset, and the results have demonstrated the superiority of the proposed MMAE. Our ablation experiments also show that the incorporation of the CDC index helps accurately identify high-risk patients. Furthermore, the proposed MMAE model can provide clinical decision support for physicians in assisting them in making more effective comorbidity diagnoses. This study has significant implications for clinical decision support and improving patient prognostic outcomes.}
}
@article{CORDEIRO2025111139,
title = {Object segmentation dataset generation framework for robotic bin-picking: Multi-metric analysis between results trained with real and synthetic data},
journal = {Computers & Industrial Engineering},
volume = {205},
pages = {111139},
year = {2025},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2025.111139},
url = {https://www.sciencedirect.com/science/article/pii/S0360835225002852},
author = {Artur Cordeiro and Luís Freitas Rocha and José Boaventura-Cunha and Eduardo J. Solteiro Pires and João Pedro Souza},
keywords = {Robotic bin-picking, Object segmentation, Deep learning dataset, Data synthesis, Automation},
abstract = {The implementation of deep learning approaches based on instance segmentation data remains a challenge for customized scenarios, owing to the time-consuming nature of acquiring and annotating real-world instance segmentation data, which requires a significant investment of semi-professional user labour. Obtaining high-quality labelled data demands expertise and meticulous attention to detail. This requirement can significantly impact the overall implementation process, adding to the complexity and resource requirements of customized scenarios with diverse objects. The proposed work addresses the challenge of generating labelled data for large-scale robotic bin-picking datasets by proposing an easy-to-use automated framework designed to create customized data with accurate labels from CAD models. The framework leverages a photorealistic rendering engine integrated with physics simulation, minimizing the gap between synthetic and real-world data. Models trained using the synthetic data generated by this framework achieved an Average Precision of 86.95%, comparable to the performance of models trained on real-world datasets. Furthermore, this paper provides a comprehensive multi-metric analysis across diverse objects representing distinct industrial applications, including naval, logistics, and aerospace domains. The evaluation also includes the use of three distinct instance segmentation networks, alongside a comparative analysis of the proposed approach against two generative model techniques.}
}
@article{YANG2025,
title = {Self-Determination, Learning, and Language Technology Engagement of Chinese International Engineering College Students:},
journal = {International Journal of Computer-Assisted Language Learning and Teaching},
volume = {15},
number = {1},
year = {2025},
issn = {2155-7098},
doi = {https://doi.org/10.4018/IJCALLT.379336},
url = {https://www.sciencedirect.com/science/article/pii/S2155709825000118},
author = {Yichen Yang and Ling Qi and Ziyi Wu and Yang Shen and Edison Estigoy and Samantha Z. Gray and Hao Sun and Bohan Zhang and Geyu Jiang},
keywords = {English Learning, Generative AI, Language Technology Engagement, Learning Engagement, Self-Determination, Translation Software},
abstract = {ABSTRACT
This study explores students’ level of self-determination, learning engagement, and use of language technology toward English language learning with an analysis in different engineering disciplines and correlation between variables. The descriptive-quantitative-correlation approach with different instruments was adopted and administered to 369 students in an international engineering college. Results revealed that there is a positive relationship between self-determination and learning engagement, where students are determined and recognize the importance of English learning. Moreover, there is a significant relationship between learning engagement and language technology engagement, indicating that there is indeed a certain correlation between the degree of learning engagement and use of language technology in the learning process. However, there is no significant relationship between self-determination and language technology engagement, which suggests individuality and independence in language learning and indicates a need for additional support in technology integration.}
}
@article{KARALASINGHAM2024101333,
title = {Wavelet-fusion image super-resolution model with deep learning for downscaling remotely-sensed, multi-band spectral albedo imagery},
journal = {Remote Sensing Applications: Society and Environment},
volume = {36},
pages = {101333},
year = {2024},
issn = {2352-9385},
doi = {https://doi.org/10.1016/j.rsase.2024.101333},
url = {https://www.sciencedirect.com/science/article/pii/S2352938524001976},
author = {Sagthitharan Karalasingham and Ravinesh C. Deo and David Casillas-Pérez and Nawin Raj and Sancho Salcedo-Sanz},
keywords = {Spectral albedo, Bifacial PV, PV yield modelling, Reflected solar radiation},
abstract = {Generating granular-scale surface albedo data is extremely important for solar photovoltaic site planning and to optimise renewable energy yield of bifacial panel installations. The albedo effect brings about a significant increase in power in bifacial photovoltaic systems, compared to their mono-facial counterparts, since the spectral response of bifacial solar panels correlates with the incident solar radiation wavelength on the back of the panel, to provide additional power generation capacity. Thus, harnessing the albedo data at relatively local scales is critical towards boosting solar power generation and providing greater power density in local electricity grids. This paper develops novel modelling approaches to produce high-resolution spectral albedo imagery across the Visible and Near Infrared (VNIR) bands, using the Wavelet-Fusion super-resolution model (i.e., Wavelet-FusionSR) trained with the Learned Gamma Correction approach by applying satellite image enhancement methodology. The proposed Wavelet-FusionSR model utilises the low-resolution moderate-resolution Imaging Spectroradiometer (MODIS) as well as high-resolution multi-spectral Advanced Space-borne Thermal Emission Reflection Radiometer (ASTER) satellite images, as critical inputs and ground-truth imagery, respectively, in order to perform sensor-to-sensor deep downscaling, without employing any synthetic or low-resolution satellite imagery data pairs. To augment the proposed deep learning algorithm across the decomposed sub-images of low-resolution inputs, we integrate local and global feature representation learning to train the proposed Wavelet-FusionSR model with Cauchy loss functions. In comparison with five competing benchmark models, the proposed Wavelet-FusionSR model demonstrates performance superiority using quantitative image downscaling metrics and visual assessments of the downscaled images for the visible band of solar radiation. The proposed Wavelet-FusionSR model yielded a Mean Square Error (MSE) of 0.00017, Signal-to-noise-ratio (PSNR) of 37.80, Structural Similarity Index (SSIM) of 0.999 and combined loss, MS-SSIMLoss, based on Multi Structural Similarity and Mean Absolute Error of 2.354 for the Visible Band images, and an MSE of 0.0014, PSNR of 28.43, SSIM of 0.999 and MS-SSIMLoss of 7.426 for the NIR spectral bands, demonstrating high efficacy of the proposed Wavelet-FusionSR method. The Wavelet-FusionSR method therefore attains high-resolution spectral albedo imagery outputs.}
}
@article{WUYTS2024998,
title = {Effectiveness of pain medication tapering in chronic pain patients: a systematic review and meta-analysis},
journal = {British Journal of Anaesthesia},
volume = {133},
number = {5},
pages = {998-1020},
year = {2024},
issn = {0007-0912},
doi = {https://doi.org/10.1016/j.bja.2024.07.025},
url = {https://www.sciencedirect.com/science/article/pii/S0007091224004720},
author = {Elke Wuyts and Lisa Goudman and Cleo L. Crunelle and Maria {Merlano Gomez} and Koen Putman and Frenn Bultinck and Julie G. Pilitsis and Maarten Moens},
keywords = {anti-migraine medication, chronic noncancer pain, gabapentinoids, opioids, pain medication tapering},
abstract = {Background
This systematic review and meta-analysis aimed to inventory all outcome measures that are affected by tapering in chronic noncancer pain and to investigate the effectiveness of tapering.
Methods
A literature search was conducted from inception to April 2024 in MEDLINE via PubMed, Web of Science, SCOPUS, EMBASE, and PsycINFO.
Results
The initial database search identified 3969 articles, which were screened by two independent reviewers. Studies evaluating pain medication tapering in adults with chronic noncancer pain were eligible for inclusion. In total, 57 and 34 articles were included in the systematic review and meta-analysis, respectively. Risk of bias assessment demonstrated poor, fair, and good quality in 30, 24, and three studies, respectively. Pain intensity was the most reported outcome measure, as reported in 28 studies. Furthermore, a random-effect three-level meta-analysis was performed. An overall effect size of 0.917 (95% confidence interval 0.61–1.22; P<0.001) was found, indicating a beneficial effect of tapering. In addition, a statistically significant improvement was demonstrated after tapering for pain intensity, headache disability, the number of headache days per month, anxiety, depression, the number of pills consumed per month, the number of days with medication intake per month, pain catastrophising, and pain interference. No statistically significant effect was observed for physical functioning, mental health-related quality of life, opioid use, pain self-efficacy, and physical health-related quality of life.
Conclusions
This systematic review revealed a broad range of outcome measures affected by tapering. Owing to the high risk of bias of the included articles, the results of this meta-analysis must be interpreted with caution.
Systematic review protocol
CRD42023416343 (PROSPERO).}
}
@article{YAN2025105322,
title = {The effects of generative AI agents and scaffolding on enhancing students’ comprehension of visual learning analytics},
journal = {Computers & Education},
volume = {234},
pages = {105322},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105322},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525000909},
author = {Lixiang Yan and Roberto Martinez-Maldonado and Yueqiao Jin and Vanessa Echeverria and Mikaela Milesi and Jie Fan and Linxuan Zhao and Riordan Alfredo and Xinyu Li and Dragan Gašević},
keywords = {Scaffolding, Generative AI, Artificial intelligence, Large language model, Visualisation literacy, Visual learning analytics, Learning analytics dashboard},
abstract = {Visual learning analytics (VLA) is becoming increasingly adopted in educational technologies and learning analytics dashboards to convey critical insights to students and educators. Yet many students experienced difficulties in comprehending complex VLA due to their limited data visualisation literacy. While conventional scaffolding approaches like data storytelling have shown effectiveness in enhancing students’ comprehension of VLA, these approaches remain difficult to scale and adapt to individual learning needs. Generative AI (GenAI) technologies, especially conversational agents, offer potential solutions by providing personalised and dynamic support to enhance students’ comprehension of VLA. This controlled lab study investigates the effectiveness of GenAI agents, particularly when integrated with scaffolding techniques, in improving students’ comprehension of VLA. A randomised controlled trial was conducted with 117 higher education students to compare the effects of two types of GenAI agents: passive agents, which respond to student queries, and proactive agents, which utilise scaffolding questions, against standalone scaffolding in a VLA comprehension task. The results show that passive agents yield comparable improvements to standalone scaffolding both during and after the intervention. Notably, proactive GenAI agents significantly enhance students’ VLA comprehension compared to both passive agents and standalone scaffolding, with these benefits persisting beyond the intervention. These findings suggest that integrating GenAI agents with scaffolding can have lasting positive effects on students’ comprehension skills and support genuine learning.}
}
@article{SUN2023101418,
title = {Relationships between perseverance of effort, subjective well-being, harmonious passion, and creativity among Chinese third-language students},
journal = {Thinking Skills and Creativity},
volume = {50},
pages = {101418},
year = {2023},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2023.101418},
url = {https://www.sciencedirect.com/science/article/pii/S1871187123001864},
author = {Jiatong Sun and Rui Chen and Xiaojia Song and Lin Lei and Fei Lei},
keywords = {Perseverance of effort, Creativity, Subjective well-being, Harmonious passion, Third language (L3) learners},
abstract = {Fostering creativity among foreign language learners has consistently received attention from researchers. However, the positive psychological processes promoting creativity among third language (L3) learners remain understudied. Focusing specifically on L3 students, this study explored the associations between perseverance of effort (PE), subjective well-being (SWB), harmonious passion (HP), and creativity. Furthermore, the study investigated the possible mediating roles of SWB and HP in the relationship between PE and creativity. Participants were 430 Chinese college students who attended an obligatory L3 course. To analyze the data, the PROCESS macro for SPSS was used to perform a mediation analysis, and the results showed that (1) PE, SWB, and HP all positively related to creativity, (2) PE directly predicted creativity, (3) SWB and HP could serve as partial mediators in the relationship between PE and creativity, and (4) the direct impact of personal trait (i.e., PE) on creativity is smaller than the indirect impact of positive emotions (i.e., SWB and HP). These findings highlight the significance of PE, SWB, and HP in facilitating creativity among L3 students. Based on these findings, instructive suggestions for fostering creativity in L3 students are discussed.}
}
@article{XIA2024104040,
title = {Semantic knowledge-driven A-GASeq: A dynamic graph learning approach for assembly sequence optimization},
journal = {Computers in Industry},
volume = {154},
pages = {104040},
year = {2024},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2023.104040},
url = {https://www.sciencedirect.com/science/article/pii/S0166361523001902},
author = {Luyao Xia and Jianfeng Lu and Yuqian Lu and Wentao Gao and Yuhang Fan and Yuhao Xu and Hao Zhang},
keywords = {Assembly sequence planning, Assembly semantic knowledge, Precedence graph, Dynamic graph learning},
abstract = {In the context of an increasingly automated and personalized manufacturing mode, efficient assembly sequence planning (ASP) has emerged as a critical factor for enhancing production efficiency, ensuring product quality, and satisfying diverse market demands. To address this need, our study first transforms the assembly topology and process into a weighted precedence graph, wherein parts represent nodes, and the assembly interconnections between parts constitute weighted edges. Then, we formulate the quantitative models of semantic knowledge, encompassing three facets: assembly direction changes, assembly stability, and part assembly interference, and thus constructs a heuristic function. We propose a novel dynamic graph learning algorithm, i.e., assembly-oriented graph attention sequence (A-GASeq), utilizing the heuristic information as edge weights of the assembly graph structure to incrementally direct the search towards optimal sequences. The performance of A-GASeq is first evaluated utilizing three key metrics: area under the receiver operation characteristic curve (AUC), precision score, and time consumption. The results reveal the superiority of our model over competing state-of-the-art graph learning models using a real-world dataset. Concurrently, we apply the algorithm to actual industrial products of diverse complexity, thereby demonstrating its broad utility across different complex products and its potential for addressing complex assembly sequence planning problems in the field of smart manufacturing.}
}
@article{KHALIFA2024100142,
title = {RETRACTED: Advancing clinical decision support: The role of artificial intelligence across six domains},
journal = {Computer Methods and Programs in Biomedicine Update},
volume = {5},
pages = {100142},
year = {2024},
issn = {2666-9900},
doi = {https://doi.org/10.1016/j.cmpbup.2024.100142},
url = {https://www.sciencedirect.com/science/article/pii/S2666990024000090},
author = {Mohamed Khalifa and Mona Albadawy and Usman Iqbal},
abstract = {This article has been retracted: please see Elsevier policy on article withdrawal (https://www.elsevier.com/about/policies-and-standards/article-withdrawal). This article has been retracted following an investigation conducted by the Publisher which determined that this paper was handled by the former Co-Editor-in-Chief of the journal, who was also an author of the paper. This compromised the impartiality of the peer review process and necessitated the retraction of the paper. As such this article represents a misuse of the scientific publishing system. The scientific community takes a very strong view on this matter and apologies are offered to readers of the journal that this was not detected during the submission process.}
}
@article{GAFFINET2025104230,
title = {Human Digital Twins: A systematic literature review and concept disambiguation for industry 5.0},
journal = {Computers in Industry},
volume = {166},
pages = {104230},
year = {2025},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2024.104230},
url = {https://www.sciencedirect.com/science/article/pii/S0166361524001581},
author = {Ben Gaffinet and Jana {Al Haj Ali} and Yannick Naudet and Hervé Panetto},
keywords = {Human Digital Twin, Industry 5.0, Digital Twin, Human-centricity},
abstract = {Human Digital Twins (HDTs) are an emerging concept with the potential to create human-centric systems for Industry 5.0. The concept has rapidly spread to new application domains, most notably Healthcare, leading to diverging conceptual interpretations. This Systematic Literature Review analyses the conceptual understanding of HDTs across all application domains to clarify the conceptual foundation. Our review reveals a consensus that an HDT’s twinned entity is a human individual. However, there is little agreement on the data flows between the individual and their HDT. We address this shortcoming by proposing three categories based on the level of data integration: Human Digital Models, Human Digital Shadows, and Human Digital Twins. Finally, we synthesise our findings in a domain-agnostic general definition for HDT. We highlight an edge case where the twinned entity is a human individual alongside a strongly coupled technical system, and name it augmented Human Digital Twin (aHDT). The definition and categorisation scheme provide the needed conceptual clarity for inter-disciplinary collaboration to address open challenges. Notable challenges are sensing human data, reliable data transfers and modelling, especially behavioural modelling. Additional ethical issues concerning security, privacy and consent are central to successful HDT adoption. We call for cross-disciplinary efforts to establish a standardised framework and ethical guidelines to enable future developments.}
}
@article{SCHWEIGER2024635,
title = {A comprehensive examination of digital retailing: A text-mining review and research agenda},
journal = {Journal of Retailing},
volume = {100},
number = {4},
pages = {635-655},
year = {2024},
issn = {0022-4359},
doi = {https://doi.org/10.1016/j.jretai.2024.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0022435924000678},
author = {Elisa B. Schweiger and Virginia Vannucci and Valentina Mazzoli and Laura Grazzini and Anne L. Roggeveen and Dhruv Grewal and Raffaele Donvito and Gaetano Aiello},
keywords = {Retail management, Digital retailing, Digitalization, Technology, Text mining, Topic modeling},
abstract = {Digital retailing encompasses all the digital technology–enabled assets and retail activities that a retailer can use to create, capture, communicate, and deliver value throughout the customer journey. This comprehensive topic modeling analysis of 4,730 articles from 35 years of research across multiple disciplines showcases how the research is evolving overtime and within the disciplines. Results reveal 11 topics areas (consisting of 66 subtopics), as well as the prevalence of these topics within each discipline. Results highlight how the topics have evolved overtime. For example, research on consumer motivation to use technology, retail environmental factors, and firm factors is increasing, while research on trust and risk factors is declining. The trends vary across disciplines. Results also highlight the relationship among the topics, and the impact of publications in each of the topic areas by considering citations across time and disciplines. Implications for future research are discussed.}
}
@article{TEUTLOFF2025106845,
title = {Winners and losers of generative AI: Early Evidence of Shifts in Freelancer Demand},
journal = {Journal of Economic Behavior & Organization},
volume = {235},
pages = {106845},
year = {2025},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2024.106845},
url = {https://www.sciencedirect.com/science/article/pii/S0167268124004591},
author = {Ole Teutloff and Johanna Einsiedler and Otto Kässi and Fabian Braesemann and Pamela Mishkin and R. Maria {del Rio-Chanona}},
keywords = {Generative AI technologies, Large language models, Automation and employment, Labor market implications of AI, Technological transition, Online labor markets},
abstract = {We examine how ChatGPT has changed the demand for freelancers in jobs where generative AI tools can act as substitutes or complements to human labor. Using BERTopic we partition job postings from a leading online freelancing platform into 116 fine-grained skill clusters and with GPT-4o we classify them as substitutable, complementary or unaffected by LLMs. Our analysis reveals that labor demand increased after the launch of ChatGPT, but only in skill clusters that were complementary to or unaffected by the AI tool. In contrast, demand for substitutable skills, such as writing and translation, decreased by 20–50% relative to the counterfactual trend, with the sharpest decline observed for short-term (1-3 week) jobs. Within complementary skill clusters, the results are mixed: demand for machine learning programming grew by 24%, and demand for AI-powered chatbot development nearly tripled, while demand for novice workers declined in general. This result suggests a shift toward more specialized expertise for freelancers rather than uniform growth across all complementary areas.}
}
@article{CAI2025102587,
title = {Factors influencing engagement in EFL learning of higher education learners in blended learning environments},
journal = {International Journal of Educational Research},
volume = {131},
pages = {102587},
year = {2025},
issn = {0883-0355},
doi = {https://doi.org/10.1016/j.ijer.2025.102587},
url = {https://www.sciencedirect.com/science/article/pii/S0883035525000618},
author = {Qianqian Cai},
keywords = {Engagement, Blended learning, Influencing factors, Higher education, English as a foreign language learning},
abstract = {Researchers have long been interested in engagement in blended learning. However, insufficient research has been conducted on factors influencing engagement in blended English as a foreign language learning. This study investigates the factors influencing engagement in blended English as a foreign language learning based on the hedonic-motivation system adoption model. This study aimed to develop a model exploring engagement in blended English as a foreign language learning employing quantitative structural equation modelling methods, supplemented by an open-ended review question. Based on feedback from 938 tertiary students, this study explored the relationship among perceived ease of use, usefulness, teacher support, enjoyment, social presence, L2 grit, and engagement in blended English as a foreign language learning using a structural equational modeling method. Through the thematic analysis of 418 responses to the open-ended question, the author gained insights into the merits, flaws, and recommendations of blended English as a foreign language learning. As a result, perceived ease of use positively affected the usefulness of blended English as a foreign language learning. Perceived ease of use, teacher support, and usefulness positively impacted the social presence of blended English as a foreign language learning. Perceived teacher support, ease of use, and social presence positively influenced the perceived enjoyment of blended English as a foreign language learning. Perceived enjoyment positively predicted second language (L2) grit of blended learning contexts. However, social presence insignificantly affected L2 grit in blended learning contexts. L2 grit, perceived enjoyment, usefulness, and social presence positively impacted engagement in blended English as a foreign language learning. Despite limitations, this study implies teachers, education researchers, and developers in further research and practice for blended language education.}
}
@article{MARTIN2025101529,
title = {The effects of climate change and environmental regulation analysing U.S. citizens' typology},
journal = {Social Sciences & Humanities Open},
volume = {11},
pages = {101529},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101529},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125002578},
author = {Juan Carlos Martín and Alessandro Indelicato},
keywords = {Climate change effects, Environmental regulation effects, Energy prices, Loss of individual freedom, Religion, Religious practices, Fuzzy clustering ECO-Extended apostle, PEW},
abstract = {This study analyses the relationship between the effects of climate change and environmental regulation for the first time, considering how some individuals' socioeconomic characteristics affect the different types of Americans' perceptions. A panoply of fuzzy set methods, including Fuzzy Hybrid TOPSIS, Fuzzy Clustering and Fuzzy Clustering ECO-Extended Apostle, are applied to a dataset of 10,156 respondents representing the USA. The latent variables are measured by two scales using an answer format based on how likely different effects of climate change and environmental regulation will happen within the next 30 years. The study determines the following respondents' categories: neither convinced of climate change and environmental regulation effects, convinced only of climate change, convinced only of environmental regulation, and convinced of both effects. The results indicate that Americans are more prone to be more convinced of both (73.8 %) than only environmental regulation effects (13.6 %), climate change effects (10.1 %) or none (2.5 %). Some socioeconomic, demographic, and other segmentation variables will be studied to analyse their impact on Americans' categorisation. The segmentation variables are mainly based on environmental attitudes, societal and political views, and political ideology. The implications and limitations of our results will be further discussed.}
}
@article{DUI2025,
title = {Spatiotemporal Resilience Analysis of IoT-enabled Unmanned System of Systems},
journal = {Engineering},
year = {2025},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2025.06.024},
url = {https://www.sciencedirect.com/science/article/pii/S2095809925003224},
author = {Hongyan Dui and Huanqi Zhang and Shaomin Wu and Min Xie},
keywords = {Spatiotemporal performance, Spatiotemporal resilience, Unmanned equipment, Importance measure},
abstract = {As advancements in the Internet of Things (IoT) and unmanned technologies continues to progress, the development of unmanned system of systems (USS) has reached unprecedented levels. While prior research has predominantly examined temporal variations in USS resilience, spatial changes remain underexplored. However, USS may involve kinetic engagements and frequent spatial changes during mission execution, affecting signal interference in data layer communications. Although time-dependent factors primarily govern mission effectiveness of the USS, spatial factors influence the transmission stability of the data layer. Consequently, assessing spatiotemporal variations in USS performance is critical. To address these challenges, this study introduces a spatiotemporal resilience assessment framework, which evaluates USS resilience across both temporal and spatial dimensions. Furthermore, we propose a spatiotemporal resilience optimization scheme that enhances system adaptability throughout the mission lifecycle, with a particular emphasis on prevention and recovery strategies. Finally, we validate the validity of the proposed concepts and methods with a case study featuring a regular hexagonal deployment of USS. The results show that the spatiotemporal resilience can better reflect the spatial change characteristics of USS, and the proposed optimization strategy improves the prevention spatiotemporal resilience, recovery spatiotemporal resilience and entire-process spatiotemporal resilience of USS by 0.22%, 7.8% and 11.3%, respectively.}
}
@article{DEWILDE2025103454,
title = {Strategies for generating synthetic computed tomography-like imaging from radiographs: A scoping review},
journal = {Medical Image Analysis},
volume = {101},
pages = {103454},
year = {2025},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2025.103454},
url = {https://www.sciencedirect.com/science/article/pii/S1361841525000027},
author = {Daniel {De Wilde} and Olivier Zanier and Raffaele {Da Mutten} and Michael Jin and Luca Regli and Carlo Serra and Victor E. Staartjes},
keywords = {Artificial intelligence, Deep learning, Synthetic CT, Machine learning, Synthetic imaging, Image conversion},
abstract = {Background
Advancements in tomographic medical imaging have revolutionized diagnostics and treatment monitoring by offering detailed 3D visualization of internal structures. Despite the significant value of computed tomography (CT), challenges such as high radiation dosage and cost barriers limit its accessibility, especially in low- and middle-income countries. Recognizing the potential of radiographic imaging in reconstructing CT images, this scoping review aims to explore the emerging field of synthesizing 3D CT-like images from 2D radiographs by examining the current methodologies.
Methods
A scoping review was carried out following PRISMA-SR guidelines. Eligibility criteria for the articles included full-text articles published up to September 9, 2024, studying methodologies for the synthesis of 3D CT images from 2D biplanar or four-projection x-ray images. Eligible articles were sourced from PubMed MEDLINE, Embase, and arXiv.
Results
76 studies were included. The majority (50.8 %, n = 30) were published between 2010 and 2020 (38.2 %, n = 29) and from 2020 onwards (36.8 %, n = 28), with European (40.8 %, n = 31), North American (26.3 %, n = 20), and Asian (32.9 %, n = 25) institutions being primary contributors. Anatomical regions varied, with 17.1 % (n = 13) of studies not using clinical data. Further, studies focused on the chest (25 %, n = 19), spine and vertebrae (17.1 %, n = 13), coronary arteries (10.5 %, n = 8), and cranial structures (10.5 %, n = 8), among other anatomical regions. Convolutional neural networks (CNN) (19.7 %, n = 15), generative adversarial networks (21.1 %, n = 16) and statistical shape models (15.8 %, n = 12) emerged as the most applied methodologies. A limited number of studies included explored the use of conditional diffusion models, iterative reconstruction algorithms, statistical shape models, and digital tomosynthesis.
Conclusion
This scoping review summarizes current strategies and challenges in synthetic imaging generation. The development of 3D CT-like imaging from 2D radiographs could reduce radiation risk while simultaneously addressing financial and logistical obstacles that impede global access to CT imaging. Despite initial promising results, the field encounters challenges with varied methodologies and frequent lack of proper validation, requiring further research to define synthetic imaging's clinical role.}
}