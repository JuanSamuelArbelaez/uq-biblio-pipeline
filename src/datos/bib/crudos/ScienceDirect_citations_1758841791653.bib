@article{ZHU2025101040,
title = {What they provide and how: An intervention study on pre-service teachers' GenAI-assisted writing feedback},
journal = {The Internet and Higher Education},
volume = {67},
pages = {101040},
year = {2025},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2025.101040},
url = {https://www.sciencedirect.com/science/article/pii/S1096751625000491},
author = {Siyu Zhu and Jialin Li and Yuan Yao and Yi Guan and Xinhua Zhu},
keywords = {Generative AI, Pre-service teachers' training, GenAI-assisted writing feedback, Writing feedback levels, Writing feedback types},
abstract = {Providing effective writing feedback to students could promote students' writing development. However, offering high-quality feedback remains a significant challenge for pre-service teachers (PSTs). Recent advancements in GenAI technology may offer solutions to this issue. The study examines the influence of a short-term teaching intervention on the feedback levels and feedback types of PSTs' ChatGPT-assisted feedback on students' written compositions, utilizing an explanatory sequential mixed-method design with 30 PSTs. The quantitative results revealed significant improvements in both feedback levels (i.e., higher-level feedback issues including ideas and elaboration and style) and feedback types (e.g., explanations and general suggestions). Additionally, the findings highlighted specific strategies employed by PSTs when considering levels and types in combination. Subsequent interviews identified the underlying influential factors of these improvements, namely the improvements in ChatGPT usage skills (i.e., prompt engineering and source use) and a deeper understanding of the feedback process (i.e., introspection). By demonstrating how short-term teaching interventions can leverage PST's ability to use GenAI tools to provide writing feedback, this research advances the theoretical understanding of human-AI collaboration in the context of writing and provides pedagogical insights for teacher training programs.}
}
@article{AN2025105893,
title = {Meta-interaction: Deployable framework integrating the metaverse and generative AI for participatory building design},
journal = {Automation in Construction},
volume = {169},
pages = {105893},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105893},
url = {https://www.sciencedirect.com/science/article/pii/S0926580524006290},
author = {Hongda An and Weisheng Lu and Liupengfei Wu and Ziyu Peng and Jinfeng Lou},
keywords = {Building design, Participatory design, Metaverse, Generative AI, Meta-interaction},
abstract = {Much has been exhorted to pursue participatory building design (PBD) but little has been done to enhance it owing to difficulties such as participant inclusion and clarity of expression. An opportunity is enabled by metaverse and generative AI technologies. This paper aims to explore this by developing a framework that integrates metaverse and generative AI. To start, a desktop study is conducted to examine the challenges related to PBD. Based on this, a PBD framework called Meta-interaction was developed. It incorporates metaverse in enabling users to participate in the immersive design process, and generative AI for automated user requirement extraction, design feature option generation, and visualization. Finally, the prototype was implemented in five pilot cases. Results show that the framework is applicable and highly valued by most designers and end-users. This study enriches the applications of metaverse and generative AI in building design and offers insights for future PBD initiatives.}
}
@article{LI2024107114,
title = {Moisture sources and isotopic composition of the 2020 extraordinary and persistent Meiyu rainfall in the Yangtze River valley modulated by large-scale circulations},
journal = {Atmospheric Research},
volume = {297},
pages = {107114},
year = {2024},
issn = {0169-8095},
doi = {https://doi.org/10.1016/j.atmosres.2023.107114},
url = {https://www.sciencedirect.com/science/article/pii/S0169809523005112},
author = {Xiaoyang Li and Ryuichi Kawamura and Kimpei Ichiyanagi and Kei Yoshimura},
keywords = {Stable water isotopes, Moisture sources, Extraordinary and persistent Meiyu, Isotopic regional spectral model, Yangtze River valley, Large-scale circulations},
abstract = {Meiyu rainfall is an important climate phenomenon in East Asia, but its interannual variability has amplified in recent decades. To gain a better understanding of the underlying atmospheric processes of torrential Meiyu rainfall, we investigated the moisture sources and isotopic composition of the 2020 extraordinary and persistent Meiyu rainfall in the Yangtze River valley from June 19 to July 10 using an isotopic regional spectral model. During the Meiyu period, significant amounts of Indian Ocean moisture were transported to Yangtze River valley by Indian monsoonal southwesterlies, especially in the middle levels between 850 hPa and 600 hPa. Whereas moderate amounts of East Asian continent moisture were distributed principally within the boundary layer below 850 hPa. Besides, tiny amounts of South China Sea moisture were transported by the western Pacific subtropical high to the middle and lower reaches of Yangtze River valley within the boundary layer below 900 hPa. With respect to isotopic characteristics, the lowest δ2H and the highest d-excess values of the Indian Ocean moisture were attributable to more rainout and below-cloud evaporation during long-distance transport. In contrast, the isotopic signals of the East Asian continent moisture and the South China Sea moisture were relatively preserved. The 2020 Meiyu rainfall exhibited significant intraseasonal variability and was classified into heavy and light Meiyu periods based on rainfall amount. Heavy Meiyu rainfall with northward migration were characterized by enhanced Indian Ocean moisture with lower δ2H and higher d-excess, resulting from the westward expansion of the western Pacific subtropical high and the deepened East Asian mid-latitude trough.}
}
@article{GOODWIN2024114231,
title = {Sustainability certification for renewable hydrogen: An international survey of energy professionals},
journal = {Energy Policy},
volume = {192},
pages = {114231},
year = {2024},
issn = {0301-4215},
doi = {https://doi.org/10.1016/j.enpol.2024.114231},
url = {https://www.sciencedirect.com/science/article/pii/S0301421524002519},
author = {Daniel Goodwin and Fred Gale and Heather Lovell and Kim Beasy and Hannah Murphy and Marion Schoen},
keywords = {Green hydrogen, Energy transitions, Governance, Sustainable, Multiple criteria, Regulation},
abstract = {Hydrogen produced from renewable energy is being promoted to decarbonise global energy systems. To support this energy transition, standards, certification, and labelling schemes (SCLs) aim to differentiate hydrogen products based on their system-wide carbon emissions and method of production characteristics. However, being certified as low-carbon, clean, or green hydrogen does not guarantee broader sustainability across economic, environmental, social, or governance dimensions. Through an international survey of energy-sector and sustainability professionals (n = 179), we investigated the desirable sustainability features for renewable hydrogen SCLs and the perceived advantages and disadvantages of sustainability certification. Our mixed-method study revealed general accordance on the feasible inclusion of diverse sustainability criteria in SCLs, albeit with varying degrees of perceived essentiality. Within the confines of the data, some differences in viewpoints emerged based on respondents’ geographical and supply chain locations, which were associated with the sharing of costs and benefits. Qualitatively, respondents found the idea of SCL harmonisation attractive but weighed this against the risks of duplication, complicated administrative procedures, and contradictory regulation. The implications of this research centre on the need for further studies to inform policy recommendations for an overarching SCL sustainability framework that embodies the principles of harmonisation in the context of multistakeholder governance.}
}
@article{PANCER2025107723,
title = {Robots in the kitchen: The automation of food preparation in restaurants and the compounding effects of perceived love and disgust on consumer evaluations},
journal = {Appetite},
volume = {204},
pages = {107723},
year = {2025},
issn = {0195-6663},
doi = {https://doi.org/10.1016/j.appet.2024.107723},
url = {https://www.sciencedirect.com/science/article/pii/S0195666324005270},
author = {Ethan Pancer and Theodore J. Noseworthy and Lindsay McShane and Nükhet Taylor and Matthew Philp},
keywords = {Automation, Contagion, Taste, Restaurants, Cooking},
abstract = {Restaurants are swiftly embracing automation to prepare food, experimenting with innovations from robotic arms for frying foods to pizza-making robots. While these advances promise to enhance efficiency and productivity, their impact on consumer psychology remains largely unexplored. We present four experiments that demonstrate how food service automation leads to negative downstream effects (i.e., diminished taste perceptions, decreased willingness to pay, less favorable attitudes towards food items) across multiple food categories. This stems in part from two distinct contagion effects, whereby automation appears to undermine the food's ability to contain symbolic love (positive contagion from human contact) while simultaneously increasing feelings of disgust (negative contagion from machine contact). Moreover, we highlight how communicating the consumer-oriented benefits of automation can suppress the disgust associated with automation and subsequently mitigate the deleterious effects on consumer evaluations. Our findings suggest that service retailers should consider the psychological impact on consumers when shifting away from human involvement in a category as intimate and consequential as the production of our food.}
}
@article{KOPALLE2025115360,
title = {Journal of Business Research Publications 1973–2024: Topics, methodological approaches, data, and analyses conducted},
journal = {Journal of Business Research},
volume = {194},
pages = {115360},
year = {2025},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2025.115360},
url = {https://www.sciencedirect.com/science/article/pii/S0148296325001833},
author = {Praveen K. Kopalle and Donald R. Lehmann and Divya Ramachandran and Ruud Wetzels},
keywords = {, Categorization, Topic modeling, Approaches, Data, Analyses},
abstract = {This study analyzes trends in research published in the Journal of Business Research (JBR) by examining 10,211 abstracts from 1973 to 2024. The analysis uses categorization (of articles published in 1977–1988 versus 2013–2024) and topic modeling (of articles published from 1973 to 2024) to identify key patterns. Key findings include: (1) A shift from conceptual papers to more empirical research with a substantive focus, (2) An increase in studies utilizing interviews, surveys, and secondary data, while papers with no data usage have decreased, and (3) A rise in advanced analysis techniques, including regression, structural models, machine learning, and textual analysis. The topic modeling analysis reveals an underlying topical structure of 19 JBR research themes. Emerging themes pertain to digital transformation and technology, value co-creation, customer and brand equity, green (product) development, transformational management, service management, and innovation management and performance. Stable JBR themes include family businesses, leadership and executive boards, communication channels, strategic decision making, business ethics and responsibility, knowledge management, advertising, consumer behavior, (international) entrepreneurship, and buyers and sellers. Declining research themes concern performance and uncertainty, and forecasting and foresight. Thus, the research areas have grown more diverse, with clear subfields receiving increased attention. At the same time, more studies have delved into narrower, specialized topics, allowing for deeper investigation.}
}
@article{STENSTROM2025104411,
title = {A million scenarios to identify conditions for robust bioenergy carbon capture in Sweden},
journal = {International Journal of Greenhouse Gas Control},
volume = {145},
pages = {104411},
year = {2025},
issn = {1750-5836},
doi = {https://doi.org/10.1016/j.ijggc.2025.104411},
url = {https://www.sciencedirect.com/science/article/pii/S1750583625001094},
author = {Oscar Stenström and Tharun Roshan Kumar and Magnus Rydén},
keywords = {Bioenergy, Carbon capture and storage, CCS, BECCS, Carbon dioxide removal, Heat integration, Robust decision making, RDM, Exploratory modelling, Scenario discovery, Data mining, Machine learning, Combined heat and power, Pulp},
abstract = {Large-scale bioenergy carbon capture and storage (BECCS) could be realized without escalating biomass use - under the right conditions. We apply robust decision-making theory to frame carbon capture as a decision problem. We then search for conditions of low costs and energy penalties by modelling the capture decision across a million scenarios of already-existing plants in Sweden. Mining the scenario data reveals that annual plant utilization, heat recovery via heat pumps and electricity prices constitute key conditions for combined heat and power plants. For pulp mills, key conditions are site-specific, but the availability of low-pressure steam and electricity prices are generally important. A sensitivity analysis supports these findings, but also identifies capture rates as key. About 19 MtCO2 could be captured annually from the 113 plants studied while combusting zero additional biomass. Under the identified conditions, this would entail reduced power and district heating generation of 5.1-7.9 TWh per year – a modest penalty relative to the 220 TWh generated annually in Sweden.}
}
@article{YAO2024102625,
title = {Pathways linking expectations for AI chatbots to loyalty: A moderated mediation analysis},
journal = {Technology in Society},
volume = {78},
pages = {102625},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102625},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24001738},
author = {Xintong Yao and Yipeng Xi},
keywords = {AI, Chatbot, Expectation violation, Machine heuristic, Human uniqueness, ChatGPT},
abstract = {Despite the prevalence of generative AI chatbots such as GPT and Bard, scholarly inquiry into how users' enduring expectations influence their engagement with AI chatbots remains scant. Drawing on expectation violation theory, the present study examines how user expectations, informed by belief in machine heuristics and concerns over human uniqueness, impact chatbot loyalty through a moderated mediation framework. A questionnaire survey of 900 participants in China revealed that belief in machine capabilities bolsters users' perceptions of machine intelligence, which in turn, enhances user loyalty. Interestingly, when users encounter service failures that challenge their expectations, their perceived intelligence of the chatbot intensifies rather than diminishes. In contrast, expectations shaped by human uniqueness concerns diminish users' perceptions of machine intelligence and, consequently, their loyalty, which remains consistent regardless of the encounter with AI failure. The study also delves into the theoretical contributions of these findings to the evolution of expectation violation theory within the sphere of human-robot interaction.}
}
@article{SALONEN202412,
title = {Digital content marketing on social media along the B2B customer journey: The effect of timely content delivery on customer engagement},
journal = {Industrial Marketing Management},
volume = {118},
pages = {12-26},
year = {2024},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2024.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S0019850124000221},
author = {Anna Salonen and Joel Mero and Juha Munnukka and Marcus Zimmer and Heikki Karjaluoto},
keywords = {Business-to-business, Customer journey, Digital marketing, Experiment, Digital content marketing, Social media content types},
abstract = {This study demonstrates the importance of content timeliness as a driver of engagement in business markets. Through an experimental approach, we show that if the customer is exposed to firm-generated content that he or she deems relevant in a particular journey stage, this leads to higher customer engagement with the selling firm and the content that it generates. We contribute to extant understanding of digital content marketing research in a B2B context by demonstrating that there are no universally correct sequences for presenting content to customers at different stages of the customer journey in order to systematically increase engagement. Instead, the findings suggest that the types of content customers prefer to see in different journey stages varies between individuals. For managers hoping to benefit from digital content marketing, we advocate further investments into technologies that improve the selling firm's ability to target content based on the customer's idiosyncratic use needs at different journey stages.}
}
@article{WANG2025101729,
title = {Cognitive foundations in the interplay between computational thinking and creativity: A scoping review},
journal = {Thinking Skills and Creativity},
volume = {56},
pages = {101729},
year = {2025},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101729},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124002700},
author = {Jinhua Wang and Weipeng Yang and Michael K. Yeung},
keywords = {Computational thinking, Creativity, Cognitive abilities, Scoping review},
abstract = {Previous studies have explored the relationship between computational thinking (CT) and creativity. However, a consensus has yet to be reached since both CT and creativity varied in ideation and assessment. To uncover the cognitive mechanism underlying the interplay between CT and creativity, we conduct a scoping review of 26 empirical studies published in 2006–2024. Our findings suggested that the effects of working memory varied in the interplay between CT and creativity due to differences in age range, neural network activation regions, and measurements. Intellectual abilities, including algorithmic fluency, reasoning ability, and coding ability, showed cognitive transfer effect on CT skills but not necessarily on creativity, suggesting that cognitive abilities embracing more intelligent elements may contribute to the functional connectivity in CT neural networks but only partly overlapped with creativity involved networks. Although executive functions (working memory, cognitive flexibility, and inhibitory control) play a crucial role in both CT and creativity, their contributions to the CT-creativity interplay are still rarely studied. Future research should explore the CT-creativity relationship from the perspective of neuroscience.}
}
@article{SU2025104352,
title = {Images and deep learning in human and urban infrastructure interactions pertinent to sustainable urban studies: Review and perspective},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {136},
pages = {104352},
year = {2025},
issn = {1569-8432},
doi = {https://doi.org/10.1016/j.jag.2024.104352},
url = {https://www.sciencedirect.com/science/article/pii/S1569843224007106},
author = {Pengxiang Su and Yingwei Yan and Hao Li and Hangbin Wu and Chun Liu and Wei Huang},
keywords = {Data fusion, Image data, Deep learning, Foundation models, SDG, Urban studies},
abstract = {As global urbanization intensifies, conflicts between humans and urban infrastructure increasingly affect socio-economic and environmental sustainability. Recently, using image data and deep learning to investigate the interactions between humans and urban infrastructure has been a popular approach since the fast development of Artificial Intelligence (AI). However, the convergence of data fusion, deep learning, and human-urban infrastructure interaction studies remains underexplored. Here we systematically analyze 3,552 papers from 2013 to 2023 that use image data to investigate the intersection area of data fusion, deep learning, and human and urban infrastructure interactions, aiming to elucidate the relationships among these three key elements. We found that the cross-applications of deep learning in the papers reviewed are not standardized. Given the trend of diversified data fusion, data fusion about real-world dynamic interactions is scarce. Lastly, four potential future research directions are identified: (1) understanding the dynamic and complex interaction processes; (2) exploring the potential and standards for the application of deep learning; (3) focusing more on research concerning cities in the Global South; (4) establishing suitable training datasets for the interaction between urban infrastructures and humans, which may provide valuable insights for applying foundation models in future urban studies.}
}
@article{YANG2026105273,
title = {Communication modality, authenticity, and continuance usage intention of GenAI chatbots: A media richness theory perspective},
journal = {Tourism Management},
volume = {112},
pages = {105273},
year = {2026},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2025.105273},
url = {https://www.sciencedirect.com/science/article/pii/S0261517725001438},
author = {Huijun Yang and Hanqun Song and Yun Zhang and Emily Ma and Andi Yang},
keywords = {Media richness theory, Communication modality, Authenticity of GenAI chatbots, Destination style, Interaction style},
abstract = {Generative AI chatbots are increasingly popular for tourist destination information searches. However, how communication modalities (text vs. voice), interaction styles (social vs. task-oriented), destination types (hedonic vs. utilitarian), and their interactions contribute to users' perceptions and continuance usage intention remains unclear. Building on media richness theory, this study used a sequential explanatory mixed-methods and multi-study research design, with four scenario-based experiments to examine how the above factors affect tourists' perceived authenticity of GenAI chatbots and continuance usage intention, and a focus group study to validate and contextualize findings. The results indicated that voice communication evokes higher GenAI chatbots' authenticity, which is positively associated with tourists' continuance usage intention. Destination type is a significant moderator, with voice modality producing higher GenAI chatbots’ authenticity than text modality only for hedonic destinations. The moderating roles of destination type and interaction style are clarified, shedding new light on destination marketing theories and practices.}
}
@article{DUAN2025489,
title = {Computational design and improvement of a broad influenza virus HA stem targeting antibody},
journal = {Structure},
volume = {33},
number = {3},
pages = {489-503.e5},
year = {2025},
issn = {0969-2126},
doi = {https://doi.org/10.1016/j.str.2025.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0969212625000024},
author = {Huarui Duan and Xiaojing Chi and Xuehua Yang and Shengnan Pan and Xiuying Liu and Peixiang Gao and Fangyuan Zhang and Xinhui Zhang and Xuemeng Dong and Yi Liao and Wei Yang},
keywords = {computational biology, RosettaAntibodyDesign, influenza A virus, hemagglutinin, neutralizing antibody},
abstract = {Summary
Broadly neutralizing antibodies (nAbs) are vital therapeutic tools to counteract both pandemic and seasonal influenza threats. Traditional strategies for optimizing nAbs generally rely on labor-intensive, high-throughput mutagenesis screens. Here, we present an innovative structure-based design framework for the optimization of nAbs, which integrates epitope-paratope analysis, computational modeling, and rational design approaches, complemented by comprehensive experimental assessment. This approach was applied to optimize MEDI8852, a nAb targeting the stalk region of influenza A virus hemagglutinin (HA). The resulting variant, M18.1.2.2, shows a marked enhancement in both affinity and neutralizing efficacy, as demonstrated both in vitro and in vivo. Computational modeling reveals that this improvement can be attributed to the fine-tuning of interactions between the antibody’s side-chains and the epitope residues that are highly conserved across the influenza A virus HA stalk. Our dry-wet iterative protocol for nAb optimization presented here yielded a promising candidate for influenza intervention.}
}
@article{YANG2025103431,
title = {Expert decision support system for biologically inspired product design integrating emotional preferences and image generation},
journal = {Advanced Engineering Informatics},
volume = {66},
pages = {103431},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103431},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625003246},
author = {Chaoxiang Yang and Xiaoying Huang and Yimin Zhang and Zhengyang Huang and Fei Liu and Yongjing Wan},
keywords = {Expert decision support, Biologically inspired design, Image generation, Emotional preference, Electric kettle},
abstract = {Influenced by the experience economy, customers put more emotional expression and spiritual needs on products. Bionic design can create products that align more with users’ psychological preferences by imitating and learning from the forms of natural creatures. However, the success of bionic design is not easy, because it mainly depends on the designer’s experience and knowledge. On the one hand, users and designers have different preferences for bionic creatures. On the other hand, designers face the problems of stereotyped thinking and lack of inspiration. This can easily lead to poor decision-making, resulting in the designs that do not meet the user’s preferences. Therefore, this paper proposed an expert decision support system for product bionic design that integrates emotional preferences and image generation to support designers in the Biologically Inspired Design (BID) process. This paper took the electric kettle as a case study. First, the biological features are matched with the product semantics to propose the bionic conversion factor. Users’ emotional preferences are analyzed to build a correlation model with the bionic conversion factors, thereby calculating product preference data. Second, the raw biometric data is calculated based on the bionic conversion factors. An intuitive fuzzy number emotional scale is used to measure users’ preferences for these bionic features. A linear function model is constructed between user preferences and the bionic conversion factors to calculate biological preference data. By fitting the product preference data, bionic creatures that align with user preferences are selected. Finally, eye-tracking experiments are conducted to identify the critical biological features. StyleGAN is then applied to integrate these features with product images, resulting in a conceptual solution that serves as a reference for designers. Based on the analysis of users concerned emotional needs, the designer optimizes the details of the concept design to create the final product scheme. User evaluation of the design outputs shows that the electric kettle designed by the proposed system has the highest score and meets the user’s expectations, which verifies the effectiveness and scientificity.}
}
@incollection{CHEONG2025119,
title = {Chapter 9 - Different regulatory treatment of generative AI blockchain, cryptocurrency, and NFT},
editor = {David Lee Kuo Chuen and Robert H. Deng},
booktitle = {Handbook of Blockchain, Digital Finance, and Inclusion, Volume 3},
publisher = {Academic Press},
pages = {119-133},
year = {2025},
isbn = {978-0-443-34717-7},
doi = {https://doi.org/10.1016/B978-0-443-34717-7.00012-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044334717700012X},
author = {Ben Chester Cheong},
keywords = {AI, Legal, Generative AI},
abstract = {This chapter delves into the timely and complex subject of regulating generative AI, particularly within the dynamic financial services market. Recognizing the profound implications for human rights, the chapter opens by exploring the crucial dimensions of ethical AI development and oversight. Following a targeted literature review, it dives into the specific context of AI in finance, highlighting current applications and potential pitfalls. It examines existing doctrinal and regulatory challenges encountered in governing AI, drawing comparisons, and identifying discrepancies across different regions. It further illuminates additional concerns specific to generative AI, such as bias, transparency, and accountability. In response to these concerns, some solutions for regulating generative AI are proposed, underpinned by principles that prioritize human rights, ethical considerations, and sustainability. The establishment of a global AI body to facilitate coordinated and effective oversight is also suggested. Access to justice, ethical considerations, and human rights remain central throughout the proposed approach. Ultimately, this chapter advocates for a nuanced and human-centered regulatory landscape for generative AI, ensuring its responsible application within the financial services market and beyond.}
}
@article{DIPAOLO2025100710,
title = {Brand strategy in the metaverse: Insights from companies venturing into virtual environments},
journal = {Journal of Innovation & Knowledge},
volume = {10},
number = {3},
pages = {100710},
year = {2025},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2025.100710},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X25000605},
author = {Francesco {Di Paolo} and Michele {Di Dalmazi} and Lucio Lamberti},
keywords = {Metaverse, Immersive technology, Branding, Strategy, Innovation, Exploration},
abstract = {The “metaverse”—envisaged as an expansive, fully interoperable network of 3D virtual worlds—remains a distant prospect with a certain degree of conceptual and technological ambiguity. Nevertheless, an increasing number of firms are investigating the potential of the metaverse as a platform for brand engagement and sales opportunities. This study examines how 16 large international corporations spanning various industries integrate the metaverse into their branding strategies. The multiple case study identified four approaches to metaverse integration, with varying degrees of success and strategic alignment. The findings contribute to the emerging literature on metaverse marketing, offering insight into brand engagement, strategic alignment, and organizational learning processes. From a managerial perspective, this study serves as a guide for leveraging the metaverse for branding. It emphasizes the importance of balancing exploration and exploitation to drive successful initiatives. The implications and limitations of the study are discussed, along with suggestions for future research.}
}
@article{JO2025119915,
title = {Asarum heterotropoides F. schmidt attenuates osteoarthritis via multi-target anti-inflammatory actions: A network pharmacology and experimental validation},
journal = {Journal of Ethnopharmacology},
volume = {349},
pages = {119915},
year = {2025},
issn = {0378-8741},
doi = {https://doi.org/10.1016/j.jep.2025.119915},
url = {https://www.sciencedirect.com/science/article/pii/S0378874125005999},
author = {Hee-Geun Jo and Chae Yun Baek and Sidra Ilyas and Yeseul Hwang and Eunhye Baek and Ho Sueb Song and Donghun Lee},
keywords = {Osteoarthritis, GEO datasets, Molecular docking, Network pharmacology,  F.Schmidt},
abstract = {Ethnopharmacological relevance
Asarum heterotropoides F. Schmidt (ARR) has a well-documented history of traditional use in East Asia for musculoskeletal pain disorders, including osteoarthritis (OA), attributed to its significant anti-inflammatory properties. While preliminary studies suggest potential anti-inflammatory effects, conclusive evidence regarding the ability of ARRs to modulate the multiple inflammatory pathologies involved in OA pathogenesis is currently lacking.
Aim of the study
This study aimed to experimentally evaluate the effects of ARR extract on pain, cartilage integrity, and inflammatory responses using in vitro and in vivo models relevant to OA, guided by initial computational predictions.
Materials and methods
Active ingredients of ARRs were retrieved from four databases and screened using SwissADME for ADME predictions. Disease targets were combined with OA-related genes from GEO microarray database. The intersecting genes underwent protein-protein interaction construction, GO, and KEGG enrichment analysis. A compound-target-pathway network was constructed using Cytoscape and was validated via molecular docking. Pain-relieving, functional, and chondroprotective effects were assessed in vivo using acetic acid-induced peripheral pain mice and monosodium iodoacetate (MIA)-induced osteoarthritis rat models. Furthermore, anti-inflammatory properties were explored by evaluating serum cartilage tissue and lipopolysaccharide-stimulated RAW 264.7 cells.
Results
Network pharmacology analysis elucidated five principal active constituents of ARR (cryptopine, 5-[2-(2-hydroxyphenyl)ethyl]-2,3-dimethoxy-phenol, 5-[2-(3-hydroxyphenyl)ethyl]-2-methoxybenzene-1,3-diol, naringenin, resorstatin) alongside 22 putative herbal targets. Molecular docking analyses revealed strong binding affinities (−8 to −9.4 kcal/mol) of these constituents towards principal target proteins. Functional GO and KEGG enrichment analyses indicated that ARR exerts its effects potentially involving pathways associated with cancer, fluid shear stress, and atherosclerosis. In vivo assessments demonstrated significant mitigation of pain, functional deficits, and cartilage degradation by ARR within an MIA-induced osteoarthritis model. Molecular dynamics simulations validated stable interactions between the primary compounds and their designated target proteins. The therapeutic efficacy of ARR was characterized by dose-dependent suppression of diverse inflammatory mediators (IL-1β, IL-6, TNF-α), matrix metalloproteinases (MMP-1, -3, -8, -13), and signaling pathways including CCND1, CDK2, IKBKB, HIF1A, BDKRB1, SIRT1, MAPK8, and NLRP3 within both RAW264.7 cells and articular cartilage tissue.
Conclusions
This investigation demonstrates that ARR exerts pain alleviation, functional enhancement, and chondroprotective effects in osteoarthritis via multi-target anti-inflammatory actions. Integrating network pharmacology, molecular docking, animal models, and cellular experiments, this study comprehensively elucidated the multifaceted anti-inflammatory mechanisms attributed to ARR. These findings collectively provide a crucial foundation for understanding the potential therapeutic efficacy and operative mechanisms of ARR for osteoarthritis management.}
}
@article{LIDDLE2026102497,
title = {Conceptual modeling: A large language model assistant for characterizing research contributions},
journal = {Data & Knowledge Engineering},
volume = {161},
pages = {102497},
year = {2026},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2025.102497},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X25000928},
author = {Stephen W. Liddle and Heinrich C. Mayr and Oscar Pastor and Veda C. Storey and Bernhard Thalheim},
keywords = {LLM-based content characterization, Characterizing Conceptual Modeling Research framework (CCMR), AI assistant for ER research evaluation, Conceptual modeling},
abstract = {The body of conceptual modeling research publications is vast and diverse, making it challenging for a single researcher or research group to fully comprehend the field’s overall development. Although some approaches have been proposed to help organize these research contributions, it is still unrealistic to expect human experts to manually comprehend and characterize all of this research. However, as generative AI tools based on large language models, such as ChatGPT, become increasingly sophisticated, it may be possible to replace or augment tedious, manual work with semi-automated approaches. In this research, we present a customized version of ChatGPT that is tuned to the task of characterizing conceptual modeling research. Experiments with this AI tool demonstrate that it is feasible to create a usable knowledge survey for the continually evolving body of conceptual modeling research contributions.}
}
@article{2025A10,
title = {Guidelines for Authors},
journal = {Journal of Endodontics},
volume = {51},
number = {3},
pages = {A10-A19},
year = {2025},
issn = {0099-2399},
doi = {https://doi.org/10.1016/S0099-2399(25)00075-5},
url = {https://www.sciencedirect.com/science/article/pii/S0099239925000755}
}
@article{CHACON2025424,
title = {An overview of the effects of algorithm use on judgmental biases affecting forecasting},
journal = {International Journal of Forecasting},
volume = {41},
number = {2},
pages = {424-439},
year = {2025},
issn = {0169-2070},
doi = {https://doi.org/10.1016/j.ijforecast.2024.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S0169207024001018},
author = {Alvaro Chacon and Esther Kaufmann},
keywords = {Judgmental biases, Algorithm use, Judgmental accuracy, Judgmental forecasting, Judgmental adjustment, Review article},
abstract = {In the realm of forecasting, judgmental biases often hinder efficiency and accuracy. Algorithms present a promising avenue for decision makers to enhance their forecasting performance. In this overview, we scrutinized the occurrence of the most relevant judgmental biases affecting forecasting across 162 papers, drawing from four recent reviews and papers published in forecasting journals, specifically focusing on the use of algorithms. Thirty-three of the 162 papers (20.4%) at least briefly mentioned one of twelve judgmental biases affecting forecasting. Our comprehensive analysis suggests that algorithms can potentially mitigate the adverse impacts of biases inherent in human judgment related to forecasting. Furthermore, these algorithms can leverage biases as an advantage, enhancing forecast accuracy. Intriguing revelations have surfaced, focusing mainly on four biases. By providing timely, relevant, well-performing, and consistent algorithmic advice, people can be effectively influenced to improve their forecasts, considering anchoring, availability, inconsistency, and confirmation bias. The findings highlight the gaps in the current research landscape and provide recommendations for practitioners. They also lay the groundwork for future studies on utilizing algorithms (e.g., large language models) and overcoming judgmental biases to improve forecasting performance.}
}
@article{GAO2025104560,
title = {Research of FDI and the reduction of the state capital in private firms——Empirical evidence during the crisis period},
journal = {International Review of Financial Analysis},
volume = {106},
pages = {104560},
year = {2025},
issn = {1057-5219},
doi = {https://doi.org/10.1016/j.irfa.2025.104560},
url = {https://www.sciencedirect.com/science/article/pii/S1057521925006477},
author = {Peng Gao and Yating Liang and Yujie Tan and Bo Yang},
keywords = {FDI, Private firm, State-owned capital, Financial crisis, Trade wars},
abstract = {Based on the backdrop of the global financial crisis and trade wars, this study utilizes a sample of Chinese A-share listed private firms from 2008 to 2010 and 2017–2019 to confirm that foreign direct investment (FDI) can lead to a reduction in state-owned capital investment in private firms. Further analysis confirms that FDI improves the business environment and fosters collaboration between private firms and foreign investors, thereby elucidating the relationship between FDI and the ownership structure of private firms. The impact of FDI on reducing state-owned capital is more pronounced in firms without political connections, firms supported by industrial policies, and those with lower overseas revenue or CEOs with an international background. This study focuses on private firms and examines the relationship between private ownership, FDI, and state-owned capital. The findings enhance the understanding of the economic consequences of FDI and corporate equity structure, offering new insights for supporting private firms and boosting regional economic vitality.}
}
@article{HOU2025101075,
title = {Digitalized opportunity space and managerial archetypes: An opportunity-centric perspective on digital innovation and transformation},
journal = {Organizational Dynamics},
volume = {54},
number = {1},
pages = {101075},
year = {2025},
issn = {0090-2616},
doi = {https://doi.org/10.1016/j.orgdyn.2024.101075},
url = {https://www.sciencedirect.com/science/article/pii/S0090261624000482},
author = {Hong Hou and Hao Ma},
keywords = {Digital innovation, Digital transformation, Digital opportunity, Opportunity space},
abstract = {As proliferating digital literature ignores how digital opportunities are generated in the first place, digital innovation and transformation can be ontologically ungrounded. To fill this gap, following a realist perspective of entrepreneurship, this article examines digital opportunities as profit propensities afforded by a digitalized environment, while treating digital innovation and transformation as the actualization process. To elaborate, first, we coin Digitalized Opportunity Space (DOS) to describe the digitalized environment as a critical intersection of four spaces - resource, utility, digital, and institutional- that muster conditions without which digital opportunities cannot be actualized. Second, we develop four managerial archetypes - resource orchestrators, utility integrators, digital evangelists, and institutional realists- who tend to recognize digital opportunities based on their organizational location and thereby endorse different digital innovations. Third, to facilitate a systemic and balanced approach to digital transformation, we recommend group-level heuristics - the generic density perspective, the ecosystem view of the firm, multi-dimensional network effects, and disciplined imagination- which restore totality from partiality. Taken together, the DOS framework (of opportunity generation), the managerial archetypes (of opportunity recognition), and the group-level heuristics (of opportunity actualization) constitute the opportunity-centric (vs technology-centric or organization-centric) perspective on digital innovation and transformation, thereby materializing the connection between digital literature and entrepreneurship.}
}
@article{MOHAMMAD2025,
title = {Knowledge Management Systems in Business Management Using Knowledge Graphs and Semantic Technologies},
journal = {International Journal of Knowledge Management},
volume = {21},
number = {1},
year = {2025},
issn = {1548-0666},
doi = {https://doi.org/10.4018/IJKM.369121},
url = {https://www.sciencedirect.com/science/article/pii/S1548066625000037},
author = {Yara Mohammad and Mirna Nachouki and Elfadil A. Mohamed},
keywords = {Knowledge Management Systems, Knowledge Graphs, Semantic Technologies, RDF, SPAROL},
abstract = {ABSTRACT
Knowledge Management Systems (KMS) are vital for organizations in managing knowledge creation, sharing, and utilization. Integrating KMS with advanced technologies like knowledge graphs and semantic technologies can greatly enhance their functionality in business contexts. This research aims to systematically reviews and evaluates studies on the integration of knowledge graphs and semantic technologies. The study follows PRISMA guidelines for methodological rigor. The review includes articles published between 2005 and 2024 from databases like ScienceDirect and IEEE Xplore, focusing on keywords such as “knowledge graph” and “knowledge management systems.” From an initial 18,900 articles, 73 were selected for detailed analysis. The findings indicate that using tools like RDF, SPARQL, OWL, and SKOS enhances KMS capabilities, enabling features like semantic search and intelligent recommendations. However, challenges such as scalability, semantic disambiguation, and data privacy need to be addressed to fully realize KMS's potential in supporting organizational knowledge management.}
}
@article{WANG2025280,
title = {Expert consensus on a multidisciplinary approach for the management of multiple myeloma-related bone disease},
journal = {Cancer Pathogenesis and Therapy},
volume = {3},
number = {4},
pages = {280-292},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2024.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S2949713224001046},
author = {Yutong Wang and Qiming Xu and Yuan Li and Yongbin Su and Ling Wang and Xiaoquan Wang and Jian Ge and Hongmei Jing and Yuxing Guo and Yalin Chen and Xianan Li and Jun-ling Zhuang and Jing Tan and Xiaobo Wang and Liye Zhong and Jun Luo and Peng Zhao and Shengjin Fan and Jinhai Ren and Haiping Yang and Heng Mei and Chunyan Sun and Chunrui Li and Xuemei Sun and Xuechun Lu and Guangxun Gao and Zeping Zhou and Yaozhu Pan and Ying Sun and Zhang Hong and Zhiqiang Liu and Yanping Ma and Yi Wang and Wei Sun and Jian Hou and Jianqing Mi and Wenming Chen and Xiaobing Huang and Bingzong Li and Rong Fu and Jumei Shi and Xuehong Ran and Fuling Zhou and Aili He and Min Mao and Zhen Cai and Nan Li and Meng Xu and Xiaojing Yan and Wei Yang and Gang An and Lihua Gong and Lichao Sun and Zhihong Li and Tang Liu and Yanjuan He and Junqiang Yin and Yao Liu and Weifeng Liu and Li Bao},
keywords = {Multiple myeloma, Bone disease, Recommendation, Diphosphonates, Therapeutic effect, Orthopedics, Quality of life},
abstract = {This consensus on multiple myeloma-related bone diseases (MBDs) underscores the importance of a multidisciplinary approach that encompasses hematology, radiology, orthopedics, and additional specialties to tackle its intricate challenges. MBD, a prevalent and debilitating complication of multiple myeloma, leads to bone pain, fractures, and skeletal-related events (SREs), which profoundly impact patients’ quality of life. The guidelines offer a thorough framework for diagnosis, treatment, and continual assessment, emphasizing early detection and consistent monitoring using imaging techniques such as positron emission tomography-computed tomography (PET-CT) and magnetic resonance imaging (MRI). Treatment strategies prioritize the careful application of anti-myeloma agents, bisphosphonates, and denosumab to minimize bone loss and decrease SRE risk, complemented by surgical and radiotherapy interventions for structural or pain-related issues. Supportive care measures, including pain management, rehabilitation, nutritional support, and dental evaluations, play a crucial role in enhancing patient outcomes and preserving quality of life. This consensus advocates a standardized, evidence-based approach to managing MBD, ensuring comprehensive and coordinated care for patients.}
}
@article{LISSACK2024389,
title = {Responsible Use of Large Language Models: An Analogy with the Oxford Tutorial System},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {10},
number = {4},
pages = {389-413},
year = {2024},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2024.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S2405872624000959},
author = {Michael Lissack and Brenden Meagher},
keywords = {responsible AI, Oxford Tutorial, large language models (LLMs), human-AI collaboration, critical thinking},
abstract = {In the rapidly evolving landscape of artificial intelligence, large language models (LLMs) have emerged as powerful tools with the potential to revolutionize how we process information, generate content, and solve complex problems. However, integrating these sophisticated AI systems into academic and professional practices raises critical questions about responsible use, ethical considerations, and the preservation of human expertise. This article introduces a novel framework for understanding and implementing responsible AI use by drawing an analogy between the optimal use of LLMs and the role of the second student in an Oxford Tutorial. Through an in-depth exploration of the Oxford Tutorial system and its parallels with LLM interaction, we propose a nuanced approach to leveraging AI language models while maintaining human agency, fostering critical thinking, and upholding ethical standards. The article examines the implications of this analogy, discusses potential risks of misuse, and provides detailed practical scenarios across various fields. By grounding the use of cutting-edge AI technology in a well-established and respected educational model, this research contributes to the ongoing discourse on AI ethics. It offers valuable insights for academics, professionals, and policymakers grappling with the challenges and opportunities presented by LLMs.}
}
@article{ZHANG2024103651,
title = {More is not always better: Examining the drivers of livestream sales from an information overload perspective},
journal = {Journal of Retailing and Consumer Services},
volume = {77},
pages = {103651},
year = {2024},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2023.103651},
url = {https://www.sciencedirect.com/science/article/pii/S0969698923004022},
author = {Cong Zhang and Siyu Pan and Yanhui Zhao},
keywords = {Livestream shopping, Information overload, Livestream sales, Curvilinear effect, Social media marketing},
abstract = {With the rapid development of Internet technologies, many retailers have incorporated live streaming as an emerging sales channel. Retailers and live streamers are eager to cover a wide range of products in their streams and entice viewers to stay for a longer duration. However, we propose from an information overload perspective that having more products and longer stay time may not always be better for sales. In this study, we empirically analyze 472 live streams to explore the curvilinear effects of the number of products and stay time on livestream shopping sales. Our findings suggest an inverted U-shaped relationship between the total number of products and the average audience stay time with sales. Moreover, we find that these relationships are contingent on the total duration of the stream and the age of the streamer. The results have practical implications for retailers regarding the design of effective livestream programs.}
}
@article{BRONS2024,
title = {Machine Learning Methods to Personalize Persuasive Strategies in mHealth Interventions That Promote Physical Activity: Scoping Review and Categorization Overview},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/47774},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124007969},
author = {Annette Brons and Shihan Wang and Bart Visser and Ben Kröse and Sander Bakkes and Remco Veltkamp},
keywords = {artificial intelligence, exercise, mobile app, adaptive, tailoring, supervised learning, reinforcement learning, recommender system},
abstract = {Background
Although physical activity (PA) has positive effects on health and well-being, physical inactivity is a worldwide problem. Mobile health interventions have been shown to be effective in promoting PA. Personalizing persuasive strategies improves intervention success and can be conducted using machine learning (ML). For PA, several studies have addressed personalized persuasive strategies without ML, whereas others have included personalization using ML without focusing on persuasive strategies. An overview of studies discussing ML to personalize persuasive strategies in PA-promoting interventions and corresponding categorizations could be helpful for such interventions to be designed in the future but is still missing.
Objective
First, we aimed to provide an overview of implemented ML techniques to personalize persuasive strategies in mobile health interventions promoting PA. Moreover, we aimed to present a categorization overview as a starting point for applying ML techniques in this field.
Methods
A scoping review was conducted based on the framework by Arksey and O’Malley and the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) criteria. Scopus, Web of Science, and PubMed were searched for studies that included ML to personalize persuasive strategies in interventions promoting PA. Papers were screened using the ASReview software. From the included papers, categorized by the research project they belonged to, we extracted data regarding general study information, target group, PA intervention, implemented technology, and study details. On the basis of the analysis of these data, a categorization overview was given.
Results
In total, 40 papers belonging to 27 different projects were included. These papers could be categorized in 4 groups based on their dimension of personalization. Then, for each dimension, 1 or 2 persuasive strategy categories were found together with a type of ML. The overview resulted in a categorization consisting of 3 levels: dimension of personalization, persuasive strategy, and type of ML. When personalizing the timing of the messages, most projects implemented reinforcement learning to personalize the timing of reminders and supervised learning (SL) to personalize the timing of feedback, monitoring, and goal-setting messages. Regarding the content of the messages, most projects implemented SL to personalize PA suggestions and feedback or educational messages. For personalizing PA suggestions, SL can be implemented either alone or combined with a recommender system. Finally, reinforcement learning was mostly used to personalize the type of feedback messages.
Conclusions
The overview of all implemented persuasive strategies and their corresponding ML methods is insightful for this interdisciplinary field. Moreover, it led to a categorization overview that provides insights into the design and development of personalized persuasive strategies to promote PA. In future papers, the categorization overview might be expanded with additional layers to specify ML methods or additional dimensions of personalization and persuasive strategies.}
}
@article{WELLS202511,
title = {Pyruvate kinase splice variants in fibroblasts influence cardiac remodeling after myocardial infarction in male mice},
journal = {Journal of Molecular and Cellular Cardiology},
volume = {206},
pages = {11-26},
year = {2025},
issn = {0022-2828},
doi = {https://doi.org/10.1016/j.yjmcc.2025.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S0022282825001166},
author = {Collin K. Wells and Daniel C. Nguyen and Robert E. Brainard and Lindsey A. McNally and Maleesha {De Silva} and Kenneth R. Brittian and Lauren Garrett and Madison S. Taylor and Yania Martinez-Ondaro and Caitlin Howard and Snigdha Suluru and Sujith Dassanayaka and Tamer M.A. Mohamed and Richa Singhal and Andrew A. Gibb and Pawel K. Lorkiewicz and Joseph B. Moore and Steven P. Jones and Bradford G. Hill},
keywords = {Heart failure, Glycolysis, Fibrosis, Extracellular matrix, Metabolism},
abstract = {Fibroblasts are crucial for cardiac repair after myocardial infarction (MI). In response to signaling cues, they differentiate to phenotypes with robust capacities to synthesize and secrete extracellular matrix (ECM) and signaling molecules. Although activated fibroblast phenotypes are associated with pronounced changes in metabolism, it remains unclear how the metabolic network upholds the effector functions of fibroblasts in the infarcted heart. We found that two enzymes that could facilitate a phosphoenolpyruvate cycle, i.e. pyruvate kinase muscle isoform 2 (PKM2) and phosphoenolpyruvate carboxykinase 2 (PCK2), are elevated in the heart after MI. Although Pck2 deletion had no effect on post-MI remodeling, fibroblast-specific switching of Pkm2 to Pkm1 (fbPkm2 → 1) mitigated ventricular dilation, wall thinning, and losses in ejection fraction caused by MI. Despite these salutary effects, fbPkm2 → 1 switching did not alter cardiac fibrosis in vivo, nor did it affect collagen production, cytokine or chemokine secretion, myofibroblast differentiation markers, or transcriptional regulation in vitro. Nevertheless, Pkm2 → 1 splice variant switching increased myofibroblast contractile activity as well as influenced the metabolic phenotype of fibroblasts, as shown by increased pyruvate kinase activity, higher mitochondrial respiratory capacity, and elevation in glycolytic intermediate abundance. Despite these changes, Pkm2 → 1 switching had relatively minor effects on glucose carbon fate, as determined by stable isotope-resolved metabolomics. Nevertheless, these metabolic data demonstrate that cardiac fibroblasts exhibit minimal glucose-supported de novo glycine synthesis in vitro, yet possess high hexosamine and glucuronate biosynthetic pathway activity. Collectively, these findings reveal that fibroblast PKM isoforms influence post-MI remodeling, highlighting pyruvate kinase as a potential therapeutic target.}
}
@article{TIAN2025100728,
title = {The impact of artificial intelligence on students’ 4C skills: A meta-analysis},
journal = {Educational Research Review},
volume = {49},
pages = {100728},
year = {2025},
issn = {1747-938X},
doi = {https://doi.org/10.1016/j.edurev.2025.100728},
url = {https://www.sciencedirect.com/science/article/pii/S1747938X2500065X},
author = {Qian Tian and Xudong Zheng},
keywords = {Artificial intelligence, Artificial intelligence in education, 4C skills, Meta-analysis},
abstract = {The widespread integration of artificial intelligence (AI) in education has highlighted its potential to enhance students' higher-order competencies, particularly the 4C skills (critical thinking, communication, collaboration, and creativity). However, the effectiveness of AI in fostering these skills remains debated, primarily due to inconsistent findings across studies. To address this research gap, this study employs the meta-analysis method, analyzing 39 experimental and quasi-experimental studies published in international journals between January 2010 and July 2024. The results reveal that: (1) AI has a moderately positive impact on students' 4C skills (the combined effect size = 0.624), while there is no significant difference in creativity, critical thinking, communication, and collaboration; (2) AI-based learning tools are most effective in enhancing the 4C skills of primary school students compared to other educational levels; (3) a mix of different technology types is more conducive to developing students' 4C skills than any single technology; (4) AI is most effective in fostering 4C skills when applied in adaptive systems and personalization; (5) smartphones, as AI learning devices, show significant potential in promoting 4C skills. These findings provide valuable insights for future research and practice aimed at leveraging AI tools to enhance students’ 4C skills, particularly by identifying key factors that maximize the effectiveness of AI in education.}
}
@article{GNADLINGER2024,
title = {Incorporating an Intelligent Tutoring System Into a Game-Based Auditory Rehabilitation Training for Adult Cochlear Implant Recipients: Algorithm Development and Validation},
journal = {JMIR Serious Games},
volume = {12},
year = {2024},
issn = {2291-9279},
doi = {https://doi.org/10.2196/55231},
url = {https://www.sciencedirect.com/science/article/pii/S2291927924000977},
author = {Florian Gnadlinger and Maika Werminghaus and André Selmanagić and Tim Filla and Jutta G Richter and Simone Kriglstein and Thomas Klenzner},
keywords = {cochlear implant, eHealth, evidence-centered design, hearing rehabilitation, adaptive learning, intelligent tutoring system, game-based learning},
abstract = {Background
Cochlear implants are implanted hearing devices; instead of amplifying sounds like common hearing aids, this technology delivers preprocessed sound information directly to the hearing (ie, auditory) nerves. After surgery and the first cochlear implant activation, patients must practice interpreting the new auditory sensations, especially for language comprehension. This rehabilitation process is accompanied by hearing therapy through face-to-face training with a therapist, self-directed training, and computer-based auditory training.
Objective
In general, self-directed, computer-based auditory training tasks have already shown advantages. However, compliance of cochlear implant recipients is still a major factor, especially for self-directed training at home. Hence, we aimed to explore the combination of 2 techniques to enhance learner motivation in this context: adaptive learning (in the form of an intelligent tutoring system) and game-based learning (in the form of a serious game).
Methods
Following the suggestions of the evidence-centered design framework, a domain analysis of hearing therapy was conducted, allowing us to partially describe human hearing skill as a probabilistic competence model (Bayesian network). We developed an algorithm that uses such a model to estimate the current competence level of a patient and create training recommendations. For training, our developed task system was based on 7 language comprehension task types that act as a blueprint for generating tasks of diverse difficulty automatically. To achieve this, 1053 audio assets with meta-information labels were created. We embedded the adaptive task system into a graphic novel–like mobile serious game. German-speaking cochlear implant recipients used the system during a feasibility study for 4 weeks.
Results
The 23 adult participants (20 women; 3 men) fulfilled 2259 tasks. In total, 2004 (90.5%) tasks were solved correctly, and 255 (9.5%) tasks were solved incorrectly. A generalized additive model analysis of these tasks indicated that the system adapted to the estimated competency levels of the cochlear implant recipients more quickly in the beginning than at the end. Compared with a uniform distribution of all task types, the recommended task types differed (χ²6=86.713; P<.001), indicating that the system selected specific task types for each patient. This is underlined by the identified categories for the error proportions of the task types.
Conclusions
This contribution demonstrates the feasibility of combining an intelligent tutoring system with a serious game in cochlear implant rehabilitation therapies. The findings presented here could lead to further advances in cochlear implant care and aural rehabilitation in general.
Trial Registration
German Clinical Trials Register (DRKS) DRKS00022860; https://drks.de/search/en/trial/DRKS00022860}
}
@article{BEYER2025107585,
title = {Sensitive periods to social adversity in immune and metabolic development: A systematic review},
journal = {Psychoneuroendocrinology},
volume = {181},
pages = {107585},
year = {2025},
issn = {0306-4530},
doi = {https://doi.org/10.1016/j.psyneuen.2025.107585},
url = {https://www.sciencedirect.com/science/article/pii/S0306453025003087},
author = {Logan Beyer and Seetha H. Davis and Michelle M.J. Mens and Saúl A. Urbina-Johanson and Meisui Russo and Paul A. Bain and Jack Shonkoff and Natalie Slopen},
keywords = {Social adversity, Sensitive periods, Immune development, Metabolic development},
abstract = {Childhood exposure to social adversity – including experiences such as poverty, discrimination, violence, family separation, household dysfunction, and maltreatment – is associated with cardiometabolic health problems across the life course. A key question in the field is whether the timing of social adversity matters. To better understand the developmental origins of cardiometabolic disease and the emergence of health disparities, we conducted a systematic review of human observational studies to synthesize the evidence for sensitive periods to social adversity in immune and metabolic development. To be included in the study, some form of social adversity had to be independently reported at two or more non-overlapping time points during the prenatal period or childhood (<21 years old) and studies were required to include an outcome relevant to immune and/or metabolic biomarkers measured at some time after the social adversity exposure. Of the 2440 unique records screened, 25 met criteria for inclusion. Twenty studies investigated sensitive periods in immune development and six in metabolic development. For immune development, studies identified sensitive periods to social adversity inconsistently from the prenatal period through age 18. However, the proportion of studies confirming sensitive periods was highest at the youngest stages of development and gradually decreased across the life course. 50 % of studies found significant sensitive period effects in the prenatal period, while only 20 % found significant effects in late adolescence. For metabolic development, studies identified sensitive periods more consistently from birth through age 12. The proportion of studies reporting sensitive periods peaked at 50 % in infancy and decreased to zero after preadolescence. Overall, we found insufficient evidence to identify precise periods during which specific social adversity exposures have been consistently associated with altered immune and metabolic development. More birth cohorts with repeated measures of both social exposures and immune and metabolic biomarkers are needed, as are studies leveraging causal inference methods to more robustly account for time-varying confounding. However, these limitations notwithstanding, our review finds evidence that early experiences matter for immune and metabolic functioning. Improving the social and economic circumstances of young children may benefit lifelong cardiometabolic health.}
}
@article{LI2024114121,
title = {An explanation framework and method for AI-based text emotion analysis and visualisation},
journal = {Decision Support Systems},
volume = {178},
pages = {114121},
year = {2024},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2023.114121},
url = {https://www.sciencedirect.com/science/article/pii/S0167923623001963},
author = {Yuming Li and Johnny Chan and Gabrielle Peko and David Sundaram},
keywords = {Explainable AI, Explanation framework, Emotion analysis, Emotion theory},
abstract = {With the rapid development of artificial intelligence, there is an increasing number of industries relying on the accuracy and efficiency of deep learning algorithms. But due to the inexplicability and black box effect of deep neural networks, we can only obtain results without knowing the applied reasoning behind them. That engenders scepticism and resistance from some quarters of deep learning-based technologies. In the context of emotion analysis used in business and public opinion monitoring, it is sometimes difficult for decision-makers to trust the outcome without explanation from the supposedly emotionless machines. There are mathematical-based explanation methods, and they often generalise emotion analysis as a classification task. Still, emotion should be different from other task categories because the generation of emotion involves human-specific factors and logic. This paper proposes an emotion analysis explanation framework that is grounded in psychological theories focusing on the stimulus from classic emotion theories. This proposed framework emphasises considering the cause and trigger of emotions as the explanation for the deep learning-based emotion analysis, and it includes two main components: the extraction of the emotion cause and the visualisation of emotion-triggering words. Compared with the existing approaches, our proposed framework is based on the perspective of human psychology with higher credibility and significant theoretical support. In addition, we purposefully design and implement an intuitive visualisation for the framework, instead of complex numerical representations, to improve the explanation comprehensibility for a broader audience.}
}
@incollection{RAMAKRISHNAN2025105,
title = {Chapter 8 - Transforming global economies: The profound impact of digitalization},
editor = {David Lee Kuo Chuen and Robert H. Deng},
booktitle = {Handbook of Blockchain, Digital Finance, and Inclusion, Volume 3},
publisher = {Academic Press},
pages = {105-118},
year = {2025},
isbn = {978-0-443-34717-7},
doi = {https://doi.org/10.1016/B978-0-443-34717-7.00008-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443347177000088},
author = {Ramaprasad Ramakrishnan and Alan Megargel},
keywords = {Digital transformation, Global economies, Payment fraud, E-commerce scams, Technology adoption},
abstract = {In the era of unprecedented digital transformation, global economies have witnessed remarkable growth, innovation, and opportunity. However, as the world rapidly embraces the digital frontier, frauds and scams emerge as formidable impediments to this digital revolution. This chapter review offers a rigorous exploration of the digital transformation, strong drivers that support the objectives, and an analysis of its profound impact on Asian markets in Singapore and India. It delves further into the research gaps and potential pitfalls, highlighting the pressing need for caution in the face of pervasive financial frauds and scams. As the world progresses toward a digitally interconnected future, this study underscores the imperative for a comprehensive understanding of these challenges and the proactive measures to safeguard promising global economies from frauds and scams.}
}
@article{ZHANG2026101984,
title = {Differences in the collaborative knowledge construction process between high- and low-achievement groups in a collaborative concept mapping task: Evidence from multiple perspectives},
journal = {Thinking Skills and Creativity},
volume = {59},
pages = {101984},
year = {2026},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2025.101984},
url = {https://www.sciencedirect.com/science/article/pii/S1871187125002330},
author = {Si Zhang and Zihan Yin},
keywords = {Cooperative/collaborative learning, Improving classroom teaching, Teaching/learning strategies, 21st century abilities, Concept mapping},
abstract = {Collaborative learning is important for assisting students in knowledge understanding and knowledge co-construction. Many studies use concept maps, a visualized tool, to aid in this process. It is crucial to look into the ways that groups of three or more people construct knowledge and to combine implicit physiological data with explicit data. In this study, we combined content analysis, ordered network analysis (ONA), and hyperscanning technology based on electroencephalograms (EEG) to analyze the data of 28 triads of high- and low-achievement groups that participated in collaborative concept mapping tasks. The frequency statistics showed that the low-achievement groups have significantly higher monitoring and adapting behavior frequencies at the individual level in the regulation dimension than the high-achievement groups. The ONA results further illustrated the sequence of knowledge transfer based on the frequency analysis. The cognitive patterns of high-achievement groups showed a cycle that began at the group level of cognition, moved to the peer level of cognition, then to the group level of regulation, and ultimately returned to the group level of cognition. The low-achievement groups' cognitive patterns also exhibited directionality, moving from the group level of regulation to the individual level of cognition and to the group level of cognition. From the implicit perspective, the theta band and temporal-parietal regions showed greater inter-brain synchrony in the high-achievement groups. Low-achievement groups, on the other hand, had comparatively lower synchrony. Their consensus was only superficial and concentrated on ensuring that everyone participated through regulation and thought integration to finish the task. Our study's findings can help teachers and instructional designers develop tailored interventions based on differences in learners' cognitive patterns during collaborative concept mapping tasks.}
}
@article{ELRHIOUANE2025130521,
title = {Integrating ESG criteria in portfolio optimization: A Moroccan case study using Markowitz’s theory and correlation network analysis},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {667},
pages = {130521},
year = {2025},
issn = {0378-4371},
doi = {https://doi.org/10.1016/j.physa.2025.130521},
url = {https://www.sciencedirect.com/science/article/pii/S0378437125001736},
author = {Afaf {El Rhiouane} and Hassan Oukhouya and Raby Guerbaz and Khalid Belkhoutout and Aziz Lmakri and Mohamed Fihri and Abdellatif {El Afia}},
keywords = {ESG criteria, Markowitz’s mean–variance theory, Graph theory, Correlation network, Portfolio optimization},
abstract = {This paper evaluates the contribution of integrating environmental, social, and governance (ESG) criteria into portfolio optimization, which is an important gap in the literature on socially responsible investing (SRI) for the context of Morocco. It offers new insights on how ESG constraints affect performance and risk in dynamic portfolios, accounting for time-varying correlations of responsible assets. The paper uses a quantitative approach by considering two models: one using only Markowitz’s theory about mean–variance (MV) optimality without considering the ESG criteria, and another model with a constraint that enforces a minimum acceptable threshold in ESG scores, named here as MV-ESG. The minimum spanning tree (MST) method was adopted for correlation network construction, and it would consider studying dynamic correlation structures on two different periods: crisis and post-crisis. The data used are the closing prices of companies listed on the Casablanca stock exchange (CSE), obtained from their official website, while the ESG scores were obtained from Refinitiv. The results show that responsible portfolios (RPs), optimized by traditional and network approaches, are neither more profitable nor less volatile than their conventional counterparts, with the exception of peripheral portfolios (Pp), which show more attractive profitability in the responsible case, but at the cost of higher risk. While the network approach has facilitated better opportunities for higher returns, reduced losses, and better ESG scores than the traditional method, the results show that in a social orientation crisis, performance will be unfavorable; it has not been able to provide positive returns during this period.}
}
@article{RIQUELMEGARCIA20252155,
title = {Annotation of biological samples data to standard ontologies with support from large language models},
journal = {Computational and Structural Biotechnology Journal},
volume = {27},
pages = {2155-2167},
year = {2025},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2025.05.020},
url = {https://www.sciencedirect.com/science/article/pii/S2001037025001837},
author = {Andrea Riquelme-García and Juan Mulero-Hernández and Jesualdo Tomás Fernández-Breis},
keywords = {Bioinformatics, Generative AI, Large language models, Data interoperability, Biological samples},
abstract = {The semantic integration of biological data is hindered by the vast heterogeneity of data sources and their limited semantic formalization. A crucial step in this process is mapping data elements to ontological concepts, which typically involves substantial manual effort. Large Language Models (LLMs) have demonstrated potential in automating complex language-related tasks and may offer a solution to streamline biological data annotation. This study investigates the utility of LLMs—specifically various base and fine-tuned GPT models—for the automatic assignment of ontological identifiers to biological sample labels. We evaluated model performance in annotating labels to four widely used ontologies: the Cell Line Ontology (CLO), Cell Ontology (CL), Uber-anatomy Ontology (UBERON), and BRENDA Tissue Ontology (BTO). Our dataset was compiled from publicly available, high-quality databases containing biologically relevant sequence information, which suffers from inconsistent annotation practices, complicating integrative analyses. Model outputs were compared against annotations generated by text2term, a state-of-the-art annotation tool. The fine-tuned GPT model outperformed both the base models and text2term in annotating cell lines and cell types, particularly for the CL and UBERON ontologies, achieving a precision of 47–64% and a recall of 88–97%. In contrast, base models exhibited significantly lower performance. These results suggest that fine-tuned LLMs can accelerate and improve the accuracy of biological data annotation. Nonetheless, our evaluation highlights persistent challenges, including variable precision across ontology categories and the continued need for expert curation to ensure annotation validity.}
}
@article{GARCIACARMONA2025,
title = {Leveraging Large Language Models for Accurate Retrieval of Patient Information From Medical Reports: Systematic Evaluation Study},
journal = {JMIR AI},
volume = {4},
year = {2025},
issn = {2817-1705},
doi = {https://doi.org/10.2196/68776},
url = {https://www.sciencedirect.com/science/article/pii/S281717052500050X},
author = {Angel Manuel Garcia-Carmona and Maria-Lorena Prieto and Enrique Puertas and Juan-Jose Beunza},
keywords = {large language models, LangChain framework, electronic health records, data mining, model evaluation, health care, digitalization},
abstract = {Background
The digital transformation of health care has introduced both opportunities and challenges, particularly in managing and analyzing the vast amounts of unstructured medical data generated daily. There is a need to explore the feasibility of generative solutions in extracting data from medical reports, categorized by specific criteria.
Objective
This study aimed to investigate the application of large language models (LLMs) for the automated extraction of structured information from unstructured medical reports, using the LangChain framework in Python.
Methods
Through a systematic evaluation of leading LLMs—GPT-4o, Llama 3, Llama 3.1, Gemma 2, Qwen 2, and Qwen 2.5—using zero-shot prompting techniques and embedding results into a vector database, this study assessed the performance of LLMs in extracting patient demographics, diagnostic details, and pharmacological data.
Results
Evaluation metrics, including accuracy, precision, recall, and F1-score, revealed high efficacy across most categories, with GPT-4o achieving the highest overall performance (91.4% accuracy).
Conclusions
The findings highlight notable differences in precision and recall between models, particularly in extracting names and age-related information. There were challenges in processing unstructured medical text, including variability in model performance across data types. Our findings demonstrate the feasibility of integrating LLMs into health care workflows; LLMs offer substantial improvements in data accessibility and support clinical decision-making processes. In addition, the paper describes the role of retrieval-augmented generation techniques in enhancing information retrieval accuracy, addressing issues such as hallucinations and outdated data in LLM outputs. Future work should explore the need for optimization through larger and more diverse training datasets, advanced prompting strategies, and the integration of domain-specific knowledge to improve model generalizability and precision.}
}
@article{OSLUND20241473,
title = {Therapeutic potential of cis-targeting bispecific antibodies},
journal = {Cell Chemical Biology},
volume = {31},
number = {8},
pages = {1473-1489},
year = {2024},
note = {Special issue: Bridging chemistry and biology},
issn = {2451-9456},
doi = {https://doi.org/10.1016/j.chembiol.2024.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S2451945624003064},
author = {Rob C. Oslund and Pamela M. Holland and Scott A. Lesley and Olugbeminiyi O. Fadeyi},
abstract = {Summary
The growing clinical success of bispecific antibodies (bsAbs) has led to rapid interest in leveraging dual targeting in order to generate novel modes of therapeutic action beyond mono-targeting approaches. While bsAbs that bind targets on two different cells (trans-targeting) are showing promise in the clinic, the co-targeting of two proteins on the same cell surface through cis-targeting bsAbs (cis-bsAbs) is an emerging strategy to elicit new functionalities. This includes the ability to induce proximity, enhance binding to a target, increase target/cell selectivity, and/or co-modulate function on the cell surface with the goal of altering, reversing, or eradicating abnormal cellular activity that contributes to disease. In this review, we focus on the impact of cis-bsAbs in the clinic, their emerging applications, and untangle the intricacies of improving bsAb discovery and development.}
}
@article{JIN2025106294,
title = {Understanding the internet-famous tourist city: Interaction within digital technology in an accelerated society},
journal = {Cities},
volume = {167},
pages = {106294},
year = {2025},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2025.106294},
url = {https://www.sciencedirect.com/science/article/pii/S0264275125005955},
author = {Honglei Jin and Pengfei Zhang and Liyu Yang and Enrique Santiago-Iglesias},
keywords = {Internet-famous tourist city, Accelerated society, Digital interaction, Capital logic},
abstract = {Under the influence of social media marketing, internet-famous tourist cities have become a hot topic in contemporary society. Tourists' attention to these cities is significantly shaped by social media interactions. By using Zibo, Harbin, and Tianshui as case studies, the study explored the effect of interaction between tourists and destinations within an accelerated societal context. The study collected a dataset of 702 videos and 67,568 comments from TikTok, Kwai, and Bilibili. Through interaction index, sentiment analysis, and BERTopic theme modeling, it measured audience interaction dynamics. The findings reveal that in the process of urban virality, social media-driven emotional resonance emerges as the core factor driving active interaction. However, cognitive conflicts arising from excessive commercial penetration have become prominent with capital expansion and market competition. Notably, audience sentiment scores exhibit a stepped decline across cities from Zibo to Harbin and Tianshui, a trend that profoundly exposes the development paradox of accelerated society. This study constructs a novel theoretical framework that integrates digital technology interaction with social acceleration, unveiling the developmental dynamics of internet-famous tourist city and guiding tourism development toward the goal of fostering a good life.}
}
@article{CASADOGARCIAHIRSCHFELD2025101124,
title = {Teaching economics in blended learning higher education: Use of whiteboard videos to engage the students},
journal = {The International Journal of Management Education},
volume = {23},
number = {2},
pages = {101124},
year = {2025},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2024.101124},
url = {https://www.sciencedirect.com/science/article/pii/S1472811724001952},
author = {Elena {Casado García-Hirschfeld} and M. Ángeles Rodríguez-Santos and Carmen López-Martín},
keywords = {Blended learning, Whiteboard videos, Learning engagement, Virtual learning environments, Economics education},
abstract = {Blended Learning (BL) is a type of learning that has been arousing interest for more than a decade and it has been playing an even greater role since the pandemic. This article sets out the results of a teaching innovation project (TIP) within the framework of blended university education in economics. This research has a dual objective. First, it aims to analyse the extent to which student involvement is stimulated through the use of the specific methodology of whiteboard videos in economics studies. Use of whiteboard videos in economy education is under researched. Second, it analyses how the development of a strong learning community can be enhanced. The results obtained from the analysis of the data taken from a survey show a high level of satisfaction among economics students with the use of these videos as a learning tool and their perception of the positive effect of watching them on encouraging and facilitating the learning process. In addition, the experience allows the lecturers in economy to improve the way they teach and boost the creation of a strong community using novel learning technologies.}
}
@article{LI2025101616,
title = {Leveraging patent classification based on deep learning: The case study on smart cities and industrial Internet of Things},
journal = {Journal of Informetrics},
volume = {19},
number = {1},
pages = {101616},
year = {2025},
issn = {1751-1577},
doi = {https://doi.org/10.1016/j.joi.2024.101616},
url = {https://www.sciencedirect.com/science/article/pii/S1751157724001287},
author = {Munan Li and Liang Wang},
keywords = {Technology-field resolution, Patent classification, Deep learning, Semantic analysis, Loss function, Smart cities, Industrial Internet of Things, GPT-4},
abstract = {With the trends of technology convergence and technology interdisciplinarity, technology-field (TF) resolution and classification of patents have gradually been challenged. Whether for patent applicants or for patent examiners, more precisely labeling the TF for a certain patent is important for technological searches. However, determining the TF of a patent may be difficult and may even involve the strategic behavior of patenting, which can cause noise in patent classification systems (PCSs). In addition, some specific patents could contain more TFs than claimed or be assigned questionable IPC codes; subsequently, in a regular search for technology/patents, information could be missed. Considering the advantages of deep learning compared with traditional machine learning algorithms in areas such as natural language processing (NLP), text classification and text sentiment analysis, this paper investigates several popular deep learning models and proposes a large-scale multilabel regression (MLR) model to handle specific patent analyses under situations of small sample learning. To verify the proposed MLR model for patent classification, the case study on smart cities and industrial Internet of Things (IIoT) is conducted. The MLR experiments on the TF resolution of smart cities and IIoT have yielded moderate results compared with those of the latest patent classification studies, which also rely on deep learning and the large language models (LLMs), which include RCNN, Bi-LSTM, BERT and GPT-4 etc. Therefore, the proposed MLR model with a customized loss function could be moderately effective for patent classification within a specific technology theme, could have implications for patent classification and the TF resolution of patents, and could further enrich methodologies for patent mining and informetrics based on artificial intelligence (AI).}
}
@article{ALQASSAB2024104750,
title = {Motivational messages from teachers before exams: Links to intrinsic motivation, engagement, and academic performance},
journal = {Teaching and Teacher Education},
volume = {151},
pages = {104750},
year = {2024},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2024.104750},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X2400283X},
author = {Maryam Alqassab and Jaime León},
keywords = {Motivational messages, Examinations, Motivation, Engagement, Academic performance, Gender},
abstract = {This mixed-method study explored teachers' motivational messages before exams and their impact on students' intrinsic motivation, engagement, and academic performance. High school students in Spain (N = 419) completed questionnaires on motivation and engagement and described teachers’ motivational messages. Messages encouraging effort and capability were the most reported, followed by reassuring messages. Serial mediations showed a positive link between reassuring messages and academic performance via intrinsic motivation and engagement, while lack of messages had a negative effect. No moderation effect of gender was found. These findings underscore the importance of reassuring messages during exam periods.}
}
@incollection{HEREDIA2025155,
title = {Research and Collaborative Working and Sharing Online},
editor = {David Baker and Lucy Ellis},
booktitle = {Encyclopedia of Libraries, Librarianship, and Information Science (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {155-167},
year = {2025},
isbn = {978-0-323-95690-1},
doi = {https://doi.org/10.1016/B978-0-323-95689-5.00111-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780323956895001115},
author = {Ana Heredia and Eloisa Viggiani},
keywords = {Collaborative tools, Data sharing, Digital age, Digital divide., Online collaboration, Research Collaboration},
abstract = {In today׳s rapidly evolving digital landscape, the way research is conducted, and how collaboration happens has undergone a significant transformation. The advent of online sharing platforms and collaborative tools has revolutionized how individuals and teams work together, communicate, and share knowledge. This entry explores the impact of online sharing and collaboration on research, sheds light on the benefits and discusses the challenges of these dynamic virtual environments. Moreover, it explores the potential impacts of these new research practices to lower current global asymmetries and inequalities in the access and dissemination of research.}
}
@article{YAN2024103867,
title = {Does usage scenario matter? Investigating user perceptions, attitude and support for policies towards ChatGPT},
journal = {Information Processing & Management},
volume = {61},
number = {6},
pages = {103867},
year = {2024},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103867},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324002267},
author = {Wenjia Yan and Bo Hu and Yu-li Liu and Changyan Li and Chuling Song},
keywords = {ChatGPT, Application scenarios, Information quality, Attitude, Perceived risk, Policy support},
abstract = {ChatGPT's impressive performance enables users to increasingly apply it to a variety of scenarios. However, previous studies investigating people's perceptions or attitudes towards ChatGPT have not considered the effects of the usage scenario. This paper aims to extract the representative scenarios of ChatGPT, explore differences in user perceptions for each scenario, and provide a policy support model. We extracted five scenarios by collecting 50 open-ended responses from Mturk, including “Scenario 1: Daily life tasks,” “Scenario 2: Enhance efficiency (work and education purposes),” “Scenario 3: Replace manpower (work and education purposes),” “Scenario 4: Browsing and general information seeking,” “Scenario 5: Enjoyment.” Subsequently, we identified four key variables to be tested (i.e., information quality, perceived risk, attitude, and policy support), and classified usage scenarios into different categories according to the perception variables measured via an online survey (n = 514). Finally, we built a model including the four variables and tested it for each scenario. The results of this study provide deep insights into user perceptions towards ChatGPT in distinct scenarios.}
}
@article{ASSET2025214,
title = {The formation of the trinitites unveiled by their oxygen and silicon isotopic compositions},
journal = {Geochimica et Cosmochimica Acta},
volume = {400},
pages = {214-226},
year = {2025},
issn = {0016-7037},
doi = {https://doi.org/10.1016/j.gca.2025.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S0016703725002443},
author = {Nathan Asset and Marc Chaussidon and Christian Koeberl and Johan Villeneuve and François Robert},
keywords = {Trinity nuclear explosion, Trinitites, Condensation, Silicon isotopes, Oxygen isotopes},
abstract = {During the world’s first nuclear explosion, in 1945, glassy melts called “trinitites”, mostly derived from the sands at the surface of the test site, formed and were deposited at or near the hypocenter. The processes of formation of this fallout remain unclear. Here, we show how the oxygen and silicon isotopic compositions of three trinitites allow to refine their formation scenario. The three samples are typical of trinitites, being composed of various crystalline phases and of glassy phases divided into three chemical groups (CaMgFe, alkali, silica) that are mixed in various proportions in the three samples. The three samples show a large range of oxygen and silicon isotopic variations (−10.9 ± 0.6 < δ30Si < 4.2 ± 0.6 ‰, and 2.3 ± 0.4 < δ18O < 24.2 ± 0.5 ‰). At variance with the Hiroshima fallout deposits, no oxygen mass-independent isotopic fractionation was found in the three trinitites. The chemical and isotopic compositions of the chemical groups reveal that they result from different processes: the silica phases are molten fragments of the site material, while the CaMgFe and alkali phases are produced by the mixing of condensates and molten site material. Models show that the observed silicon isotopic variations resulted from Rayleigh distillation during condensation of the gaseous species injected into the cloud, while the variability in composition of the site materials also played an important role for controlling the oxygen isotopic compositions. From these observations, a general scenario, beginning with the vaporization of the site surface, producing a depression, is proposed. The vaporized material condensed and grew by agglomeration with other condensates and liquid materials. These agglomerates rained on the surface and quenched, forming the trinitites. This scenario is different from the formation of the Hiroshima glasses but shows some similarities to tektite formation.}
}
@article{YOSHIOKA2025116217,
title = {Tractable fish growth models considering individual differences with an application to the fish Plecoglossus altivelis},
journal = {Applied Mathematical Modelling},
volume = {148},
pages = {116217},
year = {2025},
issn = {0307-904X},
doi = {https://doi.org/10.1016/j.apm.2025.116217},
url = {https://www.sciencedirect.com/science/article/pii/S0307904X25002926},
author = {Hidekazu Yoshioka and Yumi Yoshioka and Motoh Tsujimura},
keywords = {Fish growth, Size spectrum, Probability density function, Misspecification, Environmental fluctuation, },
abstract = {Modeling fish growth is an important research topic in ecological and fishery sciences because body weight statistics directly affect the total biomass of fish in a habitat, which in turn affects their population dynamics. Many models of fish growth assume that the fish population in a habitat is homogenous, meaning that there is no physiological spectrum and, therefore, no size spectrum. Moreover, models that account for the size spectrum are not always analytically tractable. We present novel mathematical models of fish growth in which the body weight of each fish is assumed to follow a von Bertalanffy-type model whose proportionality coefficient, representing the maximum body weight, may differ among individual fish. This probabilistic description introduces the size spectrum into the model, owing to which the time-dependent probability density of this model is obtained explicitly. We also consider a misspecified version and a stochastic version of the model as advanced cases. We apply the first model to the real growth data of Plecoglossus altivelis as a keystone fish species in Japan. The model successfully reproduces the skewed size spectrum of this fish species over multiple years. We further use the stochastic model to investigate how fish growth dynamics are affected by environmental fluctuations.}
}
@article{HSIAO2025100901,
title = {Molecular Display of the Animal Meta-Venome for Discovery of Novel Therapeutic Peptides},
journal = {Molecular & Cellular Proteomics},
volume = {24},
number = {2},
pages = {100901},
year = {2025},
issn = {1535-9476},
doi = {https://doi.org/10.1016/j.mcpro.2024.100901},
url = {https://www.sciencedirect.com/science/article/pii/S1535947624001919},
author = {Meng-Hsuan Hsiao and Yang Miao and Zixing Liu and Konstantin Schütze and Nathachit Limjunyawong and Daphne Chun-Che Chien and Wayne Denis Monteiro and Lee-Shin Chu and William Morgenlander and Sahana Jayaraman and Sung-eun Jang and Jeffrey J. Gray and Heng Zhu and Xinzhong Dong and Martin Steinegger and H. Benjamin Larman},
keywords = {venom, phage display, ligand discovery, database mining, itch receptor},
abstract = {Animal venoms, distinguished by their unique structural features and potent bioactivities, represent a vast and relatively untapped reservoir of therapeutic molecules. However, limitations associated with comprehensively constructing and expressing highly complex venom and venom-like molecule libraries have precluded their therapeutic evaluation via high-throughput screening. Here, we developed an innovative computational approach to design a highly diverse library of animal venoms and “metavenoms”. We used programmable M13 hyperphage display to preserve critical disulfide-bonded structures for highly parallelized single-round biopanning with quantitation via high-throughput DNA sequencing. Our approach led to the discovery of Kunitz-type domain containing proteins that target the human itch receptor Mas-related G-protein coupled receptor member X4, which plays a crucial role in itch perception. Deep learning-based structural homology mining identified two endogenous human homologs, tissue factor pathway inhibitor (TFPI), and serine peptidase inhibitor, Kunitz type 2 (SPINT2), which exhibit agonist-dependent potentiation of Mas-related G-protein coupled receptor member X4. Highly multiplexed screening of animal venoms and metavenoms is therefore a promising approach to uncover new drug candidates.}
}
@article{CHEN2025103695,
title = {Imaginaries of the resilient second nuclear era: Nuclear paradox resolution and a feasible atomic priesthood},
journal = {Nuclear Engineering and Technology},
volume = {57},
number = {10},
pages = {103695},
year = {2025},
issn = {1738-5733},
doi = {https://doi.org/10.1016/j.net.2025.103695},
url = {https://www.sciencedirect.com/science/article/pii/S1738573325002633},
author = {Juan Chen and Isaac Yap},
keywords = {Imaginary, Second nuclear era, LFTR, Nuclear paradox, Atomic priesthood},
abstract = {The enduring philosophical and political struggle between embracing nuclear energy as a climate solution and an economic catalyst, and resisting it over risks of weapons proliferation and catastrophic accidents, has been a prominent fixture since the aftermath of Hiroshima and Nagasaki. Termed as the nuclear paradox, this dual framing of nuclear energy often oscillates between promise and peril depending on which aspect of its duality appears more immediate, leaving society to navigate the difficult trade-offs. This study re-examines the structural shortcomings of the first nuclear era and outlines the conditions necessary for a more resilient second phase of nuclear development in the context of today's evolving energy market. It argues that the Liquid Fluoride Thorium Reactor (LFTR), through its distinctive reactor design and fuel cycle, offers a comprehensive response to long-standing concerns about safety, economic viability, proliferation, and waste permanence—exemplified by the ill-fated concept of the Atomic Priesthood. The analysis concludes with concrete policy recommendations to accelerate LFTR research and implementation, contributing to the realization of a more secure and sustainable nuclear energy future.}
}
@article{ASKR2024112009,
title = {Explainable ResNet50 learning model based on copula entropy for cotton plant disease prediction},
journal = {Applied Soft Computing},
volume = {164},
pages = {112009},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.112009},
url = {https://www.sciencedirect.com/science/article/pii/S156849462400783X},
author = {Heba Askr and Mohamed El-dosuky and Ashraf Darwish and Aboul Ella Hassanien},
keywords = {Cotton leaf disease, Deep learning (DL), ResNet50, Grey Wolf Optimization (GWO), Copula entropy (CE), Random Forests (RF), and Explainable Artificial Intelligence (XAI)},
abstract = {This paper presents a novel Deep Learning (DL) framework for cotton plant disease prediction based on Explainable Artificial Intelligence (XAI) and Copula entropy based-Grey Wolf Optimization (GWO) algorithm. The suggested framework uses a cotton plant image as input and pre-processes it to produce an image with enhanced contrast. Features are extracted from the leaf images with the ResNet50 CNN model. A crucial pre-processing model known as feature selection helps to improve the effectiveness of image classification by deleting extraneous or irrelevant features. Therefore, the Gray Wolf optimization (GWO) algorithm which is a global search method with potential use in feature selection is employed in this paper. The proposed framework introduces Copula entropy (CE) as an indicator of association to create the GWO’s initial population and enhance the GWO feature engineering process. For the GWO initialization procedure, CE has been used to choose the most significant features which substantially improved the quality of the GWO starting population and as a result improved the performance of the proposed CE-based GWO algorithm by 78.57 % faster than the traditional GWO as stated by the time complexity analysis. In addition, Feature importance explanation is determined using XAI layer. The final classification is achieved using Random Forests (RF) classifier which is an ensemble learning approach. According to the experimental results, the suggested model has a classification accuracy of 99 % and a mean squared error of 0.0383. Furthermore, the proposed model has been compared to state-of-the-art algorithms and the results showed that the proposed model has the superiority performance. The proposed model can therefore be used to track a variety of cotton areas to enable faster analysis and response, resulting in higher productivity.}
}
@article{HERATH2025133329,
title = {Subgrid informed neural networks for high-resolution flood mapping},
journal = {Journal of Hydrology},
volume = {660},
pages = {133329},
year = {2025},
issn = {0022-1694},
doi = {https://doi.org/10.1016/j.jhydrol.2025.133329},
url = {https://www.sciencedirect.com/science/article/pii/S0022169425006675},
author = {Herath Mudiyanselage Viraj Vidura Herath and Lucy Marshall and Abhishek Saha and Sanka Rasnayaka and Sachith Seneviratne},
keywords = {Flood mapping, U-net, Physics-informed machine learning, Hybrid models, Subgrid, Super-resolution},
abstract = {Physics-based hydrodynamic models are essential for accurate flood prediction but are computationally expensive, limiting their applicability for real-time forecasting and probabilistic analyses. Conversely, pure machine learning (ML) models offer both computational efficiency and accuracy but often lack interpretability. To address this gap, we propose SGUnet, a physics-informed ML model and a hybrid theory-guided data science approach, for rapid, high-resolution flood mapping. It utilizes a neural network with U-Net architecture and integrates subgrid-based coarse-grid hydrodynamic model predictions as initial estimates, upskilling them to achieve fine-grid model accuracy. Unlike traditional hydrodynamic models, the subgrid method embeds fine-scale topographic details within coarse-grid cells, enhancing both computational efficiency and predictive accuracy. SGUnet processes flood depth raster patches (512 × 512 pixels) and corresponding digital elevation models as inputs. It functions as a deep learning-based corrector, refining flood predictions from numerical simulators. Trained through supervised learning, SGUnet learns to correct deviations in coarse-grid predictions using fine-grid model outputs as target values. The model is evaluated across three large Australian watersheds—Wollombi, Chowilla, and Burnett River—using HEC-RAS flood simulations with subgrid formulation. SGUnet reduces root mean squared error by a factor of 4.5–5.3 compared to coarse-grid models, achieves a critical success index exceeding 0.9 for flood extent mapping, and delivers a 50x speed-up over fine-grid hydrodynamic models. Furthermore, SGUnet outperforms a state-of-the-art ML-based upskilling model in depth and extent predictions. By effectively correcting flood artifacts from coarse-grid models, SGUnet achieves near fine-grid accuracy with significantly reduced computational cost, demonstrating its potential for real-time flood risk assessment.}
}
@article{ALKAABI2025,
title = {Generative AI Implementation and Assessment in Arabic Language Teaching},
journal = {International Journal of Online Pedagogy and Course Design},
volume = {15},
number = {1},
year = {2025},
issn = {2155-6873},
doi = {https://doi.org/10.4018/IJOPCD.368037},
url = {https://www.sciencedirect.com/science/article/pii/S2155687325000057},
author = {Mozah H. Alkaabi and Asma Saeed Almaamari},
keywords = {Arabic Language Teaching, Generative AI, Teaching Assistant, Assessment Methods, Teacher Training, Cultural Sensitivity},
abstract = {ABSTRACT
Artificial intelligence (AI) models struggle to reach performance levels due to the complex nature of Arabic grammar and diverse regional dialects. This study investigated how generative AI (GenAI) functions as a teaching assistant in Arabic language classrooms. Using qualitative methods, semi-structured interviews were conducted with 15 instructors; the data was then analyzed using thematic analysis. Results revealed that instructors used GenAI to create material, assess students’ work, and create personalized learning plans. Instructors struggled, however, with AI accuracy in dialect processing, cultural authenticity, and ensuring accurate assessment methods. The analysis raised significant gaps in teacher training, assessment strategies, and institutional guidelines. Instructors found it challenging to evaluate AI-generated Arabic content across different dialects and maintain academic integrity in student assignments. This study recommends developing instructor training, specifically on using GenAI tools for Arabic dialect variations and creating culturally appropriate Arabic language learning materials.}
}
@article{SHI2026112391,
title = {Jailbreak attack with multimodal virtual scenario hypnosis for vision-language models},
journal = {Pattern Recognition},
volume = {172},
pages = {112391},
year = {2026},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2025.112391},
url = {https://www.sciencedirect.com/science/article/pii/S0031320325010520},
author = {Xiayang Shi and Shangfeng Chen and Gang Zhang and Wei Wei and Yinlin Li and Zhaoxin Fan and Jingjing Liu},
keywords = {Jailbreak, Large vision-language models, Security alignment, Safe AI},
abstract = {Due to the inherent vulnerabilities of large Vision-Language Models (VLMs), security governance has emerged as a critical concern, particularly given the risks posed by noisy and biased training data as well as adversarial attacks, including data poisoning and prompt injection. These perturbations can significantly degrade model performance and introduce multifaceted societal risks. To verify the safe robustness of VLMs and further inspire the design of defensive AI frameworks, we propose Virtual Scenario Hypnosis (VSH), a multimodal prompt injection jailbreak method that embeds malicious queries into prompts through a deceptive narrative framework. This approach strategically distracts the model while compromising its resistance to jailbreak attempts. Our methodology features two key innovations: 1) Targeted adversarial image prompts that transform textual content into visual layouts through optimized typographic designs, circumventing safety alignment mechanisms to elicit harmful responses; and 2) An information veil encrypted In-Context Learning (ICL) method for text prompts that systematically evades safety detection protocols. To streamline evaluation, we employ Large Language Models (LLMs) to facilitate an efficient assessment of jailbreak success rates, supported by a meticulously designed prompt template incorporating multi-dimensional scoring rules and evaluation metrics. Extensive experiments demonstrate the efficacy of VSH, achieving an overall success rate exceeding 82% on 500 harmful queries spanning multiple domains when tested against LLaVA-v1.5-13B and GPT-4o mini.}
}
@article{WEI2024106042,
title = {Grafting semi-wild tomato GZ-05 rootstocks improved cold tolerance via the signalling of melatonin and jasmonic acid},
journal = {Environmental and Experimental Botany},
volume = {228},
pages = {106042},
year = {2024},
issn = {0098-8472},
doi = {https://doi.org/10.1016/j.envexpbot.2024.106042},
url = {https://www.sciencedirect.com/science/article/pii/S0098847224004003},
author = {Jianming Wei and Yunzhou Li and Ping Tan and Dalong Zhang and Yan Liang},
keywords = {Tomato, Grafting, Melatonin, Jasmonic acid, Cold tolerance},
abstract = {Tomato (Solanum lycopersicum) cultivation in the off-season is significantly hindered by cold stress; hence, utilising stress-resistant rootstocks in grafting is a critical solution. This study used 30 semi-wild tomato GZ-05 plants as rootstocks and Ailsa Craig (AC) tomatoes as scions. After cold stress, the scion tolerance index, leaf ion permeability, and other physiological and biological indicators were used to determine the most tolerant plants. To understand the molecular basis of GZ-05 rootstock cold stress resistance, RNA sequencing and reverse transcription polymerase chain reaction techniques were used to compare the varying genes expressed in the grafted AC/GZ-05 and self-grafted AC/AC plant scion leaves. The results indicated that genes associated with melatonin (MT) and jasmonic acid (JA) production and their signalling pathways were considerably altered. The initial MT and JA levels in the GZ-05-grafted plant scions were high, and when they were exposed to cold stress, the amount of active MT and JA in AC/GZ-05 heterologous grafts were great. Using clustered regularly interspaced short palindromic repeats (CRISPR)/CRISPR-associated protein 9, we knocked out the MT synthesis gene (SlCOMT14) and JA synthesis gene (SlLoxD) and found that GZ-05 plant cold stress tolerance decreased. External tests were conducted to evaluate the GZ-05 SlCOMT14 and SlLoxD knockout lines. Source spraying with MT and methyl jasmonate showed that knockout strain cold stress tolerance could be recovered. SlICE1, a tomato cold stress tolerance transcription factor, was silenced, resulting in decreased tolerance to MT- and JA-induced cold stress. The MT/JA-inducer of C-repeat binding factor (CBF) expression 1-CBF pathway may be the mechanism by which the semi-wild tomato GZ-05 rootstock confers cold tolerance to plants. This study has uncovered the molecular mechanism by which grafting semi-wild tomato GZ-05 rootstocks increases plant cold tolerance, thereby laying the groundwork for the utilisation of Guizhou's native semi-wild tomato germplasm resources.}
}
@article{KHALIFA2024100141,
title = {Artificial intelligence for diabetes: Enhancing prevention, diagnosis, and effective management},
journal = {Computer Methods and Programs in Biomedicine Update},
volume = {5},
pages = {100141},
year = {2024},
issn = {2666-9900},
doi = {https://doi.org/10.1016/j.cmpbup.2024.100141},
url = {https://www.sciencedirect.com/science/article/pii/S2666990024000089},
author = {Mohamed Khalifa and Mona Albadawy},
keywords = {Artificial intelligence, Machine learning, Diabetes},
abstract = {Introduction
Diabetes, a major cause of premature mortality and complications, affects millions globally, with its prevalence increasing due to lifestyle factors and aging populations. This systematic review explores the role of Artificial Intelligence (AI) in enhancing the prevention, diagnosis, and management of diabetes, highlighting the potential for personalised and proactive healthcare.
Methods
A structured four-step method was used, including extensive literature searches, specific inclusion and exclusion criteria, data extraction from selected studies focusing on AI's role in diabetes, and thorough analysis to identify specific domains and functions where AI contributes significantly.
Results
Through examining 43 experimental studies, AI has been identified as a transformative force across eight key domains in diabetes care: 1) Diabetes Management and Treatment, 2) Diagnostic and Imaging Technologies, 3) Health Monitoring Systems, 4) Developing Predictive Models, 5) Public Health Interventions, 6) Lifestyle and Dietary Management, 7) Enhancing Clinical Decision-Making, and 8) Patient Engagement and Self-Management. Each domain showcases AI's potential to revolutionize care, from personalizing treatment plans and improving diagnostic accuracy to enhancing patient engagement and predictive healthcare.
Discussion
AI's integration into diabetes care offers personalised, efficient, and proactive solutions. It enhances care accuracy, empowers patients, and provides better understanding of diabetes management. However, the successful implementation of AI requires continued research, data security, interdisciplinary collaboration, and a focus on patient-centered solutions. Education for healthcare professionals and regulatory frameworks are also crucial to address challenges like algorithmic bias and ethics.
Conclusion and Recommendations
AI in diabetes care promises improved health outcomes and quality of life through personalised and proactive healthcare. Future efforts should focus on continued investment, ensuring data security, fostering interdisciplinary collaboration, and prioritizing patient-centered solutions. Regular monitoring and evaluation are essential to adjust strategies and understand long-term impacts, ensuring AI's ethical and effective integration into healthcare.}
}
@article{FOGARTY2024100914,
title = {The big data crossroads: Accounting education and the challenge of 21st century technology},
journal = {Journal of Accounting Education},
volume = {68},
pages = {100914},
year = {2024},
issn = {0748-5751},
doi = {https://doi.org/10.1016/j.jaccedu.2024.100914},
url = {https://www.sciencedirect.com/science/article/pii/S0748575124000307},
author = {Timothy J. Fogarty and Cory Campbell},
keywords = {Big Data analytics, Emerging technology, Higher education, Accounting curricula, Accounting practice},
abstract = {Many believe that accounting education will soon be remade by the possibilities and probabilities of “Big Data” and other emerging technologies. Despite the complexities and challenges of the situation, accounting education must respond to changing demands of business and the accounting profession. This paper discusses the nature of the technological forces acting upon the academy and the economy to chart a course for accounting education. While this includes considerations for larger units of higher education such as the business school, most of the attention of this paper is on the reaction of accounting departments to redesign curricula, redeploy faculty and attend to attracting suitable students. The general message is that we must put our own house in order.}
}
@article{HAN2025117296,
title = {Eutrema japonicum–derived exosome-like nanoparticles as an immunostimulatory nutraceutical candidate with anti-cancer potential},
journal = {Food Research International},
volume = {221},
pages = {117296},
year = {2025},
issn = {0963-9969},
doi = {https://doi.org/10.1016/j.foodres.2025.117296},
url = {https://www.sciencedirect.com/science/article/pii/S0963996925016345},
author = {Jeong Moo Han and Jaeyoon Lim and Hyein Kang and Woo Sik Kim and Bo-Gyeong Yoo and Eui-Hong Byun and Sangyong Lim and Jaehan Kim and Eui-Baek Byun},
keywords = {, Exosome-like nanoparticle, Dendritic cell activation, Anti-cancer nutraceutical, Immunomodulation, Functional foods},
abstract = {Plant-derived exosome-like nanoparticles (ELNs) are promising bioactive carriers with enhanced stability and delivery capacity. This study explores the anti-cancer nutraceutical potential of Eutrema japonicum–derived ELNs (EJ-ELNs) through immune modulation and tumor suppression. EJ-ELNs were isolated using differential ultracentrifugation, tangential flow filtration, and cushioned ultracentrifugation, and characterized by transmission electron microscopy and nanoparticle tracking analysis. The isolated EJ-ELNs demonstrated excellent colloidal stability, maintaining structural integrity under simulated gastrointestinal fluid, enzymatic degradation (DNase, RNase, Proteinase K) and acidic conditions (pH 2), and diverse storage conditions (25 °C, 4 °C, −80 °C, and lyophilization). In vitro, EJ-ELNs promoted dendritic cell (DC) maturation by upregulating surface molecules and enhancing the secretion of Th1-polarizing cytokine, while suppressing antigen uptake via MAPK and NF-κB pathways. These activated DCs facilitated the differentiation of naïve T cells into IFN-γ–producing Th1 cells and promoted the activation of cytotoxic CD8+ T cells. In vivo, oral administration of EJ-ELNs restored DC function and expanded polyfunctional CD4+ and CD8+ T cells co-expressing CD107a, IFN-γ, IL-2, and TNF-α, ultimately leading to significant tumor suppression. Lipidomic and metabolomic profiling identified ceramide, Hex1Cer, naringenin, and genistein as key immunostimulatory constituents. These findings position EJ-ELNs as a novel anti-cancer nutraceutical candidate, offering a promising strategy for immune activation and tumor suppression in functional food applications.}
}
@article{TAPARK2025,
title = {Knowledge, Attitudes, and Behaviors Related to Dementia Prevention and Caregiving Among Korean Americans (the KIMCHI Project): Pre- and Posttest Evaluation Study},
journal = {JMIR Aging},
volume = {8},
year = {2025},
issn = {2561-7605},
doi = {https://doi.org/10.2196/72147},
url = {https://www.sciencedirect.com/science/article/pii/S2561760525001070},
author = {Van {Ta Park} and Bora Nam and Daren Huang and Stacy W Yun and Nicole Phan and Eun Jeong Lee and Hye-Won Shin},
keywords = {Alzheimer disease and related dementias, Korean Americans, knowledge, attitudes, behaviors, caregiving, community-based dissemination},
abstract = {Background
Many Korean American older adults have limited English proficiency, have low socioeconomic status, and are immigrants. The availability and accessibility of linguistic and culturally appropriate dementia-related health care and caregiving resources for this population are limited. This is concerning given that Korean American older adults are a rapidly growing population, and Alzheimer disease and related dementias (ADRD) represent a significant public health issue.
Objective
We aimed to assess changes in pre- and posttest knowledge, attitudes, and behaviors regarding ADRD prevention and caregiving among participants in the Koreans Invested in Making Caregivers’ Health Important (KIMCHI) before and after their participation in KIMCHI workshop presentations.
Methods
A community engagement dissemination project, KIMCHI, was developed by academic and community partners to culturally and linguistically tailor selected evidence-based research from the Patient-Centered Outcomes Research Institute for Korean American older adults, caregivers, and other stakeholders. Dissemination activities were conducted in-person (as workshops) and on digital platforms. Through partnerships with 1 academic institution and 2 community organizations that serve Korean Americans, 211 participants participated in the KIMCHI in-person workshop presentations, and 134 participants participated asynchronously online (via fact sheets on the project website, YouTube videos, and other social media, such as Facebook and X [formerly known as Twitter]). Pre- and postparticipation tests on knowledge, attitudes, and behaviors for ADRD and caregiving were conducted with workshop participants. We administered satisfaction surveys to all participants (workshop and online) and conducted two-tailed paired-sample 2-tailed t tests to assess mean changes in the pre- and postparticipation tests.
Results
Among the workshop participants (N=211), most (114/204, 55.9%) were older adults (mean age 69, SD 12.1 y; range 24-90 y), female (n=148, 70.1%), and foreign-born (n=203, 96.2%). Many reported having limited English proficiency (167/211, 79.1%). Significant changes were observed in posttest ADRD knowledge (mean 11.51, SD 2.64), attitudes (mean 7.13, SD 2.83), and behaviors (mean 8.88, SD 2.72) compared to pretest scores (knowledge: mean 10.34, SD 2.67; t210=1.17; P<.001; attitudes: mean 6.33, SD 2.44; t210=0.8; P<.001; and behaviors: mean 8.11, SD 2.68; t210=0.76; P<.001). Workshop participants reported high satisfaction (196/209, 93.8%) with KIMCHI, with the workshop presentations being perceived as culturally relevant and applicable (196/209, 93.8%). Most workshop participants expressed interest in learning more about ADRD-related health topics (186/209, 89%). Similarly, the online participants (N=134) expressed high satisfaction (115/134, 85.8%) and agreed that the topics and content were culturally relevant and applicable (116/133, 87.2%) and learned new information (110/134, 82.1%).
Conclusions
The findings indicate that KIMCHI may have a positive impact on improving ADRD knowledge, attitudes, and behaviors among Korean Americans. Academic-community collaborations should continue to culturally tailor the programs and studies to help ensure greater representation of Korean Americans in research and community engagement projects.}
}
@article{2023228,
title = {Guide for Authors},
journal = {Intelligent Medicine},
volume = {3},
number = {3},
pages = {228-234},
year = {2023},
issn = {2667-1026},
doi = {https://doi.org/10.1016/S2667-1026(23)00055-4},
url = {https://www.sciencedirect.com/science/article/pii/S2667102623000554}
}
@article{ROSENBERGER2025127043,
title = {CareerBERT: Matching resumes to ESCO jobs in a shared embedding space for generic job recommendations},
journal = {Expert Systems with Applications},
volume = {275},
pages = {127043},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.127043},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425006657},
author = {Julian Rosenberger and Lukas Wolfrum and Sven Weinzierl and Mathias Kraus and Patrick Zschech},
keywords = {Job consultation, Job markets, Job recommendation system, BERT, NLP},
abstract = {The rapidly evolving labor market, driven by technological advancements and economic shifts, presents significant challenges for traditional job matching and consultation services. In response, we introduce an advanced support tool for career counselors and job seekers based on CareerBERT, a novel approach that leverages the power of unstructured textual data sources, such as resumes, to provide more accurate and comprehensive job recommendations. In contrast to previous approaches that primarily focus on job recommendations based on a fixed set of concrete job advertisements, our approach involves the creation of a corpus that combines data from the European Skills, Competences, and Occupations (ESCO) taxonomy and EURopean Employment Services (EURES) job advertisements, ensuring an up-to-date and well-defined representation of general job titles in the labor market. Our two-step evaluation approach, consisting of an application-grounded evaluation using EURES job advertisements and a human-grounded evaluation using real-world resumes and Human Resources (HR) expert feedback, provides a comprehensive assessment of CareerBERT’s performance. Our experimental results demonstrate that CareerBERT outperforms both traditional and state-of-the-art embedding approaches while showing robust effectiveness in human expert evaluations. These results confirm the effectiveness of CareerBERT in supporting career consultants by generating relevant job recommendations based on resumes, ultimately enhancing the efficiency of job consultations and expanding the perspectives of job seekers. This research contributes to the field of NLP and job recommendation systems, offering valuable insights for both researchers and practitioners in the domain of career consulting and job matching.}
}
@article{MENG2025119338,
title = {Machine learning-driven mass transfer modeling and inverse design for nanofiltration membranes},
journal = {Desalination},
volume = {616},
pages = {119338},
year = {2025},
issn = {0011-9164},
doi = {https://doi.org/10.1016/j.desal.2025.119338},
url = {https://www.sciencedirect.com/science/article/pii/S0011916425008148},
author = {Chunchun Meng and Haochen Zhu and Aziz Ghoufi},
keywords = {Nanofiltration membrane, Machine learning, Mass transfer, Micro-nano modeling, Inverse design, Desalination},
abstract = {Nanofiltration-based desalination systems are of great importance as a key technology in the field of water treatment. A central challenge lies in elucidating the multiscale mass transport mechanisms of multicomponent fluids within nanopores. However, traditional micro-nano scale models fail to describe the nonlinear features inherent in non-equilibrium transport processes accurately. By integrating multi-physical feature datasets such as pore size distribution, surface potential, and salt concentration, machine learning (ML) can capture nonlinear correlations between membrane structural parameters and mass transfer kinetics, thereby enhancing the spatiotemporal resolution and computational efficiency of fluid transport process simulations. Meanwhile, this data-driven modeling framework that integrates underlying physical fields allows for optimizing polymer molecular structures based on target properties, thus revolutionizing the design process of membrane materials. Therefore, this review focuses on the construction of ML-accelerated multiscale models for mass transfer based on nanofiltration membranes in the desalination process, including density functional theory (DFT) calculations, molecular dynamics (MD) simulations, and coarse-grained simulations (GCMD and DPD). It also summarizes the “closed-loop” inverse design framework for desalination membrane materials derived from the powerful data-driven capabilities of ML, and analyzes how to inverse derive and optimize the structural parameters and preparation conditions of membrane materials based on target desalination performance requirements. Finally, we discuss the future research directions for ML-assisted NF membrane mass transfer modeling and inverse design, guiding the development of next-generation high-performance intelligent seawater desalination NF membranes.}
}
@article{SHAW20251250,
title = {Engineering biocompatibility and mechanical performance via heat treatment of LPBF-fabricated Ti-6Al-4V for next-generation implants},
journal = {Journal of Manufacturing Processes},
volume = {152},
pages = {1250-1274},
year = {2025},
issn = {1526-6125},
doi = {https://doi.org/10.1016/j.jmapro.2025.08.057},
url = {https://www.sciencedirect.com/science/article/pii/S1526612525009454},
author = {Pratik Kumar Shaw and Suryank Dwivedi and Amit Rai Dixit and Alokesh Pramanik},
keywords = {Laser powder bed fusion, Ti-6Al-4 V, Heat treatment, Surface characteristics, Materials properties, Bio-tribology, Cell viability},
abstract = {This study examined the influence of the different heat treatments on the surface and bulk properties and its comparison with the as-printed Ti-6Al-4V counterpart, fabricated through the laser powder bed fusion (LPBF) technique for biomedical applications. Different heat treatment cycles as a post-processing step were incorporated at 670°C and 950°C to optimize phase stability, relieve residual stresses, and enhance material properties. The surface roughness analyses revealed substantial improvement in the surface properties, such as topography, undulation, and minimal pores, with the 950°C heat treatment cycle. The microstructural characterization demonstrated a transformation from α’ martensite to a lamellar α + β phase, reducing dislocation density and improving mechanical integrity, significantly affecting the microhardness and tensile strength with improved biological compatibility. The HT950 samples exhibited a 15% increase in hardness, while HT670 samples showed a 10% decrease compared to untreated samples. Wettability analysis revealed that HT950 samples achieved the highest SFE of 64.8 mN/m with a contact angle of 31.3°, demonstrating superior hydrophilicity along the build direction. Further, bio-tribological assessments highlighted superior wear resistance and reduced friction coefficients in heat-treated samples, particularly under the 950°C condition, attributed to a direct correlation with hardness and refined phase distribution. Biological evaluations using cell culture assays confirmed improved cell viability and adhesion in heat-treated specimens, exhibiting optimal biocompatibility for the 950°C treated sample. The findings underscore the critical role of heat treatment in tailoring the microstructural, mechanical, bio-tribological, and biological attributes of LPBF-produced Ti-6Al-4V for orthopedic implants. This research advances the understanding of post-processing strategies for enhanced durability and biocompatibility in biomedical implants.}
}
@article{KORUCUKIS2024101639,
title = {Zone of proximal creativity: An empirical study on EFL teachers’ use of ChatGPT for enhanced practice},
journal = {Thinking Skills and Creativity},
volume = {54},
pages = {101639},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101639},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124001779},
author = {Saadet Korucu-Kış},
keywords = {Creativity, Artificial Intelligence, ChatGPT, Teachers, EFL},
abstract = {Enhancing creativity among educators has emerged as a crucial aspect of contemporary education. The emergence of artificial intelligence (AI) chatbots such as ChatGPT, renowned for its advanced language generation capabilities and interactive conversational interface, presents a promising opportunity to support teachers in their creativity pursuits. While interest in ChatGPT for educational applications is rising, there is a lack of empirical research exploring its effectiveness in fostering teacher creativity. Therefore, this timely study aims to fill this gap by investigating the efficacy of ChatGPT in facilitating creativity, particularly among English as a foreign (EFL) teachers. A total of twenty-nine teachers enrolled in a post-graduate program participated in the study. Conducting an inductive content analysis, teachers’ ChatGPT inquiry threads, lesson plans, written reflections, and responses to an open-ended survey were analysed. The analysis revealed that ChatGPT enabled teachers to (a) seek for novel perspectives, (b) explore multiple ideas, (c) expand on ideas, (d) change perspectives, (e) refer for information, (f) inquire about teaching tools, and (g) ask for information. Two challenges were also identified: (a) the need for precise input and (b) repetitive content. Building on these findings, a conceptual model is proposed that frames ChatGPT as a tool for creative ideation and a knowledge resource, facilitating EFL teachers' progression towards their Zone of Proximal Creativity, with its effectiveness contingent on the teacher's existing expertise.}
}
@article{CHOU2025123019,
title = {Future prediction on the remaining useful life of proton exchange membrane fuel using temporal fusion transformer model},
journal = {Renewable Energy},
volume = {247},
pages = {123019},
year = {2025},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2025.123019},
url = {https://www.sciencedirect.com/science/article/pii/S0960148125006810},
author = {Jia-Hong Chou and Fu-Kwun Wang},
keywords = {Proton exchange membrane fuel cell, Remaining useful life, Temporal fusion transformer, Future prediction},
abstract = {Proton exchange membrane fuel cell (PEMFC) is regarded as one of the leading developmental directions of the green power source. Predicting the remaining useful life (RUL) of online PEMFCs is challenging, primarily due to factors such as complex nonlinear degradation patterns and unknown data. To enhance the performance of RUL prediction, we present a deep learning model-based temporal fusion transformer model to predict the future total voltage of a PEMFC stack. The performance of RUL predictions was evaluated using different starting RUL prediction points to compare them with the existing study. The experiments are conducted with different future prediction steps for future RUL prediction to determine the model's prediction step limit. The proposed method achieved relative errors of 0.0148 %, 0.0060 %, 0.0662 %, and 0.0486 % for training lengths 300, 400, 500, and 600, respectively, in the FC1 and 0.0326 % in the FC2 datasets compared to the existing study scenarios. The experimental analysis resulted in relative errors of 0.0738 % for the FC1 dataset, 1.0239 % and 1.6512 % for the two FC2 dataset scenarios.}
}
@article{VONGVISITSIN2025104996,
title = {Technology start-ups in tourism and hospitality: A networked social capital theory perspective from early-stage start-up founders},
journal = {Tourism Management},
volume = {106},
pages = {104996},
year = {2025},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2024.104996},
url = {https://www.sciencedirect.com/science/article/pii/S0261517724001158},
author = {Thanakarn Bella Vongvisitsin and Vincent Wing Sun Tung},
keywords = {Early-stage start-up, Entrepreneurship, Founder, Hospitality innovation, Social capital, Technology start-up, Tourism technology, Web3},
abstract = {Technology start-up entrepreneurship serves as the backbone of innovations within the tourism and hospitality industry. However, there is a lack of comprehensive research investigating the perspectives of founders who are the original innovators. Via social capital theory, this study aims to explore the entrepreneurial processes of founders during the critical early stages, determining the survival of technology start-ups. The research adopts a qualitative in-depth interviewing approach with seventeen early-stage tourism and hospitality start-up founders in Hong Kong and Thailand. By employing abductive thematic analysis, the study develops a novel conceptualization of the networked social capital, comprising four interconnected themes: team building, fundraising and resource acquisition, collaboration and partnerships, and credibility building. Also, the study highlights the evolving social dynamics among start-up ecosystem actors influenced by cutting-edge technologies. This study contributes to the tourism and hospitality literature and offers practical implications for start-up entrepreneurs, public policymakers, and tourism and hospitality firms.}
}
@article{AZADI2025122816,
title = {The influence of alkali and alkaline earth substitution on the reduction of Fe2O3[001] by H2 – a DFT study},
journal = {Surface Science},
volume = {761},
pages = {122816},
year = {2025},
issn = {0039-6028},
doi = {https://doi.org/10.1016/j.susc.2025.122816},
url = {https://www.sciencedirect.com/science/article/pii/S0039602825001232},
author = {Saeid Khesali Azadi and Matti Alatalo and Marko Huttula and Timo Fabritius and Samuli Urpelainen},
keywords = {FeO oxygen carrier, Density functional theory, Alkali and alkaline earth substitutions, H adsorption, Reaction mechanism},
abstract = {The reactivity of Fe2O3 oxygen carriers (OCs) in the presence of alkali and alkaline earth metal substitutions was investigated using density functional theory (DFT) to enhance their reduction behavior. Our calculations reveal that these substitutions preferentially occupy surface sites on Fe2O3[001], rather than the bulk. Compared to alkaline earth metals, the surface oxygen vacancy formation energy (Evac), a measure of reducibility, is substantially lower near alkali substitutions, indicating more oxygen release. Additionally, we investigated H2 oxidation and adsorption on pure and Na-substituted Fe2O3[001] surfaces that have an oxygen vacancy. Adsorption energies demonstrate that H2 preferentially dissociates on O top and hollow sites rather than on Fe-related sites. The oxidation of H2 is both thermodynamically and kinetically more advantageous on O sites, resulting in the production of H2O via either direct adsorption or H atom migration pathways. Conversely, Fe sites demonstrate elevated steric hindrances and reduced reactivity. Finally, oxygen migration from the bulk to the surface was identified as a mechanism driven by high temperatures, which may influence oxygen availability during cycling. These findings offer essential understanding of the impact of substitutions on the redox behavior of Fe2O3 OCs, relevant to applications in chemical looping and sustainable hydrogen consumption.}
}
@article{WOSNY2024,
title = {Practical Recommendations for Navigating Digital Tools in Hospitals: Qualitative Interview Study},
journal = {JMIR Medical Education},
volume = {10},
year = {2024},
issn = {2369-3762},
doi = {https://doi.org/10.2196/60031},
url = {https://www.sciencedirect.com/science/article/pii/S2369376224001429},
author = {Marie Wosny and Livia Maria Strasser and Simone Kraehenmann and Janna Hastings},
keywords = {health care, hospital, information system, information technology, technology implementation, training, medical education, digital literacy, curriculum development, health care workforce development, mobile phone},
abstract = {Background
The digitalization of health care organizations is an integral part of a clinician’s daily life, making it vital for health care professionals (HCPs) to understand and effectively use digital tools in hospital settings. However, clinicians often express a lack of preparedness for their digital work environments. Particularly, new clinical end users, encompassing medical and nursing students, seasoned professionals transitioning to new health care environments, and experienced practitioners encountering new health care technologies, face critically intense learning periods, often with a lack of adequate time for learning digital tools, resulting in difficulties in integrating and adopting these digital tools into clinical practice.
Objective
This study aims to comprehensively collect advice from experienced HCPs in Switzerland to guide new clinical end users on how to initiate their engagement with health ITs within hospital settings.
Methods
We conducted qualitative interviews with 52 HCPs across Switzerland, representing 24 medical specialties from 14 hospitals. The interviews were transcribed verbatim and analyzed through inductive thematic analysis. Codes were developed iteratively, and themes and aggregated dimensions were refined through collaborative discussions.
Results
Ten themes emerged from the interview data, namely (1) digital tool understanding, (2) peer-based learning strategies, (3) experimental learning approaches, (4) knowledge exchange and support, (5) training approaches, (6) proactive innovation, (7) an adaptive technology mindset, (8) critical thinking approaches, (9) dealing with emotions, and (10) empathy and human factors. Consequently, we devised 10 recommendations with specific advice to new clinical end users on how to approach new health care technologies, encompassing the following: take time to get to know and understand the tools you are working with; proactively ask experienced colleagues; simply try it out and practice; know where to get help and information; take sufficient training; embrace curiosity and pursue innovation; maintain an open and adaptable mindset; keep thinking critically and use your knowledge base; overcome your fears, and never lose the human and patient focus.
Conclusions
Our study emphasized the importance of comprehensive training and learning approaches for health care technologies based on the advice and recommendations of experienced HCPs based in Swiss hospitals. Moreover, these recommendations have implications for medical educators and clinical instructors, providing advice on effective methods to instruct and support new end users, enabling them to use novel technologies proficiently. Therefore, we advocate for new clinical end users, health care institutions and clinical instructors, academic institutions and medical educators, and regulatory bodies to prioritize effective training and cultivating technological readiness to optimize IT use in health care.}
}
@article{FASANO2025101911,
title = {Exploring the impact of AI on Web3 decentralized platform business model innovation},
journal = {Journal of Engineering and Technology Management},
volume = {78},
pages = {101911},
year = {2025},
issn = {0923-4748},
doi = {https://doi.org/10.1016/j.jengtecman.2025.101911},
url = {https://www.sciencedirect.com/science/article/pii/S0923474825000529},
author = {Francesco Fasano and Chiara Bartoli and Francesco Cappa and Paolo Boccardelli},
keywords = {Artificial Intelligence, Platform, Decentralized, Blockchain, Business model, Innovation, Web3},
abstract = {Advancements in information technologies have revolutionized business models (BMs), which are now increasingly based on digital platforms. The spread of Web3 has led to further development in this direction, giving rise to platform business models enabled by blockchain technology. At the same time, the advent of artificial intelligence (AI) has further expanded opportunities to innovate BMs. In this study we examine how the integration of AI influences BMs in blockchain-based platforms. We find that the integration of AI plays a key role in the three main dimensions of platform business models: value creation, value delivery, and value capture. We demonstrate, in particular, how AI enhances operational efficiency, strategic governance, and decision-making in Web3 platforms enabled by blockchains. Moreover, AI optimizes personalization, matching processes, and interactions in decentralized platforms. AI also fosters innovation in decentralized platform BMs and requires a skilled workforce. This research underscores how AI can improve performance in blockchain-based platforms, advancing scientific knowledge of decentralized platforms and offering recommendations for managers and policymakers on how to innovate their BMs and leverage AI to maximize value across platforms.}
}
@article{YAN2025,
title = {A Systematic Review of AI Ethics in Education:},
journal = {Journal of Global Information Management},
volume = {33},
number = {1},
year = {2025},
issn = {1062-7375},
doi = {https://doi.org/10.4018/JGIM.386381},
url = {https://www.sciencedirect.com/science/article/pii/S1062737525000654},
author = {Yuyang Yan and Hui Liu and Toby Chau},
keywords = {AI Ethics, AIED, Systematic Review, Ethical Governance, Stakeholder Framework},
abstract = {ABSTRACT
As AI becomes more embedded in education, urgent ethical concerns—bias, privacy, transparency—demand scholarly attention. This systematic review examines 34 peer-reviewed studies on AI ethics in education (2020–2024), using the PRISMA framework and a multi-dimensional coding scheme. It identifies stakeholder-specific ethical tensions and highlights gaps in empirical validation, geographic diversity, and policy implementation. Findings cluster into four solution domains: AIED Ethical Frameworks, Ethical Assessment Frameworks, AIED Literacy Frameworks, and Literacy Assessment Frameworks. These are mapped against stakeholder groups and educational levels to expose misalignments and oversights. Visual tools—frequency summaries and a stakeholder–tension Sankey diagram—deepen the analysis. This study offers a structured typology and actionable, context-sensitive recommendations to support equitable and responsible AI integration across K–12 and higher education settings.}
}
@article{KLIMAS2025102819,
title = {Decoding coopetition performance using impactful coopetition attributes: Evidence from manufacturing companies},
journal = {Technology in Society},
volume = {81},
pages = {102819},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.102819},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25000090},
author = {Patrycja Klimas and Arkadiusz Kawa and Karina Sachpazidu and Sylwia Stańczyk and Katharina Brenk and Dominik K. Kanbach},
keywords = {Coopetition, Coopetition success, Coopetition performance, Coopetition attributes, CB-SEM, Large-scale survey, Manufacturing companies},
abstract = {The concept of coopetition - simultaneous collaboration and competition between organizations to achieve mutually beneficial outcomes - plays a pivotal role in shaping business performance, particularly during periods of rapid technological advancements. This is especially evident the manufacturing sector, where innovation and competitive dynamics intersect with economic and social forces. The current academic discourse predominantly focuses on the qualitative identification and analysis of coopetition attributes, leaving a significant gap for large-scale quantitative studies to enable empirical assessment. This study aims to examine the significance of three groups of coopetition attributes for coopetition performance classified into two strategic (dynamics, paradoxicality), six relational (asymmetry, complexity, coopetition intensity, mutual dependence, strength, tensions), and five behavioral attributes (competition intensity, conflict, formality, investments, trust). Using data from 1216 manufacturing firms in Poland and employing a generalized Covariance based Structural Equation Model (CB-SEM), this study offers nuanced insights to the global discourse at the intersection of technological change and social dynamics. The results indicate that the strategic attribute paradoxicality, the relational attribute strength, and most of the behavioral attributes (trust, competition intensity, investments, formality) positively impact coopetition performance. Additionally, a significant negative impact of the strategic attribute dynamics was demonstrated, while no significant influence was identified for the remaining relational attributes (asymmetry, tensions) as well as the behavioral attribute conflict. Diverging from prior qualitative approaches, this study offers data-driven insights for decision-makers navigating societal and technological change, highlighting which attributes should be stimulated to enhance coopetition performance while minimizing the level of dynamics within coopetition strategies.}
}
@article{LIU2024102248,
title = {Internal control opinion shopping: Does initial audit fee discounting matter?},
journal = {Research in International Business and Finance},
volume = {69},
pages = {102248},
year = {2024},
issn = {0275-5319},
doi = {https://doi.org/10.1016/j.ribaf.2024.102248},
url = {https://www.sciencedirect.com/science/article/pii/S0275531924000400},
author = {Wu-Po Liu and Hua-Wei Huang},
keywords = {Audit fee discounting, Initial audit engagement, Opinion shopping, Internal control weakness, Resignation and dismissal, Audit market competition},
abstract = {Both regulators and researchers are concerned that the lowballing of initial year audit fees may impair auditor independence (U.S. Senate 1977, 2002; American Institute of Certified Public Accountants (AICPA), 1978; Securities and Exchange Commission [SEC], 2000; Huang et al. 2015). Using a full sample of 1373 U.S. firm-year observations for which the client’s predecessor auditor reports an adverse SOX Section 404 internal control opinion, we find that in the following year a successor auditor who lowballs audit fees is more likely to issue a clean internal control opinion. The results hold when the predecessor auditors are dismissed, but not when the predecessors resign. We also find that firms are no more likely to succeed in opinion shopping when the proportion of audit committee financial experts is high. In addition, we find internal control opinion shopping occurs with initial fee discounting only in competitive audit markets and the period of a few years following the adoption of SOX (since 2007).}
}
@article{PYRKOV2023103675,
title = {Quantum computing for near-term applications in generative chemistry and drug discovery},
journal = {Drug Discovery Today},
volume = {28},
number = {8},
pages = {103675},
year = {2023},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2023.103675},
url = {https://www.sciencedirect.com/science/article/pii/S1359644623001915},
author = {Alexey Pyrkov and Alex Aliper and Dmitry Bezrukov and Yen-Chu Lin and Daniil Polykovskiy and Petrina Kamya and Feng Ren and Alex Zhavoronkov},
keywords = {generative chemistry, Quantum computing, quantum machine learning, quantum chemistry, artificial intelligence for drug discovery, noisy intermediate-scale quantum (NISQ) devices,  generation of small molecules},
abstract = {In recent years, drug discovery and life sciences have been revolutionized with machine learning and artificial intelligence (AI) methods. Quantum computing is touted to be the next most significant leap in technology; one of the main early practical applications for quantum computing solutions is predicted to be in quantum chemistry simulations. Here, we review the near-term applications of quantum computing and their advantages for generative chemistry and highlight the challenges that can be addressed with noisy intermediate-scale quantum (NISQ) devices. We also discuss the possible integration of generative systems running on quantum computers into established generative AI platforms.}
}
@article{RANA2024103064,
title = {Assessing the nexus of Generative AI adoption, ethical considerations and organizational performance},
journal = {Technovation},
volume = {135},
pages = {103064},
year = {2024},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2024.103064},
url = {https://www.sciencedirect.com/science/article/pii/S0166497224001147},
author = {Nripendra P. Rana and Rajasshrie Pillai and Brijesh Sivathanu and Nishtha Malik},
keywords = {Institutional theory, AI ethics, Generative AI, Organizational innovativeness, Organizational performance},
abstract = {Numerous enterprises employ Generative AI (GenAI) for a plethora of business operations, which can enhance organizational effectiveness. The adoption might be driven by multiple factors influencing the business landscape. Additionally, numerous ethical considerations could impact the deployment of GenAI. This unique study investigated how organizations adopt GenAI and its effects on their performance. Further, this research utilized institutional theory and ethical guidelines for AI design to develop a research framework examining how organizations adopt GenAI and its impact on their performance. A survey of 384 managers from information technology (IT) and information technology-enabled services (ITeS) companies was conducted. Data analysis was done using PLS-SEM to examine and validate the proposed model. The study outcome reveals that institutional pressures, i.e., coercive, normative and mimetic forces, influence the use of GenAI in organizations. It was also found that fairness, accountability, transparency, accuracy and autonomy influence the use of GenAI. Also, the results divulge that the use of GenAI influences organizational performance and is moderated by organizational innovativeness. This study provides insights to developers of GenAI, senior management of companies, the government and IT policymakers by highlighting the institutional pressures and ethical principles influencing the use of GenAI.}
}
@article{CISNEROSPINEDA2025179148,
title = {Demographic changes will shape planetary biodiversity},
journal = {Science of The Total Environment},
volume = {974},
pages = {179148},
year = {2025},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2025.179148},
url = {https://www.sciencedirect.com/science/article/pii/S0048969725007831},
author = {Alfredo Cisneros-Pineda and Abhishek Chaudhary and Uris L.C. Baldos and Yolanda Sung and Thomas Hertel},
keywords = {Biodiversity footprints, Demography, Countryside species-area relationship, GTAP-AEZ, Global trade, Land-use change, Consumption-based accounting, Forecast, Uncertainty},
abstract = {Recent studies have highlighted how future population growth in combination with other contemporaneous global drivers can degrade natural capital and the associated ecosystem services whereas policies that invest in nature can yield benefits for multiple economic and environmental variables. However, studies have yet to highlight and isolate the consequences of changing demographic dynamics in different world regions on global patterns of biodiversity. To fill this research gap, we link a computational general equilibrium economic model (GTAP-AEZ) with biodiversity characterization factors representing potential species loss per unit area due to human land-uses in different world regions for mammals, birds, amphibians, reptiles, and plants combined. This allows us to project the impact on species loss of a business-as-usual global economic scenario between 2021 and 2041, driven by changes in population, GDP, capital stock, labor force, and productivity growth. Second, we focus on demographic change as a sole driver of biodiversity loss and contrast the impacts of historical population growth (2001−2021) with those of future demographic trends (2021–2041) using the same biodiversity metric and economic model. Third, we analyze how the biodiversity projections are affected by the underlying uncertainty in 2041 population based on the United Nations Probabilistic Population Projections. Finally, we also identify those economic sectors and the three major market mechanisms driving the land-use change that explains biodiversity loss in each region. These are: domestic substitution of imports; direct increase in trade to satisfy the increased population abroad; and indirect increase in trade through third markets. The findings highlight how slowing population growth in the wealthiest countries will benefit biodiversity in some parts of the world, while continued strong population growth in Africa will lead to more rapid biodiversity loss in other regions. Our results provide insights into the global hotspots, drivers, and linkages that can be useful to diverse stakeholders (businesses, governments, and conservationists) for making progress towards the achievement of the global biodiversity targets and the UN Sustainable Development Goal 15 (Life on Land).}
}
@article{FU2025108692,
title = {Peer effect matters for the adoption of new energy vehicles: Evidence from consumer sentiment analysis using Chat-GPT},
journal = {Energy Economics},
volume = {148},
pages = {108692},
year = {2025},
issn = {0140-9883},
doi = {https://doi.org/10.1016/j.eneco.2025.108692},
url = {https://www.sciencedirect.com/science/article/pii/S0140988325005195},
author = {Tong Fu and Shuyi Yu and Shiyu Tan},
keywords = {Technological uncertainty, New energy vehicles, Peer effect, Chat-GPT},
abstract = {Although it is widely believed that reducing technological uncertainty can promote the adoption of new technologies, the mechanisms through which consumers perceive such reductions—and how these perceptions influence adoption decisions—remain underexplored. Utilizing Chat-GPT for sentiment analysis of online consumer reviews and treating consumer sentiment as a key measure of the peer effect, this study investigates the role of peer effects in mediating the causal relationship between technology uncertainty and the adoption of new energy vehicles (NEVs). The findings indicate that reducing technological uncertainty enhances both online word-of-mouth (active peer effects) and government procurement (passive peer effects), both of which facilitate greater NEVs adoption. Additionally, moderation effect analyses suggest that social trust amplifies the negative impact of technological uncertainty on NEV consumption intensity, thereby indirectly validating the role of peer effects in fostering NEV adoption. Ultimately, this research underscores that, even without government fiscal subsidies, peer effects can serve as a vital self-reinforcing mechanism in adopting green technologies.}
}
@article{ZHOU202414702,
title = {Targeting Solvent-Front Mutations for Kinase Drug Discovery: From Structural Basis to Design Strategies},
journal = {Journal of Medicinal Chemistry},
volume = {67},
number = {17},
pages = {14702-14722},
year = {2024},
issn = {1520-4804},
doi = {https://doi.org/10.1021/acs.jmedchem.4c00361},
url = {https://www.sciencedirect.com/science/article/pii/S1520480424007932},
author = {Yang Zhou and Jibo Kang and Xiaoyun Lu},
abstract = {Solvent-front mutations have emerged as a common mechanism leading to acquired resistance to kinase inhibitors, representing a major challenge in the clinic. Several new-generation kinase inhibitors targeting solvent-front mutations have either been approved or advanced to clinical trials. However, there remains a need to discover effective, new-generation inhibitors. In this Perspective, we systematically summarize the general types of solvent-front mutations across the kinome and describe the development of inhibitors targeting some key solvent-front mutations. Additionally, we highlight the challenges and opportunities for the next generation of kinase inhibitors directed toward overcoming solvent-front mutations.
}
}
@article{HU2024104010,
title = {Knowledge-prompted ChatGPT: Enhancing drug trafficking detection on social media},
journal = {Information & Management},
volume = {61},
number = {6},
pages = {104010},
year = {2024},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2024.104010},
url = {https://www.sciencedirect.com/science/article/pii/S0378720624000922},
author = {Chuanbo Hu and Bin Liu and Xin Li and Yanfang Ye and Minglei Yin},
keywords = {Large language models, ChatGPT, Prompt engineering, Drug trafficking, Social media},
abstract = {Social media platforms such as Instagram and Twitter have emerged as critical channels for marketing and selling illegal drugs. Detecting and labeling online illicit drug trafficking activities have become an important measure to combat online drug trafficking. Recently, machine learning has been applied to drug trafficking detection. However, the effectiveness of conventional supervised learning methods in detecting drug trafficking heavily relies on access to substantial amounts of labeled data, while data annotation is time-consuming and resource-intensive. Furthermore, these models often face challenges in accurately identifying trafficking activities when drug dealers use deceptive language and euphemisms to avoid detection. To overcome this limitation, we conduct the first systematic study on leveraging large language models (LLMs), such as ChatGPT, to detect illicit drug trafficking activities on social media. We propose an analytical framework to compose knowledge-informed prompts, which serve as the interface that humans can interact with and use LLMs to perform the detection task. Additionally, we designed a Monte Carlo dropout-based prompt optimization method to further improve performance and interpretability. Our experimental findings demonstrate that the proposed framework outperforms other baseline language models in terms of drug trafficking detection accuracy, showing a remarkable improvement of nearly 12%. By integrating prior knowledge and the proposed prompts, ChatGPT can effectively identify and label drug trafficking activities on social networks, even in the presence of deceptive language and euphemisms used by drug dealers to evade detection. The implications of our research extend to social networks, emphasizing the importance of incorporating prior knowledge and scenario-based prompts into analytical tools to improve online security and public safety.}
}
@article{LIN2025,
title = {Writing Is Coding:},
journal = {International Journal of Online Pedagogy and Course Design},
volume = {15},
number = {1},
year = {2025},
issn = {2155-6873},
doi = {https://doi.org/10.4018/IJOPCD.385016},
url = {https://www.sciencedirect.com/science/article/pii/S2155687325000082},
author = {Hao-Chiang Koong Lin},
keywords = {AI Co-Creation, Writing is Coding, Multimodal Learning, Prompt Engineering, Digital Literacy, Generative AI, Educational Technology},
abstract = {ABSTRACT
Writing in the digital age has transformed from a mere communicative practice into a computational interface for multimodal creation—establishing a new paradigm where natural language functions as executable code for artificial intelligence systems. This research examines the pedagogical implications of this “Writing is Coding” framework, focusing on how learners navigate cross-media AI co-creation processes. Through a comprehensive three-round experiment, 102 undergraduate students engaged in progressive AI collaboration across textual, visual, and video modalities, using natural language as their primary creative instrument. Employing grounded theory methodology, the researchers analyzed data from student reflection journals, teacher observation logs, and semi-structured interviews to identify emergent patterns in AI-human creative partnerships. Five interconnected themes emerged: (1) prompt engineering as algorithmic thinking, (2) multimodal literacy development, (3) collaborative negotiation of creative agency, (4) emotional engagement through iterative refinement, and (5) metacognitive awareness of human-AI boundaries. Findings suggest that the “Writing is Coding” framework facilitates a deeper understanding of computational processes while enhancing creative expression. The three-round progression demonstrated increasing student comfort with AI collaboration, though tensions around authorship and creative identity persisted. This research contributes to emerging pedagogical approaches that position writing as a form of programming in AI-enhanced learning environments, with implications for curriculum design and digital literacy development.}
}
@article{CHEN2024676,
title = {Artificial intelligence applications implication for ESG performance: can digital transformation of enterprises promote sustainable development?},
journal = {Chinese Management Studies},
volume = {19},
number = {3},
pages = {676-701},
year = {2024},
issn = {1750-614X},
doi = {https://doi.org/10.1108/CMS-11-2023-0653},
url = {https://www.sciencedirect.com/science/article/pii/S1750614X24000089},
author = {Rongxin Chen and Tianxing Zhang},
keywords = {AI, Enterprise compliance, ESG performance, Internal control, Information environment},
abstract = {Purpose
In the global context, artificial intelligence (AI) technology and environmental, social and governance (ESG) have emerged as central drivers facilitating corporate transformation and the business model revolution. This paper aims to investigate whether and how the application of AI enhances the ESG performance of enterprises.
Design/methodology/approach
This study uses panel data from Chinese A-share listed companies spanning the period from 2012 to 2022. Through a multivariate regression analysis, it examines the impact of AI on the ESG performance of enterprises.
Findings
The findings suggest that the application of AI in enterprises has a positive impact on ESG performance. Internal control systems within the organization and external information environments act as mediators in the relationship between AI and corporate ESG performance. Furthermore, corporate compliance plays a moderating role in the connection between AI and corporate ESG performance.
Originality/value
This paper underscores the pivotal role played by AI in enhancing corporate ESG performance. It explores the pathways to improving corporate ESG behavior from the perspectives of internal control and information environments. This discussion holds significant implications for advancing the application of AI in enterprises and enhancing their sustainable governance capabilities.}
}
@article{JEONG2025127067,
title = {A correlation for onset of significant void (OSV) in forced convective subcooled flow boiling},
journal = {International Journal of Heat and Mass Transfer},
volume = {246},
pages = {127067},
year = {2025},
issn = {0017-9310},
doi = {https://doi.org/10.1016/j.ijheatmasstransfer.2025.127067},
url = {https://www.sciencedirect.com/science/article/pii/S0017931025004089},
author = {Hyeon-won Jeong and Ohyoung Kim and W. Jaewoo Shim},
keywords = {Boiling heat transfer, Forced convective flow boiling, Flow instability, Onset of significant void (OSV), Subcooled flow boiling, Net vapor generation (NVG), Weber number, Laplace length scale},
abstract = {The aim of this research was to propose a new correlation for the onset of significant void (OSV) using a verified database encompassing a broad spectrum of experimental conditions. These conditions included variables such as pressure, inlet subcooling, diameter, length, flow channel, heat flux, and mass flux. The database also accounted for the use of six different coolants (R-113, R-114, R-12, R-22, water, and heavy water) and flow in five distinct heated flow channels (round tube, two types of annular tubes, and two types of rectangular channels). The applicable range of the database is as follows: hydraulic diameter (0.00240–0.0240 m), pressure (1.00–158.00 bar), mass flux (27.50–7500.00 kg/m2s), and heat flux (0.006–8.520 MW/m2). Previous studies have largely focused on acquiring the void fraction distribution, with limited attention given to OSV calculations. To address this gap, we established a database that integrated 206 OSV data points calculated using graphical methods from 402 previously published void fraction distribution datasets. This was further supplemented with 246 verified OSV data points obtained from published literature, resulting in a comprehensive database of 452 OSV data points. Utilizing this database, we developed a new OSV correlation that introduces a novel criterion for flow boiling regions, based on Weber number of 10. This number delineates between a 'surface tension dominated flow region' and an 'inertia dominated flow region.' The new correlation outperformed nine other published correlations in terms of OSV prediction, exhibiting a mean error (ME) of 0.25 % and a root mean square error (RMSE) of 27.56 %.}
}
@article{LI2024149044,
title = {Selective hydrogenation of furfural to tetrahydrofurfuryl alcohol in isopropanol over hydrotalcite-derived nickel-based catalyst},
journal = {Chemical Engineering Journal},
volume = {482},
pages = {149044},
year = {2024},
issn = {1385-8947},
doi = {https://doi.org/10.1016/j.cej.2024.149044},
url = {https://www.sciencedirect.com/science/article/pii/S1385894724005291},
author = {Zheng Li and Huiru Yang and Shanshan Feng and Qianxin Sun and Ge Gao and Zhicheng Jiang and Changwei Hu},
keywords = {Furfural, Tetrahydrofurfuryl alcohol, Hydrogenation, Isopropanol, Hydrotalcite-derived, Nickle-based catalyst},
abstract = {A series of hydrotalcite-derived nickel-based catalysts were synthesized by coprecipitation, drying, calcination and reduction, and used for the selective hydrogenation of furfural to tetrahydrofurfuryl alcohol. Ni1Zr1Al2-R, with specific surface area (SBET) of 145.6 m2, narrow pore size distribution of 7.1 nm, and small Ni0 particle size of 7.31 nm, showed 100 % furfural conversion and 94.5 % tetrahydrofurfuryl alcohol selectivity under mild conditions (140 °C, 2 h). It was found that furfural was first hydrogenated to furfuryl alcohol, which was further hydrogenated to tetrahydrofurfuryl alcohol. XRD and TEM showed that Ni0 (111) plane played an important role on the catalytic hydrogenation process. Al increased the specific surface area (SBET) and total acid sites of the catalyst, providing more possibilities for the catalyst to contact the substrate. The introduction of Zr improved the ratio of medium acid sites and decreased the size of metal nickel particles, improving the resistance to carbon deposition and allowing the structure and catalytic performance to remain stable after five recycles.}
}
@article{CUI2025105163,
title = {Reconsidering teacher assessment literacy in GenAI-enhanced environments: A scoping review},
journal = {Teaching and Teacher Education},
volume = {165},
pages = {105163},
year = {2025},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2025.105163},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X25002409},
author = {Yu Cui and Yaru Meng and Lingjie Tang},
keywords = {Teacher assessment literacy, Generative AI, Scoping review, Digital assessment, AI in education, Assessment in education},
abstract = {Generative AI (GenAI) in educational assessment is an emerging field where the necessary competencies teachers need yet to be fully defined. This scoping review analyzes 70 papers to explore themes related to teacher assessment literacy (AL) in GenAI-enhanced environments (TALiGAI). The study identifies key competencies, including knowledge, cognition, emotion, and contextual factors, which are essential for integrating GenAI into assessment practices. It highlights the challenges and opportunities associated with GenAI, emphasizing the need for targeted professional development for teachers. The findings also provide insights into the necessary competencies and inform policy-making to support the effective use of GenAI in educational assessments.}
}
@article{GUAN2025105362,
title = {When and how learners engage with source information in digital multiple-text reading: Effects of task instruction and text trustworthiness from eye-tracking technology},
journal = {Computers & Education},
volume = {236},
pages = {105362},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105362},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525001307},
author = {Zheng-Hong Guan and Sunny S.J. Lin},
keywords = {21st-century abilities, Improving classroom teaching, Information literacy, Post-secondary education, Teaching/learning strategies},
abstract = {Digital reading with multiple-text comprehension is essential in daily life, especially with the rise of AI-generated contents, making source evaluation crucial for authenticity of online information, particularly in academic contexts. Despite its importance, there is limited moment-to-moment evidence on reading processes in multiple-text use. To bridge this gap, we used eye-tracking technology to see how task instructions affect reading multiple texts with high and low trustworthiness. The transitions among texts and source information, as well as how much attention the readers paid are particularly of concern. Sixty-one college students were randomly divided into summary and argument groups, tasked with writing a summary or an argument, respectively. Both groups read four texts presenting conflicting views on genetically modified technology. Each text featured high or low trustworthiness and included three paragraphs: source, evidence, and conclusion. Results of eye-movement data showed both groups spent more time rereading high-trustworthiness texts and evidence paragraphs. The summary group notably reread more on source information, made more transitions between source and evidence, and accessed texts more times than the argument group. In essay writing, the summary group showed better integration by using more source citations and connectives and referring to more concepts, compared to the argument group. Mediation analysis revealed that the process data of rereading time and number of click times successfully mediated the relationship between task instructions and multiple-text integration, confirming that the summary group engaged deeply. These findings offer both theoretical contributions and practical implications for developing adaptive, personalized digital reading environments.}
}
@article{DELKE2025101077,
title = {Experimental game-based learning: A serious game experiment in purchasing and supply management},
journal = {Journal of Purchasing and Supply Management},
pages = {101077},
year = {2025},
issn = {1478-4092},
doi = {https://doi.org/10.1016/j.pursup.2025.101077},
url = {https://www.sciencedirect.com/science/article/pii/S147840922500086X},
author = {Vincent Delke and Frederik G.S. Vos and Holger Schiele},
abstract = {To better prepare higher education graduates for the early stages of their careers, universities aim to bridge the gap between classroom teaching and the skills demanded by industry, particularly in the field of procurement. Today, procurement professionals increasingly require specialised skill sets, rather than generalist education, to effectively fulfil their role-specific responsibilities. This study integrates experiential learning theory with game-based learning by presenting a synthesised model that unites both perspectives. Building on this model, a purchasing-specific game is employed to compare traditional lecture-based teaching with experiential game-based learning, focusing on purchasing skills as well as cognitive and affective learning outcomes. The effectiveness of the game-based approach is examined through a group comparison experiment, contrasting students who played the game (N = 202) with those who attended conventional lectures (N = 135). The findings indicate that the game effectively develops purchasing and supply management (PSM) skills relevant to professional practice. Moreover, students evaluated the game as a highly positive learning experience, and it outperformed traditional lecturing in most skill-related, cognitive, and affective outcomes, ultimately leading to improved examination performance. For educators, the study highlights the design and implementation of the serious game, its pedagogical implications, and directions for future research in procurement education and beyond.}
}
@article{MENG2026112630,
title = {GLA-SDP: A novel attention-based semantic and static feature fusion method using GCN and LSTM for software defect prediction},
journal = {Journal of Systems and Software},
volume = {231},
pages = {112630},
year = {2026},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2025.112630},
url = {https://www.sciencedirect.com/science/article/pii/S0164121225002997},
author = {Haining Meng and Han Wu and Xiaoqing Li and Xinhong Hei},
keywords = {Feature fusion, Abstract syntax tree, Graph convolutional network, Additive attention mechanism, Software defect prediction},
abstract = {Software defect prediction (SDP) is crucial for improving software quality and optimizing resource allocation by identifying potential defects at early development stages. Traditional SDP methods rely on manually crafted static features, which often fail to capture the semantic and contextual information in code. Recent advances using abstract syntax trees (ASTs) have improved semantic feature extraction, yet they often neglect structural dependencies and lack effective integration with static features. To address these limitations, this study proposes GLA-SDP, a novel defect prediction model that fuses features through the integration of Graph Convolutional Networks (GCNs), Long Short-Term Memory (LSTM) networks, and an additive attention fusion mechanism. Specifically, a recursive AST-to-graph construction method is designed to extract rich semantic features using GCNs, while LSTMs are employed to capture sequential patterns from static code metrics. Furthermore, an attention-based fusion mechanism dynamically weight and combine semantic and static features, preserving their complementary importance in defect prediction. Extensive experiments on eight Java projects from the PROMISE dataset and four C-language projects from the Devign dataset demonstrate that GLA-SDP consistently outperforms state-of-the-art baselines, achieving average improvements of 37 % in F1-score and 24 % in MCC. These results highlight the superior accuracy and practical applicability of the proposed approach.}
}
@article{LIU2024116974,
title = {Hydraulic model of partial dam break based on sluice gate flow},
journal = {Ocean Engineering},
volume = {295},
pages = {116974},
year = {2024},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2024.116974},
url = {https://www.sciencedirect.com/science/article/pii/S0029801824003111},
author = {Yanshun Liu and Xiao Zhang and Hao Yu and Yuxue Sun and Chuanyu Sun and Zihan Li and Xianghui Li},
keywords = {Partial dam break, Sluice gate flow, Hydraulic model, Stepwise algorithm, Experimental validation},
abstract = {Accurately predicting the flow of water during a dam break is crucial for managing and responding to potential flood disasters. Although the characteristics of a dam break wave after a complete dam break have been investigated extensively, studies on partial dam break processes have been rare. To this end, this paper proposed a hydraulic model for partial dam breaks based on the water flow through a sluice gate. Five different hydraulic models using 459 datasets of sluice gate flows from both experimental tests and the literature were evaluated. A stepwise algorithm was developed by combining the sluice gate flow model with the law of mass conservation; this algorithm was used to develop a predictive model for the flow and level of water during partial dam breaks. Based on the water-level data obtained from partial dam break simulations, the hydraulic model was improved by introducing time and submergence correction coefficients. Compared with the experimental results, the mean absolute percentage error of the corrected model was 1.572 %, indicating a high prediction accuracy. Consequently, the proposed model can provide important technical support for managing partial dam break.}
}
@article{KIM2024105615,
title = {Image generation of hazardous situations in construction sites using text-to-image generative model for training deep neural networks},
journal = {Automation in Construction},
volume = {166},
pages = {105615},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105615},
url = {https://www.sciencedirect.com/science/article/pii/S0926580524003510},
author = {Hayoung Kim and June-Seong Yi},
keywords = {Construction safety, Construction site monitoring, Text-to-image synthesis, Computer vision, Training data},
abstract = {There has been a persistent challenge in acquiring sufficient training image data for deep neural networks (DNNs) to enhance safety monitoring on construction sites. Given the prevalence of textual data in the construction sector and the capabilities of multi-modal AI systems, this paper presents the use of text-to-image models to generate training images that capture the relationships between objects involved in construction accidents. Through a systematic prompt design process, a synthetic dataset of 3585 images across 27 hazardous scenarios was generated. The efficacy of this method is demonstrated by the performance of DNN models trained on these virtual images, which achieved a mean Average Precision (mAP) of approximately 64% in object detection and 60% in segmentation tasks. This paper demonstrates the potential of text-to-image models in mitigating the scarcity of training data and enhancing the capability of DNNs to identify potential hazards.}
}
@article{HONIG202455,
title = {GenAI in the classroom: Customized GPT roleplay for process safety education},
journal = {Education for Chemical Engineers},
volume = {49},
pages = {55-66},
year = {2024},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2024.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S1749772824000216},
author = {Christopher DF Honig and Aditya Desu and John Franklin},
keywords = {Generative AI, ChatGPT, Safety, Viva, Engineering education, Chemical engineering, Process safety, Case study, Consultant, Technology acceptance},
abstract = {This paper outlines innovative pedagogical approaches in chemical engineering safety education, utilising three key strategies: (1) Integration of the direct experiences of experienced professional engineers to teach expertise-aligned process safety case studies; (2) Shifting from traditional short oral presentations to more comprehensive and dynamic ‘engineering meeting’ formats to drive constructive student learning; and (3) The use of Generative AI to enhance (1) and (2), with cost/time scalability, improved student access and by accommodating greater learning-style diversity. Evaluation of these educational innovations is performed through a mixed-methods approach and reveals positive impacts on student learning and engagement. The paper provides a detailed outline of classroom implementation, with supporting resources, for straightforward integration by other academics.}
}
@article{BELLO2025100031,
title = {Cloud computing for chatbot in the construction industry: An implementation framework for conversational-BIM voice assistant},
journal = {Digital Engineering},
volume = {5},
pages = {100031},
year = {2025},
issn = {2950-550X},
doi = {https://doi.org/10.1016/j.dte.2024.100031},
url = {https://www.sciencedirect.com/science/article/pii/S2950550X24000311},
author = {Sururah A. Bello and Lukumon O. Oyedele and Lukman A. Akanbi and Abdul-Lateef Bello},
keywords = {Software project management, Amazon web services, Cloud computing, Building information modelling (BIM), Conversational AI, Construction industry, Framework implementation, Chatbot, construction workers, Design thinking methodology, Focus group, Stakeholders management},
abstract = {This study presents a structural framework for selecting cloud services for the Conversational AI system implementation in the construction industry using Design Thinking Methodology. A focus group discussion approach was used to obtain user requirements from construction workers to implement the Conversational AI for BIM. This resulted in five factors: finance, speed of operation, privacy, estimation, and interface. The user specifications were mapped into technical modules, which were used to select cloud services employed to implement the virtual assistant for the construction industry. The study thus presented the comprehensive requirements for the different categories of construction workers to implement the Conversational-BIM Chatbot (Conversational-BIM) system. Furthermore, the study presented the architecture of Conversational-BIM using Amazon Web Services. The study is useful to researchers and IT developers in implementing chatbots for the construction industry as it presents the relevant considerations for conversational AI applications in the industry.}
}
@article{LI2025113592,
title = {Enhanced photoacoustic tomography via accelerated mean-reverting generative diffusion model},
journal = {Optics & Laser Technology},
volume = {192},
pages = {113592},
year = {2025},
issn = {0030-3992},
doi = {https://doi.org/10.1016/j.optlastec.2025.113592},
url = {https://www.sciencedirect.com/science/article/pii/S0030399225011831},
author = {Jiahong Li and Jiawen Hu and Wei Li and Guolin Liu and Shuhao Ma and Haipeng Wei and Shangkun Hou and Zilong Li and Jiabin Lin and Zhixin Zhao and Qiegen Liu and Xianlin Song},
abstract = {Photoacoustic tomography (PAT), as a novel non-invasive hybrid biomedical imaging technology, combines the advantages of high contrast from optical imaging and deep penetration from acoustic imaging, and its applications in biomedical imaging are becoming increasingly widespread. However, the conventional standard reconstruction methods under sparse view may lead to low-quality image in photoacoustic tomography. To address this issue, this paper proposes a sparse sinogram (projection domain) data reconstruction method based on mean-reverting diffusion model. By simulating the forward and reverse of the Stochastic Differential Equation (SDE) processes from high-quality images (full-view projection data) to degraded low-quality images (sparse-view projection data), this method enables the restoration of sparse-view projection data to full-view projection data without relying on any task-specific prior knowledge. Blood vessels simulation data, circular phantom data, the animal in vivo experimental data, and data acquired from an actual PAT system were used to evaluate the performance of the proposed method. In the experimental tests on the “T”-shaped sample data acquired from the actual imaging system, even under extremely sparse projections (16 projections), the proposed method demonstrated significant improvements in peak signal-to-noise ratio compared to Cycle-GAN and U-Net, with increases of 16.46 dB (∼69.2 %) and 0.86 dB in the projection domain, respectively. This method enhances the sparse reconstruction capability of PAT in the sinogram domain, which is expected to reduce the costs and shorten the acquisition time of PAT in the practical applications, thus further expanding the application scope of PAT.}
}
@article{KHAN2025109593,
title = {Generalized fractional optimization-based explainable lightweight CNN model for malaria disease classification},
journal = {Computers in Biology and Medicine},
volume = {185},
pages = {109593},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.109593},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524016780},
author = {Zeshan Aslam Khan and Muhammad Waqar and Muhammad Junaid Ali Asif Raja and Naveed Ishtiaq Chaudhary and Abeer Tahir Mehmood Anwar Khan and Muhammad Asif Zahoor Raja},
keywords = {Convolutional neural networks, Generalized fractional optimizer, Malaria disease classification, Explainable AI, Lightweight model, Convergence speed},
abstract = {Over the past few decades, machine learning and deep learning (DL) have incredibly influenced a broader range of scientific disciplines. DL-based strategies have displayed superior performance in image processing compared to conventional standard methods, especially in healthcare settings. Among the biggest threats to global public health is the fast spread of malaria. The plasmodium falciparum infection, the disease origin causes the intestinal illness. Fortunately, advances in artificial intelligence techniques have made it possible to use visual data sets to quickly and effectively diagnose malaria which has also proven to be cost and time effective. In literature, several DL approaches have previously been used with good precision but suffer from computational inefficiency and interpretability. Therefore, this research proposes a generalized fractional order-based explainable lightweight convolutional neural network model to overcome these limitations. The fractional order optimization algorithms have proven worth in terms of estimation accuracy and convergence speed for different applications. The proposed fractional order optimizer-based model offers an improved solution to malaria disease diagnosis with a percentage accuracy of 95 % using the standard NIH dataset and outperforms the existing complex models concerning speed and effectiveness. The proposed fractionally optimized lightweight CNN model has shown substantial performance on the external MP-IDB dataset and M5 test set as well by achieving a generalized test accuracy of 92 % and 90.4 % which verifies the robustness and generalizability of the proposed solution under available circumstances. Moreover, the efficacy of the proposed lightweight architecture is endorsed through evaluation metrics of precision, recall, and F1-score.}
}
@article{MEHTA2024100186,
title = {Potential Mechanisms of Precision Nutrition-Based Interventions for Managing Obesity},
journal = {Advances in Nutrition},
volume = {15},
number = {3},
pages = {100186},
year = {2024},
issn = {2161-8313},
doi = {https://doi.org/10.1016/j.advnut.2024.100186},
url = {https://www.sciencedirect.com/science/article/pii/S2161831324000206},
author = {Neel H Mehta and Samantha L Huey and Rebecca Kuriyan and Juan Pablo Peña-Rosas and Julia L Finkelstein and Sangeeta Kashyap and Saurabh Mehta},
keywords = {personalized nutrition, overweight, adiposity, prevention, interventions, randomized trials},
abstract = {Precision nutrition (PN) considers multiple individual-level and environmental characteristics or variables to better inform dietary strategies and interventions for optimizing health, including managing obesity and metabolic disorders. Here, we review the evidence on potential mechanisms—including ones to identify individuals most likely to respond—that can be leveraged in the development of PN interventions addressing obesity. We conducted a review of the literature and included laboratory, animal, and human studies evaluating biochemical and genetic data, completed and ongoing clinical trials, and public programs in this review. Our analysis describes the potential mechanisms related to 6 domains including genetic predisposition, circadian rhythms, physical activity and sedentary behavior, metabolomics, the gut microbiome, and behavioral and socioeconomic characteristics, i.e., the factors that can be leveraged to design PN-based interventions to prevent and treat obesity-related outcomes such as weight loss or metabolic health as laid out by the NIH 2030 Strategic Plan for Nutrition Research. For example, single nucleotide polymorphisms can modify responses to certain dietary interventions, and epigenetic modulation of obesity risk via physical activity patterns and macronutrient intake have also been demonstrated. Additionally, we identified limitations including questions of equitable implementation across a limited number of clinical trials. These include the limited ability of current PN interventions to address systemic influences such as supply chains and food distribution, healthcare systems, racial or cultural inequities, and economic disparities, particularly when designing and implementing PN interventions in low- and middle-income communities. PN has the potential to help manage obesity by addressing intra- and inter-individual variation as well as context, as opposed to “one-size fits all” approaches though there is limited clinical trial evidence to date.}
}
@article{ZHANG2025112484,
title = {Are you worth the wait? Waiting time modulates the social feedback processing: Evidence from event-related potentials},
journal = {International Journal of Psychophysiology},
volume = {208},
pages = {112484},
year = {2025},
issn = {0167-8760},
doi = {https://doi.org/10.1016/j.ijpsycho.2024.112484},
url = {https://www.sciencedirect.com/science/article/pii/S0167876024001880},
author = {Xukai Zhang and Jutta Peterburs and Susannah C.S.A. Otieno and Paavo H.T. Leppänen and Qiang Xu and Yi Lei and Hong Li},
keywords = {EEG, Reward positivity, Waiting time, Social evaluation, Subjective preferences},
abstract = {Processing social feedback is essential for establishing appropriate social connections. However, social feedback is not always immediate, and the impact of waiting time on social feedback processing remains unexplored. Using electroencephalography (EEG) and event-related potentials (ERPs), the present study investigated how waiting time affects the N170, reward positivity (RewP), and P3. Participants (N = 36) completed a social evaluation task, awaiting feedback from liked and disliked peers with short (800–1200 ms) or long (5000–6000 ms) waiting times. Participants were more motivated to receive feedback from liked peers, and they rated acceptance from liked peers as more pleasant than rejection. Notably, participants found longer waits more worthwhile when receiving acceptance from liked peers, but less worthwhile when awaiting feedback from disliked peers. EEG results revealed that the RewP was increased for long waiting times for feedback from liked peers, and, conversely, reduced for long waiting times for feedback from disliked peers. Additionally, N170 and P3 were found to be sensitive to waiting time, with larger amplitudes for long compared to short waits. Overall, this study demonstrates that waiting time differentially affects social feedback processing, as reflected by changes in the N170, RewP, and P3. Our findings suggest that increased waiting time does not necessarily reduce reward value; it can enhance it depending on subjective social preferences. The increased N170 and P3 amplitudes during longer waits may indicate heightened attentional and memory demands. This study advances our understanding of the neurocognitive mechanisms underlying social decision-making.}
}
@article{BRIAZU2024107600,
title = {The effectiveness of personalised food choice advice tailored to an individual's socio-demographic, cognitive characteristics, and sensory preferences},
journal = {Appetite},
volume = {201},
pages = {107600},
year = {2024},
issn = {0195-6663},
doi = {https://doi.org/10.1016/j.appet.2024.107600},
url = {https://www.sciencedirect.com/science/article/pii/S0195666324004033},
author = {R.A. Briazu and L. Bell and G.F. Dodd and S. Blackburn and C. Massri and B. Chang and S. Fischaber and A. Kehlbacher and C.M. Williams and L. Methven and R. McCloy},
keywords = {Personalised food choice advice, Behaviour change support, eHealth design, Cluster modelling, Synthetic dataset},
abstract = {Personalised dietary advice has become increasingly popular, currently however most approaches are based on an individual's genetic and phenotypic profile whilst largely ignoring other determinants such as socio economic and cognitive variables. This paper provides novel insights by testing the effectiveness of personalised healthy eating advice concurrently tailored to an individual's socio-demographic group, cognitive characteristics, and sensory preferences. We first used existing data to build a synthetic dataset based on information from 3654 households (Study 1a), and then developed a cluster model to identify individuals characterised by similar socio-demographic, cognitive, and sensory aspects (Study 1b). Finally, in Study 2 we used the characteristics of 8 clusters to build 8 separate personalised food choice advice and assess their ability to motivate the increased consumption of fruit and vegetables and decreased intakes of saturated fat and sugar. We presented 218 participants with either generic UK Government “EatWell” advice, advice that was tailored to their allocated cluster (matched personalised), or advice tailored to a different cluster (unmatched personalised). Results showed that, when compared to generic advice, participants that received matched personalised advice were significantly more likely to indicate they would change their diet. Participants were similarly motivated to increase vegetable consumption and decrease saturated fat intake when they received unmatched personalised advice, potentially highlighting the power of providing alternative food choices. Overall, this study demonstrated that the power of personalizing food choice advice, based on a combination of individual characteristics, can be more effective than current approaches in motivating dietary change. Our study also emphasizes the viability of addressing population health through automatically delivered web-based personalised advice.}
}
@article{HUANG2025107877,
title = {Can LLM-generated misinformation be detected: A study on Cyber Threat Intelligence},
journal = {Future Generation Computer Systems},
volume = {173},
pages = {107877},
year = {2025},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2025.107877},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X25001724},
author = {He Huang and Nan Sun and Massimiliano Tani and Yu Zhang and Jiaojiao Jiang and Sanjay Jha},
keywords = {Cyber security, Artificial intelligence, Human-centric},
abstract = {Given the increasing number and severity of cyber attacks, there has been a surge in cybersecurity information across various mediums such as posts, news articles, reports, and other resources. Cyber Threat Intelligence (CTI) involves processing data from these cybersecurity sources, enabling professionals and organizations to gain valuable insights. However, with the rapid dissemination of cybersecurity information, the inclusion of fake CTI can lead to severe consequences, including data poisoning attacks. To address this challenge, we have implemented a three-step strategy: generating synthetic CTI, evaluating the quality of the generated CTI, and detecting fake CTI. Unlike other subdomains, such as fake COVID news detection, there is currently no publicly available dataset specifically tailored for fake CTI detection research. To address this gap, we first establish a reliable groundtruth dataset by utilizing domain-specific cybersecurity data to fine-tune a Large Language Model (LLM) for synthetic CTI generation. We then employ crowdsourcing techniques and advanced synthetic data verification methods to evaluate the quality of the generated dataset, introducing a novel evaluation methodology that combines quantitative and qualitative approaches. Our comprehensive evaluation reveals that the generated CTI cannot be distinguished from genuine CTI by human annotators, regardless of their computer science background, demonstrating the effectiveness of our generation approach. We benchmark various misinformation detection techniques against our groundtruth dataset to establish baseline performance metrics for identifying fake CTI. By leveraging existing techniques and adapting them to the context of fake CTI detection, we provide a foundation for future research in this critical field. To facilitate further research, we make our code, dataset, and experimental results publicly available on GitHub.}
}
@article{DHUNNOO2024,
title = {Evaluation of Telemedicine Consultations Using Health Outcomes and User Attitudes and Experiences: Scoping Review},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/53266},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124003698},
author = {Pranavsingh Dhunnoo and Bridie Kemp and Karen McGuigan and Bertalan Meskó and Vicky O’Rourke and Michael McCann},
keywords = {telemedicine, internet-based consultation, chronic illnesses, cyberpsychology, digital health, scoping review},
abstract = {Background
Despite a recent rise in adoption, telemedicine consultations retention remains challenging, and aspects around the associated experiences and outcomes remain unclear. The need to further investigate these aspects was a motivating factor for conducting this scoping review.
Objective
With a focus on synchronous telemedicine consultations between patients with nonmalignant chronic illnesses and health care professionals (HCPs), this scoping review aimed to gain insights into (1) the available evidence on telemedicine consultations to improve health outcomes for patients, (2) the associated behaviors and attitudes of patients and HCPs, and (3) how supplemental technology can assist in remote consultations.
Methods
PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) guided the scoping review process. Inclusion criteria were (1) involving adults with nonmalignant, noncommunicable chronic conditions as the study population; (2) focusing on health outcomes and experiences of and attitudes toward synchronous telemedicine consultations between patients and HCPs; and (3) conducting empirical research. A search strategy was applied to PubMed (including MEDLINE), CINAHL Complete, APA PsycNet, Web of Science, IEEE, and ACM Digital. Screening of articles and data extraction from included articles were performed in parallel and independently by 2 researchers, who corroborated their findings and resolved any conflicts.
Results
Overall, 4167 unique articles were identified from the databases searched. Following multilayer filtration, 19 (0.46%) studies fulfilled the inclusion criteria for data extraction. They investigated 6 nonmalignant chronic conditions, namely chronic obstructive pulmonary disease, diabetes, chronic kidney disease, ulcerative colitis, hypertension, and congestive heart failure, and the telemedicine consultation modality varied in each case. Most observed positive health outcomes for patients with chronic conditions using telemedicine consultations. Patients generally favored the modality’s convenience, but concerns were highlighted around cost, practical logistics, and thoroughness of clinical examinations. The majority of HCPs were also in favor of the technology, but a minority experienced reduced job satisfaction. Supplemental technological assistance was identified in relation to technical considerations, improved remote workflow, and training in remote care use.
Conclusions
For patients with noncommunicable chronic conditions, telemedicine consultations are generally associated with positive health outcomes that are either directly or indirectly related to their ailment, but sustained improvements remain unclear. These modalities also indicate the potential to empower such patients to better manage their condition. HCPs and patients tend to be satisfied with remote care experience, and most are receptive to the modality as an option. Assistance from supplemental technologies mostly resides in addressing technical issues, and additional modules could be integrated to address challenges relevant to patients and HCPs. However, positive outcomes and attitudes toward the modality might not apply to all cases, indicating that telemedicine consultations are more appropriate as options rather than replacements of in-person visits.}
}
@article{KRAUTH2024108137,
title = {Advanced collision risk estimation in terminal manoeuvring areas using a disentangled variational autoencoder for uncertainty quantification},
journal = {Engineering Applications of Artificial Intelligence},
volume = {133},
pages = {108137},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108137},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624002951},
author = {Timothé Krauth and Jérôme Morio and Xavier Olive and Benoit Figuet},
keywords = {Air traffic management, Rare event probability estimation, Deep generative models, Variational autoencoder, Uncertainty quantification},
abstract = {Air Traffic Management aims at ensuring safety during aircraft operations, particularly within Terminal Manoeuvring Areas where traffic density is high. The challenge lies in balancing safety and efficiency by closely managing the likelihood of mid-air collisions regarding the airport movements. Traditional models like the Reich and Anderson-Hsu models have been influential, but they fall short in representing the complex reality of Terminal Manoeuvring Areas. Data-driven approaches are emerging, with Monte Carlo simulations offering a more flexible methodology for collision risk estimation. This paper introduces a framework for assessing Mid-Air Collision likelihood resulting from Terminal Manoeuvring Area procedures by combining the field of Deep Generative Modelling using a Variational Autoencoder with the domain of rare event statistics through Subset Simulation. By incorporating disentanglement into the Variational Autoencoders model, we create a latent space that aligns dimensions with distinctive trajectory traits. Then, Subset Simulation is employed to gauge Mid-Air Collision probability, utilizing latent representations as input. Finally, sensitivity analysis reveals pivotal factors influencing collision risk, correlated with trajectory attributes via disentanglement. The methodology is applied to traffic around Zurich Airport: it evaluates the risk arising from go-around and take-off procedures using Automatic Dependent Surveillance-Broadcast data.}
}
@article{CHINIVAR2025100147,
title = {OVALYTICS: Enhancing Offensive Video Detection with YouTube Transcriptions and Advanced Language Models},
journal = {Natural Language Processing Journal},
volume = {11},
pages = {100147},
year = {2025},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2025.100147},
url = {https://www.sciencedirect.com/science/article/pii/S2949719125000238},
author = {Sneha Chinivar and Roopa M.S. and Arunalatha J.S. and Venugopal K.R.},
keywords = {Classification head, Large language models, Offensive video detection, Text transcription, Whisper AI},
abstract = {The exponential growth of offensive content online underscores the need for robust content moderation. In response, this work presents OVALYTICS (Offensive Video Analysis Leveraging YouTube Transcriptions with Intelligent Classification System), a comprehensive framework that introduces novel integrations of advanced technologies for offensive video detection. Unlike existing approaches, OVALYTICS uniquely combines Whisper AI for accurate audio-to-text transcription with state-of-the-art large language models (LLMs) such as BERT, ALBERT, XLM-R, MPNet, and T5 for semantic analysis. The framework also features a newly curated dataset tailored for fine-grained evaluation, achieving significant improvements in accuracy and F1-scores over traditional methods and advancing the state of automated content moderation.}
}
@article{MILLAT2025,
title = {Inflammatory cytokines and specific factors influencing lung cancer progression},
journal = {Cancer Pathogenesis and Therapy},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2025.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S2949713225000370},
author = {Md. Shalahuddin Millat and Md. Mahmudul Hasan and Mohammad Sarowar Uddin and Md. Abdus Salam and Md. Abdul Aziz and Irin Akhter and Md. Saddam Hussain and Nor Mohammad and Farjana Afrin Tanjum and Md. Saqline Mostaq and Md. Ashiq Mahmud and Mohammad Nurul Amin and Mohammad Safiqul Islam},
keywords = {Lung cancer, Inflammation, Cytokines, Angiogenesis, Tumorigenesis},
abstract = {Lung cancer (LC) is one of the main causes of illness and death. Inflammation is a facilitator of cancer growth and progression, affecting processes such as angiogenesis, antiapoptotic pathways, and DNA adduct formation. Cytokines are small proteins that can accelerate or slow tumor growth by controlling associated signaling processes such as cell proliferation, development, metastasis, and apoptosis. This review reveals the role of tumor necrosis factor-alpha, interferon-gamma, transforming growth factor-beta (TGF-β), and interleukins in LC. Macrophages play a role in non-small cell lung cancer (NSCLC) pathogenesis and are associated with poor prognosis. A nested case–control study revealed that elevated concentrations of IL-6 and IL-8 were strongly associated with the risk of LC. Specifically, the odds ratio for IL-6 and IL-8 in former smokers (fourth quartile vs. first quartile) were 2.70 (95% confidence interval [CI]: 1.55–4.70) and 2.83 (95% CI: 1.18–6.75). Because C-reactive protein levels are elevated in patients with NSCLC with larger and higher-grade tumors, CRP has been identified as a systemic indicator of chronic inflammation. Insulin-like growth factors influence cellular signal transduction pathways and contribute to tumorigenesis. Soluble tumor necrosis factor receptors have been explored for their role in NSCLC prognosis, highlighting their association with chromogranin. Transient receptor potential cation channel, subfamily M, member 7 (TRPM7), urokinase plasminogen activator, matrix metalloproteinases, and monocyte chemoattractant protein-1 have been identified with a focus on their expression patterns and prognostic significance in LC tissues. Moreover, lung angiogenesis induces vascular endothelial growth factor, soluble intercellular adhesion molecule-1, myeloperoxidase, and tissue inhibitors of metalloproteinase expressions. In conclusion, this review thoroughly summarized the inflammatory cytokines and specific factors influencing LC, providing the basis for further research on potential treatment approaches.}
}
@article{MA2024103009,
title = {A comprehensive quantitative lifecycle cost and environmental impact analysis model for computing infrastructure},
journal = {MethodsX},
volume = {13},
pages = {103009},
year = {2024},
issn = {2215-0161},
doi = {https://doi.org/10.1016/j.mex.2024.103009},
url = {https://www.sciencedirect.com/science/article/pii/S2215016124004606},
author = {Kezhuo Ma and Yu Zhou},
keywords = {Computing infrastructure, Lifecycle cost analysis, Greenhouse gas emission, Emission factor method},
abstract = {This paper presents a comprehensive quantitative model for quantitative assessment of the lifecycle costs and environmental impacts of computing infrastructure, with a focus on internet data centers (IDCs) and high-performance computing (HPC) facilities. The key innovation lies in the integration of interdisciplinary cost evaluation and carbon emission methods for the establishment of this quantitative model. This framework, which outlines key cost components and carbon emission factors, enables the calculation of total costs, electricity expenses, and greenhouse gas emissions throughout the lifecycle of infrastructure. With IDCs as a case study, the research clarifies the intricate cost structure associated with equipment procurement, energy usage, land acquisition, and operational expenses. This paper provides an in-depth understanding of the cost structure and environmental impact of computing infrastructure in support of sustainable decision-making in its development.•Based on established cost estimation methods, such as Lifecycle Cost Analysis (LCCA) and the Analogous Estimating Method, this study examines costs across construction and operation phases.•The Emission Factor Method is used to quantify environmental impact, emphasizing the significance of regional energy mix and power usage effectiveness (PUE).}
}
@article{LIAN2024102442,
title = {Public attitudes and sentiments toward ChatGPT in China: A text mining analysis based on social media},
journal = {Technology in Society},
volume = {76},
pages = {102442},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2023.102442},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X23002476},
author = {Ying Lian and Huiting Tang and Mengting Xiang and Xuefan Dong},
keywords = {ChatGPT, Artificial intelligence, Social media, Public perception, Text mining, Online public opinion},
abstract = {ChatGPT, an innovative artificial intelligence language model, is attracted significant attention around the world, sparking both enthusiasm and controversy, but identifying its societal impact and addressing its potential concerns necessitate an understanding of the prevailing public's attitudes toward the tool. In this study, we leverage text mining techniques to analyze the sentiments and themes prevalent among Chinese social media discussions of ChatGPT. In total, 96,435 comment data and 55,186 repost data were used, and the results show that public discussions mainly focused on ChatGPT's technical support, AI-related effectiveness, impact on human work, and effects on education and technology. Concerns were related to disinformation risks, technological unemployment, and the human–computer relationship. In addition, we found that social media played a prominent role in information dissemination, while official media and government units demonstrated a limited influence. The insights obtained through this study can inform policymakers, industry stakeholders, and the public of the public's prevailing attitude toward AI technologies, and they can facilitate informed decision-making.}
}